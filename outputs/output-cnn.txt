
Parameters:
ALLOW_SOFT_PLACEMENT=True
BATCH_SIZE=50
CHECKPOINT_EVERY=100
DROPOUT_KEEP_PROB=0.5
EMBEDDING_DIM=300
EVALUATE_EVERY=100
FILTER_SIZES=3,4,5
L2_REG_LAMBDA=0.15
LOG_DEVICE_PLACEMENT=False
NUM_EPOCHS=100
NUM_FILTERS=100
WORD2VEC=GoogleNews-vectors-negative300.bin

Loading data...
Vocabulary Size: 18758
Train/Dev split: 9662/1000
Writing to /home/cil/lstm-context-embeddings/runs/1473068725

Load word2vec file GoogleNews-vectors-negative300.bin

2016-09-05T17:45:43.215341: step 1, loss 0.693147, acc 0.44
2016-09-05T17:45:43.426082: step 2, loss 0.707313, acc 0.44
2016-09-05T17:45:43.628909: step 3, loss 0.694685, acc 0.46
2016-09-05T17:45:43.833869: step 4, loss 0.688641, acc 0.54
2016-09-05T17:45:44.078707: step 5, loss 0.655204, acc 0.64
2016-09-05T17:45:44.287170: step 6, loss 0.712719, acc 0.56
2016-09-05T17:45:44.509197: step 7, loss 0.778554, acc 0.46
2016-09-05T17:45:44.733418: step 8, loss 0.760218, acc 0.42
2016-09-05T17:45:44.931869: step 9, loss 0.673848, acc 0.6
2016-09-05T17:45:45.121292: step 10, loss 0.697161, acc 0.48
2016-09-05T17:45:45.317374: step 11, loss 0.680901, acc 0.62
2016-09-05T17:45:45.519893: step 12, loss 0.717887, acc 0.44
2016-09-05T17:45:45.724430: step 13, loss 0.688085, acc 0.56
2016-09-05T17:45:45.935734: step 14, loss 0.702327, acc 0.54
2016-09-05T17:45:46.138355: step 15, loss 0.690184, acc 0.54
2016-09-05T17:45:46.330852: step 16, loss 0.706493, acc 0.52
2016-09-05T17:45:46.536895: step 17, loss 0.705486, acc 0.5
2016-09-05T17:45:46.724767: step 18, loss 0.733655, acc 0.38
2016-09-05T17:45:46.932807: step 19, loss 0.69896, acc 0.52
2016-09-05T17:45:47.147913: step 20, loss 0.687715, acc 0.58
2016-09-05T17:45:47.392478: step 21, loss 0.674172, acc 0.58
2016-09-05T17:45:47.600382: step 22, loss 0.692709, acc 0.54
2016-09-05T17:45:47.805643: step 23, loss 0.715752, acc 0.52
2016-09-05T17:45:48.010847: step 24, loss 0.723381, acc 0.48
2016-09-05T17:45:48.239619: step 25, loss 0.71721, acc 0.5
2016-09-05T17:45:48.441005: step 26, loss 0.709846, acc 0.48
2016-09-05T17:45:48.635059: step 27, loss 0.703221, acc 0.48
2016-09-05T17:45:48.855787: step 28, loss 0.701331, acc 0.54
2016-09-05T17:45:49.103398: step 29, loss 0.693765, acc 0.54
2016-09-05T17:45:49.320487: step 30, loss 0.697111, acc 0.46
2016-09-05T17:45:49.513333: step 31, loss 0.684494, acc 0.56
2016-09-05T17:45:49.728436: step 32, loss 0.67367, acc 0.54
2016-09-05T17:45:49.942803: step 33, loss 0.688044, acc 0.5
2016-09-05T17:45:50.144259: step 34, loss 0.699166, acc 0.52
2016-09-05T17:45:50.357391: step 35, loss 0.714319, acc 0.48
2016-09-05T17:45:50.562898: step 36, loss 0.714058, acc 0.44
2016-09-05T17:45:50.763232: step 37, loss 0.722506, acc 0.4
2016-09-05T17:45:50.969591: step 38, loss 0.68777, acc 0.5
2016-09-05T17:45:51.176573: step 39, loss 0.676503, acc 0.66
2016-09-05T17:45:51.385764: step 40, loss 0.684799, acc 0.58
2016-09-05T17:45:51.610721: step 41, loss 0.650826, acc 0.68
2016-09-05T17:45:51.819659: step 42, loss 0.675615, acc 0.52
2016-09-05T17:45:52.011422: step 43, loss 0.695002, acc 0.56
2016-09-05T17:45:52.202192: step 44, loss 0.676122, acc 0.54
2016-09-05T17:45:52.397513: step 45, loss 0.695926, acc 0.52
2016-09-05T17:45:52.609981: step 46, loss 0.647919, acc 0.7
2016-09-05T17:45:52.843075: step 47, loss 0.67131, acc 0.66
2016-09-05T17:45:53.050317: step 48, loss 0.67414, acc 0.6
2016-09-05T17:45:53.283453: step 49, loss 0.698008, acc 0.54
2016-09-05T17:45:53.484398: step 50, loss 0.661487, acc 0.56
2016-09-05T17:45:53.678258: step 51, loss 0.632619, acc 0.66
2016-09-05T17:45:53.870150: step 52, loss 0.667138, acc 0.58
2016-09-05T17:45:54.084354: step 53, loss 0.683235, acc 0.5
2016-09-05T17:45:54.282271: step 54, loss 0.676569, acc 0.62
2016-09-05T17:45:54.478533: step 55, loss 0.663328, acc 0.58
2016-09-05T17:45:54.689132: step 56, loss 0.674122, acc 0.56
2016-09-05T17:45:54.901863: step 57, loss 0.630904, acc 0.7
2016-09-05T17:45:55.100978: step 58, loss 0.634891, acc 0.72
2016-09-05T17:45:55.304646: step 59, loss 0.610717, acc 0.8
2016-09-05T17:45:55.502756: step 60, loss 0.685773, acc 0.62
2016-09-05T17:45:55.743788: step 61, loss 0.673477, acc 0.56
2016-09-05T17:45:55.984350: step 62, loss 0.673935, acc 0.56
2016-09-05T17:45:56.189985: step 63, loss 0.649933, acc 0.64
2016-09-05T17:45:56.401205: step 64, loss 0.618548, acc 0.74
2016-09-05T17:45:56.603487: step 65, loss 0.616519, acc 0.7
2016-09-05T17:45:56.791543: step 66, loss 0.647219, acc 0.66
2016-09-05T17:45:57.001649: step 67, loss 0.660127, acc 0.62
2016-09-05T17:45:57.205442: step 68, loss 0.667876, acc 0.66
2016-09-05T17:45:57.402508: step 69, loss 0.63623, acc 0.7
2016-09-05T17:45:57.604856: step 70, loss 0.604623, acc 0.72
2016-09-05T17:45:57.805074: step 71, loss 0.672387, acc 0.58
2016-09-05T17:45:58.006168: step 72, loss 0.612188, acc 0.68
2016-09-05T17:45:58.207899: step 73, loss 0.651415, acc 0.6
2016-09-05T17:45:58.400497: step 74, loss 0.643803, acc 0.64
2016-09-05T17:45:58.606080: step 75, loss 0.617549, acc 0.7
2016-09-05T17:45:58.812713: step 76, loss 0.682066, acc 0.56
2016-09-05T17:45:59.008222: step 77, loss 0.594944, acc 0.7
2016-09-05T17:45:59.205639: step 78, loss 0.665235, acc 0.6
2016-09-05T17:45:59.396530: step 79, loss 0.615595, acc 0.66
2016-09-05T17:45:59.601903: step 80, loss 0.63435, acc 0.6
2016-09-05T17:45:59.805465: step 81, loss 0.667153, acc 0.58
2016-09-05T17:46:00.012609: step 82, loss 0.568005, acc 0.8
2016-09-05T17:46:00.209132: step 83, loss 0.6287, acc 0.68
2016-09-05T17:46:00.414827: step 84, loss 0.570724, acc 0.72
2016-09-05T17:46:00.621194: step 85, loss 0.614103, acc 0.64
2016-09-05T17:46:00.829078: step 86, loss 0.586066, acc 0.78
2016-09-05T17:46:01.039014: step 87, loss 0.604334, acc 0.72
2016-09-05T17:46:01.268356: step 88, loss 0.565577, acc 0.78
2016-09-05T17:46:01.471745: step 89, loss 0.635494, acc 0.66
2016-09-05T17:46:01.670147: step 90, loss 0.660596, acc 0.62
2016-09-05T17:46:01.885124: step 91, loss 0.595845, acc 0.72
2016-09-05T17:46:02.089240: step 92, loss 0.57377, acc 0.68
2016-09-05T17:46:02.294346: step 93, loss 0.606759, acc 0.6
2016-09-05T17:46:02.504596: step 94, loss 0.590805, acc 0.7
2016-09-05T17:46:02.715148: step 95, loss 0.619056, acc 0.74
2016-09-05T17:46:02.932162: step 96, loss 0.571811, acc 0.72
2016-09-05T17:46:03.146567: step 97, loss 0.611917, acc 0.7
2016-09-05T17:46:03.332988: step 98, loss 0.515366, acc 0.8
2016-09-05T17:46:03.535380: step 99, loss 0.520107, acc 0.74
2016-09-05T17:46:03.751103: step 100, loss 0.559472, acc 0.68

Evaluation:
2016-09-05T17:46:04.323851: step 100, loss 0.595161, acc 0.66

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-100

2016-09-05T17:46:05.086211: step 101, loss 0.590077, acc 0.66
2016-09-05T17:46:05.364621: step 102, loss 0.644954, acc 0.64
2016-09-05T17:46:05.553753: step 103, loss 0.511593, acc 0.76
2016-09-05T17:46:05.756528: step 104, loss 0.565061, acc 0.72
2016-09-05T17:46:05.954887: step 105, loss 0.526965, acc 0.78
2016-09-05T17:46:06.174823: step 106, loss 0.587747, acc 0.72
2016-09-05T17:46:06.373088: step 107, loss 0.612135, acc 0.6
2016-09-05T17:46:06.577340: step 108, loss 0.507811, acc 0.7
2016-09-05T17:46:06.780841: step 109, loss 0.514987, acc 0.78
2016-09-05T17:46:06.969912: step 110, loss 0.527694, acc 0.78
2016-09-05T17:46:07.163531: step 111, loss 0.598902, acc 0.66
2016-09-05T17:46:07.369000: step 112, loss 0.61466, acc 0.64
2016-09-05T17:46:07.561076: step 113, loss 0.59144, acc 0.72
2016-09-05T17:46:07.786676: step 114, loss 0.45861, acc 0.84
2016-09-05T17:46:07.979575: step 115, loss 0.534635, acc 0.72
2016-09-05T17:46:08.186676: step 116, loss 0.51431, acc 0.72
2016-09-05T17:46:08.394550: step 117, loss 0.520911, acc 0.8
2016-09-05T17:46:08.592287: step 118, loss 0.553037, acc 0.76
2016-09-05T17:46:08.784255: step 119, loss 0.554719, acc 0.7
2016-09-05T17:46:08.983342: step 120, loss 0.467569, acc 0.84
2016-09-05T17:46:09.190054: step 121, loss 0.52815, acc 0.78
2016-09-05T17:46:09.393974: step 122, loss 0.5241, acc 0.78
2016-09-05T17:46:09.589969: step 123, loss 0.580598, acc 0.74
2016-09-05T17:46:09.787782: step 124, loss 0.552187, acc 0.66
2016-09-05T17:46:10.007841: step 125, loss 0.544552, acc 0.74
2016-09-05T17:46:10.263825: step 126, loss 0.517563, acc 0.78
2016-09-05T17:46:10.474491: step 127, loss 0.569315, acc 0.72
2016-09-05T17:46:10.681307: step 128, loss 0.476542, acc 0.76
2016-09-05T17:46:10.901367: step 129, loss 0.485584, acc 0.8
2016-09-05T17:46:11.101106: step 130, loss 0.525982, acc 0.68
2016-09-05T17:46:11.304982: step 131, loss 0.559668, acc 0.8
2016-09-05T17:46:11.506038: step 132, loss 0.490709, acc 0.78
2016-09-05T17:46:11.697930: step 133, loss 0.499919, acc 0.78
2016-09-05T17:46:11.904273: step 134, loss 0.412938, acc 0.86
2016-09-05T17:46:12.118609: step 135, loss 0.527011, acc 0.7
2016-09-05T17:46:12.312208: step 136, loss 0.490593, acc 0.72
2016-09-05T17:46:12.522306: step 137, loss 0.52384, acc 0.72
2016-09-05T17:46:12.714391: step 138, loss 0.472698, acc 0.8
2016-09-05T17:46:12.913802: step 139, loss 0.533108, acc 0.72
2016-09-05T17:46:13.115166: step 140, loss 0.397159, acc 0.84
2016-09-05T17:46:13.310651: step 141, loss 0.547989, acc 0.74
2016-09-05T17:46:13.507077: step 142, loss 0.481182, acc 0.8
2016-09-05T17:46:13.719813: step 143, loss 0.650034, acc 0.62
2016-09-05T17:46:13.934257: step 144, loss 0.559065, acc 0.8
2016-09-05T17:46:14.138028: step 145, loss 0.541642, acc 0.76
2016-09-05T17:46:14.358031: step 146, loss 0.494668, acc 0.78
2016-09-05T17:46:14.573113: step 147, loss 0.561253, acc 0.68
2016-09-05T17:46:14.770877: step 148, loss 0.440033, acc 0.8
2016-09-05T17:46:14.989219: step 149, loss 0.624779, acc 0.66
2016-09-05T17:46:15.195122: step 150, loss 0.51849, acc 0.76
2016-09-05T17:46:15.399478: step 151, loss 0.510524, acc 0.8
2016-09-05T17:46:15.611268: step 152, loss 0.538987, acc 0.7
2016-09-05T17:46:15.830273: step 153, loss 0.589901, acc 0.74
2016-09-05T17:46:16.032985: step 154, loss 0.563509, acc 0.7
2016-09-05T17:46:16.235890: step 155, loss 0.490596, acc 0.74
2016-09-05T17:46:16.440269: step 156, loss 0.494583, acc 0.76
2016-09-05T17:46:16.634220: step 157, loss 0.556008, acc 0.68
2016-09-05T17:46:16.860604: step 158, loss 0.539876, acc 0.7
2016-09-05T17:46:17.097701: step 159, loss 0.477543, acc 0.8
2016-09-05T17:46:17.315914: step 160, loss 0.483021, acc 0.8
2016-09-05T17:46:17.540238: step 161, loss 0.579005, acc 0.66
2016-09-05T17:46:17.765853: step 162, loss 0.539142, acc 0.74
2016-09-05T17:46:18.008680: step 163, loss 0.422198, acc 0.78
2016-09-05T17:46:18.254011: step 164, loss 0.511818, acc 0.7
2016-09-05T17:46:18.454328: step 165, loss 0.437535, acc 0.82
2016-09-05T17:46:18.663663: step 166, loss 0.443755, acc 0.84
2016-09-05T17:46:18.866777: step 167, loss 0.502608, acc 0.72
2016-09-05T17:46:19.086177: step 168, loss 0.442466, acc 0.84
2016-09-05T17:46:19.285138: step 169, loss 0.562963, acc 0.74
2016-09-05T17:46:19.479320: step 170, loss 0.524191, acc 0.76
2016-09-05T17:46:19.681276: step 171, loss 0.499448, acc 0.74
2016-09-05T17:46:19.904650: step 172, loss 0.488313, acc 0.74
2016-09-05T17:46:20.101372: step 173, loss 0.54966, acc 0.72
2016-09-05T17:46:20.305379: step 174, loss 0.464888, acc 0.78
2016-09-05T17:46:20.506441: step 175, loss 0.446564, acc 0.82
2016-09-05T17:46:20.711926: step 176, loss 0.397436, acc 0.82
2016-09-05T17:46:20.924146: step 177, loss 0.422045, acc 0.82
2016-09-05T17:46:21.129063: step 178, loss 0.44387, acc 0.8
2016-09-05T17:46:21.363333: step 179, loss 0.462137, acc 0.78
2016-09-05T17:46:21.583175: step 180, loss 0.357604, acc 0.84
2016-09-05T17:46:21.785818: step 181, loss 0.535227, acc 0.72
2016-09-05T17:46:21.995897: step 182, loss 0.417002, acc 0.78
2016-09-05T17:46:22.221930: step 183, loss 0.500203, acc 0.76
2016-09-05T17:46:22.436183: step 184, loss 0.55991, acc 0.68
2016-09-05T17:46:22.675153: step 185, loss 0.512832, acc 0.82
2016-09-05T17:46:22.872173: step 186, loss 0.412574, acc 0.82
2016-09-05T17:46:23.068794: step 187, loss 0.468199, acc 0.78
2016-09-05T17:46:23.279582: step 188, loss 0.445392, acc 0.76
2016-09-05T17:46:23.476307: step 189, loss 0.465242, acc 0.74
2016-09-05T17:46:23.681390: step 190, loss 0.496585, acc 0.8
2016-09-05T17:46:23.889287: step 191, loss 0.487006, acc 0.84
2016-09-05T17:46:24.114007: step 192, loss 0.509106, acc 0.76
2016-09-05T17:46:24.327684: step 193, loss 0.388497, acc 0.86
2016-09-05T17:46:24.448798: step 194, loss 0.417813, acc 0.833333
2016-09-05T17:46:24.675484: step 195, loss 0.277481, acc 0.94
2016-09-05T17:46:24.866998: step 196, loss 0.374248, acc 0.82
2016-09-05T17:46:25.080525: step 197, loss 0.336997, acc 0.9
2016-09-05T17:46:25.286471: step 198, loss 0.360094, acc 0.9
2016-09-05T17:46:25.486660: step 199, loss 0.382696, acc 0.86
2016-09-05T17:46:25.700774: step 200, loss 0.366925, acc 0.86

Evaluation:
2016-09-05T17:46:26.254855: step 200, loss 0.485191, acc 0.769

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-200

2016-09-05T17:46:26.969879: step 201, loss 0.289559, acc 0.9
2016-09-05T17:46:27.171187: step 202, loss 0.40069, acc 0.8
2016-09-05T17:46:27.372644: step 203, loss 0.316364, acc 0.86
2016-09-05T17:46:27.594827: step 204, loss 0.393894, acc 0.88
2016-09-05T17:46:27.808924: step 205, loss 0.372195, acc 0.86
2016-09-05T17:46:28.012644: step 206, loss 0.30816, acc 0.92
2016-09-05T17:46:28.222659: step 207, loss 0.421161, acc 0.76
2016-09-05T17:46:28.425637: step 208, loss 0.417363, acc 0.8
2016-09-05T17:46:28.637863: step 209, loss 0.440403, acc 0.82
2016-09-05T17:46:28.858639: step 210, loss 0.405777, acc 0.82
2016-09-05T17:46:29.060997: step 211, loss 0.338038, acc 0.88
2016-09-05T17:46:29.268715: step 212, loss 0.372776, acc 0.78
2016-09-05T17:46:29.489852: step 213, loss 0.334782, acc 0.9
2016-09-05T17:46:29.705828: step 214, loss 0.41473, acc 0.82
2016-09-05T17:46:29.905984: step 215, loss 0.320807, acc 0.9
2016-09-05T17:46:30.107106: step 216, loss 0.407799, acc 0.86
2016-09-05T17:46:30.308070: step 217, loss 0.379801, acc 0.82
2016-09-05T17:46:30.529421: step 218, loss 0.404335, acc 0.84
2016-09-05T17:46:30.749964: step 219, loss 0.314315, acc 0.88
2016-09-05T17:46:30.942771: step 220, loss 0.300234, acc 0.9
2016-09-05T17:46:31.150992: step 221, loss 0.298445, acc 0.86
2016-09-05T17:46:31.354540: step 222, loss 0.319023, acc 0.86
2016-09-05T17:46:31.553817: step 223, loss 0.333145, acc 0.86
2016-09-05T17:46:31.767097: step 224, loss 0.298374, acc 0.9
2016-09-05T17:46:31.965351: step 225, loss 0.426594, acc 0.84
2016-09-05T17:46:32.168073: step 226, loss 0.350903, acc 0.82
2016-09-05T17:46:32.409897: step 227, loss 0.293908, acc 0.92
2016-09-05T17:46:32.620168: step 228, loss 0.312966, acc 0.86
2016-09-05T17:46:32.822173: step 229, loss 0.215205, acc 0.96
2016-09-05T17:46:33.030770: step 230, loss 0.283632, acc 0.9
2016-09-05T17:46:33.232107: step 231, loss 0.252731, acc 0.9
2016-09-05T17:46:33.442364: step 232, loss 0.316775, acc 0.9
2016-09-05T17:46:33.651170: step 233, loss 0.551049, acc 0.78
2016-09-05T17:46:33.851965: step 234, loss 0.291028, acc 0.9
2016-09-05T17:46:34.050401: step 235, loss 0.354206, acc 0.8
2016-09-05T17:46:34.261672: step 236, loss 0.334893, acc 0.92
2016-09-05T17:46:34.460681: step 237, loss 0.435601, acc 0.82
2016-09-05T17:46:34.657965: step 238, loss 0.394436, acc 0.82
2016-09-05T17:46:34.869954: step 239, loss 0.474463, acc 0.78
2016-09-05T17:46:35.061593: step 240, loss 0.376913, acc 0.86
2016-09-05T17:46:35.266094: step 241, loss 0.321332, acc 0.84
2016-09-05T17:46:35.464425: step 242, loss 0.34294, acc 0.84
2016-09-05T17:46:35.669794: step 243, loss 0.451441, acc 0.8
2016-09-05T17:46:35.867761: step 244, loss 0.366626, acc 0.88
2016-09-05T17:46:36.062205: step 245, loss 0.24733, acc 0.88
2016-09-05T17:46:36.257403: step 246, loss 0.35004, acc 0.86
2016-09-05T17:46:36.468800: step 247, loss 0.266324, acc 0.9
2016-09-05T17:46:36.675218: step 248, loss 0.259137, acc 0.92
2016-09-05T17:46:36.875256: step 249, loss 0.435159, acc 0.84
2016-09-05T17:46:37.083281: step 250, loss 0.278614, acc 0.88
2016-09-05T17:46:37.277539: step 251, loss 0.40794, acc 0.8
2016-09-05T17:46:37.488176: step 252, loss 0.266809, acc 0.9
2016-09-05T17:46:37.673674: step 253, loss 0.318183, acc 0.86
2016-09-05T17:46:37.876793: step 254, loss 0.461746, acc 0.8
2016-09-05T17:46:38.091786: step 255, loss 0.489391, acc 0.82
2016-09-05T17:46:38.305966: step 256, loss 0.344651, acc 0.84
2016-09-05T17:46:38.516744: step 257, loss 0.265959, acc 0.9
2016-09-05T17:46:38.727781: step 258, loss 0.393706, acc 0.82
2016-09-05T17:46:38.918249: step 259, loss 0.379387, acc 0.84
2016-09-05T17:46:39.129724: step 260, loss 0.304196, acc 0.88
2016-09-05T17:46:39.331109: step 261, loss 0.201627, acc 0.98
2016-09-05T17:46:39.530765: step 262, loss 0.339655, acc 0.88
2016-09-05T17:46:39.743714: step 263, loss 0.41118, acc 0.86
2016-09-05T17:46:39.944102: step 264, loss 0.376132, acc 0.8
2016-09-05T17:46:40.149987: step 265, loss 0.308532, acc 0.9
2016-09-05T17:46:40.366568: step 266, loss 0.358049, acc 0.82
2016-09-05T17:46:40.590436: step 267, loss 0.287501, acc 0.92
2016-09-05T17:46:40.793573: step 268, loss 0.404563, acc 0.82
2016-09-05T17:46:40.998391: step 269, loss 0.353109, acc 0.92
2016-09-05T17:46:41.200768: step 270, loss 0.256769, acc 0.92
2016-09-05T17:46:41.411412: step 271, loss 0.326162, acc 0.84
2016-09-05T17:46:41.604831: step 272, loss 0.332768, acc 0.84
2016-09-05T17:46:41.811054: step 273, loss 0.277358, acc 0.88
2016-09-05T17:46:42.017530: step 274, loss 0.342548, acc 0.88
2016-09-05T17:46:42.221436: step 275, loss 0.340833, acc 0.9
2016-09-05T17:46:42.440081: step 276, loss 0.415663, acc 0.82
2016-09-05T17:46:42.647741: step 277, loss 0.463461, acc 0.84
2016-09-05T17:46:42.867871: step 278, loss 0.325302, acc 0.9
2016-09-05T17:46:43.096734: step 279, loss 0.325399, acc 0.86
2016-09-05T17:46:43.296546: step 280, loss 0.359337, acc 0.84
2016-09-05T17:46:43.500600: step 281, loss 0.320249, acc 0.84
2016-09-05T17:46:43.702556: step 282, loss 0.347302, acc 0.86
2016-09-05T17:46:43.917560: step 283, loss 0.376628, acc 0.78
2016-09-05T17:46:44.099625: step 284, loss 0.410706, acc 0.82
2016-09-05T17:46:44.299898: step 285, loss 0.370078, acc 0.82
2016-09-05T17:46:44.511486: step 286, loss 0.380856, acc 0.86
2016-09-05T17:46:44.737011: step 287, loss 0.368924, acc 0.88
2016-09-05T17:46:44.938220: step 288, loss 0.337639, acc 0.84
2016-09-05T17:46:45.129565: step 289, loss 0.306407, acc 0.92
2016-09-05T17:46:45.320186: step 290, loss 0.320458, acc 0.86
2016-09-05T17:46:45.538467: step 291, loss 0.294104, acc 0.9
2016-09-05T17:46:45.725694: step 292, loss 0.209485, acc 0.94
2016-09-05T17:46:45.923770: step 293, loss 0.377419, acc 0.84
2016-09-05T17:46:46.134107: step 294, loss 0.321618, acc 0.88
2016-09-05T17:46:46.329119: step 295, loss 0.305966, acc 0.94
2016-09-05T17:46:46.531055: step 296, loss 0.297857, acc 0.88
2016-09-05T17:46:46.743197: step 297, loss 0.478055, acc 0.82
2016-09-05T17:46:46.943416: step 298, loss 0.275796, acc 0.86
2016-09-05T17:46:47.137455: step 299, loss 0.401715, acc 0.8
2016-09-05T17:46:47.352679: step 300, loss 0.227027, acc 0.94

Evaluation:
2016-09-05T17:46:47.930259: step 300, loss 0.470051, acc 0.786

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-300

2016-09-05T17:46:48.573394: step 301, loss 0.440549, acc 0.84
2016-09-05T17:46:48.781377: step 302, loss 0.313527, acc 0.9
2016-09-05T17:46:48.992569: step 303, loss 0.395092, acc 0.86
2016-09-05T17:46:49.205028: step 304, loss 0.370227, acc 0.88
2016-09-05T17:46:49.449001: step 305, loss 0.409824, acc 0.86
2016-09-05T17:46:49.656804: step 306, loss 0.274792, acc 0.82
2016-09-05T17:46:49.866338: step 307, loss 0.307562, acc 0.88
2016-09-05T17:46:50.131169: step 308, loss 0.406377, acc 0.84
2016-09-05T17:46:50.337492: step 309, loss 0.316235, acc 0.82
2016-09-05T17:46:50.554430: step 310, loss 0.291437, acc 0.88
2016-09-05T17:46:50.767019: step 311, loss 0.176103, acc 0.96
2016-09-05T17:46:50.988503: step 312, loss 0.333738, acc 0.88
2016-09-05T17:46:51.222445: step 313, loss 0.306589, acc 0.88
2016-09-05T17:46:51.446416: step 314, loss 0.461019, acc 0.8
2016-09-05T17:46:51.637756: step 315, loss 0.506094, acc 0.7
2016-09-05T17:46:51.860397: step 316, loss 0.41294, acc 0.82
2016-09-05T17:46:52.071689: step 317, loss 0.392601, acc 0.88
2016-09-05T17:46:52.275575: step 318, loss 0.213493, acc 0.92
2016-09-05T17:46:52.478488: step 319, loss 0.307326, acc 0.9
2016-09-05T17:46:52.679580: step 320, loss 0.400477, acc 0.78
2016-09-05T17:46:52.877029: step 321, loss 0.281689, acc 0.9
2016-09-05T17:46:53.084983: step 322, loss 0.324116, acc 0.86
2016-09-05T17:46:53.282080: step 323, loss 0.286392, acc 0.9
2016-09-05T17:46:53.483384: step 324, loss 0.328713, acc 0.86
2016-09-05T17:46:53.690258: step 325, loss 0.434468, acc 0.82
2016-09-05T17:46:53.899508: step 326, loss 0.460223, acc 0.76
2016-09-05T17:46:54.104894: step 327, loss 0.361857, acc 0.8
2016-09-05T17:46:54.294231: step 328, loss 0.340634, acc 0.92
2016-09-05T17:46:54.494622: step 329, loss 0.392409, acc 0.78
2016-09-05T17:46:54.689187: step 330, loss 0.35649, acc 0.84
2016-09-05T17:46:54.885848: step 331, loss 0.266108, acc 0.94
2016-09-05T17:46:55.086438: step 332, loss 0.349124, acc 0.9
2016-09-05T17:46:55.290077: step 333, loss 0.361548, acc 0.86
2016-09-05T17:46:55.499496: step 334, loss 0.307976, acc 0.9
2016-09-05T17:46:55.689272: step 335, loss 0.284527, acc 0.9
2016-09-05T17:46:55.885004: step 336, loss 0.37628, acc 0.86
2016-09-05T17:46:56.104195: step 337, loss 0.320492, acc 0.88
2016-09-05T17:46:56.299270: step 338, loss 0.361668, acc 0.82
2016-09-05T17:46:56.506181: step 339, loss 0.307711, acc 0.84
2016-09-05T17:46:56.703418: step 340, loss 0.321897, acc 0.84
2016-09-05T17:46:56.900599: step 341, loss 0.22906, acc 0.96
2016-09-05T17:46:57.092936: step 342, loss 0.230793, acc 0.94
2016-09-05T17:46:57.301680: step 343, loss 0.360027, acc 0.84
2016-09-05T17:46:57.541022: step 344, loss 0.378888, acc 0.8
2016-09-05T17:46:57.736474: step 345, loss 0.309464, acc 0.92
2016-09-05T17:46:57.924987: step 346, loss 0.450422, acc 0.8
2016-09-05T17:46:58.152193: step 347, loss 0.263753, acc 0.92
2016-09-05T17:46:58.347328: step 348, loss 0.273887, acc 0.92
2016-09-05T17:46:58.551526: step 349, loss 0.345446, acc 0.84
2016-09-05T17:46:58.755508: step 350, loss 0.329249, acc 0.84
2016-09-05T17:46:58.952215: step 351, loss 0.326861, acc 0.88
2016-09-05T17:46:59.152199: step 352, loss 0.372423, acc 0.82
2016-09-05T17:46:59.361278: step 353, loss 0.354981, acc 0.86
2016-09-05T17:46:59.584220: step 354, loss 0.338853, acc 0.88
2016-09-05T17:46:59.776082: step 355, loss 0.372289, acc 0.84
2016-09-05T17:46:59.975140: step 356, loss 0.307474, acc 0.86
2016-09-05T17:47:00.190332: step 357, loss 0.427173, acc 0.78
2016-09-05T17:47:00.404750: step 358, loss 0.36365, acc 0.86
2016-09-05T17:47:00.613618: step 359, loss 0.386367, acc 0.82
2016-09-05T17:47:00.825109: step 360, loss 0.350719, acc 0.86
2016-09-05T17:47:01.033359: step 361, loss 0.27662, acc 0.9
2016-09-05T17:47:01.228139: step 362, loss 0.479896, acc 0.78
2016-09-05T17:47:01.435620: step 363, loss 0.482664, acc 0.82
2016-09-05T17:47:01.636861: step 364, loss 0.313547, acc 0.94
2016-09-05T17:47:01.834335: step 365, loss 0.336907, acc 0.86
2016-09-05T17:47:02.036467: step 366, loss 0.299408, acc 0.9
2016-09-05T17:47:02.244726: step 367, loss 0.345314, acc 0.86
2016-09-05T17:47:02.450167: step 368, loss 0.347869, acc 0.84
2016-09-05T17:47:02.641529: step 369, loss 0.335874, acc 0.88
2016-09-05T17:47:02.853296: step 370, loss 0.405771, acc 0.82
2016-09-05T17:47:03.040065: step 371, loss 0.41358, acc 0.84
2016-09-05T17:47:03.230647: step 372, loss 0.37478, acc 0.78
2016-09-05T17:47:03.429995: step 373, loss 0.293119, acc 0.88
2016-09-05T17:47:03.648155: step 374, loss 0.367238, acc 0.92
2016-09-05T17:47:03.851159: step 375, loss 0.34822, acc 0.88
2016-09-05T17:47:04.050551: step 376, loss 0.247729, acc 0.92
2016-09-05T17:47:04.251514: step 377, loss 0.423026, acc 0.78
2016-09-05T17:47:04.453456: step 378, loss 0.255559, acc 0.9
2016-09-05T17:47:04.657997: step 379, loss 0.334979, acc 0.86
2016-09-05T17:47:04.874440: step 380, loss 0.319719, acc 0.9
2016-09-05T17:47:05.088165: step 381, loss 0.44009, acc 0.82
2016-09-05T17:47:05.294544: step 382, loss 0.293212, acc 0.84
2016-09-05T17:47:05.506287: step 383, loss 0.308983, acc 0.9
2016-09-05T17:47:05.711146: step 384, loss 0.38015, acc 0.82
2016-09-05T17:47:05.912118: step 385, loss 0.29386, acc 0.92
2016-09-05T17:47:06.126185: step 386, loss 0.360682, acc 0.88
2016-09-05T17:47:06.319711: step 387, loss 0.36546, acc 0.82
2016-09-05T17:47:06.470014: step 388, loss 0.507434, acc 0.75
2016-09-05T17:47:06.676757: step 389, loss 0.249152, acc 0.9
2016-09-05T17:47:06.874948: step 390, loss 0.190389, acc 0.94
2016-09-05T17:47:07.070254: step 391, loss 0.249015, acc 0.98
2016-09-05T17:47:07.282410: step 392, loss 0.194584, acc 0.98
2016-09-05T17:47:07.488241: step 393, loss 0.189733, acc 0.96
2016-09-05T17:47:07.710686: step 394, loss 0.208411, acc 0.96
2016-09-05T17:47:07.954923: step 395, loss 0.168831, acc 0.98
2016-09-05T17:47:08.164552: step 396, loss 0.170328, acc 0.96
2016-09-05T17:47:08.366424: step 397, loss 0.240405, acc 0.9
2016-09-05T17:47:08.554400: step 398, loss 0.202791, acc 0.98
2016-09-05T17:47:08.751669: step 399, loss 0.195489, acc 0.96
2016-09-05T17:47:08.951660: step 400, loss 0.151669, acc 0.98

Evaluation:
2016-09-05T17:47:09.512234: step 400, loss 0.474439, acc 0.79

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-400

2016-09-05T17:47:10.220354: step 401, loss 0.196096, acc 0.92
2016-09-05T17:47:10.424564: step 402, loss 0.196872, acc 0.96
2016-09-05T17:47:10.628772: step 403, loss 0.210912, acc 0.94
2016-09-05T17:47:10.868990: step 404, loss 0.161585, acc 0.98
2016-09-05T17:47:11.083001: step 405, loss 0.157381, acc 0.96
2016-09-05T17:47:11.285715: step 406, loss 0.197017, acc 0.94
2016-09-05T17:47:11.496615: step 407, loss 0.126476, acc 0.96
2016-09-05T17:47:11.687192: step 408, loss 0.1995, acc 0.94
2016-09-05T17:47:11.883753: step 409, loss 0.258924, acc 0.94
2016-09-05T17:47:12.107059: step 410, loss 0.130043, acc 0.98
2016-09-05T17:47:12.295915: step 411, loss 0.138764, acc 1
2016-09-05T17:47:12.502842: step 412, loss 0.205128, acc 0.9
2016-09-05T17:47:12.713997: step 413, loss 0.15691, acc 0.98
2016-09-05T17:47:12.923985: step 414, loss 0.208628, acc 0.9
2016-09-05T17:47:13.109035: step 415, loss 0.236322, acc 0.94
2016-09-05T17:47:13.321890: step 416, loss 0.132301, acc 0.98
2016-09-05T17:47:13.527116: step 417, loss 0.227167, acc 0.98
2016-09-05T17:47:13.725012: step 418, loss 0.184338, acc 0.98
2016-09-05T17:47:13.938684: step 419, loss 0.110116, acc 0.98
2016-09-05T17:47:14.135229: step 420, loss 0.24632, acc 0.88
2016-09-05T17:47:14.333299: step 421, loss 0.317725, acc 0.88
2016-09-05T17:47:14.549136: step 422, loss 0.175842, acc 0.98
2016-09-05T17:47:14.787657: step 423, loss 0.215567, acc 0.92
2016-09-05T17:47:14.990600: step 424, loss 0.226605, acc 0.94
2016-09-05T17:47:15.184099: step 425, loss 0.147409, acc 0.96
2016-09-05T17:47:15.392412: step 426, loss 0.168636, acc 0.94
2016-09-05T17:47:15.647878: step 427, loss 0.224723, acc 0.92
2016-09-05T17:47:15.889933: step 428, loss 0.260799, acc 0.88
2016-09-05T17:47:16.100005: step 429, loss 0.09589, acc 1
2016-09-05T17:47:16.328658: step 430, loss 0.132538, acc 0.98
2016-09-05T17:47:16.536874: step 431, loss 0.164195, acc 1
2016-09-05T17:47:16.747858: step 432, loss 0.292322, acc 0.9
2016-09-05T17:47:16.948637: step 433, loss 0.190522, acc 0.96
2016-09-05T17:47:17.148411: step 434, loss 0.27509, acc 0.86
2016-09-05T17:47:17.332286: step 435, loss 0.16689, acc 0.94
2016-09-05T17:47:17.544360: step 436, loss 0.247459, acc 0.92
2016-09-05T17:47:17.739435: step 437, loss 0.210563, acc 0.94
2016-09-05T17:47:17.958198: step 438, loss 0.192125, acc 0.94
2016-09-05T17:47:18.170674: step 439, loss 0.100911, acc 0.98
2016-09-05T17:47:18.375782: step 440, loss 0.292957, acc 0.9
2016-09-05T17:47:18.617332: step 441, loss 0.169837, acc 0.96
2016-09-05T17:47:18.815792: step 442, loss 0.154514, acc 0.94
2016-09-05T17:47:19.030401: step 443, loss 0.113861, acc 0.98
2016-09-05T17:47:19.243726: step 444, loss 0.151482, acc 1
2016-09-05T17:47:19.471688: step 445, loss 0.173932, acc 0.92
2016-09-05T17:47:19.669529: step 446, loss 0.147864, acc 0.98
2016-09-05T17:47:19.875668: step 447, loss 0.198657, acc 0.9
2016-09-05T17:47:20.080225: step 448, loss 0.153922, acc 0.98
2016-09-05T17:47:20.296398: step 449, loss 0.121106, acc 1
2016-09-05T17:47:20.525517: step 450, loss 0.25175, acc 0.92
2016-09-05T17:47:20.729894: step 451, loss 0.152892, acc 0.96
2016-09-05T17:47:20.922654: step 452, loss 0.119088, acc 0.98
2016-09-05T17:47:21.129971: step 453, loss 0.143967, acc 0.98
2016-09-05T17:47:21.321833: step 454, loss 0.176773, acc 0.94
2016-09-05T17:47:21.530917: step 455, loss 0.161883, acc 0.96
2016-09-05T17:47:21.767800: step 456, loss 0.171607, acc 0.92
2016-09-05T17:47:21.982853: step 457, loss 0.207798, acc 0.96
2016-09-05T17:47:22.175071: step 458, loss 0.293274, acc 0.9
2016-09-05T17:47:22.380549: step 459, loss 0.218355, acc 0.94
2016-09-05T17:47:22.576311: step 460, loss 0.196513, acc 0.94
2016-09-05T17:47:22.767325: step 461, loss 0.234823, acc 0.94
2016-09-05T17:47:22.961519: step 462, loss 0.158283, acc 0.98
2016-09-05T17:47:23.157855: step 463, loss 0.159942, acc 0.96
2016-09-05T17:47:23.355611: step 464, loss 0.166841, acc 0.96
2016-09-05T17:47:23.550763: step 465, loss 0.204817, acc 0.94
2016-09-05T17:47:23.763513: step 466, loss 0.199054, acc 0.94
2016-09-05T17:47:23.968899: step 467, loss 0.173312, acc 0.94
2016-09-05T17:47:24.188950: step 468, loss 0.110126, acc 1
2016-09-05T17:47:24.391449: step 469, loss 0.206541, acc 0.92
2016-09-05T17:47:24.591046: step 470, loss 0.140584, acc 0.94
2016-09-05T17:47:24.802046: step 471, loss 0.143183, acc 0.98
2016-09-05T17:47:25.002863: step 472, loss 0.179698, acc 0.96
2016-09-05T17:47:25.207167: step 473, loss 0.188636, acc 0.96
2016-09-05T17:47:25.395435: step 474, loss 0.267745, acc 0.9
2016-09-05T17:47:25.588791: step 475, loss 0.139185, acc 0.94
2016-09-05T17:47:25.777103: step 476, loss 0.165241, acc 0.96
2016-09-05T17:47:25.987016: step 477, loss 0.242671, acc 0.92
2016-09-05T17:47:26.179804: step 478, loss 0.139919, acc 0.96
2016-09-05T17:47:26.396742: step 479, loss 0.260673, acc 0.9
2016-09-05T17:47:26.600528: step 480, loss 0.15419, acc 0.94
2016-09-05T17:47:26.792839: step 481, loss 0.1199, acc 1
2016-09-05T17:47:26.985217: step 482, loss 0.18415, acc 0.96
2016-09-05T17:47:27.201071: step 483, loss 0.1635, acc 0.94
2016-09-05T17:47:27.428475: step 484, loss 0.101055, acc 1
2016-09-05T17:47:27.641542: step 485, loss 0.202868, acc 0.96
2016-09-05T17:47:27.850688: step 486, loss 0.159346, acc 0.96
2016-09-05T17:47:28.083063: step 487, loss 0.187752, acc 0.94
2016-09-05T17:47:28.299912: step 488, loss 0.218676, acc 0.9
2016-09-05T17:47:28.518678: step 489, loss 0.229659, acc 0.94
2016-09-05T17:47:28.719006: step 490, loss 0.120863, acc 0.98
2016-09-05T17:47:28.919953: step 491, loss 0.159919, acc 0.94
2016-09-05T17:47:29.115916: step 492, loss 0.168415, acc 0.94
2016-09-05T17:47:29.323116: step 493, loss 0.171649, acc 0.92
2016-09-05T17:47:29.522049: step 494, loss 0.14304, acc 0.98
2016-09-05T17:47:29.719235: step 495, loss 0.167817, acc 0.96
2016-09-05T17:47:29.933434: step 496, loss 0.186468, acc 0.96
2016-09-05T17:47:30.122989: step 497, loss 0.185008, acc 0.94
2016-09-05T17:47:30.327255: step 498, loss 0.168869, acc 0.92
2016-09-05T17:47:30.526624: step 499, loss 0.19667, acc 0.94
2016-09-05T17:47:30.712652: step 500, loss 0.18978, acc 0.94

Evaluation:
2016-09-05T17:47:31.271044: step 500, loss 0.516405, acc 0.779

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-500

2016-09-05T17:47:32.046573: step 501, loss 0.218278, acc 0.9
2016-09-05T17:47:32.267356: step 502, loss 0.171044, acc 0.94
2016-09-05T17:47:32.523298: step 503, loss 0.179547, acc 0.94
2016-09-05T17:47:32.731272: step 504, loss 0.157617, acc 0.98
2016-09-05T17:47:32.933466: step 505, loss 0.147554, acc 0.98
2016-09-05T17:47:33.137354: step 506, loss 0.143419, acc 0.98
2016-09-05T17:47:33.327313: step 507, loss 0.175507, acc 0.96
2016-09-05T17:47:33.536418: step 508, loss 0.141385, acc 0.96
2016-09-05T17:47:33.747140: step 509, loss 0.268226, acc 0.9
2016-09-05T17:47:33.948689: step 510, loss 0.191271, acc 0.92
2016-09-05T17:47:34.147973: step 511, loss 0.110428, acc 1
2016-09-05T17:47:34.359246: step 512, loss 0.134644, acc 0.98
2016-09-05T17:47:34.564710: step 513, loss 0.221516, acc 0.9
2016-09-05T17:47:34.760080: step 514, loss 0.320971, acc 0.84
2016-09-05T17:47:34.955566: step 515, loss 0.232867, acc 0.96
2016-09-05T17:47:35.160788: step 516, loss 0.170575, acc 0.96
2016-09-05T17:47:35.350122: step 517, loss 0.181067, acc 0.94
2016-09-05T17:47:35.526890: step 518, loss 0.304642, acc 0.88
2016-09-05T17:47:35.741802: step 519, loss 0.215315, acc 0.9
2016-09-05T17:47:35.945594: step 520, loss 0.233356, acc 0.92
2016-09-05T17:47:36.138449: step 521, loss 0.255671, acc 0.92
2016-09-05T17:47:36.350351: step 522, loss 0.176215, acc 0.96
2016-09-05T17:47:36.539452: step 523, loss 0.164144, acc 0.96
2016-09-05T17:47:36.756922: step 524, loss 0.219104, acc 0.92
2016-09-05T17:47:36.958426: step 525, loss 0.180763, acc 0.92
2016-09-05T17:47:37.161135: step 526, loss 0.172651, acc 0.94
2016-09-05T17:47:37.365373: step 527, loss 0.151704, acc 0.98
2016-09-05T17:47:37.566799: step 528, loss 0.174359, acc 0.98
2016-09-05T17:47:37.771362: step 529, loss 0.215672, acc 0.94
2016-09-05T17:47:37.974369: step 530, loss 0.0959588, acc 1
2016-09-05T17:47:38.177138: step 531, loss 0.103719, acc 0.98
2016-09-05T17:47:38.377083: step 532, loss 0.136887, acc 0.98
2016-09-05T17:47:38.571181: step 533, loss 0.314798, acc 0.86
2016-09-05T17:47:38.766599: step 534, loss 0.286324, acc 0.9
2016-09-05T17:47:38.953220: step 535, loss 0.192678, acc 0.92
2016-09-05T17:47:39.154427: step 536, loss 0.163095, acc 0.96
2016-09-05T17:47:39.375557: step 537, loss 0.185419, acc 0.94
2016-09-05T17:47:39.574185: step 538, loss 0.173971, acc 0.94
2016-09-05T17:47:39.764702: step 539, loss 0.146438, acc 0.94
2016-09-05T17:47:39.990314: step 540, loss 0.289038, acc 0.92
2016-09-05T17:47:40.192463: step 541, loss 0.200356, acc 0.94
2016-09-05T17:47:40.413804: step 542, loss 0.244164, acc 0.94
2016-09-05T17:47:40.626631: step 543, loss 0.188848, acc 0.94
2016-09-05T17:47:40.823855: step 544, loss 0.204543, acc 0.98
2016-09-05T17:47:41.036833: step 545, loss 0.156292, acc 0.94
2016-09-05T17:47:41.236519: step 546, loss 0.164081, acc 0.98
2016-09-05T17:47:41.436077: step 547, loss 0.12807, acc 0.98
2016-09-05T17:47:41.640409: step 548, loss 0.18067, acc 0.96
2016-09-05T17:47:41.839030: step 549, loss 0.180026, acc 0.94
2016-09-05T17:47:42.036485: step 550, loss 0.135404, acc 0.98
2016-09-05T17:47:42.260676: step 551, loss 0.146728, acc 0.96
2016-09-05T17:47:42.470081: step 552, loss 0.203691, acc 0.94
2016-09-05T17:47:42.670487: step 553, loss 0.170363, acc 0.94
2016-09-05T17:47:42.896890: step 554, loss 0.127544, acc 0.98
2016-09-05T17:47:43.103377: step 555, loss 0.306845, acc 0.9
2016-09-05T17:47:43.316717: step 556, loss 0.277429, acc 0.9
2016-09-05T17:47:43.557774: step 557, loss 0.216194, acc 0.92
2016-09-05T17:47:43.744912: step 558, loss 0.131123, acc 0.98
2016-09-05T17:47:43.937440: step 559, loss 0.135324, acc 0.98
2016-09-05T17:47:44.143894: step 560, loss 0.195124, acc 0.94
2016-09-05T17:47:44.339685: step 561, loss 0.155809, acc 0.98
2016-09-05T17:47:44.544366: step 562, loss 0.144736, acc 0.94
2016-09-05T17:47:44.751337: step 563, loss 0.191812, acc 0.9
2016-09-05T17:47:44.963500: step 564, loss 0.361294, acc 0.88
2016-09-05T17:47:45.175471: step 565, loss 0.168606, acc 0.96
2016-09-05T17:47:45.392811: step 566, loss 0.307017, acc 0.92
2016-09-05T17:47:45.627168: step 567, loss 0.171825, acc 0.98
2016-09-05T17:47:45.859461: step 568, loss 0.171195, acc 0.96
2016-09-05T17:47:46.093408: step 569, loss 0.193011, acc 0.94
2016-09-05T17:47:46.301568: step 570, loss 0.245563, acc 0.92
2016-09-05T17:47:46.497226: step 571, loss 0.139955, acc 0.96
2016-09-05T17:47:46.691293: step 572, loss 0.219881, acc 0.94
2016-09-05T17:47:46.877976: step 573, loss 0.269792, acc 0.88
2016-09-05T17:47:47.084601: step 574, loss 0.146402, acc 0.98
2016-09-05T17:47:47.339142: step 575, loss 0.132866, acc 0.96
2016-09-05T17:47:47.546222: step 576, loss 0.23044, acc 0.88
2016-09-05T17:47:47.745944: step 577, loss 0.163801, acc 0.94
2016-09-05T17:47:47.932084: step 578, loss 0.330156, acc 0.9
2016-09-05T17:47:48.141902: step 579, loss 0.159095, acc 0.96
2016-09-05T17:47:48.346094: step 580, loss 0.156007, acc 0.98
2016-09-05T17:47:48.557552: step 581, loss 0.234044, acc 0.96
2016-09-05T17:47:48.680286: step 582, loss 0.106507, acc 1
2016-09-05T17:47:48.910335: step 583, loss 0.116091, acc 0.96
2016-09-05T17:47:49.115286: step 584, loss 0.100234, acc 1
2016-09-05T17:47:49.328167: step 585, loss 0.109224, acc 0.98
2016-09-05T17:47:49.524932: step 586, loss 0.108446, acc 0.98
2016-09-05T17:47:49.737771: step 587, loss 0.0742955, acc 1
2016-09-05T17:47:49.957383: step 588, loss 0.0830917, acc 0.98
2016-09-05T17:47:50.149619: step 589, loss 0.089745, acc 1
2016-09-05T17:47:50.340987: step 590, loss 0.0833704, acc 1
2016-09-05T17:47:50.560790: step 591, loss 0.110154, acc 1
2016-09-05T17:47:50.788200: step 592, loss 0.120236, acc 0.96
2016-09-05T17:47:50.987493: step 593, loss 0.0824941, acc 1
2016-09-05T17:47:51.187554: step 594, loss 0.0905875, acc 1
2016-09-05T17:47:51.420687: step 595, loss 0.153074, acc 0.98
2016-09-05T17:47:51.650497: step 596, loss 0.0918046, acc 1
2016-09-05T17:47:51.846371: step 597, loss 0.114779, acc 1
2016-09-05T17:47:52.028035: step 598, loss 0.100688, acc 0.98
2016-09-05T17:47:52.260243: step 599, loss 0.103947, acc 1
2016-09-05T17:47:52.460927: step 600, loss 0.0827088, acc 1

Evaluation:
2016-09-05T17:47:53.021279: step 600, loss 0.522332, acc 0.794

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-600

2016-09-05T17:47:53.750450: step 601, loss 0.0940628, acc 0.98
2016-09-05T17:47:53.970477: step 602, loss 0.0822761, acc 0.98
2016-09-05T17:47:54.165387: step 603, loss 0.0752823, acc 1
2016-09-05T17:47:54.360635: step 604, loss 0.11727, acc 0.96
2016-09-05T17:47:54.577257: step 605, loss 0.170287, acc 0.96
2016-09-05T17:47:54.798332: step 606, loss 0.083273, acc 1
2016-09-05T17:47:55.009067: step 607, loss 0.0812148, acc 1
2016-09-05T17:47:55.205257: step 608, loss 0.0818852, acc 1
2016-09-05T17:47:55.401445: step 609, loss 0.120504, acc 0.98
2016-09-05T17:47:55.593539: step 610, loss 0.0673786, acc 1
2016-09-05T17:47:55.791617: step 611, loss 0.110427, acc 0.98
2016-09-05T17:47:55.988064: step 612, loss 0.0730386, acc 1
2016-09-05T17:47:56.207465: step 613, loss 0.0935869, acc 0.98
2016-09-05T17:47:56.425648: step 614, loss 0.157323, acc 0.94
2016-09-05T17:47:56.629744: step 615, loss 0.111097, acc 0.98
2016-09-05T17:47:56.822383: step 616, loss 0.117166, acc 0.96
2016-09-05T17:47:57.022915: step 617, loss 0.0709395, acc 1
2016-09-05T17:47:57.230360: step 618, loss 0.147115, acc 0.96
2016-09-05T17:47:57.431898: step 619, loss 0.0873133, acc 1
2016-09-05T17:47:57.645509: step 620, loss 0.146265, acc 0.98
2016-09-05T17:47:57.857089: step 621, loss 0.111588, acc 0.96
2016-09-05T17:47:58.058552: step 622, loss 0.0718286, acc 1
2016-09-05T17:47:58.291397: step 623, loss 0.0794443, acc 1
2016-09-05T17:47:58.483786: step 624, loss 0.133673, acc 0.94
2016-09-05T17:47:58.705010: step 625, loss 0.0764627, acc 1
2016-09-05T17:47:58.896115: step 626, loss 0.131412, acc 0.96
2016-09-05T17:47:59.099820: step 627, loss 0.112545, acc 0.96
2016-09-05T17:47:59.288815: step 628, loss 0.0749044, acc 1
2016-09-05T17:47:59.499592: step 629, loss 0.130027, acc 0.98
2016-09-05T17:47:59.708277: step 630, loss 0.116025, acc 1
2016-09-05T17:47:59.922052: step 631, loss 0.133278, acc 0.98
2016-09-05T17:48:00.123794: step 632, loss 0.112775, acc 0.98
2016-09-05T17:48:00.344360: step 633, loss 0.0922934, acc 1
2016-09-05T17:48:00.546326: step 634, loss 0.120772, acc 0.98
2016-09-05T17:48:00.763441: step 635, loss 0.108073, acc 0.98
2016-09-05T17:48:00.970816: step 636, loss 0.178834, acc 0.92
2016-09-05T17:48:01.182319: step 637, loss 0.166346, acc 0.96
2016-09-05T17:48:01.396040: step 638, loss 0.0970162, acc 0.98
2016-09-05T17:48:01.604824: step 639, loss 0.0905821, acc 0.98
2016-09-05T17:48:01.795420: step 640, loss 0.0953107, acc 1
2016-09-05T17:48:02.005363: step 641, loss 0.131177, acc 0.98
2016-09-05T17:48:02.215053: step 642, loss 0.105463, acc 0.98
2016-09-05T17:48:02.421520: step 643, loss 0.101193, acc 0.98
2016-09-05T17:48:02.643666: step 644, loss 0.0992754, acc 1
2016-09-05T17:48:02.887986: step 645, loss 0.149886, acc 0.98
2016-09-05T17:48:03.096299: step 646, loss 0.124335, acc 0.98
2016-09-05T17:48:03.298956: step 647, loss 0.12581, acc 0.98
2016-09-05T17:48:03.519858: step 648, loss 0.14477, acc 0.98
2016-09-05T17:48:03.742951: step 649, loss 0.0747843, acc 1
2016-09-05T17:48:03.959951: step 650, loss 0.0925322, acc 1
2016-09-05T17:48:04.153466: step 651, loss 0.084901, acc 1
2016-09-05T17:48:04.361575: step 652, loss 0.0809548, acc 1
2016-09-05T17:48:04.605592: step 653, loss 0.0721072, acc 1
2016-09-05T17:48:04.817461: step 654, loss 0.0778481, acc 1
2016-09-05T17:48:05.027286: step 655, loss 0.134188, acc 0.98
2016-09-05T17:48:05.227990: step 656, loss 0.123725, acc 0.98
2016-09-05T17:48:05.442245: step 657, loss 0.114114, acc 0.98
2016-09-05T17:48:05.668052: step 658, loss 0.0796191, acc 1
2016-09-05T17:48:05.919959: step 659, loss 0.14466, acc 0.98
2016-09-05T17:48:06.116938: step 660, loss 0.0678428, acc 1
2016-09-05T17:48:06.331519: step 661, loss 0.109754, acc 0.98
2016-09-05T17:48:06.545808: step 662, loss 0.103913, acc 1
2016-09-05T17:48:06.764758: step 663, loss 0.110441, acc 0.98
2016-09-05T17:48:06.961490: step 664, loss 0.106837, acc 0.98
2016-09-05T17:48:07.172914: step 665, loss 0.108574, acc 1
2016-09-05T17:48:07.377279: step 666, loss 0.0976845, acc 1
2016-09-05T17:48:07.603882: step 667, loss 0.0821708, acc 1
2016-09-05T17:48:07.809713: step 668, loss 0.134522, acc 0.96
2016-09-05T17:48:08.045099: step 669, loss 0.150921, acc 0.94
2016-09-05T17:48:08.270751: step 670, loss 0.0780477, acc 1
2016-09-05T17:48:08.492414: step 671, loss 0.0778634, acc 1
2016-09-05T17:48:08.708117: step 672, loss 0.140315, acc 0.94
2016-09-05T17:48:08.910074: step 673, loss 0.128101, acc 0.96
2016-09-05T17:48:09.128001: step 674, loss 0.0943994, acc 0.98
2016-09-05T17:48:09.336418: step 675, loss 0.17309, acc 0.92
2016-09-05T17:48:09.533684: step 676, loss 0.0901461, acc 0.98
2016-09-05T17:48:09.760121: step 677, loss 0.0630705, acc 1
2016-09-05T17:48:09.953835: step 678, loss 0.104014, acc 0.98
2016-09-05T17:48:10.168430: step 679, loss 0.0858789, acc 1
2016-09-05T17:48:10.370235: step 680, loss 0.149794, acc 0.96
2016-09-05T17:48:10.577564: step 681, loss 0.0863242, acc 1
2016-09-05T17:48:10.786575: step 682, loss 0.0784613, acc 1
2016-09-05T17:48:10.989461: step 683, loss 0.142363, acc 0.98
2016-09-05T17:48:11.210368: step 684, loss 0.0909382, acc 1
2016-09-05T17:48:11.461340: step 685, loss 0.0876441, acc 0.98
2016-09-05T17:48:11.672651: step 686, loss 0.249328, acc 0.96
2016-09-05T17:48:11.858989: step 687, loss 0.138023, acc 0.96
2016-09-05T17:48:12.062651: step 688, loss 0.111568, acc 0.98
2016-09-05T17:48:12.268007: step 689, loss 0.116924, acc 0.96
2016-09-05T17:48:12.503309: step 690, loss 0.113188, acc 0.98
2016-09-05T17:48:12.719191: step 691, loss 0.107653, acc 0.98
2016-09-05T17:48:12.924895: step 692, loss 0.0789416, acc 1
2016-09-05T17:48:13.118417: step 693, loss 0.114974, acc 0.98
2016-09-05T17:48:13.310541: step 694, loss 0.11937, acc 0.96
2016-09-05T17:48:13.511669: step 695, loss 0.137643, acc 0.98
2016-09-05T17:48:13.712146: step 696, loss 0.10944, acc 0.98
2016-09-05T17:48:13.959628: step 697, loss 0.0755739, acc 1
2016-09-05T17:48:14.164598: step 698, loss 0.0941098, acc 0.98
2016-09-05T17:48:14.398250: step 699, loss 0.0886255, acc 0.98
2016-09-05T17:48:14.596505: step 700, loss 0.118215, acc 0.94

Evaluation:
2016-09-05T17:48:15.140570: step 700, loss 0.561656, acc 0.792

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-700

2016-09-05T17:48:15.831398: step 701, loss 0.139059, acc 0.98
2016-09-05T17:48:16.055981: step 702, loss 0.157087, acc 0.96
2016-09-05T17:48:16.309638: step 703, loss 0.104265, acc 0.98
2016-09-05T17:48:16.507558: step 704, loss 0.0979044, acc 0.96
2016-09-05T17:48:16.721073: step 705, loss 0.122591, acc 0.98
2016-09-05T17:48:16.930917: step 706, loss 0.102579, acc 0.98
2016-09-05T17:48:17.132549: step 707, loss 0.116386, acc 1
2016-09-05T17:48:17.343223: step 708, loss 0.107881, acc 0.96
2016-09-05T17:48:17.540082: step 709, loss 0.0884138, acc 0.98
2016-09-05T17:48:17.768950: step 710, loss 0.10999, acc 1
2016-09-05T17:48:17.977430: step 711, loss 0.0961795, acc 1
2016-09-05T17:48:18.185249: step 712, loss 0.139957, acc 0.96
2016-09-05T17:48:18.413503: step 713, loss 0.0794903, acc 1
2016-09-05T17:48:18.608202: step 714, loss 0.115279, acc 1
2016-09-05T17:48:18.815243: step 715, loss 0.118432, acc 0.98
2016-09-05T17:48:19.030605: step 716, loss 0.10228, acc 0.98
2016-09-05T17:48:19.235015: step 717, loss 0.116303, acc 1
2016-09-05T17:48:19.428840: step 718, loss 0.0646826, acc 1
2016-09-05T17:48:19.631438: step 719, loss 0.0773263, acc 1
2016-09-05T17:48:19.835288: step 720, loss 0.0878871, acc 1
2016-09-05T17:48:20.037257: step 721, loss 0.0695964, acc 1
2016-09-05T17:48:20.235054: step 722, loss 0.100074, acc 0.98
2016-09-05T17:48:20.437301: step 723, loss 0.150785, acc 0.96
2016-09-05T17:48:20.640503: step 724, loss 0.0799615, acc 1
2016-09-05T17:48:20.850380: step 725, loss 0.118876, acc 0.96
2016-09-05T17:48:21.048575: step 726, loss 0.0971988, acc 0.98
2016-09-05T17:48:21.249727: step 727, loss 0.0757551, acc 1
2016-09-05T17:48:21.458073: step 728, loss 0.0992095, acc 1
2016-09-05T17:48:21.657160: step 729, loss 0.103107, acc 0.98
2016-09-05T17:48:21.854480: step 730, loss 0.0818144, acc 1
2016-09-05T17:48:22.069395: step 731, loss 0.116029, acc 0.98
2016-09-05T17:48:22.281950: step 732, loss 0.0977589, acc 0.98
2016-09-05T17:48:22.487329: step 733, loss 0.0969979, acc 0.98
2016-09-05T17:48:22.713799: step 734, loss 0.0908591, acc 1
2016-09-05T17:48:22.952045: step 735, loss 0.139101, acc 0.94
2016-09-05T17:48:23.155432: step 736, loss 0.131311, acc 0.98
2016-09-05T17:48:23.385640: step 737, loss 0.150909, acc 0.98
2016-09-05T17:48:23.608410: step 738, loss 0.0916748, acc 0.98
2016-09-05T17:48:23.814049: step 739, loss 0.0974767, acc 1
2016-09-05T17:48:24.016914: step 740, loss 0.129397, acc 0.98
2016-09-05T17:48:24.218514: step 741, loss 0.121861, acc 0.98
2016-09-05T17:48:24.447748: step 742, loss 0.122756, acc 0.98
2016-09-05T17:48:24.646039: step 743, loss 0.110659, acc 0.98
2016-09-05T17:48:24.860186: step 744, loss 0.134368, acc 0.98
2016-09-05T17:48:25.068206: step 745, loss 0.140349, acc 0.98
2016-09-05T17:48:25.265422: step 746, loss 0.102942, acc 1
2016-09-05T17:48:25.467499: step 747, loss 0.105669, acc 0.98
2016-09-05T17:48:25.676385: step 748, loss 0.0802502, acc 0.98
2016-09-05T17:48:25.875221: step 749, loss 0.100857, acc 0.98
2016-09-05T17:48:26.070066: step 750, loss 0.111783, acc 0.98
2016-09-05T17:48:26.271214: step 751, loss 0.139238, acc 0.98
2016-09-05T17:48:26.461994: step 752, loss 0.0713669, acc 1
2016-09-05T17:48:26.680122: step 753, loss 0.101264, acc 1
2016-09-05T17:48:26.892953: step 754, loss 0.139128, acc 0.96
2016-09-05T17:48:27.134827: step 755, loss 0.0866282, acc 0.98
2016-09-05T17:48:27.335912: step 756, loss 0.124643, acc 0.98
2016-09-05T17:48:27.554511: step 757, loss 0.0963412, acc 0.98
2016-09-05T17:48:27.768956: step 758, loss 0.0738841, acc 1
2016-09-05T17:48:27.965596: step 759, loss 0.142872, acc 0.98
2016-09-05T17:48:28.169028: step 760, loss 0.107882, acc 0.98
2016-09-05T17:48:28.367695: step 761, loss 0.0751524, acc 1
2016-09-05T17:48:28.584233: step 762, loss 0.173063, acc 0.94
2016-09-05T17:48:28.791839: step 763, loss 0.0912647, acc 0.98
2016-09-05T17:48:29.006574: step 764, loss 0.0666318, acc 1
2016-09-05T17:48:29.221204: step 765, loss 0.0850256, acc 0.98
2016-09-05T17:48:29.430232: step 766, loss 0.0780523, acc 1
2016-09-05T17:48:29.651687: step 767, loss 0.134292, acc 0.96
2016-09-05T17:48:29.860351: step 768, loss 0.11166, acc 0.96
2016-09-05T17:48:30.057889: step 769, loss 0.182835, acc 0.94
2016-09-05T17:48:30.268455: step 770, loss 0.175024, acc 0.98
2016-09-05T17:48:30.476715: step 771, loss 0.106736, acc 0.98
2016-09-05T17:48:30.703518: step 772, loss 0.122611, acc 0.96
2016-09-05T17:48:30.892986: step 773, loss 0.15683, acc 0.96
2016-09-05T17:48:31.105056: step 774, loss 0.18449, acc 0.94
2016-09-05T17:48:31.316345: step 775, loss 0.10238, acc 0.96
2016-09-05T17:48:31.437038: step 776, loss 0.0978939, acc 1
2016-09-05T17:48:31.650939: step 777, loss 0.0743152, acc 1
2016-09-05T17:48:31.876099: step 778, loss 0.0590512, acc 1
2016-09-05T17:48:32.069925: step 779, loss 0.0717789, acc 1
2016-09-05T17:48:32.275436: step 780, loss 0.0959938, acc 0.98
2016-09-05T17:48:32.487491: step 781, loss 0.0596433, acc 1
2016-09-05T17:48:32.711097: step 782, loss 0.0589894, acc 1
2016-09-05T17:48:32.923329: step 783, loss 0.0699759, acc 1
2016-09-05T17:48:33.121037: step 784, loss 0.0618971, acc 1
2016-09-05T17:48:33.310391: step 785, loss 0.0778437, acc 1
2016-09-05T17:48:33.528008: step 786, loss 0.0600981, acc 1
2016-09-05T17:48:33.721740: step 787, loss 0.0618843, acc 1
2016-09-05T17:48:33.935744: step 788, loss 0.0592137, acc 1
2016-09-05T17:48:34.135974: step 789, loss 0.0531009, acc 1
2016-09-05T17:48:34.358193: step 790, loss 0.0778239, acc 1
2016-09-05T17:48:34.590014: step 791, loss 0.0955444, acc 0.98
2016-09-05T17:48:34.808487: step 792, loss 0.0644733, acc 1
2016-09-05T17:48:35.055645: step 793, loss 0.0632905, acc 1
2016-09-05T17:48:35.274140: step 794, loss 0.0574203, acc 1
2016-09-05T17:48:35.521137: step 795, loss 0.0682306, acc 1
2016-09-05T17:48:35.719400: step 796, loss 0.0667726, acc 1
2016-09-05T17:48:35.913915: step 797, loss 0.0697501, acc 1
2016-09-05T17:48:36.121295: step 798, loss 0.0614907, acc 1
2016-09-05T17:48:36.341931: step 799, loss 0.0951685, acc 0.98
2016-09-05T17:48:36.582460: step 800, loss 0.0567209, acc 1

Evaluation:
2016-09-05T17:48:37.162097: step 800, loss 0.593296, acc 0.785

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-800

2016-09-05T17:48:37.922634: step 801, loss 0.0853024, acc 1
2016-09-05T17:48:38.168528: step 802, loss 0.0583024, acc 1
2016-09-05T17:48:38.377613: step 803, loss 0.0662579, acc 1
2016-09-05T17:48:38.618624: step 804, loss 0.0593645, acc 1
2016-09-05T17:48:38.833154: step 805, loss 0.0628036, acc 1
2016-09-05T17:48:39.025842: step 806, loss 0.085659, acc 0.98
2016-09-05T17:48:39.246328: step 807, loss 0.0883672, acc 0.98
2016-09-05T17:48:39.449619: step 808, loss 0.0815661, acc 1
2016-09-05T17:48:39.677136: step 809, loss 0.0640615, acc 1
2016-09-05T17:48:39.869197: step 810, loss 0.0628743, acc 1
2016-09-05T17:48:40.079891: step 811, loss 0.0850588, acc 1
2016-09-05T17:48:40.274843: step 812, loss 0.0777966, acc 0.98
2016-09-05T17:48:40.472271: step 813, loss 0.0634771, acc 1
2016-09-05T17:48:40.684919: step 814, loss 0.107415, acc 0.98
2016-09-05T17:48:40.892216: step 815, loss 0.0603266, acc 1
2016-09-05T17:48:41.100334: step 816, loss 0.0640653, acc 1
2016-09-05T17:48:41.322558: step 817, loss 0.107637, acc 0.98
2016-09-05T17:48:41.547261: step 818, loss 0.0783023, acc 1
2016-09-05T17:48:41.779686: step 819, loss 0.0587911, acc 1
2016-09-05T17:48:42.030315: step 820, loss 0.125029, acc 0.98
2016-09-05T17:48:42.234457: step 821, loss 0.0896285, acc 0.98
2016-09-05T17:48:42.429795: step 822, loss 0.0629493, acc 1
2016-09-05T17:48:42.625084: step 823, loss 0.0807804, acc 0.98
2016-09-05T17:48:42.829579: step 824, loss 0.0706003, acc 1
2016-09-05T17:48:43.028395: step 825, loss 0.0555447, acc 1
2016-09-05T17:48:43.227914: step 826, loss 0.0662172, acc 1
2016-09-05T17:48:43.435651: step 827, loss 0.0823768, acc 0.98
2016-09-05T17:48:43.647808: step 828, loss 0.0910037, acc 0.98
2016-09-05T17:48:43.832209: step 829, loss 0.0975538, acc 0.96
2016-09-05T17:48:44.014917: step 830, loss 0.0899007, acc 0.98
2016-09-05T17:48:44.203883: step 831, loss 0.0489484, acc 1
2016-09-05T17:48:44.393485: step 832, loss 0.116867, acc 0.98
2016-09-05T17:48:44.586819: step 833, loss 0.102831, acc 0.96
2016-09-05T17:48:44.776450: step 834, loss 0.0622531, acc 1
2016-09-05T17:48:44.994074: step 835, loss 0.061892, acc 1
2016-09-05T17:48:45.176489: step 836, loss 0.0808818, acc 1
2016-09-05T17:48:45.378917: step 837, loss 0.0722559, acc 1
2016-09-05T17:48:45.591823: step 838, loss 0.0653819, acc 0.98
2016-09-05T17:48:45.806873: step 839, loss 0.0671389, acc 0.98
2016-09-05T17:48:46.019277: step 840, loss 0.0691834, acc 1
2016-09-05T17:48:46.228685: step 841, loss 0.103398, acc 0.98
2016-09-05T17:48:46.422025: step 842, loss 0.0727601, acc 1
2016-09-05T17:48:46.656563: step 843, loss 0.0580297, acc 1
2016-09-05T17:48:46.851325: step 844, loss 0.122747, acc 0.98
2016-09-05T17:48:47.037037: step 845, loss 0.104117, acc 0.98
2016-09-05T17:48:47.236672: step 846, loss 0.071501, acc 0.98
2016-09-05T17:48:47.431152: step 847, loss 0.0611406, acc 1
2016-09-05T17:48:47.620961: step 848, loss 0.112336, acc 1
2016-09-05T17:48:47.814126: step 849, loss 0.0694287, acc 1
2016-09-05T17:48:48.025411: step 850, loss 0.0599852, acc 1
2016-09-05T17:48:48.226764: step 851, loss 0.0816627, acc 0.98
2016-09-05T17:48:48.434695: step 852, loss 0.0771054, acc 1
2016-09-05T17:48:48.670032: step 853, loss 0.073184, acc 1
2016-09-05T17:48:48.878834: step 854, loss 0.167211, acc 0.96
2016-09-05T17:48:49.088429: step 855, loss 0.0902845, acc 0.98
2016-09-05T17:48:49.323223: step 856, loss 0.05449, acc 1
2016-09-05T17:48:49.517158: step 857, loss 0.071631, acc 1
2016-09-05T17:48:49.706417: step 858, loss 0.067177, acc 1
2016-09-05T17:48:49.906038: step 859, loss 0.0657155, acc 1
2016-09-05T17:48:50.101482: step 860, loss 0.111688, acc 0.98
2016-09-05T17:48:50.318817: step 861, loss 0.0711977, acc 0.98
2016-09-05T17:48:50.529418: step 862, loss 0.127732, acc 0.96
2016-09-05T17:48:50.726871: step 863, loss 0.0668131, acc 1
2016-09-05T17:48:50.945662: step 864, loss 0.0618069, acc 1
2016-09-05T17:48:51.141525: step 865, loss 0.0579613, acc 1
2016-09-05T17:48:51.335731: step 866, loss 0.0620758, acc 1
2016-09-05T17:48:51.536495: step 867, loss 0.105471, acc 0.98
2016-09-05T17:48:51.737918: step 868, loss 0.0778354, acc 1
2016-09-05T17:48:51.951494: step 869, loss 0.0711499, acc 1
2016-09-05T17:48:52.177987: step 870, loss 0.0857201, acc 0.98
2016-09-05T17:48:52.416461: step 871, loss 0.0605154, acc 1
2016-09-05T17:48:52.629284: step 872, loss 0.0745137, acc 1
2016-09-05T17:48:52.826123: step 873, loss 0.0670417, acc 1
2016-09-05T17:48:53.038077: step 874, loss 0.0798519, acc 1
2016-09-05T17:48:53.235358: step 875, loss 0.0791748, acc 1
2016-09-05T17:48:53.454031: step 876, loss 0.123472, acc 0.98
2016-09-05T17:48:53.645212: step 877, loss 0.0813582, acc 1
2016-09-05T17:48:53.864665: step 878, loss 0.0767749, acc 1
2016-09-05T17:48:54.076416: step 879, loss 0.0919016, acc 0.98
2016-09-05T17:48:54.284009: step 880, loss 0.0799558, acc 0.98
2016-09-05T17:48:54.497229: step 881, loss 0.118177, acc 0.96
2016-09-05T17:48:54.721480: step 882, loss 0.0677302, acc 1
2016-09-05T17:48:54.904623: step 883, loss 0.0589101, acc 1
2016-09-05T17:48:55.110912: step 884, loss 0.0585203, acc 1
2016-09-05T17:48:55.331352: step 885, loss 0.117164, acc 0.98
2016-09-05T17:48:55.561670: step 886, loss 0.0509711, acc 1
2016-09-05T17:48:55.784079: step 887, loss 0.0557424, acc 1
2016-09-05T17:48:56.000116: step 888, loss 0.074537, acc 1
2016-09-05T17:48:56.208674: step 889, loss 0.0651647, acc 1
2016-09-05T17:48:56.409053: step 890, loss 0.0962114, acc 1
2016-09-05T17:48:56.622158: step 891, loss 0.0637806, acc 1
2016-09-05T17:48:56.817769: step 892, loss 0.0794852, acc 1
2016-09-05T17:48:57.031811: step 893, loss 0.0690074, acc 1
2016-09-05T17:48:57.234250: step 894, loss 0.0803806, acc 1
2016-09-05T17:48:57.434574: step 895, loss 0.0653936, acc 1
2016-09-05T17:48:57.642368: step 896, loss 0.0533564, acc 1
2016-09-05T17:48:57.854154: step 897, loss 0.0608154, acc 1
2016-09-05T17:48:58.071242: step 898, loss 0.0806466, acc 1
2016-09-05T17:48:58.279734: step 899, loss 0.0569084, acc 1
2016-09-05T17:48:58.487683: step 900, loss 0.0621785, acc 1

Evaluation:
2016-09-05T17:48:59.032696: step 900, loss 0.606399, acc 0.795

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-900

2016-09-05T17:48:59.749746: step 901, loss 0.0832752, acc 0.98
2016-09-05T17:48:59.983784: step 902, loss 0.0567988, acc 1
2016-09-05T17:49:00.196911: step 903, loss 0.0872066, acc 1
2016-09-05T17:49:00.410659: step 904, loss 0.0706994, acc 1
2016-09-05T17:49:00.610381: step 905, loss 0.0683485, acc 0.98
2016-09-05T17:49:00.815741: step 906, loss 0.0646698, acc 1
2016-09-05T17:49:01.055668: step 907, loss 0.0570162, acc 1
2016-09-05T17:49:01.253461: step 908, loss 0.0570305, acc 1
2016-09-05T17:49:01.450409: step 909, loss 0.0986456, acc 0.98
2016-09-05T17:49:01.650469: step 910, loss 0.0638257, acc 1
2016-09-05T17:49:01.871725: step 911, loss 0.0816221, acc 1
2016-09-05T17:49:02.087453: step 912, loss 0.0575311, acc 1
2016-09-05T17:49:02.300633: step 913, loss 0.0547986, acc 1
2016-09-05T17:49:02.509428: step 914, loss 0.0879087, acc 0.96
2016-09-05T17:49:02.711043: step 915, loss 0.0913486, acc 0.98
2016-09-05T17:49:02.908037: step 916, loss 0.0720871, acc 1
2016-09-05T17:49:03.093273: step 917, loss 0.0684896, acc 1
2016-09-05T17:49:03.285245: step 918, loss 0.0645992, acc 1
2016-09-05T17:49:03.482342: step 919, loss 0.0765277, acc 0.96
2016-09-05T17:49:03.712481: step 920, loss 0.0836005, acc 1
2016-09-05T17:49:03.926840: step 921, loss 0.0633933, acc 1
2016-09-05T17:49:04.131861: step 922, loss 0.10276, acc 0.98
2016-09-05T17:49:04.345457: step 923, loss 0.0553037, acc 1
2016-09-05T17:49:04.564454: step 924, loss 0.0774582, acc 1
2016-09-05T17:49:04.759540: step 925, loss 0.071115, acc 1
2016-09-05T17:49:04.952043: step 926, loss 0.0675271, acc 1
2016-09-05T17:49:05.155212: step 927, loss 0.0689462, acc 1
2016-09-05T17:49:05.370455: step 928, loss 0.0584697, acc 1
2016-09-05T17:49:05.611968: step 929, loss 0.0814066, acc 1
2016-09-05T17:49:05.829254: step 930, loss 0.061199, acc 1
2016-09-05T17:49:06.025632: step 931, loss 0.0637784, acc 1
2016-09-05T17:49:06.240228: step 932, loss 0.081819, acc 1
2016-09-05T17:49:06.469782: step 933, loss 0.0719877, acc 0.98
2016-09-05T17:49:06.711573: step 934, loss 0.0854607, acc 1
2016-09-05T17:49:06.907476: step 935, loss 0.110522, acc 0.98
2016-09-05T17:49:07.110773: step 936, loss 0.060835, acc 1
2016-09-05T17:49:07.319152: step 937, loss 0.0584041, acc 1
2016-09-05T17:49:07.510615: step 938, loss 0.096808, acc 0.98
2016-09-05T17:49:07.711711: step 939, loss 0.0967269, acc 0.98
2016-09-05T17:49:07.939074: step 940, loss 0.0675376, acc 1
2016-09-05T17:49:08.151350: step 941, loss 0.0882423, acc 0.98
2016-09-05T17:49:08.365294: step 942, loss 0.0588868, acc 1
2016-09-05T17:49:08.571501: step 943, loss 0.103222, acc 1
2016-09-05T17:49:08.777643: step 944, loss 0.0648127, acc 1
2016-09-05T17:49:08.994193: step 945, loss 0.139629, acc 0.96
2016-09-05T17:49:09.196100: step 946, loss 0.0662417, acc 1
2016-09-05T17:49:09.404420: step 947, loss 0.0639575, acc 1
2016-09-05T17:49:09.615422: step 948, loss 0.122852, acc 0.94
2016-09-05T17:49:09.829906: step 949, loss 0.0675531, acc 1
2016-09-05T17:49:10.055589: step 950, loss 0.081608, acc 0.96
2016-09-05T17:49:10.261895: step 951, loss 0.0766039, acc 1
2016-09-05T17:49:10.472145: step 952, loss 0.0667068, acc 1
2016-09-05T17:49:10.667022: step 953, loss 0.0532355, acc 1
2016-09-05T17:49:10.855381: step 954, loss 0.0658452, acc 0.98
2016-09-05T17:49:11.058331: step 955, loss 0.0570702, acc 1
2016-09-05T17:49:11.271005: step 956, loss 0.0530541, acc 1
2016-09-05T17:49:11.465937: step 957, loss 0.070622, acc 1
2016-09-05T17:49:11.665749: step 958, loss 0.0547487, acc 1
2016-09-05T17:49:11.875315: step 959, loss 0.050128, acc 1
2016-09-05T17:49:12.083301: step 960, loss 0.0828287, acc 1
2016-09-05T17:49:12.289967: step 961, loss 0.0830908, acc 1
2016-09-05T17:49:12.537540: step 962, loss 0.075259, acc 1
2016-09-05T17:49:12.739081: step 963, loss 0.0801639, acc 1
2016-09-05T17:49:12.950821: step 964, loss 0.0787037, acc 1
2016-09-05T17:49:13.151361: step 965, loss 0.0758516, acc 0.98
2016-09-05T17:49:13.359865: step 966, loss 0.0600768, acc 1
2016-09-05T17:49:13.603726: step 967, loss 0.104429, acc 0.98
2016-09-05T17:49:13.837884: step 968, loss 0.0515647, acc 1
2016-09-05T17:49:14.052686: step 969, loss 0.0942646, acc 0.98
2016-09-05T17:49:14.193359: step 970, loss 0.0414635, acc 1
2016-09-05T17:49:14.414799: step 971, loss 0.0558146, acc 1
2016-09-05T17:49:14.628337: step 972, loss 0.0585215, acc 1
2016-09-05T17:49:14.822284: step 973, loss 0.0537449, acc 1
2016-09-05T17:49:15.016621: step 974, loss 0.0612448, acc 1
2016-09-05T17:49:15.271965: step 975, loss 0.0581476, acc 1
2016-09-05T17:49:15.462878: step 976, loss 0.0529655, acc 1
2016-09-05T17:49:15.656618: step 977, loss 0.0640681, acc 1
2016-09-05T17:49:15.846425: step 978, loss 0.0525117, acc 1
2016-09-05T17:49:16.046255: step 979, loss 0.0523776, acc 1
2016-09-05T17:49:16.245011: step 980, loss 0.0730437, acc 1
2016-09-05T17:49:16.457502: step 981, loss 0.047521, acc 1
2016-09-05T17:49:16.663988: step 982, loss 0.054447, acc 1
2016-09-05T17:49:16.867680: step 983, loss 0.0613316, acc 1
2016-09-05T17:49:17.063056: step 984, loss 0.0569029, acc 1
2016-09-05T17:49:17.265879: step 985, loss 0.0466188, acc 1
2016-09-05T17:49:17.456413: step 986, loss 0.0701562, acc 1
2016-09-05T17:49:17.673607: step 987, loss 0.0554585, acc 1
2016-09-05T17:49:17.904948: step 988, loss 0.0573937, acc 1
2016-09-05T17:49:18.114241: step 989, loss 0.0613576, acc 1
2016-09-05T17:49:18.319815: step 990, loss 0.0532923, acc 1
2016-09-05T17:49:18.527923: step 991, loss 0.0892067, acc 0.98
2016-09-05T17:49:18.730139: step 992, loss 0.0570777, acc 1
2016-09-05T17:49:18.989133: step 993, loss 0.0524173, acc 1
2016-09-05T17:49:19.204823: step 994, loss 0.0527932, acc 1
2016-09-05T17:49:19.408672: step 995, loss 0.0542403, acc 1
2016-09-05T17:49:19.626949: step 996, loss 0.0803522, acc 1
2016-09-05T17:49:19.836171: step 997, loss 0.0466417, acc 1
2016-09-05T17:49:20.020744: step 998, loss 0.048999, acc 1
2016-09-05T17:49:20.213966: step 999, loss 0.0500591, acc 1
2016-09-05T17:49:20.422157: step 1000, loss 0.051648, acc 1

Evaluation:
2016-09-05T17:49:20.985463: step 1000, loss 0.620527, acc 0.785

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-1000

2016-09-05T17:49:21.758053: step 1001, loss 0.0607356, acc 1
2016-09-05T17:49:22.004689: step 1002, loss 0.0653181, acc 1
2016-09-05T17:49:22.205842: step 1003, loss 0.0713799, acc 0.98
2016-09-05T17:49:22.422829: step 1004, loss 0.0614636, acc 1
2016-09-05T17:49:22.637106: step 1005, loss 0.0833296, acc 0.98
2016-09-05T17:49:22.839634: step 1006, loss 0.0479057, acc 1
2016-09-05T17:49:23.048688: step 1007, loss 0.060341, acc 1
2016-09-05T17:49:23.240112: step 1008, loss 0.0538127, acc 1
2016-09-05T17:49:23.433840: step 1009, loss 0.0714542, acc 1
2016-09-05T17:49:23.641326: step 1010, loss 0.0580443, acc 1
2016-09-05T17:49:23.850028: step 1011, loss 0.044479, acc 1
2016-09-05T17:49:24.046003: step 1012, loss 0.0548444, acc 1
2016-09-05T17:49:24.240085: step 1013, loss 0.0715455, acc 1
2016-09-05T17:49:24.458243: step 1014, loss 0.0617059, acc 1
2016-09-05T17:49:24.663317: step 1015, loss 0.0483029, acc 1
2016-09-05T17:49:24.857918: step 1016, loss 0.0429247, acc 1
2016-09-05T17:49:25.068692: step 1017, loss 0.0809838, acc 0.98
2016-09-05T17:49:25.286518: step 1018, loss 0.0796918, acc 0.98
2016-09-05T17:49:25.477008: step 1019, loss 0.0625138, acc 1
2016-09-05T17:49:25.682487: step 1020, loss 0.0527471, acc 1
2016-09-05T17:49:25.875754: step 1021, loss 0.0578191, acc 1
2016-09-05T17:49:26.064088: step 1022, loss 0.0451415, acc 1
2016-09-05T17:49:26.266993: step 1023, loss 0.0485817, acc 1
2016-09-05T17:49:26.482062: step 1024, loss 0.062563, acc 1
2016-09-05T17:49:26.671955: step 1025, loss 0.053551, acc 1
2016-09-05T17:49:26.888770: step 1026, loss 0.048563, acc 1
2016-09-05T17:49:27.103584: step 1027, loss 0.063675, acc 1
2016-09-05T17:49:27.293318: step 1028, loss 0.0581054, acc 1
2016-09-05T17:49:27.486265: step 1029, loss 0.0413169, acc 1
2016-09-05T17:49:27.691981: step 1030, loss 0.0488237, acc 1
2016-09-05T17:49:27.890509: step 1031, loss 0.0432718, acc 1
2016-09-05T17:49:28.082445: step 1032, loss 0.0553341, acc 1
2016-09-05T17:49:28.299643: step 1033, loss 0.0581094, acc 1
2016-09-05T17:49:28.499929: step 1034, loss 0.0471698, acc 1
2016-09-05T17:49:28.725594: step 1035, loss 0.0718668, acc 1
2016-09-05T17:49:28.931049: step 1036, loss 0.0694643, acc 0.98
2016-09-05T17:49:29.132590: step 1037, loss 0.0469127, acc 1
2016-09-05T17:49:29.339147: step 1038, loss 0.0535386, acc 1
2016-09-05T17:49:29.550763: step 1039, loss 0.043174, acc 1
2016-09-05T17:49:29.764610: step 1040, loss 0.0477941, acc 1
2016-09-05T17:49:30.004319: step 1041, loss 0.0478498, acc 1
2016-09-05T17:49:30.208841: step 1042, loss 0.0557986, acc 1
2016-09-05T17:49:30.410397: step 1043, loss 0.101929, acc 0.98
2016-09-05T17:49:30.596409: step 1044, loss 0.0629635, acc 1
2016-09-05T17:49:30.784205: step 1045, loss 0.056067, acc 1
2016-09-05T17:49:31.010680: step 1046, loss 0.0541896, acc 1
2016-09-05T17:49:31.207944: step 1047, loss 0.0592742, acc 1
2016-09-05T17:49:31.428791: step 1048, loss 0.0557718, acc 1
2016-09-05T17:49:31.622710: step 1049, loss 0.0513421, acc 1
2016-09-05T17:49:31.824131: step 1050, loss 0.0697478, acc 0.98
2016-09-05T17:49:32.013348: step 1051, loss 0.052144, acc 1
2016-09-05T17:49:32.211946: step 1052, loss 0.0607142, acc 1
2016-09-05T17:49:32.396269: step 1053, loss 0.0441031, acc 1
2016-09-05T17:49:32.603070: step 1054, loss 0.0732453, acc 0.98
2016-09-05T17:49:32.790388: step 1055, loss 0.0586918, acc 1
2016-09-05T17:49:33.012186: step 1056, loss 0.0423056, acc 1
2016-09-05T17:49:33.197915: step 1057, loss 0.0570525, acc 1
2016-09-05T17:49:33.405744: step 1058, loss 0.0564456, acc 1
2016-09-05T17:49:33.619788: step 1059, loss 0.0666743, acc 1
2016-09-05T17:49:33.822854: step 1060, loss 0.0679272, acc 1
2016-09-05T17:49:34.031969: step 1061, loss 0.0497098, acc 1
2016-09-05T17:49:34.217621: step 1062, loss 0.0582913, acc 1
2016-09-05T17:49:34.403755: step 1063, loss 0.0468979, acc 1
2016-09-05T17:49:34.613504: step 1064, loss 0.0523041, acc 1
2016-09-05T17:49:34.825558: step 1065, loss 0.0433293, acc 1
2016-09-05T17:49:35.071111: step 1066, loss 0.0530403, acc 1
2016-09-05T17:49:35.299909: step 1067, loss 0.0647199, acc 1
2016-09-05T17:49:35.515222: step 1068, loss 0.0542136, acc 1
2016-09-05T17:49:35.706420: step 1069, loss 0.0666743, acc 0.98
2016-09-05T17:49:35.916411: step 1070, loss 0.0597585, acc 1
2016-09-05T17:49:36.114238: step 1071, loss 0.0669777, acc 1
2016-09-05T17:49:36.309301: step 1072, loss 0.0653237, acc 1
2016-09-05T17:49:36.511182: step 1073, loss 0.0753022, acc 0.98
2016-09-05T17:49:36.714713: step 1074, loss 0.0558315, acc 1
2016-09-05T17:49:36.948615: step 1075, loss 0.0821567, acc 0.98
2016-09-05T17:49:37.142032: step 1076, loss 0.0434817, acc 1
2016-09-05T17:49:37.337374: step 1077, loss 0.0473473, acc 1
2016-09-05T17:49:37.543566: step 1078, loss 0.04795, acc 1
2016-09-05T17:49:37.742066: step 1079, loss 0.0745774, acc 1
2016-09-05T17:49:37.975062: step 1080, loss 0.0474637, acc 1
2016-09-05T17:49:38.162073: step 1081, loss 0.0624729, acc 1
2016-09-05T17:49:38.353833: step 1082, loss 0.0491587, acc 1
2016-09-05T17:49:38.589149: step 1083, loss 0.0515466, acc 1
2016-09-05T17:49:38.795513: step 1084, loss 0.0662129, acc 1
2016-09-05T17:49:38.982248: step 1085, loss 0.0772994, acc 1
2016-09-05T17:49:39.193118: step 1086, loss 0.064036, acc 1
2016-09-05T17:49:39.401193: step 1087, loss 0.0492225, acc 1
2016-09-05T17:49:39.599107: step 1088, loss 0.071563, acc 1
2016-09-05T17:49:39.800258: step 1089, loss 0.0875505, acc 0.98
2016-09-05T17:49:39.994628: step 1090, loss 0.0512641, acc 1
2016-09-05T17:49:40.180511: step 1091, loss 0.0667611, acc 1
2016-09-05T17:49:40.384051: step 1092, loss 0.0604011, acc 1
2016-09-05T17:49:40.605567: step 1093, loss 0.0544302, acc 1
2016-09-05T17:49:40.797661: step 1094, loss 0.0497988, acc 1
2016-09-05T17:49:41.002335: step 1095, loss 0.0530237, acc 1
2016-09-05T17:49:41.214904: step 1096, loss 0.0481321, acc 1
2016-09-05T17:49:41.419470: step 1097, loss 0.0636818, acc 1
2016-09-05T17:49:41.624198: step 1098, loss 0.0678478, acc 1
2016-09-05T17:49:41.837125: step 1099, loss 0.0440203, acc 1
2016-09-05T17:49:42.046676: step 1100, loss 0.0533353, acc 0.98

Evaluation:
2016-09-05T17:49:42.625011: step 1100, loss 0.63881, acc 0.785

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-1100

2016-09-05T17:49:43.339872: step 1101, loss 0.0875576, acc 1
2016-09-05T17:49:43.550269: step 1102, loss 0.0611567, acc 1
2016-09-05T17:49:43.762251: step 1103, loss 0.0432947, acc 1
2016-09-05T17:49:44.010888: step 1104, loss 0.0470718, acc 1
2016-09-05T17:49:44.225868: step 1105, loss 0.0693347, acc 1
2016-09-05T17:49:44.442921: step 1106, loss 0.0753872, acc 0.98
2016-09-05T17:49:44.627307: step 1107, loss 0.0606737, acc 1
2016-09-05T17:49:44.821912: step 1108, loss 0.0537819, acc 1
2016-09-05T17:49:45.016493: step 1109, loss 0.0510244, acc 1
2016-09-05T17:49:45.223390: step 1110, loss 0.0552977, acc 1
2016-09-05T17:49:45.433798: step 1111, loss 0.0744196, acc 0.98
2016-09-05T17:49:45.663114: step 1112, loss 0.0604806, acc 1
2016-09-05T17:49:45.865477: step 1113, loss 0.0511752, acc 1
2016-09-05T17:49:46.060593: step 1114, loss 0.0652717, acc 1
2016-09-05T17:49:46.250509: step 1115, loss 0.0430988, acc 1
2016-09-05T17:49:46.436511: step 1116, loss 0.0950088, acc 0.98
2016-09-05T17:49:46.645107: step 1117, loss 0.0495641, acc 1
2016-09-05T17:49:46.840101: step 1118, loss 0.0445096, acc 1
2016-09-05T17:49:47.050811: step 1119, loss 0.0831329, acc 0.98
2016-09-05T17:49:47.291315: step 1120, loss 0.0485537, acc 1
2016-09-05T17:49:47.483655: step 1121, loss 0.0484118, acc 1
2016-09-05T17:49:47.707364: step 1122, loss 0.0518555, acc 1
2016-09-05T17:49:47.933014: step 1123, loss 0.0880198, acc 0.98
2016-09-05T17:49:48.146157: step 1124, loss 0.0523498, acc 1
2016-09-05T17:49:48.367028: step 1125, loss 0.0539205, acc 1
2016-09-05T17:49:48.614488: step 1126, loss 0.05095, acc 1
2016-09-05T17:49:48.844851: step 1127, loss 0.0420054, acc 1
2016-09-05T17:49:49.053911: step 1128, loss 0.0556674, acc 1
2016-09-05T17:49:49.242367: step 1129, loss 0.0769202, acc 0.98
2016-09-05T17:49:49.458286: step 1130, loss 0.0581801, acc 1
2016-09-05T17:49:49.645119: step 1131, loss 0.0548006, acc 1
2016-09-05T17:49:49.857896: step 1132, loss 0.0542302, acc 1
2016-09-05T17:49:50.043133: step 1133, loss 0.0569829, acc 1
2016-09-05T17:49:50.246380: step 1134, loss 0.0459997, acc 1
2016-09-05T17:49:50.446002: step 1135, loss 0.0505623, acc 1
2016-09-05T17:49:50.665242: step 1136, loss 0.0506182, acc 1
2016-09-05T17:49:50.862035: step 1137, loss 0.0491204, acc 1
2016-09-05T17:49:51.057869: step 1138, loss 0.0547243, acc 1
2016-09-05T17:49:51.250300: step 1139, loss 0.0489365, acc 1
2016-09-05T17:49:51.451671: step 1140, loss 0.0469688, acc 1
2016-09-05T17:49:51.663556: step 1141, loss 0.0554385, acc 1
2016-09-05T17:49:51.877702: step 1142, loss 0.0549845, acc 1
2016-09-05T17:49:52.091699: step 1143, loss 0.0789483, acc 0.98
2016-09-05T17:49:52.315591: step 1144, loss 0.0444894, acc 1
2016-09-05T17:49:52.510338: step 1145, loss 0.071786, acc 0.98
2016-09-05T17:49:52.703652: step 1146, loss 0.0667781, acc 1
2016-09-05T17:49:52.903067: step 1147, loss 0.0784668, acc 0.98
2016-09-05T17:49:53.104847: step 1148, loss 0.068354, acc 1
2016-09-05T17:49:53.353803: step 1149, loss 0.0671952, acc 0.98
2016-09-05T17:49:53.564170: step 1150, loss 0.0684486, acc 1
2016-09-05T17:49:53.770677: step 1151, loss 0.0527845, acc 1
2016-09-05T17:49:53.975700: step 1152, loss 0.0417434, acc 1
2016-09-05T17:49:54.169797: step 1153, loss 0.0677051, acc 0.98
2016-09-05T17:49:54.366332: step 1154, loss 0.0463603, acc 1
2016-09-05T17:49:54.565373: step 1155, loss 0.059202, acc 1
2016-09-05T17:49:54.765907: step 1156, loss 0.0428696, acc 1
2016-09-05T17:49:54.972179: step 1157, loss 0.0961682, acc 0.98
2016-09-05T17:49:55.170051: step 1158, loss 0.0619736, acc 1
2016-09-05T17:49:55.387100: step 1159, loss 0.0564159, acc 1
2016-09-05T17:49:55.578385: step 1160, loss 0.0513681, acc 1
2016-09-05T17:49:55.782943: step 1161, loss 0.0511508, acc 1
2016-09-05T17:49:55.982128: step 1162, loss 0.0474385, acc 1
2016-09-05T17:49:56.190146: step 1163, loss 0.0559954, acc 1
2016-09-05T17:49:56.318733: step 1164, loss 0.108249, acc 1
2016-09-05T17:49:56.522427: step 1165, loss 0.0471331, acc 1
2016-09-05T17:49:56.740518: step 1166, loss 0.0394052, acc 1
2016-09-05T17:49:56.962389: step 1167, loss 0.0435617, acc 1
2016-09-05T17:49:57.170590: step 1168, loss 0.0410593, acc 1
2016-09-05T17:49:57.374696: step 1169, loss 0.0778405, acc 0.98
2016-09-05T17:49:57.582290: step 1170, loss 0.0410545, acc 1
2016-09-05T17:49:57.804285: step 1171, loss 0.0460524, acc 1
2016-09-05T17:49:57.997229: step 1172, loss 0.0385988, acc 1
2016-09-05T17:49:58.200899: step 1173, loss 0.0497517, acc 1
2016-09-05T17:49:58.392408: step 1174, loss 0.0582115, acc 1
2016-09-05T17:49:58.580572: step 1175, loss 0.0776057, acc 0.98
2016-09-05T17:49:58.775867: step 1176, loss 0.0441583, acc 1
2016-09-05T17:49:58.993119: step 1177, loss 0.0404697, acc 1
2016-09-05T17:49:59.198750: step 1178, loss 0.0400469, acc 1
2016-09-05T17:49:59.402297: step 1179, loss 0.0408836, acc 1
2016-09-05T17:49:59.604967: step 1180, loss 0.0380041, acc 1
2016-09-05T17:49:59.792375: step 1181, loss 0.0396701, acc 1
2016-09-05T17:49:59.990654: step 1182, loss 0.0460615, acc 1
2016-09-05T17:50:00.190757: step 1183, loss 0.0411747, acc 1
2016-09-05T17:50:00.406028: step 1184, loss 0.0500703, acc 1
2016-09-05T17:50:00.618057: step 1185, loss 0.0664992, acc 0.98
2016-09-05T17:50:00.815167: step 1186, loss 0.0477449, acc 1
2016-09-05T17:50:01.012364: step 1187, loss 0.0730183, acc 0.98
2016-09-05T17:50:01.217373: step 1188, loss 0.0533918, acc 1
2016-09-05T17:50:01.441880: step 1189, loss 0.046112, acc 1
2016-09-05T17:50:01.663442: step 1190, loss 0.0420557, acc 1
2016-09-05T17:50:01.895758: step 1191, loss 0.0619707, acc 1
2016-09-05T17:50:02.114607: step 1192, loss 0.0524678, acc 1
2016-09-05T17:50:02.334930: step 1193, loss 0.0399359, acc 1
2016-09-05T17:50:02.545563: step 1194, loss 0.045049, acc 1
2016-09-05T17:50:02.779705: step 1195, loss 0.0403659, acc 1
2016-09-05T17:50:02.972448: step 1196, loss 0.0428771, acc 1
2016-09-05T17:50:03.194270: step 1197, loss 0.0577414, acc 1
2016-09-05T17:50:03.396278: step 1198, loss 0.0420373, acc 1
2016-09-05T17:50:03.612253: step 1199, loss 0.0434396, acc 1
2016-09-05T17:50:03.823702: step 1200, loss 0.0465426, acc 1

Evaluation:
2016-09-05T17:50:04.379350: step 1200, loss 0.640236, acc 0.79

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-1200

2016-09-05T17:50:05.182445: step 1201, loss 0.0440656, acc 1
2016-09-05T17:50:05.380645: step 1202, loss 0.0391481, acc 1
2016-09-05T17:50:05.600067: step 1203, loss 0.0467614, acc 1
2016-09-05T17:50:05.798558: step 1204, loss 0.05589, acc 0.98
2016-09-05T17:50:06.020304: step 1205, loss 0.0448136, acc 1
2016-09-05T17:50:06.247838: step 1206, loss 0.0449292, acc 1
2016-09-05T17:50:06.453815: step 1207, loss 0.0380263, acc 1
2016-09-05T17:50:06.648123: step 1208, loss 0.0383501, acc 1
2016-09-05T17:50:06.854345: step 1209, loss 0.0495728, acc 1
2016-09-05T17:50:07.061057: step 1210, loss 0.043387, acc 1
2016-09-05T17:50:07.278226: step 1211, loss 0.0429049, acc 1
2016-09-05T17:50:07.518846: step 1212, loss 0.0421909, acc 1
2016-09-05T17:50:07.748399: step 1213, loss 0.0453978, acc 1
2016-09-05T17:50:07.933613: step 1214, loss 0.0799033, acc 0.98
2016-09-05T17:50:08.157620: step 1215, loss 0.0388281, acc 1
2016-09-05T17:50:08.367101: step 1216, loss 0.043253, acc 1
2016-09-05T17:50:08.578144: step 1217, loss 0.0482902, acc 1
2016-09-05T17:50:08.800928: step 1218, loss 0.0376282, acc 1
2016-09-05T17:50:09.021873: step 1219, loss 0.0353392, acc 1
2016-09-05T17:50:09.225189: step 1220, loss 0.0491336, acc 1
2016-09-05T17:50:09.439844: step 1221, loss 0.0550856, acc 1
2016-09-05T17:50:09.643091: step 1222, loss 0.0503557, acc 1
2016-09-05T17:50:09.840249: step 1223, loss 0.0426809, acc 1
2016-09-05T17:50:10.059972: step 1224, loss 0.0381835, acc 1
2016-09-05T17:50:10.261513: step 1225, loss 0.0436182, acc 1
2016-09-05T17:50:10.475294: step 1226, loss 0.0459047, acc 1
2016-09-05T17:50:10.688477: step 1227, loss 0.0636425, acc 1
2016-09-05T17:50:10.933096: step 1228, loss 0.0329138, acc 1
2016-09-05T17:50:11.133581: step 1229, loss 0.0659677, acc 1
2016-09-05T17:50:11.352859: step 1230, loss 0.0382595, acc 1
2016-09-05T17:50:11.556089: step 1231, loss 0.0410285, acc 1
2016-09-05T17:50:11.769341: step 1232, loss 0.037501, acc 1
2016-09-05T17:50:11.982795: step 1233, loss 0.0442218, acc 1
2016-09-05T17:50:12.179209: step 1234, loss 0.0446696, acc 1
2016-09-05T17:50:12.378564: step 1235, loss 0.0550575, acc 1
2016-09-05T17:50:12.580661: step 1236, loss 0.0513231, acc 1
2016-09-05T17:50:12.779366: step 1237, loss 0.042138, acc 1
2016-09-05T17:50:12.991897: step 1238, loss 0.037329, acc 1
2016-09-05T17:50:13.185297: step 1239, loss 0.0351063, acc 1
2016-09-05T17:50:13.387632: step 1240, loss 0.0457639, acc 1
2016-09-05T17:50:13.589392: step 1241, loss 0.0646108, acc 1
2016-09-05T17:50:13.790884: step 1242, loss 0.0443566, acc 1
2016-09-05T17:50:14.003200: step 1243, loss 0.0564331, acc 1
2016-09-05T17:50:14.208120: step 1244, loss 0.0458897, acc 1
2016-09-05T17:50:14.398715: step 1245, loss 0.0377138, acc 1
2016-09-05T17:50:14.601495: step 1246, loss 0.0684857, acc 0.98
2016-09-05T17:50:14.800798: step 1247, loss 0.0494782, acc 1
2016-09-05T17:50:15.001637: step 1248, loss 0.0448803, acc 1
2016-09-05T17:50:15.191238: step 1249, loss 0.0407303, acc 1
2016-09-05T17:50:15.395747: step 1250, loss 0.0503309, acc 1
2016-09-05T17:50:15.606395: step 1251, loss 0.0465545, acc 1
2016-09-05T17:50:15.787557: step 1252, loss 0.0388643, acc 1
2016-09-05T17:50:15.991784: step 1253, loss 0.0416972, acc 1
2016-09-05T17:50:16.192269: step 1254, loss 0.0576043, acc 0.98
2016-09-05T17:50:16.409252: step 1255, loss 0.0467158, acc 1
2016-09-05T17:50:16.602273: step 1256, loss 0.038347, acc 1
2016-09-05T17:50:16.799053: step 1257, loss 0.0452903, acc 1
2016-09-05T17:50:17.008968: step 1258, loss 0.0549549, acc 1
2016-09-05T17:50:17.204473: step 1259, loss 0.049949, acc 1
2016-09-05T17:50:17.401627: step 1260, loss 0.0861365, acc 0.98
2016-09-05T17:50:17.602976: step 1261, loss 0.0420764, acc 1
2016-09-05T17:50:17.820907: step 1262, loss 0.0438319, acc 1
2016-09-05T17:50:18.033334: step 1263, loss 0.0558735, acc 1
2016-09-05T17:50:18.231938: step 1264, loss 0.0455152, acc 1
2016-09-05T17:50:18.438436: step 1265, loss 0.047065, acc 1
2016-09-05T17:50:18.668788: step 1266, loss 0.0423289, acc 1
2016-09-05T17:50:18.871524: step 1267, loss 0.0477984, acc 1
2016-09-05T17:50:19.080416: step 1268, loss 0.105723, acc 0.96
2016-09-05T17:50:19.284097: step 1269, loss 0.0365384, acc 1
2016-09-05T17:50:19.496454: step 1270, loss 0.0394141, acc 1
2016-09-05T17:50:19.716692: step 1271, loss 0.0367937, acc 1
2016-09-05T17:50:19.937423: step 1272, loss 0.06437, acc 1
2016-09-05T17:50:20.143546: step 1273, loss 0.0538623, acc 1
2016-09-05T17:50:20.359146: step 1274, loss 0.0489877, acc 1
2016-09-05T17:50:20.562919: step 1275, loss 0.0486552, acc 1
2016-09-05T17:50:20.798228: step 1276, loss 0.0543363, acc 1
2016-09-05T17:50:21.006998: step 1277, loss 0.0549419, acc 1
2016-09-05T17:50:21.201431: step 1278, loss 0.0624756, acc 1
2016-09-05T17:50:21.424002: step 1279, loss 0.0433101, acc 1
2016-09-05T17:50:21.630806: step 1280, loss 0.0442538, acc 1
2016-09-05T17:50:21.832633: step 1281, loss 0.0357412, acc 1
2016-09-05T17:50:22.042449: step 1282, loss 0.0531122, acc 1
2016-09-05T17:50:22.247345: step 1283, loss 0.0540508, acc 1
2016-09-05T17:50:22.454307: step 1284, loss 0.0457928, acc 1
2016-09-05T17:50:22.657843: step 1285, loss 0.0371124, acc 1
2016-09-05T17:50:22.864295: step 1286, loss 0.0503428, acc 1
2016-09-05T17:50:23.057104: step 1287, loss 0.0539098, acc 1
2016-09-05T17:50:23.245812: step 1288, loss 0.0550924, acc 1
2016-09-05T17:50:23.445020: step 1289, loss 0.0455538, acc 1
2016-09-05T17:50:23.639787: step 1290, loss 0.0784678, acc 0.98
2016-09-05T17:50:23.837948: step 1291, loss 0.0471953, acc 1
2016-09-05T17:50:24.052991: step 1292, loss 0.0479324, acc 1
2016-09-05T17:50:24.254854: step 1293, loss 0.036096, acc 1
2016-09-05T17:50:24.463257: step 1294, loss 0.0561369, acc 1
2016-09-05T17:50:24.684243: step 1295, loss 0.0557838, acc 0.98
2016-09-05T17:50:24.879184: step 1296, loss 0.0469744, acc 1
2016-09-05T17:50:25.089864: step 1297, loss 0.0352303, acc 1
2016-09-05T17:50:25.292222: step 1298, loss 0.0578544, acc 1
2016-09-05T17:50:25.504185: step 1299, loss 0.0506627, acc 1
2016-09-05T17:50:25.691710: step 1300, loss 0.0332219, acc 1

Evaluation:
2016-09-05T17:50:26.260112: step 1300, loss 0.658711, acc 0.783

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-1300

2016-09-05T17:50:26.963139: step 1301, loss 0.051357, acc 1
2016-09-05T17:50:27.180707: step 1302, loss 0.0494722, acc 1
2016-09-05T17:50:27.381069: step 1303, loss 0.0726044, acc 0.98
2016-09-05T17:50:27.577876: step 1304, loss 0.0475134, acc 1
2016-09-05T17:50:27.784135: step 1305, loss 0.0631223, acc 1
2016-09-05T17:50:27.986382: step 1306, loss 0.0549623, acc 1
2016-09-05T17:50:28.180031: step 1307, loss 0.0541244, acc 1
2016-09-05T17:50:28.385997: step 1308, loss 0.0378053, acc 1
2016-09-05T17:50:28.597864: step 1309, loss 0.0510105, acc 1
2016-09-05T17:50:28.805474: step 1310, loss 0.0562628, acc 1
2016-09-05T17:50:28.994703: step 1311, loss 0.0614939, acc 1
2016-09-05T17:50:29.203154: step 1312, loss 0.046957, acc 1
2016-09-05T17:50:29.406766: step 1313, loss 0.0559855, acc 1
2016-09-05T17:50:29.602464: step 1314, loss 0.0394853, acc 1
2016-09-05T17:50:29.800227: step 1315, loss 0.0585262, acc 1
2016-09-05T17:50:29.996178: step 1316, loss 0.0457216, acc 1
2016-09-05T17:50:30.195794: step 1317, loss 0.062423, acc 1
2016-09-05T17:50:30.400757: step 1318, loss 0.0485486, acc 1
2016-09-05T17:50:30.599354: step 1319, loss 0.0389612, acc 1
2016-09-05T17:50:30.781927: step 1320, loss 0.0476726, acc 1
2016-09-05T17:50:31.000495: step 1321, loss 0.0694455, acc 1
2016-09-05T17:50:31.208432: step 1322, loss 0.0628851, acc 1
2016-09-05T17:50:31.405718: step 1323, loss 0.0499645, acc 1
2016-09-05T17:50:31.607912: step 1324, loss 0.0372561, acc 1
2016-09-05T17:50:31.809488: step 1325, loss 0.0616192, acc 0.98
2016-09-05T17:50:32.022577: step 1326, loss 0.0454221, acc 1
2016-09-05T17:50:32.211908: step 1327, loss 0.0412688, acc 1
2016-09-05T17:50:32.412332: step 1328, loss 0.0441139, acc 1
2016-09-05T17:50:32.622430: step 1329, loss 0.0379498, acc 1
2016-09-05T17:50:32.833827: step 1330, loss 0.0656639, acc 1
2016-09-05T17:50:33.037081: step 1331, loss 0.0540328, acc 1
2016-09-05T17:50:33.236290: step 1332, loss 0.0406384, acc 1
2016-09-05T17:50:33.455009: step 1333, loss 0.0430084, acc 1
2016-09-05T17:50:33.676829: step 1334, loss 0.0544482, acc 1
2016-09-05T17:50:33.904761: step 1335, loss 0.0440473, acc 1
2016-09-05T17:50:34.097285: step 1336, loss 0.0426517, acc 1
2016-09-05T17:50:34.300723: step 1337, loss 0.0386462, acc 1
2016-09-05T17:50:34.503341: step 1338, loss 0.0553216, acc 1
2016-09-05T17:50:34.716409: step 1339, loss 0.0363373, acc 1
2016-09-05T17:50:34.932516: step 1340, loss 0.0544936, acc 0.98
2016-09-05T17:50:35.129725: step 1341, loss 0.0411255, acc 1
2016-09-05T17:50:35.342722: step 1342, loss 0.0579423, acc 0.98
2016-09-05T17:50:35.539468: step 1343, loss 0.0347896, acc 1
2016-09-05T17:50:35.734285: step 1344, loss 0.036929, acc 1
2016-09-05T17:50:35.939480: step 1345, loss 0.0460381, acc 1
2016-09-05T17:50:36.148032: step 1346, loss 0.0428863, acc 1
2016-09-05T17:50:36.337391: step 1347, loss 0.052368, acc 1
2016-09-05T17:50:36.540143: step 1348, loss 0.0421042, acc 1
2016-09-05T17:50:36.745640: step 1349, loss 0.0482142, acc 1
2016-09-05T17:50:36.945927: step 1350, loss 0.0439612, acc 1
2016-09-05T17:50:37.137404: step 1351, loss 0.0730123, acc 0.98
2016-09-05T17:50:37.341355: step 1352, loss 0.0480206, acc 1
2016-09-05T17:50:37.538329: step 1353, loss 0.0392662, acc 1
2016-09-05T17:50:37.749706: step 1354, loss 0.0747736, acc 0.98
2016-09-05T17:50:37.965290: step 1355, loss 0.0487181, acc 1
2016-09-05T17:50:38.152206: step 1356, loss 0.0577714, acc 1
2016-09-05T17:50:38.359676: step 1357, loss 0.0441091, acc 1
2016-09-05T17:50:38.478683: step 1358, loss 0.041116, acc 1
2016-09-05T17:50:38.673152: step 1359, loss 0.0402428, acc 1
2016-09-05T17:50:38.902834: step 1360, loss 0.0400681, acc 1
2016-09-05T17:50:39.105010: step 1361, loss 0.036745, acc 1
2016-09-05T17:50:39.303558: step 1362, loss 0.0376697, acc 1
2016-09-05T17:50:39.503854: step 1363, loss 0.0360989, acc 1
2016-09-05T17:50:39.695356: step 1364, loss 0.0431614, acc 1
2016-09-05T17:50:39.905415: step 1365, loss 0.0443977, acc 1
2016-09-05T17:50:40.150420: step 1366, loss 0.0352144, acc 1
2016-09-05T17:50:40.361829: step 1367, loss 0.0342622, acc 1
2016-09-05T17:50:40.595162: step 1368, loss 0.0409456, acc 1
2016-09-05T17:50:40.797028: step 1369, loss 0.0458629, acc 1
2016-09-05T17:50:41.032752: step 1370, loss 0.0377747, acc 1
2016-09-05T17:50:41.261680: step 1371, loss 0.0429354, acc 1
2016-09-05T17:50:41.451617: step 1372, loss 0.0364935, acc 1
2016-09-05T17:50:41.648488: step 1373, loss 0.0435359, acc 1
2016-09-05T17:50:41.848959: step 1374, loss 0.0353254, acc 1
2016-09-05T17:50:42.043877: step 1375, loss 0.0413597, acc 1
2016-09-05T17:50:42.251040: step 1376, loss 0.0363163, acc 1
2016-09-05T17:50:42.470714: step 1377, loss 0.0536423, acc 1
2016-09-05T17:50:42.685076: step 1378, loss 0.0346643, acc 1
2016-09-05T17:50:42.900925: step 1379, loss 0.0415355, acc 1
2016-09-05T17:50:43.098264: step 1380, loss 0.0395365, acc 1
2016-09-05T17:50:43.283700: step 1381, loss 0.033597, acc 1
2016-09-05T17:50:43.488740: step 1382, loss 0.0433606, acc 1
2016-09-05T17:50:43.682905: step 1383, loss 0.0424429, acc 1
2016-09-05T17:50:43.885407: step 1384, loss 0.0371723, acc 1
2016-09-05T17:50:44.079802: step 1385, loss 0.0346131, acc 1
2016-09-05T17:50:44.271381: step 1386, loss 0.0415223, acc 1
2016-09-05T17:50:44.478237: step 1387, loss 0.0387783, acc 1
2016-09-05T17:50:44.691941: step 1388, loss 0.0386486, acc 1
2016-09-05T17:50:44.889188: step 1389, loss 0.0412154, acc 1
2016-09-05T17:50:45.091838: step 1390, loss 0.0448115, acc 1
2016-09-05T17:50:45.304977: step 1391, loss 0.0350496, acc 1
2016-09-05T17:50:45.501083: step 1392, loss 0.0371429, acc 1
2016-09-05T17:50:45.693048: step 1393, loss 0.0497968, acc 0.98
2016-09-05T17:50:45.907079: step 1394, loss 0.0495275, acc 1
2016-09-05T17:50:46.098645: step 1395, loss 0.0399146, acc 1
2016-09-05T17:50:46.293986: step 1396, loss 0.0528238, acc 1
2016-09-05T17:50:46.497003: step 1397, loss 0.031672, acc 1
2016-09-05T17:50:46.710504: step 1398, loss 0.0316008, acc 1
2016-09-05T17:50:46.908610: step 1399, loss 0.0391143, acc 1
2016-09-05T17:50:47.121290: step 1400, loss 0.0413015, acc 1

Evaluation:
2016-09-05T17:50:47.700348: step 1400, loss 0.672605, acc 0.783

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-1400

2016-09-05T17:50:48.453001: step 1401, loss 0.0495191, acc 1
2016-09-05T17:50:48.695659: step 1402, loss 0.0354497, acc 1
2016-09-05T17:50:48.944969: step 1403, loss 0.0393292, acc 1
2016-09-05T17:50:49.145856: step 1404, loss 0.0386349, acc 1
2016-09-05T17:50:49.360465: step 1405, loss 0.0412809, acc 1
2016-09-05T17:50:49.552037: step 1406, loss 0.0391185, acc 1
2016-09-05T17:50:49.794876: step 1407, loss 0.0355916, acc 1
2016-09-05T17:50:50.009653: step 1408, loss 0.0330816, acc 1
2016-09-05T17:50:50.232096: step 1409, loss 0.0361519, acc 1
2016-09-05T17:50:50.436814: step 1410, loss 0.0509523, acc 1
2016-09-05T17:50:50.637613: step 1411, loss 0.0363812, acc 1
2016-09-05T17:50:50.837964: step 1412, loss 0.0476972, acc 1
2016-09-05T17:50:51.048033: step 1413, loss 0.0314041, acc 1
2016-09-05T17:50:51.257726: step 1414, loss 0.0427481, acc 1
2016-09-05T17:50:51.457337: step 1415, loss 0.0321762, acc 1
2016-09-05T17:50:51.716527: step 1416, loss 0.0310347, acc 1
2016-09-05T17:50:51.947366: step 1417, loss 0.0390311, acc 1
2016-09-05T17:50:52.144321: step 1418, loss 0.0395787, acc 1
2016-09-05T17:50:52.333827: step 1419, loss 0.0350903, acc 1
2016-09-05T17:50:52.542655: step 1420, loss 0.0364606, acc 1
2016-09-05T17:50:52.747443: step 1421, loss 0.0367696, acc 1
2016-09-05T17:50:52.946498: step 1422, loss 0.0506886, acc 1
2016-09-05T17:50:53.128752: step 1423, loss 0.0371257, acc 1
2016-09-05T17:50:53.340580: step 1424, loss 0.0414887, acc 1
2016-09-05T17:50:53.530743: step 1425, loss 0.0400769, acc 1
2016-09-05T17:50:53.764729: step 1426, loss 0.030231, acc 1
2016-09-05T17:50:53.967244: step 1427, loss 0.0394816, acc 1
2016-09-05T17:50:54.175256: step 1428, loss 0.0402644, acc 1
2016-09-05T17:50:54.371172: step 1429, loss 0.0430823, acc 1
2016-09-05T17:50:54.565735: step 1430, loss 0.0380795, acc 1
2016-09-05T17:50:54.770439: step 1431, loss 0.0359923, acc 1
2016-09-05T17:50:54.966671: step 1432, loss 0.0402494, acc 1
2016-09-05T17:50:55.161924: step 1433, loss 0.0324146, acc 1
2016-09-05T17:50:55.368828: step 1434, loss 0.0354021, acc 1
2016-09-05T17:50:55.563078: step 1435, loss 0.0406356, acc 1
2016-09-05T17:50:55.762293: step 1436, loss 0.0461307, acc 1
2016-09-05T17:50:55.967937: step 1437, loss 0.0351871, acc 1
2016-09-05T17:50:56.195190: step 1438, loss 0.0303453, acc 1
2016-09-05T17:50:56.439585: step 1439, loss 0.0571131, acc 1
2016-09-05T17:50:56.651611: step 1440, loss 0.0502753, acc 1
2016-09-05T17:50:56.860981: step 1441, loss 0.0511091, acc 1
2016-09-05T17:50:57.068314: step 1442, loss 0.039413, acc 1
2016-09-05T17:50:57.294155: step 1443, loss 0.0334046, acc 1
2016-09-05T17:50:57.501724: step 1444, loss 0.0377488, acc 1
2016-09-05T17:50:57.750345: step 1445, loss 0.0390175, acc 1
2016-09-05T17:50:57.984579: step 1446, loss 0.0290347, acc 1
2016-09-05T17:50:58.195309: step 1447, loss 0.0390685, acc 1
2016-09-05T17:50:58.395895: step 1448, loss 0.0320806, acc 1
2016-09-05T17:50:58.590311: step 1449, loss 0.0528086, acc 1
2016-09-05T17:50:58.795092: step 1450, loss 0.0409856, acc 1
2016-09-05T17:50:58.991926: step 1451, loss 0.0713082, acc 0.98
2016-09-05T17:50:59.177905: step 1452, loss 0.0428895, acc 1
2016-09-05T17:50:59.394377: step 1453, loss 0.0358019, acc 1
2016-09-05T17:50:59.615645: step 1454, loss 0.0456255, acc 1
2016-09-05T17:50:59.807869: step 1455, loss 0.0359997, acc 1
2016-09-05T17:51:00.004754: step 1456, loss 0.0388145, acc 1
2016-09-05T17:51:00.213896: step 1457, loss 0.033263, acc 1
2016-09-05T17:51:00.404393: step 1458, loss 0.0354177, acc 1
2016-09-05T17:51:00.598040: step 1459, loss 0.0386492, acc 1
2016-09-05T17:51:00.796868: step 1460, loss 0.0410794, acc 1
2016-09-05T17:51:01.018636: step 1461, loss 0.0530989, acc 1
2016-09-05T17:51:01.230785: step 1462, loss 0.0338345, acc 1
2016-09-05T17:51:01.462198: step 1463, loss 0.0397571, acc 1
2016-09-05T17:51:01.663777: step 1464, loss 0.0502286, acc 1
2016-09-05T17:51:01.879521: step 1465, loss 0.0383797, acc 1
2016-09-05T17:51:02.112045: step 1466, loss 0.0374575, acc 1
2016-09-05T17:51:02.317894: step 1467, loss 0.0410028, acc 1
2016-09-05T17:51:02.541043: step 1468, loss 0.0356308, acc 1
2016-09-05T17:51:02.778286: step 1469, loss 0.0356182, acc 1
2016-09-05T17:51:02.989598: step 1470, loss 0.0307779, acc 1
2016-09-05T17:51:03.200325: step 1471, loss 0.031209, acc 1
2016-09-05T17:51:03.403411: step 1472, loss 0.0441113, acc 1
2016-09-05T17:51:03.606358: step 1473, loss 0.0406248, acc 1
2016-09-05T17:51:03.828239: step 1474, loss 0.0375827, acc 1
2016-09-05T17:51:04.041351: step 1475, loss 0.0536291, acc 1
2016-09-05T17:51:04.246294: step 1476, loss 0.0356689, acc 1
2016-09-05T17:51:04.468681: step 1477, loss 0.0326489, acc 1
2016-09-05T17:51:04.675152: step 1478, loss 0.0371005, acc 1
2016-09-05T17:51:04.891429: step 1479, loss 0.072657, acc 0.98
2016-09-05T17:51:05.091233: step 1480, loss 0.0331273, acc 1
2016-09-05T17:51:05.324943: step 1481, loss 0.0372065, acc 1
2016-09-05T17:51:05.529410: step 1482, loss 0.0422972, acc 1
2016-09-05T17:51:05.741928: step 1483, loss 0.0529166, acc 1
2016-09-05T17:51:05.949029: step 1484, loss 0.0345296, acc 1
2016-09-05T17:51:06.187548: step 1485, loss 0.0419923, acc 1
2016-09-05T17:51:06.400442: step 1486, loss 0.0453043, acc 1
2016-09-05T17:51:06.605702: step 1487, loss 0.0358386, acc 1
2016-09-05T17:51:06.828909: step 1488, loss 0.0346434, acc 1
2016-09-05T17:51:07.046141: step 1489, loss 0.0369132, acc 1
2016-09-05T17:51:07.247052: step 1490, loss 0.0424979, acc 1
2016-09-05T17:51:07.456172: step 1491, loss 0.0469965, acc 1
2016-09-05T17:51:07.668903: step 1492, loss 0.0326184, acc 1
2016-09-05T17:51:07.885071: step 1493, loss 0.0579462, acc 1
2016-09-05T17:51:08.080011: step 1494, loss 0.0285197, acc 1
2016-09-05T17:51:08.300119: step 1495, loss 0.0400408, acc 1
2016-09-05T17:51:08.514178: step 1496, loss 0.0538363, acc 0.98
2016-09-05T17:51:08.733125: step 1497, loss 0.028572, acc 1
2016-09-05T17:51:08.973861: step 1498, loss 0.032258, acc 1
2016-09-05T17:51:09.181693: step 1499, loss 0.0432121, acc 1
2016-09-05T17:51:09.380446: step 1500, loss 0.0427975, acc 1

Evaluation:
2016-09-05T17:51:09.973081: step 1500, loss 0.692113, acc 0.785

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-1500

2016-09-05T17:51:10.789880: step 1501, loss 0.0326434, acc 1
2016-09-05T17:51:11.001199: step 1502, loss 0.029857, acc 1
2016-09-05T17:51:11.225252: step 1503, loss 0.038273, acc 1
2016-09-05T17:51:11.445620: step 1504, loss 0.030873, acc 1
2016-09-05T17:51:11.663739: step 1505, loss 0.0375854, acc 1
2016-09-05T17:51:11.863635: step 1506, loss 0.0474206, acc 1
2016-09-05T17:51:12.089919: step 1507, loss 0.0354063, acc 1
2016-09-05T17:51:12.285208: step 1508, loss 0.0361186, acc 1
2016-09-05T17:51:12.502000: step 1509, loss 0.0365888, acc 1
2016-09-05T17:51:12.700933: step 1510, loss 0.0353126, acc 1
2016-09-05T17:51:12.900266: step 1511, loss 0.0352327, acc 1
2016-09-05T17:51:13.096358: step 1512, loss 0.0392082, acc 1
2016-09-05T17:51:13.293487: step 1513, loss 0.0525931, acc 1
2016-09-05T17:51:13.493828: step 1514, loss 0.0452537, acc 1
2016-09-05T17:51:13.709117: step 1515, loss 0.0399696, acc 1
2016-09-05T17:51:13.907764: step 1516, loss 0.0417638, acc 1
2016-09-05T17:51:14.110794: step 1517, loss 0.031656, acc 1
2016-09-05T17:51:14.343092: step 1518, loss 0.0441183, acc 1
2016-09-05T17:51:14.537734: step 1519, loss 0.0361387, acc 1
2016-09-05T17:51:14.734053: step 1520, loss 0.0419207, acc 1
2016-09-05T17:51:14.925487: step 1521, loss 0.0372437, acc 1
2016-09-05T17:51:15.114623: step 1522, loss 0.0370511, acc 1
2016-09-05T17:51:15.309053: step 1523, loss 0.0464442, acc 1
2016-09-05T17:51:15.506937: step 1524, loss 0.0373996, acc 1
2016-09-05T17:51:15.722370: step 1525, loss 0.0377616, acc 1
2016-09-05T17:51:15.921263: step 1526, loss 0.0455452, acc 1
2016-09-05T17:51:16.131087: step 1527, loss 0.0327264, acc 1
2016-09-05T17:51:16.320315: step 1528, loss 0.0365324, acc 1
2016-09-05T17:51:16.513429: step 1529, loss 0.0457554, acc 1
2016-09-05T17:51:16.711289: step 1530, loss 0.0336813, acc 1
2016-09-05T17:51:16.918389: step 1531, loss 0.0399795, acc 1
2016-09-05T17:51:17.125073: step 1532, loss 0.0438056, acc 1
2016-09-05T17:51:17.327995: step 1533, loss 0.037687, acc 1
2016-09-05T17:51:17.530945: step 1534, loss 0.0430962, acc 1
2016-09-05T17:51:17.760973: step 1535, loss 0.0561365, acc 0.98
2016-09-05T17:51:17.968986: step 1536, loss 0.0416912, acc 1
2016-09-05T17:51:18.173231: step 1537, loss 0.0488853, acc 0.98
2016-09-05T17:51:18.377439: step 1538, loss 0.0373228, acc 1
2016-09-05T17:51:18.593463: step 1539, loss 0.0342027, acc 1
2016-09-05T17:51:18.797270: step 1540, loss 0.0383939, acc 1
2016-09-05T17:51:19.020034: step 1541, loss 0.0545242, acc 1
2016-09-05T17:51:19.230058: step 1542, loss 0.0357239, acc 1
2016-09-05T17:51:19.441478: step 1543, loss 0.0374587, acc 1
2016-09-05T17:51:19.651345: step 1544, loss 0.0345073, acc 1
2016-09-05T17:51:19.871438: step 1545, loss 0.0346467, acc 1
2016-09-05T17:51:20.069165: step 1546, loss 0.0499613, acc 1
2016-09-05T17:51:20.269766: step 1547, loss 0.0447016, acc 1
2016-09-05T17:51:20.476621: step 1548, loss 0.0342471, acc 1
2016-09-05T17:51:20.687371: step 1549, loss 0.04373, acc 1
2016-09-05T17:51:20.913508: step 1550, loss 0.0451626, acc 1
2016-09-05T17:51:21.141401: step 1551, loss 0.0483554, acc 1
2016-09-05T17:51:21.269701: step 1552, loss 0.0320637, acc 1
2016-09-05T17:51:21.489260: step 1553, loss 0.0321938, acc 1
2016-09-05T17:51:21.751283: step 1554, loss 0.0362759, acc 1
2016-09-05T17:51:21.943689: step 1555, loss 0.0349597, acc 1
2016-09-05T17:51:22.152336: step 1556, loss 0.0315033, acc 1
2016-09-05T17:51:22.364162: step 1557, loss 0.035003, acc 1
2016-09-05T17:51:22.561305: step 1558, loss 0.0359327, acc 1
2016-09-05T17:51:22.763407: step 1559, loss 0.0324443, acc 1
2016-09-05T17:51:22.970894: step 1560, loss 0.031394, acc 1
2016-09-05T17:51:23.182287: step 1561, loss 0.0336431, acc 1
2016-09-05T17:51:23.398533: step 1562, loss 0.0312041, acc 1
2016-09-05T17:51:23.663149: step 1563, loss 0.0297624, acc 1
2016-09-05T17:51:23.881831: step 1564, loss 0.025875, acc 1
2016-09-05T17:51:24.114853: step 1565, loss 0.0446722, acc 1
2016-09-05T17:51:24.351973: step 1566, loss 0.0375188, acc 1
2016-09-05T17:51:24.553003: step 1567, loss 0.0384729, acc 1
2016-09-05T17:51:24.775395: step 1568, loss 0.0447405, acc 1
2016-09-05T17:51:24.979947: step 1569, loss 0.029737, acc 1
2016-09-05T17:51:25.187607: step 1570, loss 0.0323745, acc 1
2016-09-05T17:51:25.382620: step 1571, loss 0.0282034, acc 1
2016-09-05T17:51:25.600905: step 1572, loss 0.0379492, acc 1
2016-09-05T17:51:25.812997: step 1573, loss 0.0307225, acc 1
2016-09-05T17:51:26.035144: step 1574, loss 0.0391189, acc 1
2016-09-05T17:51:26.248320: step 1575, loss 0.0271674, acc 1
2016-09-05T17:51:26.478687: step 1576, loss 0.0297181, acc 1
2016-09-05T17:51:26.684871: step 1577, loss 0.0427786, acc 1
2016-09-05T17:51:26.888888: step 1578, loss 0.0316377, acc 1
2016-09-05T17:51:27.090438: step 1579, loss 0.0306314, acc 1
2016-09-05T17:51:27.289919: step 1580, loss 0.0364745, acc 1
2016-09-05T17:51:27.492611: step 1581, loss 0.0301425, acc 1
2016-09-05T17:51:27.687870: step 1582, loss 0.0428026, acc 1
2016-09-05T17:51:27.878534: step 1583, loss 0.0297752, acc 1
2016-09-05T17:51:28.076488: step 1584, loss 0.0354533, acc 1
2016-09-05T17:51:28.276654: step 1585, loss 0.0315816, acc 1
2016-09-05T17:51:28.476492: step 1586, loss 0.0323241, acc 1
2016-09-05T17:51:28.674645: step 1587, loss 0.0347687, acc 1
2016-09-05T17:51:28.883838: step 1588, loss 0.0359643, acc 1
2016-09-05T17:51:29.070153: step 1589, loss 0.0340298, acc 1
2016-09-05T17:51:29.283425: step 1590, loss 0.0313867, acc 1
2016-09-05T17:51:29.491927: step 1591, loss 0.032349, acc 1
2016-09-05T17:51:29.686253: step 1592, loss 0.0328234, acc 1
2016-09-05T17:51:29.880700: step 1593, loss 0.0365634, acc 1
2016-09-05T17:51:30.100146: step 1594, loss 0.031815, acc 1
2016-09-05T17:51:30.290812: step 1595, loss 0.0321174, acc 1
2016-09-05T17:51:30.501404: step 1596, loss 0.0341865, acc 1
2016-09-05T17:51:30.692018: step 1597, loss 0.0449571, acc 1
2016-09-05T17:51:30.871803: step 1598, loss 0.0266708, acc 1
2016-09-05T17:51:31.072859: step 1599, loss 0.0286851, acc 1
2016-09-05T17:51:31.290627: step 1600, loss 0.036921, acc 1

Evaluation:
2016-09-05T17:51:31.851830: step 1600, loss 0.695813, acc 0.78

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-1600

2016-09-05T17:51:32.611803: step 1601, loss 0.0300586, acc 1
2016-09-05T17:51:32.843273: step 1602, loss 0.0349033, acc 1
2016-09-05T17:51:33.059008: step 1603, loss 0.0324367, acc 1
2016-09-05T17:51:33.245536: step 1604, loss 0.0364691, acc 1
2016-09-05T17:51:33.452229: step 1605, loss 0.0282549, acc 1
2016-09-05T17:51:33.656293: step 1606, loss 0.0382773, acc 1
2016-09-05T17:51:33.857915: step 1607, loss 0.0484141, acc 1
2016-09-05T17:51:34.052949: step 1608, loss 0.0331302, acc 1
2016-09-05T17:51:34.250114: step 1609, loss 0.043104, acc 1
2016-09-05T17:51:34.453456: step 1610, loss 0.0280071, acc 1
2016-09-05T17:51:34.675631: step 1611, loss 0.0269715, acc 1
2016-09-05T17:51:34.880786: step 1612, loss 0.0312412, acc 1
2016-09-05T17:51:35.078737: step 1613, loss 0.0318041, acc 1
2016-09-05T17:51:35.291710: step 1614, loss 0.0337396, acc 1
2016-09-05T17:51:35.488517: step 1615, loss 0.0291316, acc 1
2016-09-05T17:51:35.733848: step 1616, loss 0.0407969, acc 1
2016-09-05T17:51:35.944082: step 1617, loss 0.0282092, acc 1
2016-09-05T17:51:36.125775: step 1618, loss 0.0332105, acc 1
2016-09-05T17:51:36.332010: step 1619, loss 0.0458146, acc 1
2016-09-05T17:51:36.536228: step 1620, loss 0.0397483, acc 1
2016-09-05T17:51:36.747447: step 1621, loss 0.0581508, acc 0.98
2016-09-05T17:51:36.966994: step 1622, loss 0.0335217, acc 1
2016-09-05T17:51:37.171952: step 1623, loss 0.0295899, acc 1
2016-09-05T17:51:37.360719: step 1624, loss 0.0320577, acc 1
2016-09-05T17:51:37.615598: step 1625, loss 0.0281973, acc 1
2016-09-05T17:51:37.829385: step 1626, loss 0.0423423, acc 1
2016-09-05T17:51:38.044622: step 1627, loss 0.0324197, acc 1
2016-09-05T17:51:38.249928: step 1628, loss 0.0294243, acc 1
2016-09-05T17:51:38.465237: step 1629, loss 0.0291209, acc 1
2016-09-05T17:51:38.667786: step 1630, loss 0.0344196, acc 1
2016-09-05T17:51:38.867966: step 1631, loss 0.0329008, acc 1
2016-09-05T17:51:39.080437: step 1632, loss 0.0451546, acc 1
2016-09-05T17:51:39.291029: step 1633, loss 0.0346036, acc 1
2016-09-05T17:51:39.512148: step 1634, loss 0.0429299, acc 1
2016-09-05T17:51:39.715075: step 1635, loss 0.0368444, acc 1
2016-09-05T17:51:39.910444: step 1636, loss 0.0376445, acc 1
2016-09-05T17:51:40.121645: step 1637, loss 0.0315103, acc 1
2016-09-05T17:51:40.323680: step 1638, loss 0.0310457, acc 1
2016-09-05T17:51:40.526210: step 1639, loss 0.0352999, acc 1
2016-09-05T17:51:40.733494: step 1640, loss 0.0291815, acc 1
2016-09-05T17:51:40.955735: step 1641, loss 0.0392731, acc 1
2016-09-05T17:51:41.155374: step 1642, loss 0.0389328, acc 1
2016-09-05T17:51:41.386692: step 1643, loss 0.0264056, acc 1
2016-09-05T17:51:41.602642: step 1644, loss 0.0371057, acc 1
2016-09-05T17:51:41.816269: step 1645, loss 0.0312944, acc 1
2016-09-05T17:51:42.054484: step 1646, loss 0.0332168, acc 1
2016-09-05T17:51:42.248899: step 1647, loss 0.0255602, acc 1
2016-09-05T17:51:42.451544: step 1648, loss 0.027664, acc 1
2016-09-05T17:51:42.679830: step 1649, loss 0.0335006, acc 1
2016-09-05T17:51:42.874726: step 1650, loss 0.0342509, acc 1
2016-09-05T17:51:43.067924: step 1651, loss 0.0300434, acc 1
2016-09-05T17:51:43.286225: step 1652, loss 0.0300395, acc 1
2016-09-05T17:51:43.491668: step 1653, loss 0.0298338, acc 1
2016-09-05T17:51:43.699980: step 1654, loss 0.0300311, acc 1
2016-09-05T17:51:43.933824: step 1655, loss 0.0351723, acc 1
2016-09-05T17:51:44.139998: step 1656, loss 0.0351563, acc 1
2016-09-05T17:51:44.345261: step 1657, loss 0.0314222, acc 1
2016-09-05T17:51:44.567365: step 1658, loss 0.0479377, acc 1
2016-09-05T17:51:44.778190: step 1659, loss 0.047454, acc 1
2016-09-05T17:51:44.996291: step 1660, loss 0.0324808, acc 1
2016-09-05T17:51:45.201055: step 1661, loss 0.0363999, acc 1
2016-09-05T17:51:45.397922: step 1662, loss 0.0308755, acc 1
2016-09-05T17:51:45.602830: step 1663, loss 0.0316281, acc 1
2016-09-05T17:51:45.814518: step 1664, loss 0.0325933, acc 1
2016-09-05T17:51:46.051821: step 1665, loss 0.0358164, acc 1
2016-09-05T17:51:46.274596: step 1666, loss 0.0262885, acc 1
2016-09-05T17:51:46.522021: step 1667, loss 0.0327113, acc 1
2016-09-05T17:51:46.726845: step 1668, loss 0.0334862, acc 1
2016-09-05T17:51:46.945089: step 1669, loss 0.0305507, acc 1
2016-09-05T17:51:47.142669: step 1670, loss 0.0321523, acc 1
2016-09-05T17:51:47.352843: step 1671, loss 0.0338215, acc 1
2016-09-05T17:51:47.556383: step 1672, loss 0.0328466, acc 1
2016-09-05T17:51:47.774954: step 1673, loss 0.0259062, acc 1
2016-09-05T17:51:47.983959: step 1674, loss 0.0312567, acc 1
2016-09-05T17:51:48.189428: step 1675, loss 0.0299869, acc 1
2016-09-05T17:51:48.390996: step 1676, loss 0.0366952, acc 1
2016-09-05T17:51:48.601816: step 1677, loss 0.0325973, acc 1
2016-09-05T17:51:48.816942: step 1678, loss 0.0343355, acc 1
2016-09-05T17:51:49.011356: step 1679, loss 0.0357104, acc 1
2016-09-05T17:51:49.216923: step 1680, loss 0.0290535, acc 1
2016-09-05T17:51:49.408375: step 1681, loss 0.0345853, acc 1
2016-09-05T17:51:49.606107: step 1682, loss 0.0442082, acc 1
2016-09-05T17:51:49.792777: step 1683, loss 0.034199, acc 1
2016-09-05T17:51:50.009332: step 1684, loss 0.0462086, acc 1
2016-09-05T17:51:50.215099: step 1685, loss 0.0493623, acc 1
2016-09-05T17:51:50.419407: step 1686, loss 0.0383401, acc 1
2016-09-05T17:51:50.606300: step 1687, loss 0.0773039, acc 0.98
2016-09-05T17:51:50.804132: step 1688, loss 0.029737, acc 1
2016-09-05T17:51:51.031613: step 1689, loss 0.0361709, acc 1
2016-09-05T17:51:51.233649: step 1690, loss 0.0282837, acc 1
2016-09-05T17:51:51.444384: step 1691, loss 0.0349431, acc 1
2016-09-05T17:51:51.643387: step 1692, loss 0.0293892, acc 1
2016-09-05T17:51:51.850250: step 1693, loss 0.048638, acc 1
2016-09-05T17:51:52.070335: step 1694, loss 0.0463984, acc 1
2016-09-05T17:51:52.272876: step 1695, loss 0.0369171, acc 1
2016-09-05T17:51:52.475437: step 1696, loss 0.0476352, acc 1
2016-09-05T17:51:52.690729: step 1697, loss 0.0314122, acc 1
2016-09-05T17:51:52.881854: step 1698, loss 0.033604, acc 1
2016-09-05T17:51:53.089572: step 1699, loss 0.0298851, acc 1
2016-09-05T17:51:53.297332: step 1700, loss 0.0344662, acc 1

Evaluation:
2016-09-05T17:51:53.861381: step 1700, loss 0.708835, acc 0.78

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-1700

2016-09-05T17:51:54.604798: step 1701, loss 0.0332887, acc 1
2016-09-05T17:51:54.848261: step 1702, loss 0.0260528, acc 1
2016-09-05T17:51:55.077287: step 1703, loss 0.0360928, acc 1
2016-09-05T17:51:55.321385: step 1704, loss 0.0365608, acc 1
2016-09-05T17:51:55.534155: step 1705, loss 0.0311192, acc 1
2016-09-05T17:51:55.748857: step 1706, loss 0.0368987, acc 1
2016-09-05T17:51:55.957720: step 1707, loss 0.0334729, acc 1
2016-09-05T17:51:56.168966: step 1708, loss 0.0352991, acc 1
2016-09-05T17:51:56.379740: step 1709, loss 0.0317937, acc 1
2016-09-05T17:51:56.584954: step 1710, loss 0.0433539, acc 0.98
2016-09-05T17:51:56.782254: step 1711, loss 0.0332794, acc 1
2016-09-05T17:51:56.996157: step 1712, loss 0.0362773, acc 1
2016-09-05T17:51:57.203548: step 1713, loss 0.0353316, acc 1
2016-09-05T17:51:57.406380: step 1714, loss 0.024906, acc 1
2016-09-05T17:51:57.624337: step 1715, loss 0.0323231, acc 1
2016-09-05T17:51:57.826389: step 1716, loss 0.0305919, acc 1
2016-09-05T17:51:58.022343: step 1717, loss 0.0310046, acc 1
2016-09-05T17:51:58.230367: step 1718, loss 0.038167, acc 1
2016-09-05T17:51:58.432193: step 1719, loss 0.0291895, acc 1
2016-09-05T17:51:58.671951: step 1720, loss 0.0305218, acc 1
2016-09-05T17:51:58.874987: step 1721, loss 0.0281652, acc 1
2016-09-05T17:51:59.072118: step 1722, loss 0.0321049, acc 1
2016-09-05T17:51:59.277716: step 1723, loss 0.0329703, acc 1
2016-09-05T17:51:59.467116: step 1724, loss 0.0381925, acc 1
2016-09-05T17:51:59.672978: step 1725, loss 0.0375446, acc 1
2016-09-05T17:51:59.882216: step 1726, loss 0.0340191, acc 1
2016-09-05T17:52:00.081972: step 1727, loss 0.0272334, acc 1
2016-09-05T17:52:00.296281: step 1728, loss 0.0343964, acc 1
2016-09-05T17:52:00.497773: step 1729, loss 0.0262327, acc 1
2016-09-05T17:52:00.688170: step 1730, loss 0.034449, acc 1
2016-09-05T17:52:00.888345: step 1731, loss 0.0352126, acc 1
2016-09-05T17:52:01.102974: step 1732, loss 0.0315406, acc 1
2016-09-05T17:52:01.352683: step 1733, loss 0.0461595, acc 1
2016-09-05T17:52:01.557696: step 1734, loss 0.037914, acc 1
2016-09-05T17:52:01.770268: step 1735, loss 0.0316746, acc 1
2016-09-05T17:52:01.989767: step 1736, loss 0.0461825, acc 1
2016-09-05T17:52:02.198828: step 1737, loss 0.0352062, acc 1
2016-09-05T17:52:02.411161: step 1738, loss 0.0331989, acc 1
2016-09-05T17:52:02.644671: step 1739, loss 0.0279267, acc 1
2016-09-05T17:52:02.874036: step 1740, loss 0.0276813, acc 1
2016-09-05T17:52:03.080453: step 1741, loss 0.0397669, acc 1
2016-09-05T17:52:03.294944: step 1742, loss 0.0341183, acc 1
2016-09-05T17:52:03.509701: step 1743, loss 0.0295238, acc 1
2016-09-05T17:52:03.710727: step 1744, loss 0.03465, acc 1
2016-09-05T17:52:03.918339: step 1745, loss 0.0325519, acc 1
2016-09-05T17:52:04.036759: step 1746, loss 0.0322356, acc 1
2016-09-05T17:52:04.254776: step 1747, loss 0.0317098, acc 1
2016-09-05T17:52:04.445070: step 1748, loss 0.0282591, acc 1
2016-09-05T17:52:04.642262: step 1749, loss 0.0347408, acc 1
2016-09-05T17:52:04.896896: step 1750, loss 0.0304979, acc 1
2016-09-05T17:52:05.127962: step 1751, loss 0.0374975, acc 1
2016-09-05T17:52:05.334667: step 1752, loss 0.0316175, acc 1
2016-09-05T17:52:05.546253: step 1753, loss 0.0313312, acc 1
2016-09-05T17:52:05.767578: step 1754, loss 0.0272091, acc 1
2016-09-05T17:52:05.973245: step 1755, loss 0.0282777, acc 1
2016-09-05T17:52:06.175114: step 1756, loss 0.0290168, acc 1
2016-09-05T17:52:06.383025: step 1757, loss 0.0267392, acc 1
2016-09-05T17:52:06.624212: step 1758, loss 0.0290604, acc 1
2016-09-05T17:52:06.813400: step 1759, loss 0.0244645, acc 1
2016-09-05T17:52:07.013470: step 1760, loss 0.0265953, acc 1
2016-09-05T17:52:07.210397: step 1761, loss 0.027891, acc 1
2016-09-05T17:52:07.410628: step 1762, loss 0.0285947, acc 1
2016-09-05T17:52:07.622579: step 1763, loss 0.0235803, acc 1
2016-09-05T17:52:07.831369: step 1764, loss 0.0401605, acc 1
2016-09-05T17:52:08.022483: step 1765, loss 0.0341595, acc 1
2016-09-05T17:52:08.238051: step 1766, loss 0.0270554, acc 1
2016-09-05T17:52:08.428779: step 1767, loss 0.0263874, acc 1
2016-09-05T17:52:08.625499: step 1768, loss 0.0302116, acc 1
2016-09-05T17:52:08.828769: step 1769, loss 0.0350692, acc 1
2016-09-05T17:52:09.083556: step 1770, loss 0.0338685, acc 1
2016-09-05T17:52:09.319302: step 1771, loss 0.0231984, acc 1
2016-09-05T17:52:09.547872: step 1772, loss 0.0259385, acc 1
2016-09-05T17:52:09.746654: step 1773, loss 0.0425764, acc 1
2016-09-05T17:52:09.954661: step 1774, loss 0.0326684, acc 1
2016-09-05T17:52:10.151098: step 1775, loss 0.0428947, acc 1
2016-09-05T17:52:10.350302: step 1776, loss 0.0277528, acc 1
2016-09-05T17:52:10.563100: step 1777, loss 0.0275019, acc 1
2016-09-05T17:52:10.770482: step 1778, loss 0.0275573, acc 1
2016-09-05T17:52:10.959314: step 1779, loss 0.0248623, acc 1
2016-09-05T17:52:11.168399: step 1780, loss 0.0335766, acc 1
2016-09-05T17:52:11.364692: step 1781, loss 0.0274504, acc 1
2016-09-05T17:52:11.569567: step 1782, loss 0.0254129, acc 1
2016-09-05T17:52:11.761579: step 1783, loss 0.0323546, acc 1
2016-09-05T17:52:11.943998: step 1784, loss 0.0283722, acc 1
2016-09-05T17:52:12.164981: step 1785, loss 0.0285085, acc 1
2016-09-05T17:52:12.368218: step 1786, loss 0.0251066, acc 1
2016-09-05T17:52:12.580147: step 1787, loss 0.0295609, acc 1
2016-09-05T17:52:12.804852: step 1788, loss 0.0285654, acc 1
2016-09-05T17:52:12.998418: step 1789, loss 0.0289396, acc 1
2016-09-05T17:52:13.195601: step 1790, loss 0.024973, acc 1
2016-09-05T17:52:13.383574: step 1791, loss 0.0309302, acc 1
2016-09-05T17:52:13.580020: step 1792, loss 0.0332109, acc 1
2016-09-05T17:52:13.772762: step 1793, loss 0.0285559, acc 1
2016-09-05T17:52:13.979441: step 1794, loss 0.0336954, acc 1
2016-09-05T17:52:14.167651: step 1795, loss 0.032503, acc 1
2016-09-05T17:52:14.370140: step 1796, loss 0.0294252, acc 1
2016-09-05T17:52:14.599124: step 1797, loss 0.0249809, acc 1
2016-09-05T17:52:14.802815: step 1798, loss 0.0238043, acc 1
2016-09-05T17:52:15.002853: step 1799, loss 0.0345064, acc 1
2016-09-05T17:52:15.194415: step 1800, loss 0.0390337, acc 1

Evaluation:
2016-09-05T17:52:15.747734: step 1800, loss 0.710409, acc 0.774

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-1800

2016-09-05T17:52:16.530266: step 1801, loss 0.0337155, acc 1
2016-09-05T17:52:16.738418: step 1802, loss 0.0308161, acc 1
2016-09-05T17:52:16.947365: step 1803, loss 0.0326467, acc 1
2016-09-05T17:52:17.145612: step 1804, loss 0.0287634, acc 1
2016-09-05T17:52:17.325981: step 1805, loss 0.0253788, acc 1
2016-09-05T17:52:17.570539: step 1806, loss 0.0272858, acc 1
2016-09-05T17:52:17.781385: step 1807, loss 0.0241943, acc 1
2016-09-05T17:52:17.994619: step 1808, loss 0.0259479, acc 1
2016-09-05T17:52:18.211005: step 1809, loss 0.0297187, acc 1
2016-09-05T17:52:18.419975: step 1810, loss 0.0304745, acc 1
2016-09-05T17:52:18.610703: step 1811, loss 0.0273663, acc 1
2016-09-05T17:52:18.806398: step 1812, loss 0.0370083, acc 1
2016-09-05T17:52:19.020997: step 1813, loss 0.030998, acc 1
2016-09-05T17:52:19.231446: step 1814, loss 0.0225266, acc 1
2016-09-05T17:52:19.459786: step 1815, loss 0.0313883, acc 1
2016-09-05T17:52:19.674759: step 1816, loss 0.0222175, acc 1
2016-09-05T17:52:19.920946: step 1817, loss 0.0279704, acc 1
2016-09-05T17:52:20.117936: step 1818, loss 0.0263493, acc 1
2016-09-05T17:52:20.324252: step 1819, loss 0.0289221, acc 1
2016-09-05T17:52:20.521529: step 1820, loss 0.0343031, acc 1
2016-09-05T17:52:20.737528: step 1821, loss 0.032391, acc 1
2016-09-05T17:52:20.960418: step 1822, loss 0.0218191, acc 1
2016-09-05T17:52:21.159155: step 1823, loss 0.0353968, acc 1
2016-09-05T17:52:21.363264: step 1824, loss 0.027148, acc 1
2016-09-05T17:52:21.555417: step 1825, loss 0.0262157, acc 1
2016-09-05T17:52:21.758802: step 1826, loss 0.0253447, acc 1
2016-09-05T17:52:21.987913: step 1827, loss 0.0289608, acc 1
2016-09-05T17:52:22.194664: step 1828, loss 0.0225641, acc 1
2016-09-05T17:52:22.412097: step 1829, loss 0.0290748, acc 1
2016-09-05T17:52:22.609084: step 1830, loss 0.0267493, acc 1
2016-09-05T17:52:22.821307: step 1831, loss 0.0316707, acc 1
2016-09-05T17:52:23.033838: step 1832, loss 0.0238743, acc 1
2016-09-05T17:52:23.248453: step 1833, loss 0.0327536, acc 1
2016-09-05T17:52:23.458022: step 1834, loss 0.0323209, acc 1
2016-09-05T17:52:23.676570: step 1835, loss 0.0337954, acc 1
2016-09-05T17:52:23.930850: step 1836, loss 0.0242809, acc 1
2016-09-05T17:52:24.135966: step 1837, loss 0.0332008, acc 1
2016-09-05T17:52:24.345241: step 1838, loss 0.039355, acc 1
2016-09-05T17:52:24.545583: step 1839, loss 0.0375921, acc 1
2016-09-05T17:52:24.767011: step 1840, loss 0.0324606, acc 1
2016-09-05T17:52:24.966617: step 1841, loss 0.0364847, acc 1
2016-09-05T17:52:25.169032: step 1842, loss 0.0359904, acc 1
2016-09-05T17:52:25.377792: step 1843, loss 0.0371386, acc 1
2016-09-05T17:52:25.573341: step 1844, loss 0.027777, acc 1
2016-09-05T17:52:25.778578: step 1845, loss 0.0236492, acc 1
2016-09-05T17:52:25.984673: step 1846, loss 0.0298994, acc 1
2016-09-05T17:52:26.187677: step 1847, loss 0.0252693, acc 1
2016-09-05T17:52:26.404556: step 1848, loss 0.0250268, acc 1
2016-09-05T17:52:26.607111: step 1849, loss 0.0356828, acc 1
2016-09-05T17:52:26.800729: step 1850, loss 0.0361858, acc 1
2016-09-05T17:52:27.010678: step 1851, loss 0.0262669, acc 1
2016-09-05T17:52:27.210396: step 1852, loss 0.0266232, acc 1
2016-09-05T17:52:27.420792: step 1853, loss 0.0291869, acc 1
2016-09-05T17:52:27.634051: step 1854, loss 0.0291776, acc 1
2016-09-05T17:52:27.885182: step 1855, loss 0.0281606, acc 1
2016-09-05T17:52:28.076386: step 1856, loss 0.0220931, acc 1
2016-09-05T17:52:28.277256: step 1857, loss 0.0370792, acc 1
2016-09-05T17:52:28.477854: step 1858, loss 0.0285038, acc 1
2016-09-05T17:52:28.682265: step 1859, loss 0.0349112, acc 1
2016-09-05T17:52:28.881783: step 1860, loss 0.0282636, acc 1
2016-09-05T17:52:29.078643: step 1861, loss 0.02736, acc 1
2016-09-05T17:52:29.282630: step 1862, loss 0.0239906, acc 1
2016-09-05T17:52:29.500664: step 1863, loss 0.0347834, acc 1
2016-09-05T17:52:29.707596: step 1864, loss 0.0254319, acc 1
2016-09-05T17:52:29.899426: step 1865, loss 0.0303032, acc 1
2016-09-05T17:52:30.105785: step 1866, loss 0.0401396, acc 0.98
2016-09-05T17:52:30.344587: step 1867, loss 0.0370284, acc 1
2016-09-05T17:52:30.575392: step 1868, loss 0.0291151, acc 1
2016-09-05T17:52:30.780079: step 1869, loss 0.0251208, acc 1
2016-09-05T17:52:31.000610: step 1870, loss 0.0264596, acc 1
2016-09-05T17:52:31.246481: step 1871, loss 0.0432022, acc 1
2016-09-05T17:52:31.463408: step 1872, loss 0.0275901, acc 1
2016-09-05T17:52:31.706789: step 1873, loss 0.028334, acc 1
2016-09-05T17:52:31.918587: step 1874, loss 0.0339433, acc 1
2016-09-05T17:52:32.134492: step 1875, loss 0.0234968, acc 1
2016-09-05T17:52:32.355351: step 1876, loss 0.0239036, acc 1
2016-09-05T17:52:32.564286: step 1877, loss 0.0276445, acc 1
2016-09-05T17:52:32.775125: step 1878, loss 0.0252083, acc 1
2016-09-05T17:52:32.995212: step 1879, loss 0.0345744, acc 1
2016-09-05T17:52:33.202783: step 1880, loss 0.029014, acc 1
2016-09-05T17:52:33.434666: step 1881, loss 0.0260899, acc 1
2016-09-05T17:52:33.658243: step 1882, loss 0.0290775, acc 1
2016-09-05T17:52:33.893534: step 1883, loss 0.0285261, acc 1
2016-09-05T17:52:34.106225: step 1884, loss 0.0545431, acc 0.98
2016-09-05T17:52:34.314458: step 1885, loss 0.0350242, acc 1
2016-09-05T17:52:34.517634: step 1886, loss 0.0280727, acc 1
2016-09-05T17:52:34.714956: step 1887, loss 0.0275166, acc 1
2016-09-05T17:52:34.923902: step 1888, loss 0.0302248, acc 1
2016-09-05T17:52:35.141936: step 1889, loss 0.028866, acc 1
2016-09-05T17:52:35.342178: step 1890, loss 0.026137, acc 1
2016-09-05T17:52:35.544742: step 1891, loss 0.0268522, acc 1
2016-09-05T17:52:35.744359: step 1892, loss 0.0344193, acc 1
2016-09-05T17:52:35.934180: step 1893, loss 0.0319348, acc 1
2016-09-05T17:52:36.140128: step 1894, loss 0.0315935, acc 1
2016-09-05T17:52:36.359523: step 1895, loss 0.0307711, acc 1
2016-09-05T17:52:36.553722: step 1896, loss 0.0414863, acc 1
2016-09-05T17:52:36.748456: step 1897, loss 0.0299684, acc 1
2016-09-05T17:52:36.962937: step 1898, loss 0.0280444, acc 1
2016-09-05T17:52:37.154378: step 1899, loss 0.0235825, acc 1
2016-09-05T17:52:37.365474: step 1900, loss 0.0250076, acc 1

Evaluation:
2016-09-05T17:52:37.922952: step 1900, loss 0.742666, acc 0.769

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-1900

2016-09-05T17:52:38.618624: step 1901, loss 0.035321, acc 1
2016-09-05T17:52:38.871577: step 1902, loss 0.0265612, acc 1
2016-09-05T17:52:39.086064: step 1903, loss 0.0455886, acc 1
2016-09-05T17:52:39.305849: step 1904, loss 0.0355903, acc 1
2016-09-05T17:52:39.530025: step 1905, loss 0.0215671, acc 1
2016-09-05T17:52:39.744864: step 1906, loss 0.02828, acc 1
2016-09-05T17:52:39.942985: step 1907, loss 0.0260391, acc 1
2016-09-05T17:52:40.143396: step 1908, loss 0.0255537, acc 1
2016-09-05T17:52:40.342533: step 1909, loss 0.0319804, acc 1
2016-09-05T17:52:40.540335: step 1910, loss 0.0369907, acc 1
2016-09-05T17:52:40.768643: step 1911, loss 0.0347855, acc 1
2016-09-05T17:52:40.960447: step 1912, loss 0.0247191, acc 1
2016-09-05T17:52:41.160159: step 1913, loss 0.0285768, acc 1
2016-09-05T17:52:41.363767: step 1914, loss 0.0270967, acc 1
2016-09-05T17:52:41.568162: step 1915, loss 0.0298692, acc 1
2016-09-05T17:52:41.760567: step 1916, loss 0.0252167, acc 1
2016-09-05T17:52:41.954355: step 1917, loss 0.0278832, acc 1
2016-09-05T17:52:42.161877: step 1918, loss 0.0246969, acc 1
2016-09-05T17:52:42.353341: step 1919, loss 0.0275696, acc 1
2016-09-05T17:52:42.560520: step 1920, loss 0.0309252, acc 1
2016-09-05T17:52:42.757049: step 1921, loss 0.0313373, acc 1
2016-09-05T17:52:42.960038: step 1922, loss 0.0448479, acc 1
2016-09-05T17:52:43.173410: step 1923, loss 0.0583117, acc 0.98
2016-09-05T17:52:43.373934: step 1924, loss 0.0289198, acc 1
2016-09-05T17:52:43.580837: step 1925, loss 0.0476248, acc 0.98
2016-09-05T17:52:43.761370: step 1926, loss 0.0290659, acc 1
2016-09-05T17:52:43.961766: step 1927, loss 0.0267002, acc 1
2016-09-05T17:52:44.179889: step 1928, loss 0.0440524, acc 1
2016-09-05T17:52:44.373403: step 1929, loss 0.0272689, acc 1
2016-09-05T17:52:44.589440: step 1930, loss 0.0290079, acc 1
2016-09-05T17:52:44.780392: step 1931, loss 0.0290876, acc 1
2016-09-05T17:52:44.970741: step 1932, loss 0.0245164, acc 1
2016-09-05T17:52:45.174228: step 1933, loss 0.0333974, acc 1
2016-09-05T17:52:45.382531: step 1934, loss 0.0315262, acc 1
2016-09-05T17:52:45.572313: step 1935, loss 0.0285733, acc 1
2016-09-05T17:52:45.781446: step 1936, loss 0.0279942, acc 1
2016-09-05T17:52:45.985026: step 1937, loss 0.0432384, acc 1
2016-09-05T17:52:46.193217: step 1938, loss 0.0281888, acc 1
2016-09-05T17:52:46.388198: step 1939, loss 0.0427909, acc 1
2016-09-05T17:52:46.505081: step 1940, loss 0.0407041, acc 1
2016-09-05T17:52:46.744025: step 1941, loss 0.0269143, acc 1
2016-09-05T17:52:46.943366: step 1942, loss 0.0285983, acc 1
2016-09-05T17:52:47.143269: step 1943, loss 0.0250621, acc 1
2016-09-05T17:52:47.377311: step 1944, loss 0.0232881, acc 1
2016-09-05T17:52:47.583208: step 1945, loss 0.0238759, acc 1
2016-09-05T17:52:47.788783: step 1946, loss 0.0249503, acc 1
2016-09-05T17:52:47.992295: step 1947, loss 0.0233471, acc 1
2016-09-05T17:52:48.195998: step 1948, loss 0.0261678, acc 1
2016-09-05T17:52:48.412331: step 1949, loss 0.0264637, acc 1
2016-09-05T17:52:48.613228: step 1950, loss 0.0292223, acc 1
2016-09-05T17:52:48.822002: step 1951, loss 0.0227565, acc 1
2016-09-05T17:52:49.030500: step 1952, loss 0.0256919, acc 1
2016-09-05T17:52:49.253094: step 1953, loss 0.0202979, acc 1
2016-09-05T17:52:49.496509: step 1954, loss 0.0223822, acc 1
2016-09-05T17:52:49.699925: step 1955, loss 0.027917, acc 1
2016-09-05T17:52:49.910421: step 1956, loss 0.0266559, acc 1
2016-09-05T17:52:50.102530: step 1957, loss 0.0312185, acc 1
2016-09-05T17:52:50.283670: step 1958, loss 0.0375542, acc 1
2016-09-05T17:52:50.487653: step 1959, loss 0.0274595, acc 1
2016-09-05T17:52:50.706098: step 1960, loss 0.0224843, acc 1
2016-09-05T17:52:50.896005: step 1961, loss 0.0215175, acc 1
2016-09-05T17:52:51.112956: step 1962, loss 0.0364441, acc 1
2016-09-05T17:52:51.320146: step 1963, loss 0.0327276, acc 1
2016-09-05T17:52:51.519066: step 1964, loss 0.0234357, acc 1
2016-09-05T17:52:51.732977: step 1965, loss 0.0226325, acc 1
2016-09-05T17:52:51.968328: step 1966, loss 0.0313253, acc 1
2016-09-05T17:52:52.168393: step 1967, loss 0.0241997, acc 1
2016-09-05T17:52:52.372989: step 1968, loss 0.0240039, acc 1
2016-09-05T17:52:52.587372: step 1969, loss 0.0273529, acc 1
2016-09-05T17:52:52.798230: step 1970, loss 0.0250037, acc 1
2016-09-05T17:52:53.000644: step 1971, loss 0.0231633, acc 1
2016-09-05T17:52:53.231373: step 1972, loss 0.0293932, acc 1
2016-09-05T17:52:53.440371: step 1973, loss 0.0275091, acc 1
2016-09-05T17:52:53.686295: step 1974, loss 0.0247697, acc 1
2016-09-05T17:52:53.889917: step 1975, loss 0.0252665, acc 1
2016-09-05T17:52:54.117646: step 1976, loss 0.0316178, acc 1
2016-09-05T17:52:54.342292: step 1977, loss 0.0255695, acc 1
2016-09-05T17:52:54.558018: step 1978, loss 0.0281859, acc 1
2016-09-05T17:52:54.774697: step 1979, loss 0.0219387, acc 1
2016-09-05T17:52:54.985735: step 1980, loss 0.0311687, acc 1
2016-09-05T17:52:55.207099: step 1981, loss 0.024995, acc 1
2016-09-05T17:52:55.430070: step 1982, loss 0.0251286, acc 1
2016-09-05T17:52:55.635075: step 1983, loss 0.0231823, acc 1
2016-09-05T17:52:55.845935: step 1984, loss 0.0220744, acc 1
2016-09-05T17:52:56.061316: step 1985, loss 0.0248187, acc 1
2016-09-05T17:52:56.263703: step 1986, loss 0.0255188, acc 1
2016-09-05T17:52:56.495619: step 1987, loss 0.0316641, acc 1
2016-09-05T17:52:56.732162: step 1988, loss 0.0238962, acc 1
2016-09-05T17:52:56.943462: step 1989, loss 0.0271859, acc 1
2016-09-05T17:52:57.148530: step 1990, loss 0.0254046, acc 1
2016-09-05T17:52:57.356245: step 1991, loss 0.0243562, acc 1
2016-09-05T17:52:57.557182: step 1992, loss 0.0301672, acc 1
2016-09-05T17:52:57.763847: step 1993, loss 0.0271035, acc 1
2016-09-05T17:52:57.979135: step 1994, loss 0.0235335, acc 1
2016-09-05T17:52:58.180809: step 1995, loss 0.0283497, acc 1
2016-09-05T17:52:58.437892: step 1996, loss 0.024635, acc 1
2016-09-05T17:52:58.623837: step 1997, loss 0.0217369, acc 1
2016-09-05T17:52:58.823617: step 1998, loss 0.0212567, acc 1
2016-09-05T17:52:59.047906: step 1999, loss 0.0225391, acc 1
2016-09-05T17:52:59.238865: step 2000, loss 0.0245052, acc 1

Evaluation:
2016-09-05T17:52:59.783375: step 2000, loss 0.735442, acc 0.762

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-2000

2016-09-05T17:53:00.511590: step 2001, loss 0.0227072, acc 1
2016-09-05T17:53:00.720018: step 2002, loss 0.0313056, acc 1
2016-09-05T17:53:00.940859: step 2003, loss 0.0356286, acc 1
2016-09-05T17:53:01.154822: step 2004, loss 0.0392905, acc 1
2016-09-05T17:53:01.356722: step 2005, loss 0.0274496, acc 1
2016-09-05T17:53:01.562789: step 2006, loss 0.0287661, acc 1
2016-09-05T17:53:01.760464: step 2007, loss 0.0282679, acc 1
2016-09-05T17:53:01.974534: step 2008, loss 0.0240839, acc 1
2016-09-05T17:53:02.168470: step 2009, loss 0.0243099, acc 1
2016-09-05T17:53:02.370530: step 2010, loss 0.0304301, acc 1
2016-09-05T17:53:02.564097: step 2011, loss 0.0244671, acc 1
2016-09-05T17:53:02.765720: step 2012, loss 0.0206046, acc 1
2016-09-05T17:53:02.995104: step 2013, loss 0.0243336, acc 1
2016-09-05T17:53:03.207595: step 2014, loss 0.0221365, acc 1
2016-09-05T17:53:03.420056: step 2015, loss 0.0234843, acc 1
2016-09-05T17:53:03.621612: step 2016, loss 0.0273644, acc 1
2016-09-05T17:53:03.873062: step 2017, loss 0.0255347, acc 1
2016-09-05T17:53:04.069332: step 2018, loss 0.0304623, acc 1
2016-09-05T17:53:04.274181: step 2019, loss 0.0214072, acc 1
2016-09-05T17:53:04.485118: step 2020, loss 0.0272928, acc 1
2016-09-05T17:53:04.694172: step 2021, loss 0.023709, acc 1
2016-09-05T17:53:04.892585: step 2022, loss 0.0253517, acc 1
2016-09-05T17:53:05.088791: step 2023, loss 0.0237076, acc 1
2016-09-05T17:53:05.289074: step 2024, loss 0.0312117, acc 1
2016-09-05T17:53:05.472346: step 2025, loss 0.0223468, acc 1
2016-09-05T17:53:05.680117: step 2026, loss 0.021779, acc 1
2016-09-05T17:53:05.899693: step 2027, loss 0.0230442, acc 1
2016-09-05T17:53:06.105440: step 2028, loss 0.0207209, acc 1
2016-09-05T17:53:06.304151: step 2029, loss 0.0217218, acc 1
2016-09-05T17:53:06.521188: step 2030, loss 0.0223132, acc 1
2016-09-05T17:53:06.730003: step 2031, loss 0.025059, acc 1
2016-09-05T17:53:06.975888: step 2032, loss 0.0379277, acc 1
2016-09-05T17:53:07.219744: step 2033, loss 0.0379978, acc 1
2016-09-05T17:53:07.429030: step 2034, loss 0.0278984, acc 1
2016-09-05T17:53:07.637185: step 2035, loss 0.0371505, acc 1
2016-09-05T17:53:07.854719: step 2036, loss 0.0372589, acc 1
2016-09-05T17:53:08.071978: step 2037, loss 0.0229884, acc 1
2016-09-05T17:53:08.312117: step 2038, loss 0.0203529, acc 1
2016-09-05T17:53:08.505380: step 2039, loss 0.0344757, acc 1
2016-09-05T17:53:08.734538: step 2040, loss 0.0215005, acc 1
2016-09-05T17:53:08.953232: step 2041, loss 0.0230048, acc 1
2016-09-05T17:53:09.161299: step 2042, loss 0.0278054, acc 1
2016-09-05T17:53:09.362995: step 2043, loss 0.0304687, acc 1
2016-09-05T17:53:09.581988: step 2044, loss 0.0242185, acc 1
2016-09-05T17:53:09.796525: step 2045, loss 0.0242301, acc 1
2016-09-05T17:53:10.006580: step 2046, loss 0.0213514, acc 1
2016-09-05T17:53:10.194091: step 2047, loss 0.0313675, acc 1
2016-09-05T17:53:10.397408: step 2048, loss 0.0270604, acc 1
2016-09-05T17:53:10.610624: step 2049, loss 0.0275548, acc 1
2016-09-05T17:53:10.830304: step 2050, loss 0.0234839, acc 1
2016-09-05T17:53:11.048125: step 2051, loss 0.0251212, acc 1
2016-09-05T17:53:11.247980: step 2052, loss 0.0287254, acc 1
2016-09-05T17:53:11.432428: step 2053, loss 0.0217116, acc 1
2016-09-05T17:53:11.635443: step 2054, loss 0.0343706, acc 1
2016-09-05T17:53:11.851569: step 2055, loss 0.0272058, acc 1
2016-09-05T17:53:12.046484: step 2056, loss 0.0254174, acc 1
2016-09-05T17:53:12.239306: step 2057, loss 0.0212963, acc 1
2016-09-05T17:53:12.446565: step 2058, loss 0.0265318, acc 1
2016-09-05T17:53:12.628550: step 2059, loss 0.0281509, acc 1
2016-09-05T17:53:12.839454: step 2060, loss 0.02821, acc 1
2016-09-05T17:53:13.036529: step 2061, loss 0.0188313, acc 1
2016-09-05T17:53:13.240993: step 2062, loss 0.0257373, acc 1
2016-09-05T17:53:13.463344: step 2063, loss 0.0343593, acc 1
2016-09-05T17:53:13.673857: step 2064, loss 0.0309752, acc 1
2016-09-05T17:53:13.864911: step 2065, loss 0.0382605, acc 1
2016-09-05T17:53:14.061024: step 2066, loss 0.0262105, acc 1
2016-09-05T17:53:14.257637: step 2067, loss 0.0233513, acc 1
2016-09-05T17:53:14.448716: step 2068, loss 0.026279, acc 1
2016-09-05T17:53:14.655548: step 2069, loss 0.0256357, acc 1
2016-09-05T17:53:14.851297: step 2070, loss 0.029124, acc 1
2016-09-05T17:53:15.063170: step 2071, loss 0.0265445, acc 1
2016-09-05T17:53:15.253261: step 2072, loss 0.0198137, acc 1
2016-09-05T17:53:15.459492: step 2073, loss 0.022944, acc 1
2016-09-05T17:53:15.661408: step 2074, loss 0.0240237, acc 1
2016-09-05T17:53:15.864809: step 2075, loss 0.0241529, acc 1
2016-09-05T17:53:16.069592: step 2076, loss 0.0260282, acc 1
2016-09-05T17:53:16.260692: step 2077, loss 0.0257752, acc 1
2016-09-05T17:53:16.457424: step 2078, loss 0.0307215, acc 1
2016-09-05T17:53:16.673582: step 2079, loss 0.0228104, acc 1
2016-09-05T17:53:16.924747: step 2080, loss 0.0255104, acc 1
2016-09-05T17:53:17.117715: step 2081, loss 0.0204671, acc 1
2016-09-05T17:53:17.314910: step 2082, loss 0.0236357, acc 1
2016-09-05T17:53:17.501545: step 2083, loss 0.0225036, acc 1
2016-09-05T17:53:17.707493: step 2084, loss 0.0207103, acc 1
2016-09-05T17:53:17.902156: step 2085, loss 0.0257622, acc 1
2016-09-05T17:53:18.097915: step 2086, loss 0.0227355, acc 1
2016-09-05T17:53:18.344450: step 2087, loss 0.0209044, acc 1
2016-09-05T17:53:18.552473: step 2088, loss 0.0266676, acc 1
2016-09-05T17:53:18.770054: step 2089, loss 0.0248587, acc 1
2016-09-05T17:53:18.978367: step 2090, loss 0.0222472, acc 1
2016-09-05T17:53:19.213920: step 2091, loss 0.0235329, acc 1
2016-09-05T17:53:19.418827: step 2092, loss 0.0238027, acc 1
2016-09-05T17:53:19.642150: step 2093, loss 0.0237589, acc 1
2016-09-05T17:53:19.856877: step 2094, loss 0.0260349, acc 1
2016-09-05T17:53:20.047800: step 2095, loss 0.0280443, acc 1
2016-09-05T17:53:20.242652: step 2096, loss 0.0258634, acc 1
2016-09-05T17:53:20.465239: step 2097, loss 0.0484413, acc 0.98
2016-09-05T17:53:20.663783: step 2098, loss 0.0304295, acc 1
2016-09-05T17:53:20.889761: step 2099, loss 0.0280238, acc 1
2016-09-05T17:53:21.105028: step 2100, loss 0.0265854, acc 1

Evaluation:
2016-09-05T17:53:21.702179: step 2100, loss 0.758581, acc 0.764

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-2100

2016-09-05T17:53:22.412256: step 2101, loss 0.0242106, acc 1
2016-09-05T17:53:22.602549: step 2102, loss 0.0210475, acc 1
2016-09-05T17:53:22.810441: step 2103, loss 0.0259625, acc 1
2016-09-05T17:53:23.009414: step 2104, loss 0.0272579, acc 1
2016-09-05T17:53:23.202125: step 2105, loss 0.0354003, acc 1
2016-09-05T17:53:23.393370: step 2106, loss 0.0231957, acc 1
2016-09-05T17:53:23.599393: step 2107, loss 0.0252342, acc 1
2016-09-05T17:53:23.781402: step 2108, loss 0.0228449, acc 1
2016-09-05T17:53:23.978314: step 2109, loss 0.0327433, acc 1
2016-09-05T17:53:24.188868: step 2110, loss 0.0287822, acc 1
2016-09-05T17:53:24.397340: step 2111, loss 0.0280726, acc 1
2016-09-05T17:53:24.598772: step 2112, loss 0.0301154, acc 1
2016-09-05T17:53:24.825999: step 2113, loss 0.0371138, acc 1
2016-09-05T17:53:25.023346: step 2114, loss 0.0252295, acc 1
2016-09-05T17:53:25.221462: step 2115, loss 0.0233504, acc 1
2016-09-05T17:53:25.416566: step 2116, loss 0.0263241, acc 1
2016-09-05T17:53:25.615256: step 2117, loss 0.0295954, acc 1
2016-09-05T17:53:25.811746: step 2118, loss 0.0227003, acc 1
2016-09-05T17:53:26.020160: step 2119, loss 0.0223038, acc 1
2016-09-05T17:53:26.206924: step 2120, loss 0.0213994, acc 1
2016-09-05T17:53:26.406587: step 2121, loss 0.0262014, acc 1
2016-09-05T17:53:26.610351: step 2122, loss 0.0227065, acc 1
2016-09-05T17:53:26.808377: step 2123, loss 0.0378655, acc 1
2016-09-05T17:53:27.028404: step 2124, loss 0.0257083, acc 1
2016-09-05T17:53:27.220078: step 2125, loss 0.0380693, acc 1
2016-09-05T17:53:27.423873: step 2126, loss 0.0240622, acc 1
2016-09-05T17:53:27.623129: step 2127, loss 0.0258197, acc 1
2016-09-05T17:53:27.840904: step 2128, loss 0.0324824, acc 1
2016-09-05T17:53:28.046583: step 2129, loss 0.0226297, acc 1
2016-09-05T17:53:28.257712: step 2130, loss 0.0212405, acc 1
2016-09-05T17:53:28.456658: step 2131, loss 0.0209553, acc 1
2016-09-05T17:53:28.713540: step 2132, loss 0.0419241, acc 1
2016-09-05T17:53:28.935405: step 2133, loss 0.0229502, acc 1
2016-09-05T17:53:29.068293: step 2134, loss 0.0199593, acc 1
2016-09-05T17:53:29.292755: step 2135, loss 0.0194529, acc 1
2016-09-05T17:53:29.491895: step 2136, loss 0.0209222, acc 1
2016-09-05T17:53:29.695510: step 2137, loss 0.0329058, acc 1
2016-09-05T17:53:29.884304: step 2138, loss 0.0219603, acc 1
2016-09-05T17:53:30.079030: step 2139, loss 0.0219813, acc 1
2016-09-05T17:53:30.342383: step 2140, loss 0.0195245, acc 1
2016-09-05T17:53:30.571921: step 2141, loss 0.0221569, acc 1
2016-09-05T17:53:30.768355: step 2142, loss 0.0221363, acc 1
2016-09-05T17:53:30.979627: step 2143, loss 0.0242846, acc 1
2016-09-05T17:53:31.230748: step 2144, loss 0.0193037, acc 1
2016-09-05T17:53:31.441384: step 2145, loss 0.0227249, acc 1
2016-09-05T17:53:31.642551: step 2146, loss 0.0207871, acc 1
2016-09-05T17:53:31.836991: step 2147, loss 0.0208956, acc 1
2016-09-05T17:53:32.041269: step 2148, loss 0.0188595, acc 1
2016-09-05T17:53:32.268303: step 2149, loss 0.0301152, acc 1
2016-09-05T17:53:32.473226: step 2150, loss 0.019705, acc 1
2016-09-05T17:53:32.677612: step 2151, loss 0.0205002, acc 1
2016-09-05T17:53:32.885439: step 2152, loss 0.023414, acc 1
2016-09-05T17:53:33.124250: step 2153, loss 0.029194, acc 1
2016-09-05T17:53:33.329606: step 2154, loss 0.0228654, acc 1
2016-09-05T17:53:33.550781: step 2155, loss 0.0211369, acc 1
2016-09-05T17:53:33.772556: step 2156, loss 0.0232388, acc 1
2016-09-05T17:53:33.980100: step 2157, loss 0.0253739, acc 1
2016-09-05T17:53:34.195584: step 2158, loss 0.0232368, acc 1
2016-09-05T17:53:34.408404: step 2159, loss 0.0216379, acc 1
2016-09-05T17:53:34.611036: step 2160, loss 0.0257085, acc 1
2016-09-05T17:53:34.814619: step 2161, loss 0.0199726, acc 1
2016-09-05T17:53:35.028963: step 2162, loss 0.0224777, acc 1
2016-09-05T17:53:35.244808: step 2163, loss 0.0192443, acc 1
2016-09-05T17:53:35.448624: step 2164, loss 0.0248003, acc 1
2016-09-05T17:53:35.653331: step 2165, loss 0.0237261, acc 1
2016-09-05T17:53:35.870907: step 2166, loss 0.0213329, acc 1
2016-09-05T17:53:36.081224: step 2167, loss 0.0189527, acc 1
2016-09-05T17:53:36.288135: step 2168, loss 0.0235299, acc 1
2016-09-05T17:53:36.493649: step 2169, loss 0.019581, acc 1
2016-09-05T17:53:36.704079: step 2170, loss 0.0220333, acc 1
2016-09-05T17:53:36.910662: step 2171, loss 0.0242528, acc 1
2016-09-05T17:53:37.151640: step 2172, loss 0.0206273, acc 1
2016-09-05T17:53:37.389602: step 2173, loss 0.0240834, acc 1
2016-09-05T17:53:37.606773: step 2174, loss 0.0223205, acc 1
2016-09-05T17:53:37.806000: step 2175, loss 0.0198712, acc 1
2016-09-05T17:53:37.993413: step 2176, loss 0.0190939, acc 1
2016-09-05T17:53:38.195942: step 2177, loss 0.0310624, acc 1
2016-09-05T17:53:38.421243: step 2178, loss 0.025161, acc 1
2016-09-05T17:53:38.668400: step 2179, loss 0.026777, acc 1
2016-09-05T17:53:38.890900: step 2180, loss 0.0268149, acc 1
2016-09-05T17:53:39.092849: step 2181, loss 0.0221022, acc 1
2016-09-05T17:53:39.328044: step 2182, loss 0.0254551, acc 1
2016-09-05T17:53:39.546695: step 2183, loss 0.0213332, acc 1
2016-09-05T17:53:39.755085: step 2184, loss 0.0228147, acc 1
2016-09-05T17:53:40.009312: step 2185, loss 0.019767, acc 1
2016-09-05T17:53:40.261352: step 2186, loss 0.0254397, acc 1
2016-09-05T17:53:40.493467: step 2187, loss 0.0199671, acc 1
2016-09-05T17:53:40.717450: step 2188, loss 0.0227585, acc 1
2016-09-05T17:53:40.925754: step 2189, loss 0.0224778, acc 1
2016-09-05T17:53:41.139379: step 2190, loss 0.0218158, acc 1
2016-09-05T17:53:41.357808: step 2191, loss 0.022062, acc 1
2016-09-05T17:53:41.570670: step 2192, loss 0.0265106, acc 1
2016-09-05T17:53:41.773472: step 2193, loss 0.0264709, acc 1
2016-09-05T17:53:41.982428: step 2194, loss 0.0239528, acc 1
2016-09-05T17:53:42.179128: step 2195, loss 0.0203452, acc 1
2016-09-05T17:53:42.392007: step 2196, loss 0.0185736, acc 1
2016-09-05T17:53:42.605521: step 2197, loss 0.0186427, acc 1
2016-09-05T17:53:42.844147: step 2198, loss 0.025309, acc 1
2016-09-05T17:53:43.061469: step 2199, loss 0.0223825, acc 1
2016-09-05T17:53:43.262968: step 2200, loss 0.0252291, acc 1

Evaluation:
2016-09-05T17:53:43.845680: step 2200, loss 0.768121, acc 0.762

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-2200

2016-09-05T17:53:44.558839: step 2201, loss 0.0221452, acc 1
2016-09-05T17:53:44.777768: step 2202, loss 0.02403, acc 1
2016-09-05T17:53:45.044490: step 2203, loss 0.0240251, acc 1
2016-09-05T17:53:45.249131: step 2204, loss 0.0326908, acc 1
2016-09-05T17:53:45.455731: step 2205, loss 0.0267808, acc 1
2016-09-05T17:53:45.661583: step 2206, loss 0.0203195, acc 1
2016-09-05T17:53:45.853822: step 2207, loss 0.023463, acc 1
2016-09-05T17:53:46.054462: step 2208, loss 0.0182888, acc 1
2016-09-05T17:53:46.268074: step 2209, loss 0.0233485, acc 1
2016-09-05T17:53:46.454952: step 2210, loss 0.0232159, acc 1
2016-09-05T17:53:46.644117: step 2211, loss 0.0249226, acc 1
2016-09-05T17:53:46.847643: step 2212, loss 0.0220019, acc 1
2016-09-05T17:53:47.062618: step 2213, loss 0.0294504, acc 1
2016-09-05T17:53:47.273474: step 2214, loss 0.0220883, acc 1
2016-09-05T17:53:47.490503: step 2215, loss 0.0202459, acc 1
2016-09-05T17:53:47.700611: step 2216, loss 0.0209608, acc 1
2016-09-05T17:53:47.921345: step 2217, loss 0.021276, acc 1
2016-09-05T17:53:48.116612: step 2218, loss 0.0203262, acc 1
2016-09-05T17:53:48.327734: step 2219, loss 0.021386, acc 1
2016-09-05T17:53:48.535862: step 2220, loss 0.0260377, acc 1
2016-09-05T17:53:48.757491: step 2221, loss 0.0227357, acc 1
2016-09-05T17:53:48.969067: step 2222, loss 0.022569, acc 1
2016-09-05T17:53:49.171567: step 2223, loss 0.020555, acc 1
2016-09-05T17:53:49.365037: step 2224, loss 0.0285661, acc 1
2016-09-05T17:53:49.559869: step 2225, loss 0.0251296, acc 1
2016-09-05T17:53:49.762186: step 2226, loss 0.0225638, acc 1
2016-09-05T17:53:49.971695: step 2227, loss 0.0261743, acc 1
2016-09-05T17:53:50.198740: step 2228, loss 0.0184294, acc 1
2016-09-05T17:53:50.410775: step 2229, loss 0.0268785, acc 1
2016-09-05T17:53:50.596609: step 2230, loss 0.0198253, acc 1
2016-09-05T17:53:50.795617: step 2231, loss 0.0211954, acc 1
2016-09-05T17:53:50.997011: step 2232, loss 0.0192622, acc 1
2016-09-05T17:53:51.193908: step 2233, loss 0.0219779, acc 1
2016-09-05T17:53:51.397414: step 2234, loss 0.0253076, acc 1
2016-09-05T17:53:51.584866: step 2235, loss 0.0238694, acc 1
2016-09-05T17:53:51.781395: step 2236, loss 0.0176821, acc 1
2016-09-05T17:53:51.977078: step 2237, loss 0.0229162, acc 1
2016-09-05T17:53:52.193375: step 2238, loss 0.0267007, acc 1
2016-09-05T17:53:52.389396: step 2239, loss 0.0274052, acc 1
2016-09-05T17:53:52.585470: step 2240, loss 0.0202794, acc 1
2016-09-05T17:53:52.794204: step 2241, loss 0.0244152, acc 1
2016-09-05T17:53:53.003885: step 2242, loss 0.0250097, acc 1
2016-09-05T17:53:53.195640: step 2243, loss 0.020048, acc 1
2016-09-05T17:53:53.405738: step 2244, loss 0.0210394, acc 1
2016-09-05T17:53:53.597433: step 2245, loss 0.0202526, acc 1
2016-09-05T17:53:53.796034: step 2246, loss 0.0232063, acc 1
2016-09-05T17:53:54.007591: step 2247, loss 0.0185423, acc 1
2016-09-05T17:53:54.223389: step 2248, loss 0.0231981, acc 1
2016-09-05T17:53:54.474921: step 2249, loss 0.0209231, acc 1
2016-09-05T17:53:54.699549: step 2250, loss 0.0252266, acc 1
2016-09-05T17:53:54.918314: step 2251, loss 0.0178718, acc 1
2016-09-05T17:53:55.124739: step 2252, loss 0.0251155, acc 1
2016-09-05T17:53:55.327525: step 2253, loss 0.0204417, acc 1
2016-09-05T17:53:55.540215: step 2254, loss 0.0234107, acc 1
2016-09-05T17:53:55.786148: step 2255, loss 0.0218326, acc 1
2016-09-05T17:53:56.008104: step 2256, loss 0.0251011, acc 1
2016-09-05T17:53:56.204442: step 2257, loss 0.0289194, acc 1
2016-09-05T17:53:56.458445: step 2258, loss 0.0221841, acc 1
2016-09-05T17:53:56.733303: step 2259, loss 0.0244581, acc 1
2016-09-05T17:53:56.951716: step 2260, loss 0.027363, acc 1
2016-09-05T17:53:57.166819: step 2261, loss 0.0205863, acc 1
2016-09-05T17:53:57.369699: step 2262, loss 0.0197017, acc 1
2016-09-05T17:53:57.576551: step 2263, loss 0.0228767, acc 1
2016-09-05T17:53:57.790803: step 2264, loss 0.0174497, acc 1
2016-09-05T17:53:57.981738: step 2265, loss 0.0213818, acc 1
2016-09-05T17:53:58.183176: step 2266, loss 0.0215194, acc 1
2016-09-05T17:53:58.426489: step 2267, loss 0.0218105, acc 1
2016-09-05T17:53:58.653045: step 2268, loss 0.0254831, acc 1
2016-09-05T17:53:58.892906: step 2269, loss 0.0237017, acc 1
2016-09-05T17:53:59.103141: step 2270, loss 0.021597, acc 1
2016-09-05T17:53:59.297478: step 2271, loss 0.0232814, acc 1
2016-09-05T17:53:59.501360: step 2272, loss 0.0242175, acc 1
2016-09-05T17:53:59.709682: step 2273, loss 0.0225548, acc 1
2016-09-05T17:53:59.939482: step 2274, loss 0.0243697, acc 1
2016-09-05T17:54:00.145722: step 2275, loss 0.0217052, acc 1
2016-09-05T17:54:00.365077: step 2276, loss 0.0178889, acc 1
2016-09-05T17:54:00.562817: step 2277, loss 0.0215311, acc 1
2016-09-05T17:54:00.753267: step 2278, loss 0.0265126, acc 1
2016-09-05T17:54:00.956721: step 2279, loss 0.0213208, acc 1
2016-09-05T17:54:01.168559: step 2280, loss 0.0211065, acc 1
2016-09-05T17:54:01.364842: step 2281, loss 0.0251342, acc 1
2016-09-05T17:54:01.577991: step 2282, loss 0.0311154, acc 1
2016-09-05T17:54:01.786661: step 2283, loss 0.0215013, acc 1
2016-09-05T17:54:02.001942: step 2284, loss 0.0258094, acc 1
2016-09-05T17:54:02.208590: step 2285, loss 0.0192949, acc 1
2016-09-05T17:54:02.415162: step 2286, loss 0.0289078, acc 1
2016-09-05T17:54:02.615900: step 2287, loss 0.0238449, acc 1
2016-09-05T17:54:02.812180: step 2288, loss 0.0209753, acc 1
2016-09-05T17:54:03.025646: step 2289, loss 0.0269673, acc 1
2016-09-05T17:54:03.223685: step 2290, loss 0.0241679, acc 1
2016-09-05T17:54:03.431298: step 2291, loss 0.0200944, acc 1
2016-09-05T17:54:03.641667: step 2292, loss 0.0194419, acc 1
2016-09-05T17:54:03.843890: step 2293, loss 0.0271152, acc 1
2016-09-05T17:54:04.055910: step 2294, loss 0.0277884, acc 1
2016-09-05T17:54:04.249637: step 2295, loss 0.0248072, acc 1
2016-09-05T17:54:04.455876: step 2296, loss 0.0325145, acc 1
2016-09-05T17:54:04.658835: step 2297, loss 0.023671, acc 1
2016-09-05T17:54:04.862645: step 2298, loss 0.0221833, acc 1
2016-09-05T17:54:05.075320: step 2299, loss 0.0218337, acc 1
2016-09-05T17:54:05.270930: step 2300, loss 0.0229371, acc 1

Evaluation:
2016-09-05T17:54:05.836375: step 2300, loss 0.801437, acc 0.763

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-2300

2016-09-05T17:54:06.638593: step 2301, loss 0.0207476, acc 1
2016-09-05T17:54:06.866954: step 2302, loss 0.0382815, acc 1
2016-09-05T17:54:07.090546: step 2303, loss 0.0213991, acc 1
2016-09-05T17:54:07.285569: step 2304, loss 0.0280638, acc 1
2016-09-05T17:54:07.492065: step 2305, loss 0.0253309, acc 1
2016-09-05T17:54:07.690799: step 2306, loss 0.0195088, acc 1
2016-09-05T17:54:07.895803: step 2307, loss 0.0245553, acc 1
2016-09-05T17:54:08.117739: step 2308, loss 0.0211193, acc 1
2016-09-05T17:54:08.328511: step 2309, loss 0.0238852, acc 1
2016-09-05T17:54:08.530174: step 2310, loss 0.0186358, acc 1
2016-09-05T17:54:08.724107: step 2311, loss 0.0228743, acc 1
2016-09-05T17:54:08.929249: step 2312, loss 0.023768, acc 1
2016-09-05T17:54:09.150687: step 2313, loss 0.0238683, acc 1
2016-09-05T17:54:09.367229: step 2314, loss 0.0227307, acc 1
2016-09-05T17:54:09.576578: step 2315, loss 0.028908, acc 1
2016-09-05T17:54:09.782170: step 2316, loss 0.0196134, acc 1
2016-09-05T17:54:09.989992: step 2317, loss 0.0185869, acc 1
2016-09-05T17:54:10.185869: step 2318, loss 0.035047, acc 1
2016-09-05T17:54:10.397647: step 2319, loss 0.0222466, acc 1
2016-09-05T17:54:10.592181: step 2320, loss 0.0179024, acc 1
2016-09-05T17:54:10.803239: step 2321, loss 0.0226587, acc 1
2016-09-05T17:54:11.014242: step 2322, loss 0.0259178, acc 1
2016-09-05T17:54:11.213146: step 2323, loss 0.01998, acc 1
2016-09-05T17:54:11.402735: step 2324, loss 0.0298666, acc 1
2016-09-05T17:54:11.629658: step 2325, loss 0.0251767, acc 1
2016-09-05T17:54:11.832448: step 2326, loss 0.031333, acc 1
2016-09-05T17:54:12.039770: step 2327, loss 0.0195213, acc 1
2016-09-05T17:54:12.159640: step 2328, loss 0.0262189, acc 1
2016-09-05T17:54:12.378417: step 2329, loss 0.0232404, acc 1
2016-09-05T17:54:12.618606: step 2330, loss 0.0175186, acc 1
2016-09-05T17:54:12.825366: step 2331, loss 0.0221338, acc 1
2016-09-05T17:54:13.016265: step 2332, loss 0.022338, acc 1
2016-09-05T17:54:13.207771: step 2333, loss 0.0219152, acc 1
2016-09-05T17:54:13.430102: step 2334, loss 0.0199172, acc 1
2016-09-05T17:54:13.653721: step 2335, loss 0.0177584, acc 1
2016-09-05T17:54:13.894057: step 2336, loss 0.0238098, acc 1
2016-09-05T17:54:14.105071: step 2337, loss 0.0193341, acc 1
2016-09-05T17:54:14.346508: step 2338, loss 0.019882, acc 1
2016-09-05T17:54:14.545371: step 2339, loss 0.0227754, acc 1
2016-09-05T17:54:14.746273: step 2340, loss 0.0229157, acc 1
2016-09-05T17:54:14.957218: step 2341, loss 0.0287207, acc 1
2016-09-05T17:54:15.175239: step 2342, loss 0.0180598, acc 1
2016-09-05T17:54:15.366286: step 2343, loss 0.0211887, acc 1
2016-09-05T17:54:15.584619: step 2344, loss 0.0202223, acc 1
2016-09-05T17:54:15.823236: step 2345, loss 0.0193447, acc 1
2016-09-05T17:54:16.039364: step 2346, loss 0.0188473, acc 1
2016-09-05T17:54:16.247121: step 2347, loss 0.0198682, acc 1
2016-09-05T17:54:16.443858: step 2348, loss 0.0201125, acc 1
2016-09-05T17:54:16.644469: step 2349, loss 0.0202193, acc 1
2016-09-05T17:54:16.861166: step 2350, loss 0.0383802, acc 0.98
2016-09-05T17:54:17.070088: step 2351, loss 0.018152, acc 1
2016-09-05T17:54:17.264175: step 2352, loss 0.0181275, acc 1
2016-09-05T17:54:17.456146: step 2353, loss 0.016926, acc 1
2016-09-05T17:54:17.664417: step 2354, loss 0.0182271, acc 1
2016-09-05T17:54:17.876261: step 2355, loss 0.0208752, acc 1
2016-09-05T17:54:18.083389: step 2356, loss 0.0239805, acc 1
2016-09-05T17:54:18.353754: step 2357, loss 0.0264232, acc 1
2016-09-05T17:54:18.590210: step 2358, loss 0.01786, acc 1
2016-09-05T17:54:18.812660: step 2359, loss 0.0234874, acc 1
2016-09-05T17:54:19.023188: step 2360, loss 0.0198289, acc 1
2016-09-05T17:54:19.221240: step 2361, loss 0.0178456, acc 1
2016-09-05T17:54:19.426717: step 2362, loss 0.018575, acc 1
2016-09-05T17:54:19.631657: step 2363, loss 0.0168923, acc 1
2016-09-05T17:54:19.835068: step 2364, loss 0.023131, acc 1
2016-09-05T17:54:20.067297: step 2365, loss 0.0316682, acc 1
2016-09-05T17:54:20.261257: step 2366, loss 0.023459, acc 1
2016-09-05T17:54:20.460057: step 2367, loss 0.0196261, acc 1
2016-09-05T17:54:20.671469: step 2368, loss 0.0180304, acc 1
2016-09-05T17:54:20.884084: step 2369, loss 0.0186073, acc 1
2016-09-05T17:54:21.085215: step 2370, loss 0.020066, acc 1
2016-09-05T17:54:21.282728: step 2371, loss 0.0176797, acc 1
2016-09-05T17:54:21.505579: step 2372, loss 0.0179505, acc 1
2016-09-05T17:54:21.720506: step 2373, loss 0.0170879, acc 1
2016-09-05T17:54:21.924046: step 2374, loss 0.0193501, acc 1
2016-09-05T17:54:22.120685: step 2375, loss 0.0175838, acc 1
2016-09-05T17:54:22.343439: step 2376, loss 0.0179611, acc 1
2016-09-05T17:54:22.547684: step 2377, loss 0.0180204, acc 1
2016-09-05T17:54:22.748300: step 2378, loss 0.0200839, acc 1
2016-09-05T17:54:22.959751: step 2379, loss 0.0239067, acc 1
2016-09-05T17:54:23.174397: step 2380, loss 0.0174242, acc 1
2016-09-05T17:54:23.394916: step 2381, loss 0.0166757, acc 1
2016-09-05T17:54:23.584323: step 2382, loss 0.0182171, acc 1
2016-09-05T17:54:23.805549: step 2383, loss 0.0369634, acc 1
2016-09-05T17:54:24.027868: step 2384, loss 0.0185249, acc 1
2016-09-05T17:54:24.257781: step 2385, loss 0.0180605, acc 1
2016-09-05T17:54:24.468892: step 2386, loss 0.0188879, acc 1
2016-09-05T17:54:24.692938: step 2387, loss 0.0176179, acc 1
2016-09-05T17:54:24.917333: step 2388, loss 0.0225362, acc 1
2016-09-05T17:54:25.159349: step 2389, loss 0.0167814, acc 1
2016-09-05T17:54:25.349614: step 2390, loss 0.0220156, acc 1
2016-09-05T17:54:25.555449: step 2391, loss 0.0181029, acc 1
2016-09-05T17:54:25.768148: step 2392, loss 0.0238372, acc 1
2016-09-05T17:54:25.963727: step 2393, loss 0.0254242, acc 1
2016-09-05T17:54:26.182960: step 2394, loss 0.0169172, acc 1
2016-09-05T17:54:26.382916: step 2395, loss 0.0235118, acc 1
2016-09-05T17:54:26.594885: step 2396, loss 0.0197388, acc 1
2016-09-05T17:54:26.794783: step 2397, loss 0.0195944, acc 1
2016-09-05T17:54:27.013514: step 2398, loss 0.0172474, acc 1
2016-09-05T17:54:27.224914: step 2399, loss 0.0175025, acc 1
2016-09-05T17:54:27.432589: step 2400, loss 0.0256062, acc 1

Evaluation:
2016-09-05T17:54:27.983614: step 2400, loss 0.784941, acc 0.762

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-2400

2016-09-05T17:54:28.725589: step 2401, loss 0.0195841, acc 1
2016-09-05T17:54:28.934892: step 2402, loss 0.0267585, acc 1
2016-09-05T17:54:29.126037: step 2403, loss 0.0192553, acc 1
2016-09-05T17:54:29.321159: step 2404, loss 0.0211845, acc 1
2016-09-05T17:54:29.532444: step 2405, loss 0.0203296, acc 1
2016-09-05T17:54:29.726700: step 2406, loss 0.020097, acc 1
2016-09-05T17:54:29.918698: step 2407, loss 0.0183201, acc 1
2016-09-05T17:54:30.134602: step 2408, loss 0.0217533, acc 1
2016-09-05T17:54:30.334477: step 2409, loss 0.0210024, acc 1
2016-09-05T17:54:30.545136: step 2410, loss 0.0198794, acc 1
2016-09-05T17:54:30.751538: step 2411, loss 0.0190045, acc 1
2016-09-05T17:54:30.947286: step 2412, loss 0.0170062, acc 1
2016-09-05T17:54:31.160850: step 2413, loss 0.0174886, acc 1
2016-09-05T17:54:31.368896: step 2414, loss 0.0179438, acc 1
2016-09-05T17:54:31.583331: step 2415, loss 0.0191315, acc 1
2016-09-05T17:54:31.775060: step 2416, loss 0.0191442, acc 1
2016-09-05T17:54:31.959345: step 2417, loss 0.018892, acc 1
2016-09-05T17:54:32.156208: step 2418, loss 0.0240937, acc 1
2016-09-05T17:54:32.350257: step 2419, loss 0.0179948, acc 1
2016-09-05T17:54:32.557224: step 2420, loss 0.0177715, acc 1
2016-09-05T17:54:32.768371: step 2421, loss 0.0200578, acc 1
2016-09-05T17:54:32.976019: step 2422, loss 0.0195786, acc 1
2016-09-05T17:54:33.178801: step 2423, loss 0.0162447, acc 1
2016-09-05T17:54:33.401800: step 2424, loss 0.0230067, acc 1
2016-09-05T17:54:33.625739: step 2425, loss 0.0193307, acc 1
2016-09-05T17:54:33.827235: step 2426, loss 0.0171234, acc 1
2016-09-05T17:54:34.032926: step 2427, loss 0.0150352, acc 1
2016-09-05T17:54:34.239272: step 2428, loss 0.0216267, acc 1
2016-09-05T17:54:34.454745: step 2429, loss 0.0178059, acc 1
2016-09-05T17:54:34.679507: step 2430, loss 0.0192786, acc 1
2016-09-05T17:54:34.876740: step 2431, loss 0.0209475, acc 1
2016-09-05T17:54:35.083447: step 2432, loss 0.018889, acc 1
2016-09-05T17:54:35.288852: step 2433, loss 0.0220144, acc 1
2016-09-05T17:54:35.490400: step 2434, loss 0.0230106, acc 1
2016-09-05T17:54:35.721872: step 2435, loss 0.0263683, acc 1
2016-09-05T17:54:35.968014: step 2436, loss 0.0211268, acc 1
2016-09-05T17:54:36.179747: step 2437, loss 0.0316231, acc 1
2016-09-05T17:54:36.365203: step 2438, loss 0.0280241, acc 1
2016-09-05T17:54:36.588207: step 2439, loss 0.0279592, acc 1
2016-09-05T17:54:36.792352: step 2440, loss 0.0202608, acc 1
2016-09-05T17:54:36.995974: step 2441, loss 0.0185923, acc 1
2016-09-05T17:54:37.219939: step 2442, loss 0.0199326, acc 1
2016-09-05T17:54:37.437923: step 2443, loss 0.0167244, acc 1
2016-09-05T17:54:37.648259: step 2444, loss 0.0244307, acc 1
2016-09-05T17:54:37.894614: step 2445, loss 0.0208562, acc 1
2016-09-05T17:54:38.101826: step 2446, loss 0.0156545, acc 1
2016-09-05T17:54:38.303540: step 2447, loss 0.0176011, acc 1
2016-09-05T17:54:38.492235: step 2448, loss 0.0241248, acc 1
2016-09-05T17:54:38.690625: step 2449, loss 0.0296213, acc 1
2016-09-05T17:54:38.881824: step 2450, loss 0.0217597, acc 1
2016-09-05T17:54:39.081845: step 2451, loss 0.0221958, acc 1
2016-09-05T17:54:39.282683: step 2452, loss 0.0170972, acc 1
2016-09-05T17:54:39.493844: step 2453, loss 0.0199998, acc 1
2016-09-05T17:54:39.716044: step 2454, loss 0.0223, acc 1
2016-09-05T17:54:39.907517: step 2455, loss 0.0186795, acc 1
2016-09-05T17:54:40.107490: step 2456, loss 0.0221486, acc 1
2016-09-05T17:54:40.307448: step 2457, loss 0.019194, acc 1
2016-09-05T17:54:40.501773: step 2458, loss 0.0281581, acc 1
2016-09-05T17:54:40.704115: step 2459, loss 0.0183363, acc 1
2016-09-05T17:54:40.924850: step 2460, loss 0.0182366, acc 1
2016-09-05T17:54:41.118461: step 2461, loss 0.0218092, acc 1
2016-09-05T17:54:41.304189: step 2462, loss 0.0259753, acc 1
2016-09-05T17:54:41.510568: step 2463, loss 0.0209327, acc 1
2016-09-05T17:54:41.712924: step 2464, loss 0.01896, acc 1
2016-09-05T17:54:41.897114: step 2465, loss 0.0239209, acc 1
2016-09-05T17:54:42.099809: step 2466, loss 0.020206, acc 1
2016-09-05T17:54:42.290207: step 2467, loss 0.0277042, acc 1
2016-09-05T17:54:42.486740: step 2468, loss 0.0271509, acc 1
2016-09-05T17:54:42.702325: step 2469, loss 0.018864, acc 1
2016-09-05T17:54:42.903725: step 2470, loss 0.0169775, acc 1
2016-09-05T17:54:43.140075: step 2471, loss 0.0203404, acc 1
2016-09-05T17:54:43.367888: step 2472, loss 0.0224674, acc 1
2016-09-05T17:54:43.569317: step 2473, loss 0.0196871, acc 1
2016-09-05T17:54:43.773743: step 2474, loss 0.0176895, acc 1
2016-09-05T17:54:43.975156: step 2475, loss 0.0210597, acc 1
2016-09-05T17:54:44.184804: step 2476, loss 0.0285701, acc 1
2016-09-05T17:54:44.389423: step 2477, loss 0.0271229, acc 1
2016-09-05T17:54:44.589803: step 2478, loss 0.0164449, acc 1
2016-09-05T17:54:44.792281: step 2479, loss 0.0188682, acc 1
2016-09-05T17:54:45.002127: step 2480, loss 0.0219324, acc 1
2016-09-05T17:54:45.207523: step 2481, loss 0.0224483, acc 1
2016-09-05T17:54:45.414869: step 2482, loss 0.0176873, acc 1
2016-09-05T17:54:45.643953: step 2483, loss 0.0201798, acc 1
2016-09-05T17:54:45.841361: step 2484, loss 0.0276598, acc 1
2016-09-05T17:54:46.050347: step 2485, loss 0.025598, acc 1
2016-09-05T17:54:46.254843: step 2486, loss 0.0200637, acc 1
2016-09-05T17:54:46.453003: step 2487, loss 0.0227393, acc 1
2016-09-05T17:54:46.646896: step 2488, loss 0.0186893, acc 1
2016-09-05T17:54:46.857183: step 2489, loss 0.0240858, acc 1
2016-09-05T17:54:47.046979: step 2490, loss 0.0192764, acc 1
2016-09-05T17:54:47.248950: step 2491, loss 0.0185369, acc 1
2016-09-05T17:54:47.440916: step 2492, loss 0.0193175, acc 1
2016-09-05T17:54:47.649650: step 2493, loss 0.0189225, acc 1
2016-09-05T17:54:47.841681: step 2494, loss 0.0200828, acc 1
2016-09-05T17:54:48.057649: step 2495, loss 0.0174635, acc 1
2016-09-05T17:54:48.268992: step 2496, loss 0.0182417, acc 1
2016-09-05T17:54:48.492583: step 2497, loss 0.0238774, acc 1
2016-09-05T17:54:48.705574: step 2498, loss 0.019656, acc 1
2016-09-05T17:54:48.911775: step 2499, loss 0.0185292, acc 1
2016-09-05T17:54:49.117183: step 2500, loss 0.0253125, acc 1

Evaluation:
2016-09-05T17:54:49.691650: step 2500, loss 0.820101, acc 0.766

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-2500

2016-09-05T17:54:50.435302: step 2501, loss 0.0244079, acc 1
2016-09-05T17:54:50.673661: step 2502, loss 0.0202397, acc 1
2016-09-05T17:54:50.884277: step 2503, loss 0.024304, acc 1
2016-09-05T17:54:51.086338: step 2504, loss 0.0184759, acc 1
2016-09-05T17:54:51.283788: step 2505, loss 0.0179407, acc 1
2016-09-05T17:54:51.483111: step 2506, loss 0.0239691, acc 1
2016-09-05T17:54:51.688252: step 2507, loss 0.0188588, acc 1
2016-09-05T17:54:51.955183: step 2508, loss 0.0233434, acc 1
2016-09-05T17:54:52.175827: step 2509, loss 0.0150791, acc 1
2016-09-05T17:54:52.404519: step 2510, loss 0.0250778, acc 1
2016-09-05T17:54:52.636564: step 2511, loss 0.0190038, acc 1
2016-09-05T17:54:52.859680: step 2512, loss 0.0161422, acc 1
2016-09-05T17:54:53.077354: step 2513, loss 0.0181442, acc 1
2016-09-05T17:54:53.298185: step 2514, loss 0.0226352, acc 1
2016-09-05T17:54:53.499424: step 2515, loss 0.0168788, acc 1
2016-09-05T17:54:53.740702: step 2516, loss 0.0193292, acc 1
2016-09-05T17:54:53.964965: step 2517, loss 0.0179623, acc 1
2016-09-05T17:54:54.184550: step 2518, loss 0.018976, acc 1
2016-09-05T17:54:54.411739: step 2519, loss 0.0324109, acc 1
2016-09-05T17:54:54.639022: step 2520, loss 0.0428056, acc 1
2016-09-05T17:54:54.852409: step 2521, loss 0.0189562, acc 1
2016-09-05T17:54:55.005011: step 2522, loss 0.0147948, acc 1
2016-09-05T17:54:55.233886: step 2523, loss 0.0174874, acc 1
2016-09-05T17:54:55.452848: step 2524, loss 0.017518, acc 1
2016-09-05T17:54:55.674469: step 2525, loss 0.0152092, acc 1
2016-09-05T17:54:55.899046: step 2526, loss 0.0156831, acc 1
2016-09-05T17:54:56.142691: step 2527, loss 0.0182004, acc 1
2016-09-05T17:54:56.347307: step 2528, loss 0.0189495, acc 1
2016-09-05T17:54:56.552809: step 2529, loss 0.017765, acc 1
2016-09-05T17:54:56.766932: step 2530, loss 0.0151376, acc 1
2016-09-05T17:54:56.992511: step 2531, loss 0.0219926, acc 1
2016-09-05T17:54:57.217824: step 2532, loss 0.0188058, acc 1
2016-09-05T17:54:57.437678: step 2533, loss 0.0196086, acc 1
2016-09-05T17:54:57.665777: step 2534, loss 0.0177798, acc 1
2016-09-05T17:54:57.887119: step 2535, loss 0.0166202, acc 1
2016-09-05T17:54:58.110307: step 2536, loss 0.019433, acc 1
2016-09-05T17:54:58.331943: step 2537, loss 0.0188677, acc 1
2016-09-05T17:54:58.540096: step 2538, loss 0.0144747, acc 1
2016-09-05T17:54:58.758348: step 2539, loss 0.0186249, acc 1
2016-09-05T17:54:58.984885: step 2540, loss 0.0159502, acc 1
2016-09-05T17:54:59.200936: step 2541, loss 0.016903, acc 1
2016-09-05T17:54:59.405410: step 2542, loss 0.0163397, acc 1
2016-09-05T17:54:59.620846: step 2543, loss 0.0267272, acc 1
2016-09-05T17:54:59.827595: step 2544, loss 0.0165251, acc 1
2016-09-05T17:55:00.049441: step 2545, loss 0.0163999, acc 1
2016-09-05T17:55:00.277665: step 2546, loss 0.0173426, acc 1
2016-09-05T17:55:00.500480: step 2547, loss 0.0141317, acc 1
2016-09-05T17:55:00.745383: step 2548, loss 0.0185087, acc 1
2016-09-05T17:55:00.967239: step 2549, loss 0.0221185, acc 1
2016-09-05T17:55:01.173107: step 2550, loss 0.016337, acc 1
2016-09-05T17:55:01.413561: step 2551, loss 0.0156832, acc 1
2016-09-05T17:55:01.628412: step 2552, loss 0.017067, acc 1
2016-09-05T17:55:01.845318: step 2553, loss 0.0189152, acc 1
2016-09-05T17:55:02.070504: step 2554, loss 0.0156313, acc 1
2016-09-05T17:55:02.298654: step 2555, loss 0.0227811, acc 1
2016-09-05T17:55:02.512954: step 2556, loss 0.0232302, acc 1
2016-09-05T17:55:02.724178: step 2557, loss 0.0212776, acc 1
2016-09-05T17:55:02.944237: step 2558, loss 0.0177179, acc 1
2016-09-05T17:55:03.178846: step 2559, loss 0.0158141, acc 1
2016-09-05T17:55:03.395587: step 2560, loss 0.0234782, acc 1
2016-09-05T17:55:03.613195: step 2561, loss 0.0162504, acc 1
2016-09-05T17:55:03.841060: step 2562, loss 0.0168913, acc 1
2016-09-05T17:55:04.064636: step 2563, loss 0.0224213, acc 1
2016-09-05T17:55:04.269088: step 2564, loss 0.0157185, acc 1
2016-09-05T17:55:04.492548: step 2565, loss 0.0155073, acc 1
2016-09-05T17:55:04.702683: step 2566, loss 0.0226312, acc 1
2016-09-05T17:55:04.908501: step 2567, loss 0.0153879, acc 1
2016-09-05T17:55:05.107488: step 2568, loss 0.0169828, acc 1
2016-09-05T17:55:05.320342: step 2569, loss 0.0162099, acc 1
2016-09-05T17:55:05.527477: step 2570, loss 0.016885, acc 1
2016-09-05T17:55:05.742844: step 2571, loss 0.0199223, acc 1
2016-09-05T17:55:05.965418: step 2572, loss 0.0202941, acc 1
2016-09-05T17:55:06.206555: step 2573, loss 0.0233267, acc 1
2016-09-05T17:55:06.413486: step 2574, loss 0.0201184, acc 1
2016-09-05T17:55:06.641969: step 2575, loss 0.0186356, acc 1
2016-09-05T17:55:06.855504: step 2576, loss 0.0159671, acc 1
2016-09-05T17:55:07.072170: step 2577, loss 0.0208151, acc 1
2016-09-05T17:55:07.311640: step 2578, loss 0.0168012, acc 1
2016-09-05T17:55:07.539247: step 2579, loss 0.0199703, acc 1
2016-09-05T17:55:07.839956: step 2580, loss 0.0162752, acc 1
2016-09-05T17:55:08.064231: step 2581, loss 0.0158427, acc 1
2016-09-05T17:55:08.282966: step 2582, loss 0.0187422, acc 1
2016-09-05T17:55:08.498577: step 2583, loss 0.0147304, acc 1
2016-09-05T17:55:08.727507: step 2584, loss 0.017314, acc 1
2016-09-05T17:55:08.941069: step 2585, loss 0.018615, acc 1
2016-09-05T17:55:09.142755: step 2586, loss 0.0174462, acc 1
2016-09-05T17:55:09.356507: step 2587, loss 0.015812, acc 1
2016-09-05T17:55:09.565955: step 2588, loss 0.0237218, acc 1
2016-09-05T17:55:09.785969: step 2589, loss 0.0191169, acc 1
2016-09-05T17:55:10.008697: step 2590, loss 0.0176244, acc 1
2016-09-05T17:55:10.228431: step 2591, loss 0.0168697, acc 1
2016-09-05T17:55:10.429402: step 2592, loss 0.0167601, acc 1
2016-09-05T17:55:10.648542: step 2593, loss 0.0203681, acc 1
2016-09-05T17:55:10.866270: step 2594, loss 0.0184228, acc 1
2016-09-05T17:55:11.104379: step 2595, loss 0.0143711, acc 1
2016-09-05T17:55:11.348639: step 2596, loss 0.0188027, acc 1
2016-09-05T17:55:11.553891: step 2597, loss 0.0183277, acc 1
2016-09-05T17:55:11.763671: step 2598, loss 0.0151349, acc 1
2016-09-05T17:55:12.003616: step 2599, loss 0.0158399, acc 1
2016-09-05T17:55:12.250500: step 2600, loss 0.0170676, acc 1

Evaluation:
2016-09-05T17:55:12.860524: step 2600, loss 0.810889, acc 0.762

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-2600

2016-09-05T17:55:13.690051: step 2601, loss 0.0326251, acc 1
2016-09-05T17:55:13.947756: step 2602, loss 0.0324689, acc 1
2016-09-05T17:55:14.185148: step 2603, loss 0.0168765, acc 1
2016-09-05T17:55:14.398683: step 2604, loss 0.0191472, acc 1
2016-09-05T17:55:14.619706: step 2605, loss 0.0207156, acc 1
2016-09-05T17:55:14.820691: step 2606, loss 0.0165618, acc 1
2016-09-05T17:55:15.040690: step 2607, loss 0.0180742, acc 1
2016-09-05T17:55:15.287253: step 2608, loss 0.0207682, acc 1
2016-09-05T17:55:15.490704: step 2609, loss 0.0170784, acc 1
2016-09-05T17:55:15.699806: step 2610, loss 0.0173149, acc 1
2016-09-05T17:55:15.925017: step 2611, loss 0.0202476, acc 1
2016-09-05T17:55:16.157831: step 2612, loss 0.0164909, acc 1
2016-09-05T17:55:16.388401: step 2613, loss 0.0199937, acc 1
2016-09-05T17:55:16.593852: step 2614, loss 0.0157369, acc 1
2016-09-05T17:55:16.807312: step 2615, loss 0.0205381, acc 1
2016-09-05T17:55:17.063200: step 2616, loss 0.0188266, acc 1
2016-09-05T17:55:17.281427: step 2617, loss 0.0153031, acc 1
2016-09-05T17:55:17.500484: step 2618, loss 0.0192737, acc 1
2016-09-05T17:55:17.716399: step 2619, loss 0.0185708, acc 1
2016-09-05T17:55:17.932080: step 2620, loss 0.0190222, acc 1
2016-09-05T17:55:18.134860: step 2621, loss 0.0149926, acc 1
2016-09-05T17:55:18.370849: step 2622, loss 0.0158061, acc 1
2016-09-05T17:55:18.616071: step 2623, loss 0.0162124, acc 1
2016-09-05T17:55:18.828148: step 2624, loss 0.0182783, acc 1
2016-09-05T17:55:19.048161: step 2625, loss 0.0240992, acc 1
2016-09-05T17:55:19.259657: step 2626, loss 0.0180518, acc 1
2016-09-05T17:55:19.481855: step 2627, loss 0.017456, acc 1
2016-09-05T17:55:19.690527: step 2628, loss 0.0189295, acc 1
2016-09-05T17:55:19.923145: step 2629, loss 0.0168687, acc 1
2016-09-05T17:55:20.129136: step 2630, loss 0.0157013, acc 1
2016-09-05T17:55:20.339683: step 2631, loss 0.0236287, acc 1
2016-09-05T17:55:20.548968: step 2632, loss 0.0196514, acc 1
2016-09-05T17:55:20.802717: step 2633, loss 0.0164173, acc 1
2016-09-05T17:55:21.036002: step 2634, loss 0.0183949, acc 1
2016-09-05T17:55:21.239908: step 2635, loss 0.0157058, acc 1
2016-09-05T17:55:21.457398: step 2636, loss 0.017072, acc 1
2016-09-05T17:55:21.707062: step 2637, loss 0.0199413, acc 1
2016-09-05T17:55:21.921436: step 2638, loss 0.0249079, acc 1
2016-09-05T17:55:22.145361: step 2639, loss 0.0185829, acc 1
2016-09-05T17:55:22.356136: step 2640, loss 0.0226859, acc 1
2016-09-05T17:55:22.567071: step 2641, loss 0.0162856, acc 1
2016-09-05T17:55:22.819288: step 2642, loss 0.0190883, acc 1
2016-09-05T17:55:23.041341: step 2643, loss 0.0162558, acc 1
2016-09-05T17:55:23.223234: step 2644, loss 0.0190232, acc 1
2016-09-05T17:55:23.445851: step 2645, loss 0.0198968, acc 1
2016-09-05T17:55:23.641398: step 2646, loss 0.018349, acc 1
2016-09-05T17:55:23.856248: step 2647, loss 0.0198049, acc 1
2016-09-05T17:55:24.075908: step 2648, loss 0.0181153, acc 1
2016-09-05T17:55:24.317416: step 2649, loss 0.0176959, acc 1
2016-09-05T17:55:24.534321: step 2650, loss 0.0162509, acc 1
2016-09-05T17:55:24.764025: step 2651, loss 0.0164666, acc 1
2016-09-05T17:55:24.974600: step 2652, loss 0.0197627, acc 1
2016-09-05T17:55:25.184142: step 2653, loss 0.0192575, acc 1
2016-09-05T17:55:25.397405: step 2654, loss 0.0287488, acc 1
2016-09-05T17:55:25.624466: step 2655, loss 0.0174082, acc 1
2016-09-05T17:55:25.878002: step 2656, loss 0.0262462, acc 1
2016-09-05T17:55:26.091087: step 2657, loss 0.0178176, acc 1
2016-09-05T17:55:26.335416: step 2658, loss 0.0229384, acc 1
2016-09-05T17:55:26.576664: step 2659, loss 0.0151763, acc 1
2016-09-05T17:55:26.789538: step 2660, loss 0.0203963, acc 1
2016-09-05T17:55:27.001019: step 2661, loss 0.0167855, acc 1
2016-09-05T17:55:27.232396: step 2662, loss 0.0316337, acc 1
2016-09-05T17:55:27.441827: step 2663, loss 0.0185695, acc 1
2016-09-05T17:55:27.689782: step 2664, loss 0.0156791, acc 1
2016-09-05T17:55:27.903036: step 2665, loss 0.0156366, acc 1
2016-09-05T17:55:28.111315: step 2666, loss 0.0137893, acc 1
2016-09-05T17:55:28.320764: step 2667, loss 0.0157542, acc 1
2016-09-05T17:55:28.544369: step 2668, loss 0.019299, acc 1
2016-09-05T17:55:28.777083: step 2669, loss 0.0175196, acc 1
2016-09-05T17:55:28.975301: step 2670, loss 0.0243374, acc 1
2016-09-05T17:55:29.218438: step 2671, loss 0.0286258, acc 1
2016-09-05T17:55:29.423194: step 2672, loss 0.0179049, acc 1
2016-09-05T17:55:29.642693: step 2673, loss 0.0254675, acc 1
2016-09-05T17:55:29.853639: step 2674, loss 0.01875, acc 1
2016-09-05T17:55:30.071817: step 2675, loss 0.0154802, acc 1
2016-09-05T17:55:30.295451: step 2676, loss 0.0164692, acc 1
2016-09-05T17:55:30.513486: step 2677, loss 0.0220778, acc 1
2016-09-05T17:55:30.741473: step 2678, loss 0.0177456, acc 1
2016-09-05T17:55:30.947503: step 2679, loss 0.0179338, acc 1
2016-09-05T17:55:31.160286: step 2680, loss 0.0155086, acc 1
2016-09-05T17:55:31.373333: step 2681, loss 0.0164563, acc 1
2016-09-05T17:55:31.598016: step 2682, loss 0.0177676, acc 1
2016-09-05T17:55:31.814516: step 2683, loss 0.0176218, acc 1
2016-09-05T17:55:32.052626: step 2684, loss 0.0174075, acc 1
2016-09-05T17:55:32.292569: step 2685, loss 0.0173351, acc 1
2016-09-05T17:55:32.502156: step 2686, loss 0.0183024, acc 1
2016-09-05T17:55:32.745261: step 2687, loss 0.0240295, acc 1
2016-09-05T17:55:32.952208: step 2688, loss 0.0149054, acc 1
2016-09-05T17:55:33.186525: step 2689, loss 0.020537, acc 1
2016-09-05T17:55:33.411455: step 2690, loss 0.0241367, acc 1
2016-09-05T17:55:33.627291: step 2691, loss 0.021435, acc 1
2016-09-05T17:55:33.847822: step 2692, loss 0.0174962, acc 1
2016-09-05T17:55:34.071986: step 2693, loss 0.0167176, acc 1
2016-09-05T17:55:34.297796: step 2694, loss 0.0177543, acc 1
2016-09-05T17:55:34.516737: step 2695, loss 0.0173322, acc 1
2016-09-05T17:55:34.728398: step 2696, loss 0.0289279, acc 1
2016-09-05T17:55:34.969568: step 2697, loss 0.0159249, acc 1
2016-09-05T17:55:35.184183: step 2698, loss 0.0190236, acc 1
2016-09-05T17:55:35.397043: step 2699, loss 0.020376, acc 1
2016-09-05T17:55:35.617904: step 2700, loss 0.0207076, acc 1

Evaluation:
2016-09-05T17:55:36.220475: step 2700, loss 0.837519, acc 0.758

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-2700

2016-09-05T17:55:37.031246: step 2701, loss 0.0231204, acc 1
2016-09-05T17:55:37.253152: step 2702, loss 0.0171788, acc 1
2016-09-05T17:55:37.498029: step 2703, loss 0.0133454, acc 1
2016-09-05T17:55:37.748922: step 2704, loss 0.0160564, acc 1
2016-09-05T17:55:37.991444: step 2705, loss 0.0189496, acc 1
2016-09-05T17:55:38.204462: step 2706, loss 0.0140343, acc 1
2016-09-05T17:55:38.420329: step 2707, loss 0.029035, acc 1
2016-09-05T17:55:38.627798: step 2708, loss 0.0231666, acc 1
2016-09-05T17:55:38.859386: step 2709, loss 0.019328, acc 1
2016-09-05T17:55:39.096916: step 2710, loss 0.0163248, acc 1
2016-09-05T17:55:39.317779: step 2711, loss 0.0228718, acc 1
2016-09-05T17:55:39.518277: step 2712, loss 0.0154207, acc 1
2016-09-05T17:55:39.721937: step 2713, loss 0.0196138, acc 1
2016-09-05T17:55:39.957457: step 2714, loss 0.0204209, acc 1
2016-09-05T17:55:40.204545: step 2715, loss 0.0232252, acc 1
2016-09-05T17:55:40.335867: step 2716, loss 0.0227108, acc 1
2016-09-05T17:55:40.557381: step 2717, loss 0.0162588, acc 1
2016-09-05T17:55:40.766829: step 2718, loss 0.0169214, acc 1
2016-09-05T17:55:40.966681: step 2719, loss 0.0157164, acc 1
2016-09-05T17:55:41.189488: step 2720, loss 0.0160726, acc 1
2016-09-05T17:55:41.418911: step 2721, loss 0.0176383, acc 1
2016-09-05T17:55:41.630131: step 2722, loss 0.021752, acc 1
2016-09-05T17:55:41.831500: step 2723, loss 0.0149917, acc 1
2016-09-05T17:55:42.034937: step 2724, loss 0.0202228, acc 1
2016-09-05T17:55:42.245607: step 2725, loss 0.0161718, acc 1
2016-09-05T17:55:42.471803: step 2726, loss 0.0146275, acc 1
2016-09-05T17:55:42.692472: step 2727, loss 0.0209683, acc 1
2016-09-05T17:55:42.913405: step 2728, loss 0.0203327, acc 1
2016-09-05T17:55:43.140673: step 2729, loss 0.0178376, acc 1
2016-09-05T17:55:43.351661: step 2730, loss 0.0156598, acc 1
2016-09-05T17:55:43.546301: step 2731, loss 0.0177078, acc 1
2016-09-05T17:55:43.792423: step 2732, loss 0.015442, acc 1
2016-09-05T17:55:43.998091: step 2733, loss 0.0163558, acc 1
2016-09-05T17:55:44.237926: step 2734, loss 0.0177809, acc 1
2016-09-05T17:55:44.440689: step 2735, loss 0.0176683, acc 1
2016-09-05T17:55:44.655323: step 2736, loss 0.013775, acc 1
2016-09-05T17:55:44.890627: step 2737, loss 0.0196692, acc 1
2016-09-05T17:55:45.103284: step 2738, loss 0.0143215, acc 1
2016-09-05T17:55:45.344082: step 2739, loss 0.01556, acc 1
2016-09-05T17:55:45.530938: step 2740, loss 0.0174919, acc 1
2016-09-05T17:55:45.753315: step 2741, loss 0.0178185, acc 1
2016-09-05T17:55:45.967576: step 2742, loss 0.0221932, acc 1
2016-09-05T17:55:46.185577: step 2743, loss 0.0215515, acc 1
2016-09-05T17:55:46.395420: step 2744, loss 0.0177881, acc 1
2016-09-05T17:55:46.619974: step 2745, loss 0.0178185, acc 1
2016-09-05T17:55:46.843838: step 2746, loss 0.0186737, acc 1
2016-09-05T17:55:47.068641: step 2747, loss 0.0174655, acc 1
2016-09-05T17:55:47.295740: step 2748, loss 0.0164748, acc 1
2016-09-05T17:55:47.501343: step 2749, loss 0.0184647, acc 1
2016-09-05T17:55:47.702256: step 2750, loss 0.0171401, acc 1
2016-09-05T17:55:47.937794: step 2751, loss 0.0157545, acc 1
2016-09-05T17:55:48.199567: step 2752, loss 0.0142464, acc 1
2016-09-05T17:55:48.423426: step 2753, loss 0.0144381, acc 1
2016-09-05T17:55:48.652111: step 2754, loss 0.0142066, acc 1
2016-09-05T17:55:48.866298: step 2755, loss 0.0207743, acc 1
2016-09-05T17:55:49.092514: step 2756, loss 0.0153985, acc 1
2016-09-05T17:55:49.295457: step 2757, loss 0.0175075, acc 1
2016-09-05T17:55:49.500679: step 2758, loss 0.0147144, acc 1
2016-09-05T17:55:49.709796: step 2759, loss 0.0164514, acc 1
2016-09-05T17:55:49.946581: step 2760, loss 0.0165763, acc 1
2016-09-05T17:55:50.205782: step 2761, loss 0.0142101, acc 1
2016-09-05T17:55:50.419367: step 2762, loss 0.021863, acc 1
2016-09-05T17:55:50.620462: step 2763, loss 0.0162399, acc 1
2016-09-05T17:55:50.823378: step 2764, loss 0.0136438, acc 1
2016-09-05T17:55:51.036877: step 2765, loss 0.0138501, acc 1
2016-09-05T17:55:51.239429: step 2766, loss 0.0127232, acc 1
2016-09-05T17:55:51.467285: step 2767, loss 0.0127381, acc 1
2016-09-05T17:55:51.699653: step 2768, loss 0.0138046, acc 1
2016-09-05T17:55:51.920628: step 2769, loss 0.0184504, acc 1
2016-09-05T17:55:52.129823: step 2770, loss 0.0170171, acc 1
2016-09-05T17:55:52.373950: step 2771, loss 0.0174685, acc 1
2016-09-05T17:55:52.623152: step 2772, loss 0.0149029, acc 1
2016-09-05T17:55:52.815732: step 2773, loss 0.0170862, acc 1
2016-09-05T17:55:53.027698: step 2774, loss 0.014264, acc 1
2016-09-05T17:55:53.246799: step 2775, loss 0.0146686, acc 1
2016-09-05T17:55:53.475952: step 2776, loss 0.0267042, acc 1
2016-09-05T17:55:53.711997: step 2777, loss 0.0149763, acc 1
2016-09-05T17:55:53.930447: step 2778, loss 0.0148462, acc 1
2016-09-05T17:55:54.137585: step 2779, loss 0.0205344, acc 1
2016-09-05T17:55:54.357322: step 2780, loss 0.0160462, acc 1
2016-09-05T17:55:54.576524: step 2781, loss 0.0165119, acc 1
2016-09-05T17:55:54.813968: step 2782, loss 0.0152086, acc 1
2016-09-05T17:55:55.058810: step 2783, loss 0.0190415, acc 1
2016-09-05T17:55:55.281012: step 2784, loss 0.0181354, acc 1
2016-09-05T17:55:55.490642: step 2785, loss 0.0174695, acc 1
2016-09-05T17:55:55.700775: step 2786, loss 0.0141694, acc 1
2016-09-05T17:55:55.929457: step 2787, loss 0.0149917, acc 1
2016-09-05T17:55:56.129990: step 2788, loss 0.0164873, acc 1
2016-09-05T17:55:56.370341: step 2789, loss 0.0168307, acc 1
2016-09-05T17:55:56.588765: step 2790, loss 0.0171337, acc 1
2016-09-05T17:55:56.805961: step 2791, loss 0.0182652, acc 1
2016-09-05T17:55:57.031636: step 2792, loss 0.0178102, acc 1
2016-09-05T17:55:57.274011: step 2793, loss 0.021186, acc 1
2016-09-05T17:55:57.495356: step 2794, loss 0.0157661, acc 1
2016-09-05T17:55:57.706929: step 2795, loss 0.0127061, acc 1
2016-09-05T17:55:57.914404: step 2796, loss 0.0158475, acc 1
2016-09-05T17:55:58.146629: step 2797, loss 0.0152302, acc 1
2016-09-05T17:55:58.395019: step 2798, loss 0.0161453, acc 1
2016-09-05T17:55:58.600328: step 2799, loss 0.0146104, acc 1
2016-09-05T17:55:58.824150: step 2800, loss 0.0179401, acc 1

Evaluation:
2016-09-05T17:55:59.428331: step 2800, loss 0.837424, acc 0.759

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-2800

2016-09-05T17:56:00.206130: step 2801, loss 0.0217049, acc 1
2016-09-05T17:56:00.443628: step 2802, loss 0.0152293, acc 1
2016-09-05T17:56:00.691983: step 2803, loss 0.0143559, acc 1
2016-09-05T17:56:00.913779: step 2804, loss 0.0220908, acc 1
2016-09-05T17:56:01.130389: step 2805, loss 0.0298393, acc 1
2016-09-05T17:56:01.327457: step 2806, loss 0.0159048, acc 1
2016-09-05T17:56:01.530859: step 2807, loss 0.0148685, acc 1
2016-09-05T17:56:01.749864: step 2808, loss 0.0186218, acc 1
2016-09-05T17:56:01.969881: step 2809, loss 0.0166217, acc 1
2016-09-05T17:56:02.187197: step 2810, loss 0.0160273, acc 1
2016-09-05T17:56:02.431281: step 2811, loss 0.0151609, acc 1
2016-09-05T17:56:02.636024: step 2812, loss 0.0149385, acc 1
2016-09-05T17:56:02.840492: step 2813, loss 0.0236544, acc 1
2016-09-05T17:56:03.055801: step 2814, loss 0.0152093, acc 1
2016-09-05T17:56:03.279270: step 2815, loss 0.0179662, acc 1
2016-09-05T17:56:03.485776: step 2816, loss 0.0171888, acc 1
2016-09-05T17:56:03.702999: step 2817, loss 0.0160254, acc 1
2016-09-05T17:56:03.945038: step 2818, loss 0.0174613, acc 1
2016-09-05T17:56:04.168959: step 2819, loss 0.0177912, acc 1
2016-09-05T17:56:04.401070: step 2820, loss 0.0174502, acc 1
2016-09-05T17:56:04.664710: step 2821, loss 0.0175359, acc 1
2016-09-05T17:56:04.872328: step 2822, loss 0.0158736, acc 1
2016-09-05T17:56:05.077108: step 2823, loss 0.0156158, acc 1
2016-09-05T17:56:05.271676: step 2824, loss 0.0206404, acc 1
2016-09-05T17:56:05.482713: step 2825, loss 0.0172333, acc 1
2016-09-05T17:56:05.698710: step 2826, loss 0.0158327, acc 1
2016-09-05T17:56:05.924960: step 2827, loss 0.0151509, acc 1
2016-09-05T17:56:06.175106: step 2828, loss 0.0175828, acc 1
2016-09-05T17:56:06.387626: step 2829, loss 0.0176496, acc 1
2016-09-05T17:56:06.595322: step 2830, loss 0.0189883, acc 1
2016-09-05T17:56:06.814709: step 2831, loss 0.015014, acc 1
2016-09-05T17:56:07.037974: step 2832, loss 0.0156267, acc 1
2016-09-05T17:56:07.271923: step 2833, loss 0.016039, acc 1
2016-09-05T17:56:07.504632: step 2834, loss 0.0153538, acc 1
2016-09-05T17:56:07.711730: step 2835, loss 0.0200688, acc 1
2016-09-05T17:56:07.926919: step 2836, loss 0.016887, acc 1
2016-09-05T17:56:08.150685: step 2837, loss 0.016948, acc 1
2016-09-05T17:56:08.364509: step 2838, loss 0.0185171, acc 1
2016-09-05T17:56:08.593787: step 2839, loss 0.0202044, acc 1
2016-09-05T17:56:08.798749: step 2840, loss 0.0177176, acc 1
2016-09-05T17:56:09.009946: step 2841, loss 0.0145678, acc 1
2016-09-05T17:56:09.252096: step 2842, loss 0.0144607, acc 1
2016-09-05T17:56:09.480107: step 2843, loss 0.0185268, acc 1
2016-09-05T17:56:09.677530: step 2844, loss 0.0160102, acc 1
2016-09-05T17:56:09.904691: step 2845, loss 0.0194052, acc 1
2016-09-05T17:56:10.114353: step 2846, loss 0.0141109, acc 1
2016-09-05T17:56:10.333952: step 2847, loss 0.0159772, acc 1
2016-09-05T17:56:10.557646: step 2848, loss 0.0149335, acc 1
2016-09-05T17:56:10.764771: step 2849, loss 0.0152601, acc 1
2016-09-05T17:56:10.995110: step 2850, loss 0.0163252, acc 1
2016-09-05T17:56:11.202437: step 2851, loss 0.0135659, acc 1
2016-09-05T17:56:11.422614: step 2852, loss 0.0142136, acc 1
2016-09-05T17:56:11.627501: step 2853, loss 0.0146816, acc 1
2016-09-05T17:56:11.852297: step 2854, loss 0.0161752, acc 1
2016-09-05T17:56:12.078851: step 2855, loss 0.016327, acc 1
2016-09-05T17:56:12.320357: step 2856, loss 0.0168141, acc 1
2016-09-05T17:56:12.523473: step 2857, loss 0.0145573, acc 1
2016-09-05T17:56:12.726353: step 2858, loss 0.0187711, acc 1
2016-09-05T17:56:12.930606: step 2859, loss 0.0203211, acc 1
2016-09-05T17:56:13.150410: step 2860, loss 0.0136918, acc 1
2016-09-05T17:56:13.361793: step 2861, loss 0.0140055, acc 1
2016-09-05T17:56:13.590346: step 2862, loss 0.0144758, acc 1
2016-09-05T17:56:13.834585: step 2863, loss 0.0159278, acc 1
2016-09-05T17:56:14.077144: step 2864, loss 0.0178071, acc 1
2016-09-05T17:56:14.291789: step 2865, loss 0.0163655, acc 1
2016-09-05T17:56:14.509601: step 2866, loss 0.0142347, acc 1
2016-09-05T17:56:14.735772: step 2867, loss 0.0184851, acc 1
2016-09-05T17:56:14.941858: step 2868, loss 0.0198173, acc 1
2016-09-05T17:56:15.154831: step 2869, loss 0.0181341, acc 1
2016-09-05T17:56:15.364417: step 2870, loss 0.0174304, acc 1
2016-09-05T17:56:15.575956: step 2871, loss 0.0139644, acc 1
2016-09-05T17:56:15.803945: step 2872, loss 0.0137564, acc 1
2016-09-05T17:56:16.014697: step 2873, loss 0.0161033, acc 1
2016-09-05T17:56:16.245980: step 2874, loss 0.0188733, acc 1
2016-09-05T17:56:16.461502: step 2875, loss 0.0168715, acc 1
2016-09-05T17:56:16.664504: step 2876, loss 0.0220648, acc 1
2016-09-05T17:56:16.869807: step 2877, loss 0.0133481, acc 1
2016-09-05T17:56:17.080851: step 2878, loss 0.017028, acc 1
2016-09-05T17:56:17.279883: step 2879, loss 0.0166756, acc 1
2016-09-05T17:56:17.484118: step 2880, loss 0.0142285, acc 1
2016-09-05T17:56:17.700982: step 2881, loss 0.0137976, acc 1
2016-09-05T17:56:17.931908: step 2882, loss 0.0135037, acc 1
2016-09-05T17:56:18.152564: step 2883, loss 0.015632, acc 1
2016-09-05T17:56:18.390476: step 2884, loss 0.0148929, acc 1
2016-09-05T17:56:18.599695: step 2885, loss 0.0223751, acc 1
2016-09-05T17:56:18.815561: step 2886, loss 0.0157593, acc 1
2016-09-05T17:56:19.022236: step 2887, loss 0.0160463, acc 1
2016-09-05T17:56:19.273270: step 2888, loss 0.0167589, acc 1
2016-09-05T17:56:19.504344: step 2889, loss 0.0161067, acc 1
2016-09-05T17:56:19.719154: step 2890, loss 0.0144481, acc 1
2016-09-05T17:56:19.922757: step 2891, loss 0.0170058, acc 1
2016-09-05T17:56:20.138621: step 2892, loss 0.0323007, acc 1
2016-09-05T17:56:20.390421: step 2893, loss 0.016735, acc 1
2016-09-05T17:56:20.608945: step 2894, loss 0.0187705, acc 1
2016-09-05T17:56:20.825408: step 2895, loss 0.0255397, acc 1
2016-09-05T17:56:21.037602: step 2896, loss 0.0203789, acc 1
2016-09-05T17:56:21.250685: step 2897, loss 0.0188538, acc 1
2016-09-05T17:56:21.476264: step 2898, loss 0.0159531, acc 1
2016-09-05T17:56:21.677623: step 2899, loss 0.0170387, acc 1
2016-09-05T17:56:21.910055: step 2900, loss 0.018078, acc 1

Evaluation:
2016-09-05T17:56:22.486353: step 2900, loss 0.860386, acc 0.757

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-2900

2016-09-05T17:56:23.113142: step 2901, loss 0.0149594, acc 1
2016-09-05T17:56:23.340957: step 2902, loss 0.0155851, acc 1
2016-09-05T17:56:23.544083: step 2903, loss 0.0179368, acc 1
2016-09-05T17:56:23.750344: step 2904, loss 0.0211327, acc 1
2016-09-05T17:56:23.970899: step 2905, loss 0.0153549, acc 1
2016-09-05T17:56:24.176559: step 2906, loss 0.0176975, acc 1
2016-09-05T17:56:24.402420: step 2907, loss 0.0169751, acc 1
2016-09-05T17:56:24.648614: step 2908, loss 0.015793, acc 1
2016-09-05T17:56:24.878440: step 2909, loss 0.0155319, acc 1
2016-09-05T17:56:25.005879: step 2910, loss 0.0137557, acc 1
2016-09-05T17:56:25.258187: step 2911, loss 0.0143076, acc 1
2016-09-05T17:56:25.459505: step 2912, loss 0.0133656, acc 1
2016-09-05T17:56:25.673286: step 2913, loss 0.0157012, acc 1
2016-09-05T17:56:25.877194: step 2914, loss 0.0147752, acc 1
2016-09-05T17:56:26.079822: step 2915, loss 0.0165079, acc 1
2016-09-05T17:56:26.289328: step 2916, loss 0.0194136, acc 1
2016-09-05T17:56:26.529859: step 2917, loss 0.0186012, acc 1
2016-09-05T17:56:26.777927: step 2918, loss 0.0167557, acc 1
2016-09-05T17:56:26.979903: step 2919, loss 0.0153676, acc 1
2016-09-05T17:56:27.188555: step 2920, loss 0.0221892, acc 1
2016-09-05T17:56:27.398844: step 2921, loss 0.0155226, acc 1
2016-09-05T17:56:27.622496: step 2922, loss 0.0149528, acc 1
2016-09-05T17:56:27.842742: step 2923, loss 0.0210199, acc 1
2016-09-05T17:56:28.085107: step 2924, loss 0.0124888, acc 1
2016-09-05T17:56:28.287210: step 2925, loss 0.0143589, acc 1
2016-09-05T17:56:28.487445: step 2926, loss 0.0166818, acc 1
2016-09-05T17:56:28.690721: step 2927, loss 0.0141895, acc 1
2016-09-05T17:56:28.922957: step 2928, loss 0.0158469, acc 1
2016-09-05T17:56:29.124866: step 2929, loss 0.013216, acc 1
2016-09-05T17:56:29.345834: step 2930, loss 0.0136447, acc 1
2016-09-05T17:56:29.560759: step 2931, loss 0.015891, acc 1
2016-09-05T17:56:29.775877: step 2932, loss 0.0148544, acc 1
2016-09-05T17:56:30.009654: step 2933, loss 0.0128258, acc 1
2016-09-05T17:56:30.210952: step 2934, loss 0.0140222, acc 1
2016-09-05T17:56:30.424660: step 2935, loss 0.0182618, acc 1
2016-09-05T17:56:30.634492: step 2936, loss 0.0173503, acc 1
2016-09-05T17:56:30.844962: step 2937, loss 0.0150801, acc 1
2016-09-05T17:56:31.046579: step 2938, loss 0.0140916, acc 1
2016-09-05T17:56:31.271817: step 2939, loss 0.0129762, acc 1
2016-09-05T17:56:31.518449: step 2940, loss 0.015385, acc 1
2016-09-05T17:56:31.739724: step 2941, loss 0.0160475, acc 1
2016-09-05T17:56:31.945467: step 2942, loss 0.0152531, acc 1
2016-09-05T17:56:32.169847: step 2943, loss 0.0142248, acc 1
2016-09-05T17:56:32.401641: step 2944, loss 0.0178802, acc 1
2016-09-05T17:56:32.618061: step 2945, loss 0.0134041, acc 1
2016-09-05T17:56:32.828480: step 2946, loss 0.0137982, acc 1
2016-09-05T17:56:33.027652: step 2947, loss 0.0139691, acc 1
2016-09-05T17:56:33.244140: step 2948, loss 0.01432, acc 1
2016-09-05T17:56:33.443407: step 2949, loss 0.0154457, acc 1
2016-09-05T17:56:33.658507: step 2950, loss 0.0137453, acc 1
2016-09-05T17:56:33.874936: step 2951, loss 0.0151719, acc 1
2016-09-05T17:56:34.103104: step 2952, loss 0.0162005, acc 1
2016-09-05T17:56:34.338844: step 2953, loss 0.0130667, acc 1
2016-09-05T17:56:34.551591: step 2954, loss 0.0143566, acc 1
2016-09-05T17:56:34.775868: step 2955, loss 0.0140833, acc 1
2016-09-05T17:56:35.007908: step 2956, loss 0.0135239, acc 1
2016-09-05T17:56:35.232522: step 2957, loss 0.0148921, acc 1
2016-09-05T17:56:35.458837: step 2958, loss 0.0135592, acc 1
2016-09-05T17:56:35.672223: step 2959, loss 0.0156579, acc 1
2016-09-05T17:56:35.912716: step 2960, loss 0.013011, acc 1
2016-09-05T17:56:36.134569: step 2961, loss 0.0134267, acc 1
2016-09-05T17:56:36.347511: step 2962, loss 0.0171791, acc 1
2016-09-05T17:56:36.580896: step 2963, loss 0.0163037, acc 1
2016-09-05T17:56:36.782259: step 2964, loss 0.0134862, acc 1
2016-09-05T17:56:36.990540: step 2965, loss 0.0126209, acc 1
2016-09-05T17:56:37.198895: step 2966, loss 0.0152991, acc 1
2016-09-05T17:56:37.416840: step 2967, loss 0.0183404, acc 1
2016-09-05T17:56:37.627304: step 2968, loss 0.0141017, acc 1
2016-09-05T17:56:37.829462: step 2969, loss 0.0158174, acc 1
2016-09-05T17:56:38.059854: step 2970, loss 0.0147478, acc 1
2016-09-05T17:56:38.303855: step 2971, loss 0.0157994, acc 1
2016-09-05T17:56:38.515563: step 2972, loss 0.0149232, acc 1
2016-09-05T17:56:38.735842: step 2973, loss 0.0133724, acc 1
2016-09-05T17:56:38.956924: step 2974, loss 0.0152156, acc 1
2016-09-05T17:56:39.170101: step 2975, loss 0.0139701, acc 1
2016-09-05T17:56:39.386658: step 2976, loss 0.0222314, acc 1
2016-09-05T17:56:39.592369: step 2977, loss 0.0156586, acc 1
2016-09-05T17:56:39.820095: step 2978, loss 0.0174308, acc 1
2016-09-05T17:56:40.028060: step 2979, loss 0.0200014, acc 1
2016-09-05T17:56:40.265144: step 2980, loss 0.0218036, acc 1
2016-09-05T17:56:40.518996: step 2981, loss 0.012114, acc 1
2016-09-05T17:56:40.735958: step 2982, loss 0.0143971, acc 1
2016-09-05T17:56:40.957300: step 2983, loss 0.013785, acc 1
2016-09-05T17:56:41.172239: step 2984, loss 0.0139292, acc 1
2016-09-05T17:56:41.420818: step 2985, loss 0.0124808, acc 1
2016-09-05T17:56:41.632479: step 2986, loss 0.0136349, acc 1
2016-09-05T17:56:41.843025: step 2987, loss 0.0141504, acc 1
2016-09-05T17:56:42.053241: step 2988, loss 0.0142796, acc 1
2016-09-05T17:56:42.259266: step 2989, loss 0.01428, acc 1
2016-09-05T17:56:42.467729: step 2990, loss 0.0140956, acc 1
2016-09-05T17:56:42.700644: step 2991, loss 0.0180121, acc 1
2016-09-05T17:56:42.929114: step 2992, loss 0.015015, acc 1
2016-09-05T17:56:43.137181: step 2993, loss 0.0134597, acc 1
2016-09-05T17:56:43.362757: step 2994, loss 0.0154862, acc 1
2016-09-05T17:56:43.562108: step 2995, loss 0.0137061, acc 1
2016-09-05T17:56:43.789370: step 2996, loss 0.0125601, acc 1
2016-09-05T17:56:43.999390: step 2997, loss 0.0142478, acc 1
2016-09-05T17:56:44.224679: step 2998, loss 0.0166228, acc 1
2016-09-05T17:56:44.443495: step 2999, loss 0.0155696, acc 1
2016-09-05T17:56:44.654463: step 3000, loss 0.0153533, acc 1

Evaluation:
2016-09-05T17:56:45.233869: step 3000, loss 0.861267, acc 0.753

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-3000

2016-09-05T17:56:45.961395: step 3001, loss 0.0126901, acc 1
2016-09-05T17:56:46.212664: step 3002, loss 0.0160897, acc 1
2016-09-05T17:56:46.429268: step 3003, loss 0.0159244, acc 1
2016-09-05T17:56:46.644667: step 3004, loss 0.0143968, acc 1
2016-09-05T17:56:46.891355: step 3005, loss 0.0131404, acc 1
2016-09-05T17:56:47.112967: step 3006, loss 0.0203628, acc 1
2016-09-05T17:56:47.325550: step 3007, loss 0.0153314, acc 1
2016-09-05T17:56:47.547963: step 3008, loss 0.0150373, acc 1
2016-09-05T17:56:47.749611: step 3009, loss 0.0164754, acc 1
2016-09-05T17:56:47.950547: step 3010, loss 0.0150417, acc 1
2016-09-05T17:56:48.173620: step 3011, loss 0.0174322, acc 1
2016-09-05T17:56:48.389430: step 3012, loss 0.0134175, acc 1
2016-09-05T17:56:48.605787: step 3013, loss 0.0141477, acc 1
2016-09-05T17:56:48.821746: step 3014, loss 0.0128879, acc 1
2016-09-05T17:56:49.051935: step 3015, loss 0.0126328, acc 1
2016-09-05T17:56:49.258968: step 3016, loss 0.0154774, acc 1
2016-09-05T17:56:49.484661: step 3017, loss 0.0166146, acc 1
2016-09-05T17:56:49.713480: step 3018, loss 0.0147287, acc 1
2016-09-05T17:56:49.932664: step 3019, loss 0.0145415, acc 1
2016-09-05T17:56:50.143421: step 3020, loss 0.0137426, acc 1
2016-09-05T17:56:50.367136: step 3021, loss 0.0140422, acc 1
2016-09-05T17:56:50.608213: step 3022, loss 0.0132771, acc 1
2016-09-05T17:56:50.823388: step 3023, loss 0.014558, acc 1
2016-09-05T17:56:51.041386: step 3024, loss 0.0144783, acc 1
2016-09-05T17:56:51.247545: step 3025, loss 0.0143434, acc 1
2016-09-05T17:56:51.448066: step 3026, loss 0.0128466, acc 1
2016-09-05T17:56:51.666198: step 3027, loss 0.014069, acc 1
2016-09-05T17:56:51.899225: step 3028, loss 0.0162158, acc 1
2016-09-05T17:56:52.113441: step 3029, loss 0.0136423, acc 1
2016-09-05T17:56:52.356885: step 3030, loss 0.0124084, acc 1
2016-09-05T17:56:52.625875: step 3031, loss 0.0130739, acc 1
2016-09-05T17:56:52.837879: step 3032, loss 0.0124919, acc 1
2016-09-05T17:56:53.065447: step 3033, loss 0.0121514, acc 1
2016-09-05T17:56:53.284465: step 3034, loss 0.0162829, acc 1
2016-09-05T17:56:53.534315: step 3035, loss 0.019887, acc 1
2016-09-05T17:56:53.752339: step 3036, loss 0.0129703, acc 1
2016-09-05T17:56:53.962517: step 3037, loss 0.0127105, acc 1
2016-09-05T17:56:54.172368: step 3038, loss 0.0191364, acc 1
2016-09-05T17:56:54.401641: step 3039, loss 0.014535, acc 1
2016-09-05T17:56:54.623330: step 3040, loss 0.0153617, acc 1
2016-09-05T17:56:54.847844: step 3041, loss 0.0146889, acc 1
2016-09-05T17:56:55.071526: step 3042, loss 0.0155623, acc 1
2016-09-05T17:56:55.274362: step 3043, loss 0.0207824, acc 1
2016-09-05T17:56:55.483812: step 3044, loss 0.0176075, acc 1
2016-09-05T17:56:55.679300: step 3045, loss 0.0155911, acc 1
2016-09-05T17:56:55.888852: step 3046, loss 0.0147352, acc 1
2016-09-05T17:56:56.096398: step 3047, loss 0.0135709, acc 1
2016-09-05T17:56:56.310373: step 3048, loss 0.0167262, acc 1
2016-09-05T17:56:56.524176: step 3049, loss 0.0213985, acc 1
2016-09-05T17:56:56.750981: step 3050, loss 0.0196556, acc 1
2016-09-05T17:56:56.966903: step 3051, loss 0.0116155, acc 1
2016-09-05T17:56:57.200949: step 3052, loss 0.0175609, acc 1
2016-09-05T17:56:57.414347: step 3053, loss 0.0206507, acc 1
2016-09-05T17:56:57.624411: step 3054, loss 0.0146989, acc 1
2016-09-05T17:56:57.850521: step 3055, loss 0.0147882, acc 1
2016-09-05T17:56:58.084294: step 3056, loss 0.0133325, acc 1
2016-09-05T17:56:58.296523: step 3057, loss 0.0176952, acc 1
2016-09-05T17:56:58.494092: step 3058, loss 0.0178967, acc 1
2016-09-05T17:56:58.703368: step 3059, loss 0.0235954, acc 1
2016-09-05T17:56:58.920430: step 3060, loss 0.0216087, acc 1
2016-09-05T17:56:59.122261: step 3061, loss 0.0144053, acc 1
2016-09-05T17:56:59.323878: step 3062, loss 0.0143355, acc 1
2016-09-05T17:56:59.540203: step 3063, loss 0.0152486, acc 1
2016-09-05T17:56:59.739859: step 3064, loss 0.0213201, acc 1
2016-09-05T17:56:59.955493: step 3065, loss 0.0179618, acc 1
2016-09-05T17:57:00.169971: step 3066, loss 0.0164048, acc 1
2016-09-05T17:57:00.424670: step 3067, loss 0.0153951, acc 1
2016-09-05T17:57:00.636779: step 3068, loss 0.0120152, acc 1
2016-09-05T17:57:00.871373: step 3069, loss 0.021217, acc 1
2016-09-05T17:57:01.078640: step 3070, loss 0.0158625, acc 1
2016-09-05T17:57:01.299802: step 3071, loss 0.0144582, acc 1
2016-09-05T17:57:01.529004: step 3072, loss 0.0200507, acc 1
2016-09-05T17:57:01.763303: step 3073, loss 0.0130231, acc 1
2016-09-05T17:57:01.983734: step 3074, loss 0.0133257, acc 1
2016-09-05T17:57:02.202835: step 3075, loss 0.0157774, acc 1
2016-09-05T17:57:02.423490: step 3076, loss 0.0168138, acc 1
2016-09-05T17:57:02.632609: step 3077, loss 0.0221598, acc 1
2016-09-05T17:57:02.843863: step 3078, loss 0.0179687, acc 1
2016-09-05T17:57:03.069845: step 3079, loss 0.0147794, acc 1
2016-09-05T17:57:03.283859: step 3080, loss 0.0170106, acc 1
2016-09-05T17:57:03.507480: step 3081, loss 0.0149043, acc 1
2016-09-05T17:57:03.732182: step 3082, loss 0.0178119, acc 1
2016-09-05T17:57:03.959192: step 3083, loss 0.0145512, acc 1
2016-09-05T17:57:04.168992: step 3084, loss 0.0242225, acc 1
2016-09-05T17:57:04.388935: step 3085, loss 0.013489, acc 1
2016-09-05T17:57:04.604199: step 3086, loss 0.0172142, acc 1
2016-09-05T17:57:04.855618: step 3087, loss 0.0213077, acc 1
2016-09-05T17:57:05.062077: step 3088, loss 0.0174658, acc 1
2016-09-05T17:57:05.294410: step 3089, loss 0.0136791, acc 1
2016-09-05T17:57:05.515413: step 3090, loss 0.0147326, acc 1
2016-09-05T17:57:05.737442: step 3091, loss 0.0195871, acc 1
2016-09-05T17:57:05.969188: step 3092, loss 0.0172117, acc 1
2016-09-05T17:57:06.177246: step 3093, loss 0.0165248, acc 1
2016-09-05T17:57:06.400867: step 3094, loss 0.017105, acc 1
2016-09-05T17:57:06.617123: step 3095, loss 0.0183597, acc 1
2016-09-05T17:57:06.842882: step 3096, loss 0.0154498, acc 1
2016-09-05T17:57:07.044516: step 3097, loss 0.015955, acc 1
2016-09-05T17:57:07.266288: step 3098, loss 0.0222434, acc 1
2016-09-05T17:57:07.467921: step 3099, loss 0.0161859, acc 1
2016-09-05T17:57:07.679900: step 3100, loss 0.0157331, acc 1

Evaluation:
2016-09-05T17:57:08.280522: step 3100, loss 0.905357, acc 0.759

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-3100

2016-09-05T17:57:09.076250: step 3101, loss 0.0143297, acc 1
2016-09-05T17:57:09.307149: step 3102, loss 0.014169, acc 1
2016-09-05T17:57:09.539261: step 3103, loss 0.0129227, acc 1
2016-09-05T17:57:09.668682: step 3104, loss 0.0140933, acc 1
2016-09-05T17:57:09.892003: step 3105, loss 0.0133879, acc 1
2016-09-05T17:57:10.126396: step 3106, loss 0.0120281, acc 1
2016-09-05T17:57:10.358136: step 3107, loss 0.0131534, acc 1
2016-09-05T17:57:10.565013: step 3108, loss 0.0132541, acc 1
2016-09-05T17:57:10.795388: step 3109, loss 0.01252, acc 1
2016-09-05T17:57:11.012296: step 3110, loss 0.0131683, acc 1
2016-09-05T17:57:11.229675: step 3111, loss 0.0131578, acc 1
2016-09-05T17:57:11.440764: step 3112, loss 0.016289, acc 1
2016-09-05T17:57:11.678391: step 3113, loss 0.0143425, acc 1
2016-09-05T17:57:11.914521: step 3114, loss 0.0145718, acc 1
2016-09-05T17:57:12.132444: step 3115, loss 0.0137393, acc 1
2016-09-05T17:57:12.385089: step 3116, loss 0.0128426, acc 1
2016-09-05T17:57:12.579227: step 3117, loss 0.0118712, acc 1
2016-09-05T17:57:12.817958: step 3118, loss 0.0163694, acc 1
2016-09-05T17:57:13.012384: step 3119, loss 0.0125854, acc 1
2016-09-05T17:57:13.224728: step 3120, loss 0.0146318, acc 1
2016-09-05T17:57:13.436038: step 3121, loss 0.0175591, acc 1
2016-09-05T17:57:13.661720: step 3122, loss 0.0131158, acc 1
2016-09-05T17:57:13.869813: step 3123, loss 0.0126068, acc 1
2016-09-05T17:57:14.092816: step 3124, loss 0.0152536, acc 1
2016-09-05T17:57:14.320252: step 3125, loss 0.013642, acc 1
2016-09-05T17:57:14.538132: step 3126, loss 0.013828, acc 1
2016-09-05T17:57:14.749341: step 3127, loss 0.0145669, acc 1
2016-09-05T17:57:14.951920: step 3128, loss 0.0144082, acc 1
2016-09-05T17:57:15.171134: step 3129, loss 0.0143768, acc 1
2016-09-05T17:57:15.393736: step 3130, loss 0.0113383, acc 1
2016-09-05T17:57:15.608344: step 3131, loss 0.0129269, acc 1
2016-09-05T17:57:15.830406: step 3132, loss 0.0174048, acc 1
2016-09-05T17:57:16.059043: step 3133, loss 0.0151253, acc 1
2016-09-05T17:57:16.307315: step 3134, loss 0.0137854, acc 1
2016-09-05T17:57:16.525921: step 3135, loss 0.016609, acc 1
2016-09-05T17:57:16.747107: step 3136, loss 0.0128844, acc 1
2016-09-05T17:57:16.961223: step 3137, loss 0.0124833, acc 1
2016-09-05T17:57:17.172796: step 3138, loss 0.0122324, acc 1
2016-09-05T17:57:17.401662: step 3139, loss 0.0141377, acc 1
2016-09-05T17:57:17.620957: step 3140, loss 0.0137833, acc 1
2016-09-05T17:57:17.868011: step 3141, loss 0.0183443, acc 1
2016-09-05T17:57:18.066255: step 3142, loss 0.0129891, acc 1
2016-09-05T17:57:18.277374: step 3143, loss 0.0138882, acc 1
2016-09-05T17:57:18.496714: step 3144, loss 0.0109288, acc 1
2016-09-05T17:57:18.734694: step 3145, loss 0.0126296, acc 1
2016-09-05T17:57:18.967156: step 3146, loss 0.0137285, acc 1
2016-09-05T17:57:19.169452: step 3147, loss 0.0110042, acc 1
2016-09-05T17:57:19.403998: step 3148, loss 0.0114306, acc 1
2016-09-05T17:57:19.628116: step 3149, loss 0.0118826, acc 1
2016-09-05T17:57:19.851014: step 3150, loss 0.0122125, acc 1
2016-09-05T17:57:20.078579: step 3151, loss 0.0139703, acc 1
2016-09-05T17:57:20.306889: step 3152, loss 0.0123033, acc 1
2016-09-05T17:57:20.532850: step 3153, loss 0.0112429, acc 1
2016-09-05T17:57:20.789995: step 3154, loss 0.0138735, acc 1
2016-09-05T17:57:21.014571: step 3155, loss 0.0158544, acc 1
2016-09-05T17:57:21.224632: step 3156, loss 0.0112484, acc 1
2016-09-05T17:57:21.450346: step 3157, loss 0.015923, acc 1
2016-09-05T17:57:21.653512: step 3158, loss 0.0131921, acc 1
2016-09-05T17:57:21.879369: step 3159, loss 0.0130981, acc 1
2016-09-05T17:57:22.104141: step 3160, loss 0.0120484, acc 1
2016-09-05T17:57:22.319908: step 3161, loss 0.016432, acc 1
2016-09-05T17:57:22.525550: step 3162, loss 0.0112849, acc 1
2016-09-05T17:57:22.771951: step 3163, loss 0.0134902, acc 1
2016-09-05T17:57:23.017389: step 3164, loss 0.0147734, acc 1
2016-09-05T17:57:23.228590: step 3165, loss 0.0132047, acc 1
2016-09-05T17:57:23.460488: step 3166, loss 0.0139711, acc 1
2016-09-05T17:57:23.668985: step 3167, loss 0.0130175, acc 1
2016-09-05T17:57:23.889164: step 3168, loss 0.011597, acc 1
2016-09-05T17:57:24.098349: step 3169, loss 0.0146272, acc 1
2016-09-05T17:57:24.331461: step 3170, loss 0.0118986, acc 1
2016-09-05T17:57:24.557254: step 3171, loss 0.0115101, acc 1
2016-09-05T17:57:24.839717: step 3172, loss 0.0137123, acc 1
2016-09-05T17:57:25.060093: step 3173, loss 0.0133482, acc 1
2016-09-05T17:57:25.279164: step 3174, loss 0.0122658, acc 1
2016-09-05T17:57:25.487223: step 3175, loss 0.0163526, acc 1
2016-09-05T17:57:25.715780: step 3176, loss 0.0145037, acc 1
2016-09-05T17:57:25.975015: step 3177, loss 0.0147339, acc 1
2016-09-05T17:57:26.187578: step 3178, loss 0.0140931, acc 1
2016-09-05T17:57:26.433408: step 3179, loss 0.0157779, acc 1
2016-09-05T17:57:26.643146: step 3180, loss 0.010997, acc 1
2016-09-05T17:57:26.854845: step 3181, loss 0.0126409, acc 1
2016-09-05T17:57:27.075181: step 3182, loss 0.0116511, acc 1
2016-09-05T17:57:27.284563: step 3183, loss 0.0126526, acc 1
2016-09-05T17:57:27.509448: step 3184, loss 0.014729, acc 1
2016-09-05T17:57:27.729882: step 3185, loss 0.0142249, acc 1
2016-09-05T17:57:27.945400: step 3186, loss 0.0114604, acc 1
2016-09-05T17:57:28.153442: step 3187, loss 0.0130225, acc 1
2016-09-05T17:57:28.383831: step 3188, loss 0.0134397, acc 1
2016-09-05T17:57:28.576526: step 3189, loss 0.0148039, acc 1
2016-09-05T17:57:28.788971: step 3190, loss 0.0144028, acc 1
2016-09-05T17:57:29.022893: step 3191, loss 0.0132975, acc 1
2016-09-05T17:57:29.248774: step 3192, loss 0.0158923, acc 1
2016-09-05T17:57:29.480787: step 3193, loss 0.0148665, acc 1
2016-09-05T17:57:29.697777: step 3194, loss 0.014857, acc 1
2016-09-05T17:57:29.927686: step 3195, loss 0.0134533, acc 1
2016-09-05T17:57:30.140460: step 3196, loss 0.0138313, acc 1
2016-09-05T17:57:30.382136: step 3197, loss 0.0126958, acc 1
2016-09-05T17:57:30.589128: step 3198, loss 0.0122244, acc 1
2016-09-05T17:57:30.796668: step 3199, loss 0.0116425, acc 1
2016-09-05T17:57:30.986752: step 3200, loss 0.0163141, acc 1

Evaluation:
2016-09-05T17:57:31.605216: step 3200, loss 0.874913, acc 0.753

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-3200

2016-09-05T17:57:32.341604: step 3201, loss 0.0116116, acc 1
2016-09-05T17:57:32.539149: step 3202, loss 0.0134157, acc 1
2016-09-05T17:57:32.742039: step 3203, loss 0.0129371, acc 1
2016-09-05T17:57:32.957846: step 3204, loss 0.01872, acc 1
2016-09-05T17:57:33.200289: step 3205, loss 0.0131481, acc 1
2016-09-05T17:57:33.389667: step 3206, loss 0.0145239, acc 1
2016-09-05T17:57:33.615968: step 3207, loss 0.0125911, acc 1
2016-09-05T17:57:33.811407: step 3208, loss 0.0115685, acc 1
2016-09-05T17:57:34.024997: step 3209, loss 0.010889, acc 1
2016-09-05T17:57:34.236044: step 3210, loss 0.0137816, acc 1
2016-09-05T17:57:34.463702: step 3211, loss 0.0121229, acc 1
2016-09-05T17:57:34.668057: step 3212, loss 0.0155093, acc 1
2016-09-05T17:57:34.898580: step 3213, loss 0.0154627, acc 1
2016-09-05T17:57:35.110884: step 3214, loss 0.0158677, acc 1
2016-09-05T17:57:35.323247: step 3215, loss 0.0177793, acc 1
2016-09-05T17:57:35.527754: step 3216, loss 0.0140812, acc 1
2016-09-05T17:57:35.763793: step 3217, loss 0.0136708, acc 1
2016-09-05T17:57:36.013258: step 3218, loss 0.0156446, acc 1
2016-09-05T17:57:36.280866: step 3219, loss 0.0266936, acc 1
2016-09-05T17:57:36.493796: step 3220, loss 0.0129792, acc 1
2016-09-05T17:57:36.719373: step 3221, loss 0.0120747, acc 1
2016-09-05T17:57:36.950002: step 3222, loss 0.0298631, acc 0.98
2016-09-05T17:57:37.162034: step 3223, loss 0.0122193, acc 1
2016-09-05T17:57:37.392370: step 3224, loss 0.0163754, acc 1
2016-09-05T17:57:37.606602: step 3225, loss 0.0137971, acc 1
2016-09-05T17:57:37.822242: step 3226, loss 0.0196706, acc 1
2016-09-05T17:57:38.052461: step 3227, loss 0.016998, acc 1
2016-09-05T17:57:38.265014: step 3228, loss 0.0161999, acc 1
2016-09-05T17:57:38.489686: step 3229, loss 0.0154605, acc 1
2016-09-05T17:57:38.695641: step 3230, loss 0.0123224, acc 1
2016-09-05T17:57:38.920732: step 3231, loss 0.0146532, acc 1
2016-09-05T17:57:39.145841: step 3232, loss 0.0115522, acc 1
2016-09-05T17:57:39.388161: step 3233, loss 0.0134082, acc 1
2016-09-05T17:57:39.610759: step 3234, loss 0.0115755, acc 1
2016-09-05T17:57:39.836802: step 3235, loss 0.0165631, acc 1
2016-09-05T17:57:40.037113: step 3236, loss 0.0172641, acc 1
2016-09-05T17:57:40.267681: step 3237, loss 0.0118403, acc 1
2016-09-05T17:57:40.519612: step 3238, loss 0.0158475, acc 1
2016-09-05T17:57:40.738842: step 3239, loss 0.0177511, acc 1
2016-09-05T17:57:40.950616: step 3240, loss 0.0177726, acc 1
2016-09-05T17:57:41.158256: step 3241, loss 0.014843, acc 1
2016-09-05T17:57:41.410026: step 3242, loss 0.0128851, acc 1
2016-09-05T17:57:41.637499: step 3243, loss 0.0133266, acc 1
2016-09-05T17:57:41.859407: step 3244, loss 0.021267, acc 1
2016-09-05T17:57:42.078780: step 3245, loss 0.0155696, acc 1
2016-09-05T17:57:42.273440: step 3246, loss 0.0149696, acc 1
2016-09-05T17:57:42.486308: step 3247, loss 0.0166645, acc 1
2016-09-05T17:57:42.722528: step 3248, loss 0.0131912, acc 1
2016-09-05T17:57:42.940575: step 3249, loss 0.0118069, acc 1
2016-09-05T17:57:43.154146: step 3250, loss 0.0139583, acc 1
2016-09-05T17:57:43.388931: step 3251, loss 0.0126914, acc 1
2016-09-05T17:57:43.638988: step 3252, loss 0.0120225, acc 1
2016-09-05T17:57:43.848164: step 3253, loss 0.0150281, acc 1
2016-09-05T17:57:44.060099: step 3254, loss 0.0124379, acc 1
2016-09-05T17:57:44.272020: step 3255, loss 0.0177925, acc 1
2016-09-05T17:57:44.517206: step 3256, loss 0.0118098, acc 1
2016-09-05T17:57:44.706158: step 3257, loss 0.0135395, acc 1
2016-09-05T17:57:44.924956: step 3258, loss 0.0201461, acc 1
2016-09-05T17:57:45.144414: step 3259, loss 0.0133878, acc 1
2016-09-05T17:57:45.369149: step 3260, loss 0.0131918, acc 1
2016-09-05T17:57:45.574615: step 3261, loss 0.0142949, acc 1
2016-09-05T17:57:45.789313: step 3262, loss 0.0117801, acc 1
2016-09-05T17:57:46.017652: step 3263, loss 0.028687, acc 0.98
2016-09-05T17:57:46.244763: step 3264, loss 0.0152314, acc 1
2016-09-05T17:57:46.451757: step 3265, loss 0.0154907, acc 1
2016-09-05T17:57:46.678196: step 3266, loss 0.0133411, acc 1
2016-09-05T17:57:46.876435: step 3267, loss 0.0158734, acc 1
2016-09-05T17:57:47.095295: step 3268, loss 0.0122785, acc 1
2016-09-05T17:57:47.306330: step 3269, loss 0.013575, acc 1
2016-09-05T17:57:47.530816: step 3270, loss 0.0131463, acc 1
2016-09-05T17:57:47.754408: step 3271, loss 0.0137452, acc 1
2016-09-05T17:57:47.963985: step 3272, loss 0.0199033, acc 1
2016-09-05T17:57:48.191916: step 3273, loss 0.0118191, acc 1
2016-09-05T17:57:48.393576: step 3274, loss 0.0120258, acc 1
2016-09-05T17:57:48.595933: step 3275, loss 0.0162383, acc 1
2016-09-05T17:57:48.809039: step 3276, loss 0.0142541, acc 1
2016-09-05T17:57:49.038344: step 3277, loss 0.0123609, acc 1
2016-09-05T17:57:49.272711: step 3278, loss 0.0131918, acc 1
2016-09-05T17:57:49.489151: step 3279, loss 0.0218772, acc 1
2016-09-05T17:57:49.690860: step 3280, loss 0.0144386, acc 1
2016-09-05T17:57:49.897510: step 3281, loss 0.0243694, acc 1
2016-09-05T17:57:50.115301: step 3282, loss 0.0226684, acc 1
2016-09-05T17:57:50.352683: step 3283, loss 0.013977, acc 1
2016-09-05T17:57:50.570354: step 3284, loss 0.0123189, acc 1
2016-09-05T17:57:50.767924: step 3285, loss 0.0128681, acc 1
2016-09-05T17:57:51.005573: step 3286, loss 0.0195203, acc 1
2016-09-05T17:57:51.216374: step 3287, loss 0.0131498, acc 1
2016-09-05T17:57:51.456235: step 3288, loss 0.0122669, acc 1
2016-09-05T17:57:51.694289: step 3289, loss 0.0129862, acc 1
2016-09-05T17:57:51.957995: step 3290, loss 0.0138401, acc 1
2016-09-05T17:57:52.175449: step 3291, loss 0.0196264, acc 1
2016-09-05T17:57:52.428108: step 3292, loss 0.0138798, acc 1
2016-09-05T17:57:52.652375: step 3293, loss 0.0133412, acc 1
2016-09-05T17:57:52.869509: step 3294, loss 0.0134242, acc 1
2016-09-05T17:57:53.138765: step 3295, loss 0.0161986, acc 1
2016-09-05T17:57:53.343186: step 3296, loss 0.0147215, acc 1
2016-09-05T17:57:53.602607: step 3297, loss 0.0126167, acc 1
2016-09-05T17:57:53.738005: step 3298, loss 0.0121207, acc 1
2016-09-05T17:57:53.971795: step 3299, loss 0.0112527, acc 1
2016-09-05T17:57:54.187956: step 3300, loss 0.0127569, acc 1

Evaluation:
2016-09-05T17:57:54.794421: step 3300, loss 0.920377, acc 0.754

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-3300

2016-09-05T17:57:55.515426: step 3301, loss 0.0108552, acc 1
2016-09-05T17:57:55.754137: step 3302, loss 0.0118225, acc 1
2016-09-05T17:57:55.961967: step 3303, loss 0.0129824, acc 1
2016-09-05T17:57:56.165108: step 3304, loss 0.0146993, acc 1
2016-09-05T17:57:56.376067: step 3305, loss 0.0131811, acc 1
2016-09-05T17:57:56.590050: step 3306, loss 0.0124762, acc 1
2016-09-05T17:57:56.800206: step 3307, loss 0.0165849, acc 1
2016-09-05T17:57:57.001043: step 3308, loss 0.012761, acc 1
2016-09-05T17:57:57.218902: step 3309, loss 0.0112388, acc 1
2016-09-05T17:57:57.463150: step 3310, loss 0.0116932, acc 1
2016-09-05T17:57:57.682642: step 3311, loss 0.0123257, acc 1
2016-09-05T17:57:57.924764: step 3312, loss 0.0166923, acc 1
2016-09-05T17:57:58.145505: step 3313, loss 0.010454, acc 1
2016-09-05T17:57:58.376747: step 3314, loss 0.0109305, acc 1
2016-09-05T17:57:58.607616: step 3315, loss 0.012045, acc 1
2016-09-05T17:57:58.835457: step 3316, loss 0.0140975, acc 1
2016-09-05T17:57:59.059095: step 3317, loss 0.0113609, acc 1
2016-09-05T17:57:59.277427: step 3318, loss 0.012999, acc 1
2016-09-05T17:57:59.501033: step 3319, loss 0.0148641, acc 1
2016-09-05T17:57:59.741510: step 3320, loss 0.0106743, acc 1
2016-09-05T17:57:59.967831: step 3321, loss 0.0132733, acc 1
2016-09-05T17:58:00.185427: step 3322, loss 0.0136438, acc 1
2016-09-05T17:58:00.416304: step 3323, loss 0.0110627, acc 1
2016-09-05T17:58:00.631010: step 3324, loss 0.0175844, acc 1
2016-09-05T17:58:00.887005: step 3325, loss 0.0179905, acc 1
2016-09-05T17:58:01.095519: step 3326, loss 0.0112573, acc 1
2016-09-05T17:58:01.307084: step 3327, loss 0.0128819, acc 1
2016-09-05T17:58:01.513182: step 3328, loss 0.013092, acc 1
2016-09-05T17:58:01.723231: step 3329, loss 0.0122615, acc 1
2016-09-05T17:58:01.921332: step 3330, loss 0.0106938, acc 1
2016-09-05T17:58:02.128935: step 3331, loss 0.0118054, acc 1
2016-09-05T17:58:02.331959: step 3332, loss 0.0142506, acc 1
2016-09-05T17:58:02.561272: step 3333, loss 0.00989447, acc 1
2016-09-05T17:58:02.777815: step 3334, loss 0.0132286, acc 1
2016-09-05T17:58:03.017369: step 3335, loss 0.01391, acc 1
2016-09-05T17:58:03.234047: step 3336, loss 0.012227, acc 1
2016-09-05T17:58:03.455618: step 3337, loss 0.0131773, acc 1
2016-09-05T17:58:03.687852: step 3338, loss 0.0160903, acc 1
2016-09-05T17:58:03.902686: step 3339, loss 0.0117011, acc 1
2016-09-05T17:58:04.130632: step 3340, loss 0.0113016, acc 1
2016-09-05T17:58:04.314309: step 3341, loss 0.0146157, acc 1
2016-09-05T17:58:04.539307: step 3342, loss 0.0119446, acc 1
2016-09-05T17:58:04.744754: step 3343, loss 0.0141869, acc 1
2016-09-05T17:58:04.967416: step 3344, loss 0.0123325, acc 1
2016-09-05T17:58:05.200879: step 3345, loss 0.0141383, acc 1
2016-09-05T17:58:05.409461: step 3346, loss 0.0165407, acc 1
2016-09-05T17:58:05.610754: step 3347, loss 0.0110448, acc 1
2016-09-05T17:58:05.825583: step 3348, loss 0.0103404, acc 1
2016-09-05T17:58:06.045468: step 3349, loss 0.016518, acc 1
2016-09-05T17:58:06.270547: step 3350, loss 0.0106749, acc 1
2016-09-05T17:58:06.488054: step 3351, loss 0.0222017, acc 1
2016-09-05T17:58:06.690696: step 3352, loss 0.0133532, acc 1
2016-09-05T17:58:06.909308: step 3353, loss 0.0134408, acc 1
2016-09-05T17:58:07.120155: step 3354, loss 0.0129054, acc 1
2016-09-05T17:58:07.368616: step 3355, loss 0.0126134, acc 1
2016-09-05T17:58:07.561400: step 3356, loss 0.0104062, acc 1
2016-09-05T17:58:07.790686: step 3357, loss 0.0166751, acc 1
2016-09-05T17:58:08.005891: step 3358, loss 0.0118856, acc 1
2016-09-05T17:58:08.243696: step 3359, loss 0.0118166, acc 1
2016-09-05T17:58:08.489747: step 3360, loss 0.0150972, acc 1
2016-09-05T17:58:08.692256: step 3361, loss 0.0116701, acc 1
2016-09-05T17:58:08.913590: step 3362, loss 0.0173623, acc 1
2016-09-05T17:58:09.124110: step 3363, loss 0.0132537, acc 1
2016-09-05T17:58:09.326659: step 3364, loss 0.0104585, acc 1
2016-09-05T17:58:09.565936: step 3365, loss 0.0137326, acc 1
2016-09-05T17:58:09.804461: step 3366, loss 0.00995936, acc 1
2016-09-05T17:58:10.013381: step 3367, loss 0.0114141, acc 1
2016-09-05T17:58:10.237772: step 3368, loss 0.0111411, acc 1
2016-09-05T17:58:10.451269: step 3369, loss 0.0124851, acc 1
2016-09-05T17:58:10.681398: step 3370, loss 0.0123588, acc 1
2016-09-05T17:58:10.902295: step 3371, loss 0.0114549, acc 1
2016-09-05T17:58:11.106157: step 3372, loss 0.0145151, acc 1
2016-09-05T17:58:11.305610: step 3373, loss 0.013274, acc 1
2016-09-05T17:58:11.507422: step 3374, loss 0.0123499, acc 1
2016-09-05T17:58:11.714992: step 3375, loss 0.0165572, acc 1
2016-09-05T17:58:11.931357: step 3376, loss 0.0128647, acc 1
2016-09-05T17:58:12.164332: step 3377, loss 0.0137192, acc 1
2016-09-05T17:58:12.380195: step 3378, loss 0.0136397, acc 1
2016-09-05T17:58:12.622208: step 3379, loss 0.0136058, acc 1
2016-09-05T17:58:12.841097: step 3380, loss 0.0102988, acc 1
2016-09-05T17:58:13.045229: step 3381, loss 0.0113173, acc 1
2016-09-05T17:58:13.245381: step 3382, loss 0.0111078, acc 1
2016-09-05T17:58:13.461567: step 3383, loss 0.0103378, acc 1
2016-09-05T17:58:13.686278: step 3384, loss 0.0122581, acc 1
2016-09-05T17:58:13.902515: step 3385, loss 0.0195738, acc 1
2016-09-05T17:58:14.135129: step 3386, loss 0.0117505, acc 1
2016-09-05T17:58:14.364204: step 3387, loss 0.0156886, acc 1
2016-09-05T17:58:14.624151: step 3388, loss 0.011192, acc 1
2016-09-05T17:58:14.842597: step 3389, loss 0.0147712, acc 1
2016-09-05T17:58:15.053600: step 3390, loss 0.0100056, acc 1
2016-09-05T17:58:15.272953: step 3391, loss 0.0126671, acc 1
2016-09-05T17:58:15.476369: step 3392, loss 0.0178014, acc 1
2016-09-05T17:58:15.710466: step 3393, loss 0.0145372, acc 1
2016-09-05T17:58:15.952549: step 3394, loss 0.0122642, acc 1
2016-09-05T17:58:16.179607: step 3395, loss 0.0139866, acc 1
2016-09-05T17:58:16.391956: step 3396, loss 0.0105586, acc 1
2016-09-05T17:58:16.612461: step 3397, loss 0.0163002, acc 1
2016-09-05T17:58:16.843893: step 3398, loss 0.0115537, acc 1
2016-09-05T17:58:17.060689: step 3399, loss 0.0131256, acc 1
2016-09-05T17:58:17.270294: step 3400, loss 0.0116199, acc 1

Evaluation:
2016-09-05T17:58:17.915380: step 3400, loss 0.914176, acc 0.747

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-3400

2016-09-05T17:58:18.604040: step 3401, loss 0.012019, acc 1
2016-09-05T17:58:18.805456: step 3402, loss 0.0109875, acc 1
2016-09-05T17:58:19.015234: step 3403, loss 0.0117206, acc 1
2016-09-05T17:58:19.226817: step 3404, loss 0.0163175, acc 1
2016-09-05T17:58:19.458636: step 3405, loss 0.0103655, acc 1
2016-09-05T17:58:19.688804: step 3406, loss 0.0120107, acc 1
2016-09-05T17:58:19.897320: step 3407, loss 0.0114926, acc 1
2016-09-05T17:58:20.098475: step 3408, loss 0.0125249, acc 1
2016-09-05T17:58:20.309372: step 3409, loss 0.0112241, acc 1
2016-09-05T17:58:20.507959: step 3410, loss 0.0110049, acc 1
2016-09-05T17:58:20.720910: step 3411, loss 0.0129041, acc 1
2016-09-05T17:58:20.930332: step 3412, loss 0.0170292, acc 1
2016-09-05T17:58:21.146104: step 3413, loss 0.011979, acc 1
2016-09-05T17:58:21.347260: step 3414, loss 0.0121952, acc 1
2016-09-05T17:58:21.571250: step 3415, loss 0.0131366, acc 1
2016-09-05T17:58:21.807712: step 3416, loss 0.0115845, acc 1
2016-09-05T17:58:22.025776: step 3417, loss 0.0161902, acc 1
2016-09-05T17:58:22.247290: step 3418, loss 0.0135031, acc 1
2016-09-05T17:58:22.490314: step 3419, loss 0.0147635, acc 1
2016-09-05T17:58:22.728765: step 3420, loss 0.0169031, acc 1
2016-09-05T17:58:22.934974: step 3421, loss 0.0138542, acc 1
2016-09-05T17:58:23.156375: step 3422, loss 0.0123748, acc 1
2016-09-05T17:58:23.374930: step 3423, loss 0.0119043, acc 1
2016-09-05T17:58:23.617444: step 3424, loss 0.0165342, acc 1
2016-09-05T17:58:23.839368: step 3425, loss 0.0109804, acc 1
2016-09-05T17:58:24.047219: step 3426, loss 0.0135581, acc 1
2016-09-05T17:58:24.251918: step 3427, loss 0.0130372, acc 1
2016-09-05T17:58:24.467214: step 3428, loss 0.011556, acc 1
2016-09-05T17:58:24.693413: step 3429, loss 0.0117221, acc 1
2016-09-05T17:58:24.917578: step 3430, loss 0.011547, acc 1
2016-09-05T17:58:25.140360: step 3431, loss 0.0164942, acc 1
2016-09-05T17:58:25.365948: step 3432, loss 0.0120109, acc 1
2016-09-05T17:58:25.577872: step 3433, loss 0.0112953, acc 1
2016-09-05T17:58:25.783580: step 3434, loss 0.0141974, acc 1
2016-09-05T17:58:26.007622: step 3435, loss 0.0131159, acc 1
2016-09-05T17:58:26.236619: step 3436, loss 0.0111103, acc 1
2016-09-05T17:58:26.488188: step 3437, loss 0.0119425, acc 1
2016-09-05T17:58:26.706343: step 3438, loss 0.0117766, acc 1
2016-09-05T17:58:26.932543: step 3439, loss 0.0162307, acc 1
2016-09-05T17:58:27.140230: step 3440, loss 0.0113823, acc 1
2016-09-05T17:58:27.352402: step 3441, loss 0.0114275, acc 1
2016-09-05T17:58:27.581510: step 3442, loss 0.0123927, acc 1
2016-09-05T17:58:27.791460: step 3443, loss 0.0108104, acc 1
2016-09-05T17:58:28.003087: step 3444, loss 0.0126429, acc 1
2016-09-05T17:58:28.196913: step 3445, loss 0.0143486, acc 1
2016-09-05T17:58:28.424862: step 3446, loss 0.0117333, acc 1
2016-09-05T17:58:28.654040: step 3447, loss 0.011899, acc 1
2016-09-05T17:58:28.886678: step 3448, loss 0.011406, acc 1
2016-09-05T17:58:29.097069: step 3449, loss 0.0101023, acc 1
2016-09-05T17:58:29.320997: step 3450, loss 0.0133261, acc 1
2016-09-05T17:58:29.530613: step 3451, loss 0.0116104, acc 1
2016-09-05T17:58:29.761902: step 3452, loss 0.013236, acc 1
2016-09-05T17:58:29.968849: step 3453, loss 0.0116436, acc 1
2016-09-05T17:58:30.188616: step 3454, loss 0.0117999, acc 1
2016-09-05T17:58:30.403828: step 3455, loss 0.0122972, acc 1
2016-09-05T17:58:30.618844: step 3456, loss 0.0142718, acc 1
2016-09-05T17:58:30.834656: step 3457, loss 0.0125649, acc 1
2016-09-05T17:58:31.034484: step 3458, loss 0.0112675, acc 1
2016-09-05T17:58:31.247104: step 3459, loss 0.0121716, acc 1
2016-09-05T17:58:31.463880: step 3460, loss 0.0131765, acc 1
2016-09-05T17:58:31.695918: step 3461, loss 0.0152637, acc 1
2016-09-05T17:58:31.902592: step 3462, loss 0.0149837, acc 1
2016-09-05T17:58:32.133288: step 3463, loss 0.0104463, acc 1
2016-09-05T17:58:32.331466: step 3464, loss 0.0136233, acc 1
2016-09-05T17:58:32.539886: step 3465, loss 0.0217152, acc 1
2016-09-05T17:58:32.771951: step 3466, loss 0.0114672, acc 1
2016-09-05T17:58:32.982422: step 3467, loss 0.0134362, acc 1
2016-09-05T17:58:33.205596: step 3468, loss 0.0138012, acc 1
2016-09-05T17:58:33.389757: step 3469, loss 0.0140754, acc 1
2016-09-05T17:58:33.600646: step 3470, loss 0.0167601, acc 1
2016-09-05T17:58:33.809404: step 3471, loss 0.0206391, acc 1
2016-09-05T17:58:34.034553: step 3472, loss 0.0136238, acc 1
2016-09-05T17:58:34.253854: step 3473, loss 0.0152101, acc 1
2016-09-05T17:58:34.469361: step 3474, loss 0.0139999, acc 1
2016-09-05T17:58:34.683281: step 3475, loss 0.0122859, acc 1
2016-09-05T17:58:34.917392: step 3476, loss 0.0118032, acc 1
2016-09-05T17:58:35.122548: step 3477, loss 0.0118452, acc 1
2016-09-05T17:58:35.346007: step 3478, loss 0.01249, acc 1
2016-09-05T17:58:35.554931: step 3479, loss 0.0152968, acc 1
2016-09-05T17:58:35.786306: step 3480, loss 0.0128332, acc 1
2016-09-05T17:58:36.018519: step 3481, loss 0.012065, acc 1
2016-09-05T17:58:36.268245: step 3482, loss 0.013708, acc 1
2016-09-05T17:58:36.491497: step 3483, loss 0.0120522, acc 1
2016-09-05T17:58:36.722936: step 3484, loss 0.0133591, acc 1
2016-09-05T17:58:36.971695: step 3485, loss 0.0124442, acc 1
2016-09-05T17:58:37.173866: step 3486, loss 0.0120384, acc 1
2016-09-05T17:58:37.378495: step 3487, loss 0.0117805, acc 1
2016-09-05T17:58:37.586490: step 3488, loss 0.0133985, acc 1
2016-09-05T17:58:37.836348: step 3489, loss 0.0126928, acc 1
2016-09-05T17:58:38.040481: step 3490, loss 0.0121569, acc 1
2016-09-05T17:58:38.244343: step 3491, loss 0.0134761, acc 1
2016-09-05T17:58:38.381490: step 3492, loss 0.0114847, acc 1
2016-09-05T17:58:38.582483: step 3493, loss 0.0117751, acc 1
2016-09-05T17:58:38.794937: step 3494, loss 0.0107525, acc 1
2016-09-05T17:58:39.028069: step 3495, loss 0.011167, acc 1
2016-09-05T17:58:39.277062: step 3496, loss 0.0112821, acc 1
2016-09-05T17:58:39.492954: step 3497, loss 0.0108041, acc 1
2016-09-05T17:58:39.701718: step 3498, loss 0.0100571, acc 1
2016-09-05T17:58:39.912123: step 3499, loss 0.0110105, acc 1
2016-09-05T17:58:40.122894: step 3500, loss 0.0111806, acc 1

Evaluation:
2016-09-05T17:58:40.739485: step 3500, loss 0.935135, acc 0.747

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-3500

2016-09-05T17:58:41.468806: step 3501, loss 0.0118367, acc 1
2016-09-05T17:58:41.706391: step 3502, loss 0.0106979, acc 1
2016-09-05T17:58:41.914708: step 3503, loss 0.0162509, acc 1
2016-09-05T17:58:42.124979: step 3504, loss 0.00992986, acc 1
2016-09-05T17:58:42.336129: step 3505, loss 0.0124415, acc 1
2016-09-05T17:58:42.573074: step 3506, loss 0.0140552, acc 1
2016-09-05T17:58:42.787593: step 3507, loss 0.0125504, acc 1
2016-09-05T17:58:42.996764: step 3508, loss 0.0107931, acc 1
2016-09-05T17:58:43.181342: step 3509, loss 0.0103158, acc 1
2016-09-05T17:58:43.399126: step 3510, loss 0.0114112, acc 1
2016-09-05T17:58:43.637995: step 3511, loss 0.0111642, acc 1
2016-09-05T17:58:43.898161: step 3512, loss 0.0103123, acc 1
2016-09-05T17:58:44.137067: step 3513, loss 0.0113076, acc 1
2016-09-05T17:58:44.345073: step 3514, loss 0.0113537, acc 1
2016-09-05T17:58:44.545988: step 3515, loss 0.0102067, acc 1
2016-09-05T17:58:44.769874: step 3516, loss 0.00973159, acc 1
2016-09-05T17:58:44.990230: step 3517, loss 0.0144372, acc 1
2016-09-05T17:58:45.218557: step 3518, loss 0.0102084, acc 1
2016-09-05T17:58:45.452498: step 3519, loss 0.0106109, acc 1
2016-09-05T17:58:45.658199: step 3520, loss 0.0125763, acc 1
2016-09-05T17:58:45.867562: step 3521, loss 0.0102598, acc 1
2016-09-05T17:58:46.069688: step 3522, loss 0.0171158, acc 1
2016-09-05T17:58:46.293262: step 3523, loss 0.0102312, acc 1
2016-09-05T17:58:46.522370: step 3524, loss 0.0105596, acc 1
2016-09-05T17:58:46.740574: step 3525, loss 0.0122615, acc 1
2016-09-05T17:58:46.949682: step 3526, loss 0.0117899, acc 1
2016-09-05T17:58:47.164649: step 3527, loss 0.0101452, acc 1
2016-09-05T17:58:47.391752: step 3528, loss 0.0103854, acc 1
2016-09-05T17:58:47.606872: step 3529, loss 0.00991891, acc 1
2016-09-05T17:58:47.859413: step 3530, loss 0.0112969, acc 1
2016-09-05T17:58:48.060526: step 3531, loss 0.0112579, acc 1
2016-09-05T17:58:48.274631: step 3532, loss 0.0111183, acc 1
2016-09-05T17:58:48.508790: step 3533, loss 0.0115786, acc 1
2016-09-05T17:58:48.710769: step 3534, loss 0.0126807, acc 1
2016-09-05T17:58:48.944989: step 3535, loss 0.0104287, acc 1
2016-09-05T17:58:49.163652: step 3536, loss 0.0118893, acc 1
2016-09-05T17:58:49.372073: step 3537, loss 0.0115259, acc 1
2016-09-05T17:58:49.576232: step 3538, loss 0.0105998, acc 1
2016-09-05T17:58:49.790556: step 3539, loss 0.0137913, acc 1
2016-09-05T17:58:49.996354: step 3540, loss 0.00907607, acc 1
2016-09-05T17:58:50.219293: step 3541, loss 0.0100618, acc 1
2016-09-05T17:58:50.422506: step 3542, loss 0.0106818, acc 1
2016-09-05T17:58:50.649911: step 3543, loss 0.00933131, acc 1
2016-09-05T17:58:50.872836: step 3544, loss 0.0101313, acc 1
2016-09-05T17:58:51.098823: step 3545, loss 0.0105577, acc 1
2016-09-05T17:58:51.308705: step 3546, loss 0.0116434, acc 1
2016-09-05T17:58:51.527944: step 3547, loss 0.0114814, acc 1
2016-09-05T17:58:51.738067: step 3548, loss 0.0142469, acc 1
2016-09-05T17:58:51.961249: step 3549, loss 0.0144726, acc 1
2016-09-05T17:58:52.200603: step 3550, loss 0.0114696, acc 1
2016-09-05T17:58:52.403584: step 3551, loss 0.0113088, acc 1
2016-09-05T17:58:52.632709: step 3552, loss 0.00953448, acc 1
2016-09-05T17:58:52.836911: step 3553, loss 0.00962404, acc 1
2016-09-05T17:58:53.067533: step 3554, loss 0.0097234, acc 1
2016-09-05T17:58:53.293430: step 3555, loss 0.0138469, acc 1
2016-09-05T17:58:53.510375: step 3556, loss 0.01108, acc 1
2016-09-05T17:58:53.722204: step 3557, loss 0.00997625, acc 1
2016-09-05T17:58:53.940309: step 3558, loss 0.0110752, acc 1
2016-09-05T17:58:54.141379: step 3559, loss 0.0124805, acc 1
2016-09-05T17:58:54.359474: step 3560, loss 0.0100384, acc 1
2016-09-05T17:58:54.585408: step 3561, loss 0.0102928, acc 1
2016-09-05T17:58:54.803694: step 3562, loss 0.0118998, acc 1
2016-09-05T17:58:55.019321: step 3563, loss 0.0120494, acc 1
2016-09-05T17:58:55.209386: step 3564, loss 0.0109785, acc 1
2016-09-05T17:58:55.440491: step 3565, loss 0.0110785, acc 1
2016-09-05T17:58:55.665995: step 3566, loss 0.0110725, acc 1
2016-09-05T17:58:55.932769: step 3567, loss 0.0127425, acc 1
2016-09-05T17:58:56.126471: step 3568, loss 0.00960225, acc 1
2016-09-05T17:58:56.342903: step 3569, loss 0.0105977, acc 1
2016-09-05T17:58:56.555778: step 3570, loss 0.0120001, acc 1
2016-09-05T17:58:56.758531: step 3571, loss 0.0123023, acc 1
2016-09-05T17:58:56.981410: step 3572, loss 0.00968769, acc 1
2016-09-05T17:58:57.224243: step 3573, loss 0.00996672, acc 1
2016-09-05T17:58:57.438060: step 3574, loss 0.011248, acc 1
2016-09-05T17:58:57.638047: step 3575, loss 0.0103205, acc 1
2016-09-05T17:58:57.850668: step 3576, loss 0.00903939, acc 1
2016-09-05T17:58:58.097078: step 3577, loss 0.0141115, acc 1
2016-09-05T17:58:58.321783: step 3578, loss 0.0126083, acc 1
2016-09-05T17:58:58.536152: step 3579, loss 0.00904823, acc 1
2016-09-05T17:58:58.765265: step 3580, loss 0.0121999, acc 1
2016-09-05T17:58:58.979045: step 3581, loss 0.0133222, acc 1
2016-09-05T17:58:59.188829: step 3582, loss 0.00995286, acc 1
2016-09-05T17:58:59.419645: step 3583, loss 0.0114102, acc 1
2016-09-05T17:58:59.620818: step 3584, loss 0.0092987, acc 1
2016-09-05T17:58:59.849787: step 3585, loss 0.0127817, acc 1
2016-09-05T17:59:00.052963: step 3586, loss 0.0119424, acc 1
2016-09-05T17:59:00.272375: step 3587, loss 0.0114655, acc 1
2016-09-05T17:59:00.479539: step 3588, loss 0.0102207, acc 1
2016-09-05T17:59:00.698322: step 3589, loss 0.0133047, acc 1
2016-09-05T17:59:00.915196: step 3590, loss 0.00998594, acc 1
2016-09-05T17:59:01.139512: step 3591, loss 0.0102381, acc 1
2016-09-05T17:59:01.343406: step 3592, loss 0.014349, acc 1
2016-09-05T17:59:01.570863: step 3593, loss 0.0106573, acc 1
2016-09-05T17:59:01.788288: step 3594, loss 0.00963323, acc 1
2016-09-05T17:59:02.036759: step 3595, loss 0.0113841, acc 1
2016-09-05T17:59:02.283653: step 3596, loss 0.0132621, acc 1
2016-09-05T17:59:02.475828: step 3597, loss 0.0127426, acc 1
2016-09-05T17:59:02.687079: step 3598, loss 0.00989504, acc 1
2016-09-05T17:59:02.889565: step 3599, loss 0.0111176, acc 1
2016-09-05T17:59:03.107959: step 3600, loss 0.012697, acc 1

Evaluation:
2016-09-05T17:59:03.713053: step 3600, loss 0.928599, acc 0.747

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-3600

2016-09-05T17:59:04.463349: step 3601, loss 0.0116787, acc 1
2016-09-05T17:59:04.680561: step 3602, loss 0.00920319, acc 1
2016-09-05T17:59:04.918223: step 3603, loss 0.011062, acc 1
2016-09-05T17:59:05.128506: step 3604, loss 0.01196, acc 1
2016-09-05T17:59:05.333468: step 3605, loss 0.0124444, acc 1
2016-09-05T17:59:05.534441: step 3606, loss 0.0118188, acc 1
2016-09-05T17:59:05.764849: step 3607, loss 0.0109199, acc 1
2016-09-05T17:59:05.996755: step 3608, loss 0.0162106, acc 1
2016-09-05T17:59:06.220690: step 3609, loss 0.010042, acc 1
2016-09-05T17:59:06.437265: step 3610, loss 0.0113144, acc 1
2016-09-05T17:59:06.651243: step 3611, loss 0.0100609, acc 1
2016-09-05T17:59:06.858321: step 3612, loss 0.0107883, acc 1
2016-09-05T17:59:07.062506: step 3613, loss 0.0105593, acc 1
2016-09-05T17:59:07.280669: step 3614, loss 0.00898455, acc 1
2016-09-05T17:59:07.491078: step 3615, loss 0.0132868, acc 1
2016-09-05T17:59:07.703627: step 3616, loss 0.0107893, acc 1
2016-09-05T17:59:07.932356: step 3617, loss 0.011561, acc 1
2016-09-05T17:59:08.141366: step 3618, loss 0.013179, acc 1
2016-09-05T17:59:08.341353: step 3619, loss 0.0111065, acc 1
2016-09-05T17:59:08.554036: step 3620, loss 0.01185, acc 1
2016-09-05T17:59:08.754207: step 3621, loss 0.0110128, acc 1
2016-09-05T17:59:08.962381: step 3622, loss 0.0127545, acc 1
2016-09-05T17:59:09.184725: step 3623, loss 0.0100159, acc 1
2016-09-05T17:59:09.457126: step 3624, loss 0.0104374, acc 1
2016-09-05T17:59:09.660970: step 3625, loss 0.0128729, acc 1
2016-09-05T17:59:09.859042: step 3626, loss 0.0100906, acc 1
2016-09-05T17:59:10.077769: step 3627, loss 0.012442, acc 1
2016-09-05T17:59:10.306096: step 3628, loss 0.0119732, acc 1
2016-09-05T17:59:10.566768: step 3629, loss 0.0123921, acc 1
2016-09-05T17:59:10.783963: step 3630, loss 0.0134246, acc 1
2016-09-05T17:59:11.024150: step 3631, loss 0.0110093, acc 1
2016-09-05T17:59:11.256513: step 3632, loss 0.00940347, acc 1
2016-09-05T17:59:11.457450: step 3633, loss 0.00915702, acc 1
2016-09-05T17:59:11.668932: step 3634, loss 0.00977029, acc 1
2016-09-05T17:59:11.865415: step 3635, loss 0.0119273, acc 1
2016-09-05T17:59:12.085721: step 3636, loss 0.00942628, acc 1
2016-09-05T17:59:12.284720: step 3637, loss 0.00984862, acc 1
2016-09-05T17:59:12.498839: step 3638, loss 0.0119314, acc 1
2016-09-05T17:59:12.719603: step 3639, loss 0.010076, acc 1
2016-09-05T17:59:12.950290: step 3640, loss 0.0113526, acc 1
2016-09-05T17:59:13.180918: step 3641, loss 0.0152736, acc 1
2016-09-05T17:59:13.391251: step 3642, loss 0.010766, acc 1
2016-09-05T17:59:13.612173: step 3643, loss 0.0110678, acc 1
2016-09-05T17:59:13.864940: step 3644, loss 0.0102766, acc 1
2016-09-05T17:59:14.089617: step 3645, loss 0.00996096, acc 1
2016-09-05T17:59:14.293099: step 3646, loss 0.00921991, acc 1
2016-09-05T17:59:14.528816: step 3647, loss 0.00980301, acc 1
2016-09-05T17:59:14.731251: step 3648, loss 0.00987428, acc 1
2016-09-05T17:59:14.951453: step 3649, loss 0.00926761, acc 1
2016-09-05T17:59:15.182392: step 3650, loss 0.0132148, acc 1
2016-09-05T17:59:15.411720: step 3651, loss 0.0146187, acc 1
2016-09-05T17:59:15.615491: step 3652, loss 0.0122963, acc 1
2016-09-05T17:59:15.832408: step 3653, loss 0.0112241, acc 1
2016-09-05T17:59:16.043703: step 3654, loss 0.0120164, acc 1
2016-09-05T17:59:16.243625: step 3655, loss 0.0145632, acc 1
2016-09-05T17:59:16.460904: step 3656, loss 0.0125133, acc 1
2016-09-05T17:59:16.677394: step 3657, loss 0.0156493, acc 1
2016-09-05T17:59:16.900136: step 3658, loss 0.0123236, acc 1
2016-09-05T17:59:17.120409: step 3659, loss 0.0121562, acc 1
2016-09-05T17:59:17.358807: step 3660, loss 0.0102445, acc 1
2016-09-05T17:59:17.571503: step 3661, loss 0.0164617, acc 1
2016-09-05T17:59:17.813393: step 3662, loss 0.0119407, acc 1
2016-09-05T17:59:18.043657: step 3663, loss 0.00989322, acc 1
2016-09-05T17:59:18.262698: step 3664, loss 0.0113212, acc 1
2016-09-05T17:59:18.474486: step 3665, loss 0.0111743, acc 1
2016-09-05T17:59:18.695514: step 3666, loss 0.014211, acc 1
2016-09-05T17:59:18.936456: step 3667, loss 0.0107023, acc 1
2016-09-05T17:59:19.119826: step 3668, loss 0.0102661, acc 1
2016-09-05T17:59:19.349547: step 3669, loss 0.0111579, acc 1
2016-09-05T17:59:19.555797: step 3670, loss 0.0131023, acc 1
2016-09-05T17:59:19.771447: step 3671, loss 0.0128543, acc 1
2016-09-05T17:59:19.986197: step 3672, loss 0.0123887, acc 1
2016-09-05T17:59:20.222321: step 3673, loss 0.012723, acc 1
2016-09-05T17:59:20.461967: step 3674, loss 0.0190109, acc 1
2016-09-05T17:59:20.671080: step 3675, loss 0.0116275, acc 1
2016-09-05T17:59:20.879577: step 3676, loss 0.0107316, acc 1
2016-09-05T17:59:21.091537: step 3677, loss 0.0125002, acc 1
2016-09-05T17:59:21.291932: step 3678, loss 0.0154732, acc 1
2016-09-05T17:59:21.513002: step 3679, loss 0.0101743, acc 1
2016-09-05T17:59:21.747402: step 3680, loss 0.0218254, acc 1
2016-09-05T17:59:21.977766: step 3681, loss 0.0103724, acc 1
2016-09-05T17:59:22.191052: step 3682, loss 0.0134933, acc 1
2016-09-05T17:59:22.397979: step 3683, loss 0.00991849, acc 1
2016-09-05T17:59:22.603179: step 3684, loss 0.0132472, acc 1
2016-09-05T17:59:22.807929: step 3685, loss 0.011887, acc 1
2016-09-05T17:59:22.936808: step 3686, loss 0.0128249, acc 1
2016-09-05T17:59:23.193425: step 3687, loss 0.0129738, acc 1
2016-09-05T17:59:23.396989: step 3688, loss 0.010884, acc 1
2016-09-05T17:59:23.616644: step 3689, loss 0.0101417, acc 1
2016-09-05T17:59:23.846528: step 3690, loss 0.0104671, acc 1
2016-09-05T17:59:24.060550: step 3691, loss 0.010338, acc 1
2016-09-05T17:59:24.295892: step 3692, loss 0.010594, acc 1
2016-09-05T17:59:24.505662: step 3693, loss 0.0108085, acc 1
2016-09-05T17:59:24.727509: step 3694, loss 0.00925028, acc 1
2016-09-05T17:59:24.948138: step 3695, loss 0.00936852, acc 1
2016-09-05T17:59:25.175160: step 3696, loss 0.0108931, acc 1
2016-09-05T17:59:25.406458: step 3697, loss 0.011113, acc 1
2016-09-05T17:59:25.602551: step 3698, loss 0.0108955, acc 1
2016-09-05T17:59:25.816295: step 3699, loss 0.0099419, acc 1
2016-09-05T17:59:26.039109: step 3700, loss 0.0105764, acc 1

Evaluation:
2016-09-05T17:59:26.663871: step 3700, loss 0.943073, acc 0.752

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-3700

2016-09-05T17:59:27.451119: step 3701, loss 0.0100966, acc 1
2016-09-05T17:59:27.663440: step 3702, loss 0.0111307, acc 1
2016-09-05T17:59:27.893556: step 3703, loss 0.0103801, acc 1
2016-09-05T17:59:28.110560: step 3704, loss 0.00855275, acc 1
2016-09-05T17:59:28.339581: step 3705, loss 0.0104317, acc 1
2016-09-05T17:59:28.567095: step 3706, loss 0.00992382, acc 1
2016-09-05T17:59:28.792031: step 3707, loss 0.0102724, acc 1
2016-09-05T17:59:29.021069: step 3708, loss 0.0107729, acc 1
2016-09-05T17:59:29.235337: step 3709, loss 0.0121607, acc 1
2016-09-05T17:59:29.436575: step 3710, loss 0.00863945, acc 1
2016-09-05T17:59:29.667919: step 3711, loss 0.0091939, acc 1
2016-09-05T17:59:29.882198: step 3712, loss 0.00831224, acc 1
2016-09-05T17:59:30.117804: step 3713, loss 0.0173144, acc 1
2016-09-05T17:59:30.338423: step 3714, loss 0.0106077, acc 1
2016-09-05T17:59:30.557989: step 3715, loss 0.00865135, acc 1
2016-09-05T17:59:30.771979: step 3716, loss 0.0122716, acc 1
2016-09-05T17:59:30.978832: step 3717, loss 0.010167, acc 1
2016-09-05T17:59:31.219832: step 3718, loss 0.0106181, acc 1
2016-09-05T17:59:31.454792: step 3719, loss 0.0104872, acc 1
2016-09-05T17:59:31.666426: step 3720, loss 0.00984915, acc 1
2016-09-05T17:59:31.863167: step 3721, loss 0.0121987, acc 1
2016-09-05T17:59:32.067435: step 3722, loss 0.00947771, acc 1
2016-09-05T17:59:32.265747: step 3723, loss 0.0103462, acc 1
2016-09-05T17:59:32.482483: step 3724, loss 0.00951921, acc 1
2016-09-05T17:59:32.695141: step 3725, loss 0.00876262, acc 1
2016-09-05T17:59:32.924535: step 3726, loss 0.0107435, acc 1
2016-09-05T17:59:33.143551: step 3727, loss 0.00897468, acc 1
2016-09-05T17:59:33.392236: step 3728, loss 0.0115022, acc 1
2016-09-05T17:59:33.611931: step 3729, loss 0.0118519, acc 1
2016-09-05T17:59:33.825112: step 3730, loss 0.0112356, acc 1
2016-09-05T17:59:34.052118: step 3731, loss 0.0134042, acc 1
2016-09-05T17:59:34.263601: step 3732, loss 0.0101239, acc 1
2016-09-05T17:59:34.496838: step 3733, loss 0.00921794, acc 1
2016-09-05T17:59:34.694317: step 3734, loss 0.01067, acc 1
2016-09-05T17:59:34.927282: step 3735, loss 0.0109362, acc 1
2016-09-05T17:59:35.164510: step 3736, loss 0.0104096, acc 1
2016-09-05T17:59:35.370569: step 3737, loss 0.0123292, acc 1
2016-09-05T17:59:35.593590: step 3738, loss 0.00892963, acc 1
2016-09-05T17:59:35.814794: step 3739, loss 0.010951, acc 1
2016-09-05T17:59:36.042497: step 3740, loss 0.00925459, acc 1
2016-09-05T17:59:36.252610: step 3741, loss 0.0103688, acc 1
2016-09-05T17:59:36.483978: step 3742, loss 0.00932493, acc 1
2016-09-05T17:59:36.701494: step 3743, loss 0.0102688, acc 1
2016-09-05T17:59:36.924456: step 3744, loss 0.0130117, acc 1
2016-09-05T17:59:37.132956: step 3745, loss 0.00950188, acc 1
2016-09-05T17:59:37.368877: step 3746, loss 0.00997466, acc 1
2016-09-05T17:59:37.595688: step 3747, loss 0.00968191, acc 1
2016-09-05T17:59:37.808041: step 3748, loss 0.011687, acc 1
2016-09-05T17:59:38.038963: step 3749, loss 0.00951673, acc 1
2016-09-05T17:59:38.250972: step 3750, loss 0.0131489, acc 1
2016-09-05T17:59:38.457525: step 3751, loss 0.0146226, acc 1
2016-09-05T17:59:38.654809: step 3752, loss 0.0127777, acc 1
2016-09-05T17:59:38.859745: step 3753, loss 0.010905, acc 1
2016-09-05T17:59:39.078410: step 3754, loss 0.0104427, acc 1
2016-09-05T17:59:39.283591: step 3755, loss 0.0103986, acc 1
2016-09-05T17:59:39.515483: step 3756, loss 0.0115629, acc 1
2016-09-05T17:59:39.752568: step 3757, loss 0.0101655, acc 1
2016-09-05T17:59:39.962465: step 3758, loss 0.0119377, acc 1
2016-09-05T17:59:40.202563: step 3759, loss 0.0102648, acc 1
2016-09-05T17:59:40.421536: step 3760, loss 0.0115245, acc 1
2016-09-05T17:59:40.656344: step 3761, loss 0.0115701, acc 1
2016-09-05T17:59:40.887893: step 3762, loss 0.0107704, acc 1
2016-09-05T17:59:41.087673: step 3763, loss 0.0116889, acc 1
2016-09-05T17:59:41.307099: step 3764, loss 0.0138126, acc 1
2016-09-05T17:59:41.499327: step 3765, loss 0.010814, acc 1
2016-09-05T17:59:41.709772: step 3766, loss 0.0116283, acc 1
2016-09-05T17:59:41.919186: step 3767, loss 0.0118806, acc 1
2016-09-05T17:59:42.163392: step 3768, loss 0.00872187, acc 1
2016-09-05T17:59:42.370550: step 3769, loss 0.00950431, acc 1
2016-09-05T17:59:42.582154: step 3770, loss 0.0125513, acc 1
2016-09-05T17:59:42.792176: step 3771, loss 0.00919671, acc 1
2016-09-05T17:59:42.997748: step 3772, loss 0.0103409, acc 1
2016-09-05T17:59:43.200553: step 3773, loss 0.0138086, acc 1
2016-09-05T17:59:43.429493: step 3774, loss 0.0105961, acc 1
2016-09-05T17:59:43.665401: step 3775, loss 0.0102643, acc 1
2016-09-05T17:59:43.865128: step 3776, loss 0.0102698, acc 1
2016-09-05T17:59:44.092705: step 3777, loss 0.0103645, acc 1
2016-09-05T17:59:44.302883: step 3778, loss 0.00898969, acc 1
2016-09-05T17:59:44.544091: step 3779, loss 0.00912515, acc 1
2016-09-05T17:59:44.792928: step 3780, loss 0.0101927, acc 1
2016-09-05T17:59:45.017438: step 3781, loss 0.0110592, acc 1
2016-09-05T17:59:45.238734: step 3782, loss 0.0104801, acc 1
2016-09-05T17:59:45.503936: step 3783, loss 0.00906541, acc 1
2016-09-05T17:59:45.711274: step 3784, loss 0.0109254, acc 1
2016-09-05T17:59:45.920006: step 3785, loss 0.0123394, acc 1
2016-09-05T17:59:46.183062: step 3786, loss 0.0101081, acc 1
2016-09-05T17:59:46.414411: step 3787, loss 0.0118241, acc 1
2016-09-05T17:59:46.627946: step 3788, loss 0.00954386, acc 1
2016-09-05T17:59:46.851068: step 3789, loss 0.00876678, acc 1
2016-09-05T17:59:47.124546: step 3790, loss 0.0108337, acc 1
2016-09-05T17:59:47.335732: step 3791, loss 0.0100349, acc 1
2016-09-05T17:59:47.534718: step 3792, loss 0.0112407, acc 1
2016-09-05T17:59:47.742416: step 3793, loss 0.0111744, acc 1
2016-09-05T17:59:47.949011: step 3794, loss 0.0117593, acc 1
2016-09-05T17:59:48.176310: step 3795, loss 0.0136361, acc 1
2016-09-05T17:59:48.398005: step 3796, loss 0.0112427, acc 1
2016-09-05T17:59:48.598135: step 3797, loss 0.00952797, acc 1
2016-09-05T17:59:48.810600: step 3798, loss 0.00944591, acc 1
2016-09-05T17:59:49.029617: step 3799, loss 0.00980271, acc 1
2016-09-05T17:59:49.233803: step 3800, loss 0.00919543, acc 1

Evaluation:
2016-09-05T17:59:49.854566: step 3800, loss 0.927181, acc 0.754

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-3800

2016-09-05T17:59:50.669221: step 3801, loss 0.0100631, acc 1
2016-09-05T17:59:50.893605: step 3802, loss 0.0127496, acc 1
2016-09-05T17:59:51.117445: step 3803, loss 0.00984074, acc 1
2016-09-05T17:59:51.349730: step 3804, loss 0.0106301, acc 1
2016-09-05T17:59:51.568570: step 3805, loss 0.00912932, acc 1
2016-09-05T17:59:51.785431: step 3806, loss 0.0112487, acc 1
2016-09-05T17:59:51.985379: step 3807, loss 0.0107401, acc 1
2016-09-05T17:59:52.198400: step 3808, loss 0.0101628, acc 1
2016-09-05T17:59:52.395673: step 3809, loss 0.0104889, acc 1
2016-09-05T17:59:52.613111: step 3810, loss 0.0098108, acc 1
2016-09-05T17:59:52.819849: step 3811, loss 0.00955917, acc 1
2016-09-05T17:59:53.044061: step 3812, loss 0.00925674, acc 1
2016-09-05T17:59:53.280328: step 3813, loss 0.0112647, acc 1
2016-09-05T17:59:53.501066: step 3814, loss 0.00974227, acc 1
2016-09-05T17:59:53.714374: step 3815, loss 0.0120551, acc 1
2016-09-05T17:59:53.919513: step 3816, loss 0.0121571, acc 1
2016-09-05T17:59:54.128027: step 3817, loss 0.00902464, acc 1
2016-09-05T17:59:54.365016: step 3818, loss 0.00937997, acc 1
2016-09-05T17:59:54.590569: step 3819, loss 0.0109464, acc 1
2016-09-05T17:59:54.802965: step 3820, loss 0.00904647, acc 1
2016-09-05T17:59:55.009549: step 3821, loss 0.00896645, acc 1
2016-09-05T17:59:55.233203: step 3822, loss 0.0107537, acc 1
2016-09-05T17:59:55.465713: step 3823, loss 0.0112112, acc 1
2016-09-05T17:59:55.681706: step 3824, loss 0.0102727, acc 1
2016-09-05T17:59:55.906034: step 3825, loss 0.0106562, acc 1
2016-09-05T17:59:56.106025: step 3826, loss 0.0145778, acc 1
2016-09-05T17:59:56.318529: step 3827, loss 0.0112694, acc 1
2016-09-05T17:59:56.538735: step 3828, loss 0.00863893, acc 1
2016-09-05T17:59:56.739941: step 3829, loss 0.01077, acc 1
2016-09-05T17:59:56.939471: step 3830, loss 0.00979111, acc 1
2016-09-05T17:59:57.152676: step 3831, loss 0.0106441, acc 1
2016-09-05T17:59:57.351367: step 3832, loss 0.0133588, acc 1
2016-09-05T17:59:57.557623: step 3833, loss 0.0103375, acc 1
2016-09-05T17:59:57.777293: step 3834, loss 0.0111061, acc 1
2016-09-05T17:59:58.006781: step 3835, loss 0.00968994, acc 1
2016-09-05T17:59:58.201895: step 3836, loss 0.00979654, acc 1
2016-09-05T17:59:58.434710: step 3837, loss 0.0113537, acc 1
2016-09-05T17:59:58.653182: step 3838, loss 0.0133256, acc 1
2016-09-05T17:59:58.864384: step 3839, loss 0.0123318, acc 1
2016-09-05T17:59:59.083987: step 3840, loss 0.0107395, acc 1
2016-09-05T17:59:59.311020: step 3841, loss 0.0111219, acc 1
2016-09-05T17:59:59.553861: step 3842, loss 0.0151037, acc 1
2016-09-05T17:59:59.769713: step 3843, loss 0.00946785, acc 1
2016-09-05T17:59:59.984930: step 3844, loss 0.010445, acc 1
2016-09-05T18:00:00.213535: step 3845, loss 0.0126699, acc 1
2016-09-05T18:00:00.478776: step 3846, loss 0.0118784, acc 1
2016-09-05T18:00:00.707735: step 3847, loss 0.0115909, acc 1
2016-09-05T18:00:00.944783: step 3848, loss 0.0102833, acc 1
2016-09-05T18:00:01.157186: step 3849, loss 0.0112398, acc 1
2016-09-05T18:00:01.362555: step 3850, loss 0.015098, acc 1
2016-09-05T18:00:01.577989: step 3851, loss 0.0105455, acc 1
2016-09-05T18:00:01.806614: step 3852, loss 0.0115583, acc 1
2016-09-05T18:00:02.020537: step 3853, loss 0.0102604, acc 1
2016-09-05T18:00:02.236840: step 3854, loss 0.0166937, acc 1
2016-09-05T18:00:02.473330: step 3855, loss 0.0101124, acc 1
2016-09-05T18:00:02.696388: step 3856, loss 0.00907805, acc 1
2016-09-05T18:00:02.901416: step 3857, loss 0.0120914, acc 1
2016-09-05T18:00:03.102407: step 3858, loss 0.0111404, acc 1
2016-09-05T18:00:03.348725: step 3859, loss 0.00991949, acc 1
2016-09-05T18:00:03.557938: step 3860, loss 0.0100877, acc 1
2016-09-05T18:00:03.774170: step 3861, loss 0.0101642, acc 1
2016-09-05T18:00:03.997040: step 3862, loss 0.00929998, acc 1
2016-09-05T18:00:04.255748: step 3863, loss 0.0119487, acc 1
2016-09-05T18:00:04.476679: step 3864, loss 0.00912254, acc 1
2016-09-05T18:00:04.684001: step 3865, loss 0.00946019, acc 1
2016-09-05T18:00:04.923384: step 3866, loss 0.0104683, acc 1
2016-09-05T18:00:05.143527: step 3867, loss 0.0108705, acc 1
2016-09-05T18:00:05.369371: step 3868, loss 0.009508, acc 1
2016-09-05T18:00:05.573343: step 3869, loss 0.0111042, acc 1
2016-09-05T18:00:05.805805: step 3870, loss 0.0111297, acc 1
2016-09-05T18:00:06.027730: step 3871, loss 0.00848666, acc 1
2016-09-05T18:00:06.249720: step 3872, loss 0.010288, acc 1
2016-09-05T18:00:06.498547: step 3873, loss 0.0105847, acc 1
2016-09-05T18:00:06.696189: step 3874, loss 0.0159572, acc 1
2016-09-05T18:00:06.906586: step 3875, loss 0.0089374, acc 1
2016-09-05T18:00:07.117224: step 3876, loss 0.0123825, acc 1
2016-09-05T18:00:07.340003: step 3877, loss 0.00901209, acc 1
2016-09-05T18:00:07.589489: step 3878, loss 0.0102849, acc 1
2016-09-05T18:00:07.827618: step 3879, loss 0.0100908, acc 1
2016-09-05T18:00:07.970743: step 3880, loss 0.0117054, acc 1
2016-09-05T18:00:08.210570: step 3881, loss 0.0111375, acc 1
2016-09-05T18:00:08.410830: step 3882, loss 0.0104136, acc 1
2016-09-05T18:00:08.628440: step 3883, loss 0.00853817, acc 1
2016-09-05T18:00:08.840704: step 3884, loss 0.0113668, acc 1
2016-09-05T18:00:09.068980: step 3885, loss 0.0113241, acc 1
2016-09-05T18:00:09.293448: step 3886, loss 0.00928237, acc 1
2016-09-05T18:00:09.506280: step 3887, loss 0.00989625, acc 1
2016-09-05T18:00:09.745211: step 3888, loss 0.0103453, acc 1
2016-09-05T18:00:09.955438: step 3889, loss 0.00883514, acc 1
2016-09-05T18:00:10.189799: step 3890, loss 0.00914998, acc 1
2016-09-05T18:00:10.410324: step 3891, loss 0.00935645, acc 1
2016-09-05T18:00:10.655230: step 3892, loss 0.0104393, acc 1
2016-09-05T18:00:10.856981: step 3893, loss 0.00931421, acc 1
2016-09-05T18:00:11.067914: step 3894, loss 0.0115292, acc 1
2016-09-05T18:00:11.271379: step 3895, loss 0.00857743, acc 1
2016-09-05T18:00:11.499313: step 3896, loss 0.00936238, acc 1
2016-09-05T18:00:11.741433: step 3897, loss 0.0103434, acc 1
2016-09-05T18:00:11.960787: step 3898, loss 0.0115733, acc 1
2016-09-05T18:00:12.164288: step 3899, loss 0.0110096, acc 1
2016-09-05T18:00:12.373192: step 3900, loss 0.0108068, acc 1

Evaluation:
2016-09-05T18:00:12.959831: step 3900, loss 0.929519, acc 0.755

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-3900

2016-09-05T18:00:13.653293: step 3901, loss 0.0101221, acc 1
2016-09-05T18:00:13.877601: step 3902, loss 0.00981287, acc 1
2016-09-05T18:00:14.081225: step 3903, loss 0.0119533, acc 1
2016-09-05T18:00:14.318569: step 3904, loss 0.00852032, acc 1
2016-09-05T18:00:14.532702: step 3905, loss 0.00982888, acc 1
2016-09-05T18:00:14.793371: step 3906, loss 0.00998276, acc 1
2016-09-05T18:00:14.994943: step 3907, loss 0.0100521, acc 1
2016-09-05T18:00:15.233870: step 3908, loss 0.00918922, acc 1
2016-09-05T18:00:15.450311: step 3909, loss 0.00823779, acc 1
2016-09-05T18:00:15.657622: step 3910, loss 0.00895802, acc 1
2016-09-05T18:00:15.888250: step 3911, loss 0.0102959, acc 1
2016-09-05T18:00:16.095527: step 3912, loss 0.00971569, acc 1
2016-09-05T18:00:16.320017: step 3913, loss 0.00933492, acc 1
2016-09-05T18:00:16.533320: step 3914, loss 0.00900569, acc 1
2016-09-05T18:00:16.772096: step 3915, loss 0.00863684, acc 1
2016-09-05T18:00:16.999266: step 3916, loss 0.0085759, acc 1
2016-09-05T18:00:17.202838: step 3917, loss 0.0102616, acc 1
2016-09-05T18:00:17.412093: step 3918, loss 0.0103294, acc 1
2016-09-05T18:00:17.626225: step 3919, loss 0.00950796, acc 1
2016-09-05T18:00:17.848875: step 3920, loss 0.00880265, acc 1
2016-09-05T18:00:18.047772: step 3921, loss 0.00992326, acc 1
2016-09-05T18:00:18.261687: step 3922, loss 0.0122212, acc 1
2016-09-05T18:00:18.504736: step 3923, loss 0.0109245, acc 1
2016-09-05T18:00:18.732502: step 3924, loss 0.00876112, acc 1
2016-09-05T18:00:18.956306: step 3925, loss 0.00980838, acc 1
2016-09-05T18:00:19.188054: step 3926, loss 0.0112384, acc 1
2016-09-05T18:00:19.404313: step 3927, loss 0.0106265, acc 1
2016-09-05T18:00:19.621399: step 3928, loss 0.00886904, acc 1
2016-09-05T18:00:19.824071: step 3929, loss 0.00803785, acc 1
2016-09-05T18:00:20.047273: step 3930, loss 0.00914053, acc 1
2016-09-05T18:00:20.256383: step 3931, loss 0.00817227, acc 1
2016-09-05T18:00:20.493023: step 3932, loss 0.0106457, acc 1
2016-09-05T18:00:20.709414: step 3933, loss 0.00794955, acc 1
2016-09-05T18:00:20.921814: step 3934, loss 0.00990704, acc 1
2016-09-05T18:00:21.141334: step 3935, loss 0.00839298, acc 1
2016-09-05T18:00:21.343066: step 3936, loss 0.008011, acc 1
2016-09-05T18:00:21.565132: step 3937, loss 0.0105138, acc 1
2016-09-05T18:00:21.778559: step 3938, loss 0.0087499, acc 1
2016-09-05T18:00:22.028338: step 3939, loss 0.00943112, acc 1
2016-09-05T18:00:22.231291: step 3940, loss 0.0133532, acc 1
2016-09-05T18:00:22.454664: step 3941, loss 0.010931, acc 1
2016-09-05T18:00:22.661835: step 3942, loss 0.012793, acc 1
2016-09-05T18:00:22.883213: step 3943, loss 0.0100969, acc 1
2016-09-05T18:00:23.088978: step 3944, loss 0.010129, acc 1
2016-09-05T18:00:23.302729: step 3945, loss 0.00976644, acc 1
2016-09-05T18:00:23.555078: step 3946, loss 0.00950193, acc 1
2016-09-05T18:00:23.745553: step 3947, loss 0.0157272, acc 1
2016-09-05T18:00:23.957018: step 3948, loss 0.0104619, acc 1
2016-09-05T18:00:24.159343: step 3949, loss 0.0100554, acc 1
2016-09-05T18:00:24.388468: step 3950, loss 0.0103323, acc 1
2016-09-05T18:00:24.614214: step 3951, loss 0.0112312, acc 1
2016-09-05T18:00:24.858964: step 3952, loss 0.00835167, acc 1
2016-09-05T18:00:25.054596: step 3953, loss 0.0110165, acc 1
2016-09-05T18:00:25.276590: step 3954, loss 0.00989106, acc 1
2016-09-05T18:00:25.478621: step 3955, loss 0.00890286, acc 1
2016-09-05T18:00:25.686643: step 3956, loss 0.0112151, acc 1
2016-09-05T18:00:25.901456: step 3957, loss 0.00801429, acc 1
2016-09-05T18:00:26.134421: step 3958, loss 0.0134897, acc 1
2016-09-05T18:00:26.373322: step 3959, loss 0.0090467, acc 1
2016-09-05T18:00:26.576956: step 3960, loss 0.00889354, acc 1
2016-09-05T18:00:26.778270: step 3961, loss 0.0104135, acc 1
2016-09-05T18:00:26.986266: step 3962, loss 0.00828103, acc 1
2016-09-05T18:00:27.237584: step 3963, loss 0.0100287, acc 1
2016-09-05T18:00:27.463476: step 3964, loss 0.0105867, acc 1
2016-09-05T18:00:27.670733: step 3965, loss 0.00888884, acc 1
2016-09-05T18:00:27.879518: step 3966, loss 0.00879401, acc 1
2016-09-05T18:00:28.094706: step 3967, loss 0.0106256, acc 1
2016-09-05T18:00:28.316233: step 3968, loss 0.00859828, acc 1
2016-09-05T18:00:28.547271: step 3969, loss 0.00911849, acc 1
2016-09-05T18:00:28.793068: step 3970, loss 0.00996397, acc 1
2016-09-05T18:00:28.989324: step 3971, loss 0.00911202, acc 1
2016-09-05T18:00:29.200173: step 3972, loss 0.0105331, acc 1
2016-09-05T18:00:29.413366: step 3973, loss 0.00863727, acc 1
2016-09-05T18:00:29.646523: step 3974, loss 0.0101169, acc 1
2016-09-05T18:00:29.861507: step 3975, loss 0.0091326, acc 1
2016-09-05T18:00:30.104160: step 3976, loss 0.00823855, acc 1
2016-09-05T18:00:30.312928: step 3977, loss 0.00982629, acc 1
2016-09-05T18:00:30.515421: step 3978, loss 0.00852707, acc 1
2016-09-05T18:00:30.723752: step 3979, loss 0.00900747, acc 1
2016-09-05T18:00:30.998488: step 3980, loss 0.0116503, acc 1
2016-09-05T18:00:31.204533: step 3981, loss 0.00827762, acc 1
2016-09-05T18:00:31.409347: step 3982, loss 0.00913435, acc 1
2016-09-05T18:00:31.613795: step 3983, loss 0.00908609, acc 1
2016-09-05T18:00:31.821801: step 3984, loss 0.0103711, acc 1
2016-09-05T18:00:32.031119: step 3985, loss 0.00928524, acc 1
2016-09-05T18:00:32.241358: step 3986, loss 0.00851215, acc 1
2016-09-05T18:00:32.463634: step 3987, loss 0.00844888, acc 1
2016-09-05T18:00:32.676617: step 3988, loss 0.0134468, acc 1
2016-09-05T18:00:32.924785: step 3989, loss 0.0091251, acc 1
2016-09-05T18:00:33.127579: step 3990, loss 0.0127992, acc 1
2016-09-05T18:00:33.338313: step 3991, loss 0.00859836, acc 1
2016-09-05T18:00:33.559147: step 3992, loss 0.00803072, acc 1
2016-09-05T18:00:33.787803: step 3993, loss 0.00912454, acc 1
2016-09-05T18:00:34.017398: step 3994, loss 0.00832891, acc 1
2016-09-05T18:00:34.232308: step 3995, loss 0.00907805, acc 1
2016-09-05T18:00:34.457321: step 3996, loss 0.0104331, acc 1
2016-09-05T18:00:34.664604: step 3997, loss 0.0109343, acc 1
2016-09-05T18:00:34.884669: step 3998, loss 0.0100343, acc 1
2016-09-05T18:00:35.108984: step 3999, loss 0.0105032, acc 1
2016-09-05T18:00:35.311491: step 4000, loss 0.00918183, acc 1

Evaluation:
2016-09-05T18:00:35.917301: step 4000, loss 0.933535, acc 0.755

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-4000

2016-09-05T18:00:36.700222: step 4001, loss 0.0120505, acc 1
2016-09-05T18:00:36.965197: step 4002, loss 0.0100329, acc 1
2016-09-05T18:00:37.184077: step 4003, loss 0.00922765, acc 1
2016-09-05T18:00:37.402081: step 4004, loss 0.00940955, acc 1
2016-09-05T18:00:37.618812: step 4005, loss 0.0104135, acc 1
2016-09-05T18:00:37.861464: step 4006, loss 0.0081008, acc 1
2016-09-05T18:00:38.091867: step 4007, loss 0.00859563, acc 1
2016-09-05T18:00:38.316253: step 4008, loss 0.0110425, acc 1
2016-09-05T18:00:38.537250: step 4009, loss 0.00950808, acc 1
2016-09-05T18:00:38.755409: step 4010, loss 0.00998411, acc 1
2016-09-05T18:00:38.993181: step 4011, loss 0.00830538, acc 1
2016-09-05T18:00:39.211427: step 4012, loss 0.0089581, acc 1
2016-09-05T18:00:39.417132: step 4013, loss 0.0117009, acc 1
2016-09-05T18:00:39.633437: step 4014, loss 0.0104145, acc 1
2016-09-05T18:00:39.882409: step 4015, loss 0.00984157, acc 1
2016-09-05T18:00:40.090042: step 4016, loss 0.00937228, acc 1
2016-09-05T18:00:40.322378: step 4017, loss 0.00925583, acc 1
2016-09-05T18:00:40.565015: step 4018, loss 0.00942549, acc 1
2016-09-05T18:00:40.791905: step 4019, loss 0.00928437, acc 1
2016-09-05T18:00:41.015539: step 4020, loss 0.00834277, acc 1
2016-09-05T18:00:41.233985: step 4021, loss 0.0089754, acc 1
2016-09-05T18:00:41.457380: step 4022, loss 0.00839803, acc 1
2016-09-05T18:00:41.681056: step 4023, loss 0.010569, acc 1
2016-09-05T18:00:41.911133: step 4024, loss 0.0161092, acc 1
2016-09-05T18:00:42.125498: step 4025, loss 0.0100712, acc 1
2016-09-05T18:00:42.345799: step 4026, loss 0.00943295, acc 1
2016-09-05T18:00:42.565210: step 4027, loss 0.00890554, acc 1
2016-09-05T18:00:42.777765: step 4028, loss 0.00862646, acc 1
2016-09-05T18:00:43.024040: step 4029, loss 0.00893994, acc 1
2016-09-05T18:00:43.232896: step 4030, loss 0.0112123, acc 1
2016-09-05T18:00:43.459131: step 4031, loss 0.0112653, acc 1
2016-09-05T18:00:43.679642: step 4032, loss 0.00896569, acc 1
2016-09-05T18:00:43.942119: step 4033, loss 0.00835539, acc 1
2016-09-05T18:00:44.174305: step 4034, loss 0.00982195, acc 1
2016-09-05T18:00:44.407164: step 4035, loss 0.00929101, acc 1
2016-09-05T18:00:44.660643: step 4036, loss 0.00980974, acc 1
2016-09-05T18:00:44.862705: step 4037, loss 0.00956933, acc 1
2016-09-05T18:00:45.077431: step 4038, loss 0.0104064, acc 1
2016-09-05T18:00:45.329418: step 4039, loss 0.00937378, acc 1
2016-09-05T18:00:45.553955: step 4040, loss 0.00856667, acc 1
2016-09-05T18:00:45.761147: step 4041, loss 0.012627, acc 1
2016-09-05T18:00:46.004852: step 4042, loss 0.00827363, acc 1
2016-09-05T18:00:46.216294: step 4043, loss 0.00967035, acc 1
2016-09-05T18:00:46.426923: step 4044, loss 0.00927587, acc 1
2016-09-05T18:00:46.666222: step 4045, loss 0.0128009, acc 1
2016-09-05T18:00:46.859566: step 4046, loss 0.00826319, acc 1
2016-09-05T18:00:47.076268: step 4047, loss 0.00921142, acc 1
2016-09-05T18:00:47.290874: step 4048, loss 0.0128688, acc 1
2016-09-05T18:00:47.504883: step 4049, loss 0.00896123, acc 1
2016-09-05T18:00:47.716436: step 4050, loss 0.0111026, acc 1
2016-09-05T18:00:47.958631: step 4051, loss 0.0124065, acc 1
2016-09-05T18:00:48.162908: step 4052, loss 0.0186486, acc 1
2016-09-05T18:00:48.368671: step 4053, loss 0.0103114, acc 1
2016-09-05T18:00:48.585131: step 4054, loss 0.0087851, acc 1
2016-09-05T18:00:48.830400: step 4055, loss 0.0127303, acc 1
2016-09-05T18:00:49.049391: step 4056, loss 0.0113779, acc 1
2016-09-05T18:00:49.261364: step 4057, loss 0.00894009, acc 1
2016-09-05T18:00:49.484102: step 4058, loss 0.0111022, acc 1
2016-09-05T18:00:49.695280: step 4059, loss 0.00861385, acc 1
2016-09-05T18:00:49.894822: step 4060, loss 0.012954, acc 1
2016-09-05T18:00:50.102437: step 4061, loss 0.0105073, acc 1
2016-09-05T18:00:50.319420: step 4062, loss 0.00989208, acc 1
2016-09-05T18:00:50.540925: step 4063, loss 0.00959356, acc 1
2016-09-05T18:00:50.797710: step 4064, loss 0.0105837, acc 1
2016-09-05T18:00:51.002303: step 4065, loss 0.00991275, acc 1
2016-09-05T18:00:51.212856: step 4066, loss 0.0121489, acc 1
2016-09-05T18:00:51.413114: step 4067, loss 0.0127166, acc 1
2016-09-05T18:00:51.640402: step 4068, loss 0.00946304, acc 1
2016-09-05T18:00:51.848124: step 4069, loss 0.0107104, acc 1
2016-09-05T18:00:52.067466: step 4070, loss 0.0120412, acc 1
2016-09-05T18:00:52.297325: step 4071, loss 0.00934598, acc 1
2016-09-05T18:00:52.499733: step 4072, loss 0.010678, acc 1
2016-09-05T18:00:52.714468: step 4073, loss 0.0122411, acc 1
2016-09-05T18:00:52.837715: step 4074, loss 0.00759354, acc 1
2016-09-05T18:00:53.072010: step 4075, loss 0.00990336, acc 1
2016-09-05T18:00:53.313137: step 4076, loss 0.00929894, acc 1
2016-09-05T18:00:53.513030: step 4077, loss 0.00928815, acc 1
2016-09-05T18:00:53.729767: step 4078, loss 0.00898569, acc 1
2016-09-05T18:00:53.989873: step 4079, loss 0.00897589, acc 1
2016-09-05T18:00:54.205419: step 4080, loss 0.00855594, acc 1
2016-09-05T18:00:54.412514: step 4081, loss 0.00961319, acc 1
2016-09-05T18:00:54.615455: step 4082, loss 0.00849954, acc 1
2016-09-05T18:00:54.825825: step 4083, loss 0.00836051, acc 1
2016-09-05T18:00:55.032274: step 4084, loss 0.013595, acc 1
2016-09-05T18:00:55.241637: step 4085, loss 0.00888527, acc 1
2016-09-05T18:00:55.450647: step 4086, loss 0.00797272, acc 1
2016-09-05T18:00:55.664660: step 4087, loss 0.00919652, acc 1
2016-09-05T18:00:55.871584: step 4088, loss 0.00921771, acc 1
2016-09-05T18:00:56.089826: step 4089, loss 0.0101953, acc 1
2016-09-05T18:00:56.317464: step 4090, loss 0.00730729, acc 1
2016-09-05T18:00:56.552594: step 4091, loss 0.0138571, acc 1
2016-09-05T18:00:56.811372: step 4092, loss 0.0111591, acc 1
2016-09-05T18:00:57.045890: step 4093, loss 0.0080369, acc 1
2016-09-05T18:00:57.247526: step 4094, loss 0.0116494, acc 1
2016-09-05T18:00:57.458014: step 4095, loss 0.010355, acc 1
2016-09-05T18:00:57.682233: step 4096, loss 0.00917999, acc 1
2016-09-05T18:00:57.882500: step 4097, loss 0.00951815, acc 1
2016-09-05T18:00:58.101777: step 4098, loss 0.008797, acc 1
2016-09-05T18:00:58.330452: step 4099, loss 0.00956429, acc 1
2016-09-05T18:00:58.558920: step 4100, loss 0.0107186, acc 1

Evaluation:
2016-09-05T18:00:59.195549: step 4100, loss 0.962997, acc 0.745

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-4100

2016-09-05T18:00:59.930373: step 4101, loss 0.012351, acc 1
2016-09-05T18:01:00.186574: step 4102, loss 0.00899065, acc 1
2016-09-05T18:01:00.397805: step 4103, loss 0.0102001, acc 1
2016-09-05T18:01:00.625423: step 4104, loss 0.00845121, acc 1
2016-09-05T18:01:00.843691: step 4105, loss 0.00962632, acc 1
2016-09-05T18:01:01.082922: step 4106, loss 0.0102173, acc 1
2016-09-05T18:01:01.301264: step 4107, loss 0.00923979, acc 1
2016-09-05T18:01:01.525869: step 4108, loss 0.00816315, acc 1
2016-09-05T18:01:01.757670: step 4109, loss 0.00908478, acc 1
2016-09-05T18:01:01.979228: step 4110, loss 0.0120178, acc 1
2016-09-05T18:01:02.202823: step 4111, loss 0.00777413, acc 1
2016-09-05T18:01:02.404243: step 4112, loss 0.0086631, acc 1
2016-09-05T18:01:02.614474: step 4113, loss 0.0103682, acc 1
2016-09-05T18:01:02.828542: step 4114, loss 0.00897245, acc 1
2016-09-05T18:01:03.042558: step 4115, loss 0.00970235, acc 1
2016-09-05T18:01:03.246700: step 4116, loss 0.00856202, acc 1
2016-09-05T18:01:03.472976: step 4117, loss 0.00748293, acc 1
2016-09-05T18:01:03.711335: step 4118, loss 0.00947136, acc 1
2016-09-05T18:01:03.929996: step 4119, loss 0.00842168, acc 1
2016-09-05T18:01:04.147073: step 4120, loss 0.00967069, acc 1
2016-09-05T18:01:04.375245: step 4121, loss 0.0086605, acc 1
2016-09-05T18:01:04.587989: step 4122, loss 0.00897465, acc 1
2016-09-05T18:01:04.814370: step 4123, loss 0.00985342, acc 1
2016-09-05T18:01:05.059679: step 4124, loss 0.00765778, acc 1
2016-09-05T18:01:05.313426: step 4125, loss 0.00973002, acc 1
2016-09-05T18:01:05.536184: step 4126, loss 0.00840267, acc 1
2016-09-05T18:01:05.748912: step 4127, loss 0.00823752, acc 1
2016-09-05T18:01:05.963934: step 4128, loss 0.00878796, acc 1
2016-09-05T18:01:06.187296: step 4129, loss 0.00829162, acc 1
2016-09-05T18:01:06.410860: step 4130, loss 0.00834306, acc 1
2016-09-05T18:01:06.630919: step 4131, loss 0.00843741, acc 1
2016-09-05T18:01:06.846503: step 4132, loss 0.00921811, acc 1
2016-09-05T18:01:07.053634: step 4133, loss 0.00755612, acc 1
2016-09-05T18:01:07.261836: step 4134, loss 0.00936996, acc 1
2016-09-05T18:01:07.516274: step 4135, loss 0.00843446, acc 1
2016-09-05T18:01:07.744553: step 4136, loss 0.00843528, acc 1
2016-09-05T18:01:07.945079: step 4137, loss 0.00861809, acc 1
2016-09-05T18:01:08.139407: step 4138, loss 0.0100197, acc 1
2016-09-05T18:01:08.358218: step 4139, loss 0.00916902, acc 1
2016-09-05T18:01:08.575856: step 4140, loss 0.00870183, acc 1
2016-09-05T18:01:08.783527: step 4141, loss 0.00847843, acc 1
2016-09-05T18:01:09.014350: step 4142, loss 0.00962049, acc 1
2016-09-05T18:01:09.260161: step 4143, loss 0.014906, acc 1
2016-09-05T18:01:09.489149: step 4144, loss 0.00970268, acc 1
2016-09-05T18:01:09.703824: step 4145, loss 0.00784577, acc 1
2016-09-05T18:01:09.938973: step 4146, loss 0.0172654, acc 1
2016-09-05T18:01:10.154814: step 4147, loss 0.0106, acc 1
2016-09-05T18:01:10.357363: step 4148, loss 0.0110813, acc 1
2016-09-05T18:01:10.562555: step 4149, loss 0.0105908, acc 1
2016-09-05T18:01:10.769577: step 4150, loss 0.008994, acc 1
2016-09-05T18:01:10.982828: step 4151, loss 0.00827889, acc 1
2016-09-05T18:01:11.190493: step 4152, loss 0.0094014, acc 1
2016-09-05T18:01:11.404680: step 4153, loss 0.00846556, acc 1
2016-09-05T18:01:11.606684: step 4154, loss 0.00910005, acc 1
2016-09-05T18:01:11.812248: step 4155, loss 0.00952032, acc 1
2016-09-05T18:01:12.021867: step 4156, loss 0.00759457, acc 1
2016-09-05T18:01:12.242862: step 4157, loss 0.00805965, acc 1
2016-09-05T18:01:12.468704: step 4158, loss 0.00904478, acc 1
2016-09-05T18:01:12.702392: step 4159, loss 0.00945772, acc 1
2016-09-05T18:01:12.901379: step 4160, loss 0.0124149, acc 1
2016-09-05T18:01:13.105856: step 4161, loss 0.0092787, acc 1
2016-09-05T18:01:13.311503: step 4162, loss 0.00916061, acc 1
2016-09-05T18:01:13.538425: step 4163, loss 0.0106433, acc 1
2016-09-05T18:01:13.762936: step 4164, loss 0.00768963, acc 1
2016-09-05T18:01:13.978525: step 4165, loss 0.00844416, acc 1
2016-09-05T18:01:14.211126: step 4166, loss 0.010416, acc 1
2016-09-05T18:01:14.451255: step 4167, loss 0.00873685, acc 1
2016-09-05T18:01:14.673358: step 4168, loss 0.00973215, acc 1
2016-09-05T18:01:14.885988: step 4169, loss 0.00909974, acc 1
2016-09-05T18:01:15.133970: step 4170, loss 0.00730246, acc 1
2016-09-05T18:01:15.339087: step 4171, loss 0.00798821, acc 1
2016-09-05T18:01:15.549276: step 4172, loss 0.0108606, acc 1
2016-09-05T18:01:15.758547: step 4173, loss 0.00864875, acc 1
2016-09-05T18:01:15.990686: step 4174, loss 0.00760345, acc 1
2016-09-05T18:01:16.227636: step 4175, loss 0.0107782, acc 1
2016-09-05T18:01:16.421007: step 4176, loss 0.0082767, acc 1
2016-09-05T18:01:16.640192: step 4177, loss 0.00789705, acc 1
2016-09-05T18:01:16.839530: step 4178, loss 0.00768088, acc 1
2016-09-05T18:01:17.055375: step 4179, loss 0.0087885, acc 1
2016-09-05T18:01:17.259782: step 4180, loss 0.00773751, acc 1
2016-09-05T18:01:17.486771: step 4181, loss 0.00843235, acc 1
2016-09-05T18:01:17.695819: step 4182, loss 0.00928968, acc 1
2016-09-05T18:01:17.901936: step 4183, loss 0.00798396, acc 1
2016-09-05T18:01:18.133448: step 4184, loss 0.0090328, acc 1
2016-09-05T18:01:18.359327: step 4185, loss 0.00794035, acc 1
2016-09-05T18:01:18.614580: step 4186, loss 0.00848909, acc 1
2016-09-05T18:01:18.837457: step 4187, loss 0.0103074, acc 1
2016-09-05T18:01:19.073064: step 4188, loss 0.0125185, acc 1
2016-09-05T18:01:19.301474: step 4189, loss 0.0122684, acc 1
2016-09-05T18:01:19.575019: step 4190, loss 0.0102363, acc 1
2016-09-05T18:01:19.779547: step 4191, loss 0.00834974, acc 1
2016-09-05T18:01:20.032737: step 4192, loss 0.0106394, acc 1
2016-09-05T18:01:20.266274: step 4193, loss 0.00724441, acc 1
2016-09-05T18:01:20.473955: step 4194, loss 0.0106319, acc 1
2016-09-05T18:01:20.682994: step 4195, loss 0.00840015, acc 1
2016-09-05T18:01:20.888038: step 4196, loss 0.0104437, acc 1
2016-09-05T18:01:21.127579: step 4197, loss 0.00861925, acc 1
2016-09-05T18:01:21.339461: step 4198, loss 0.00795967, acc 1
2016-09-05T18:01:21.575596: step 4199, loss 0.00905029, acc 1
2016-09-05T18:01:21.789851: step 4200, loss 0.00911019, acc 1

Evaluation:
2016-09-05T18:01:22.436923: step 4200, loss 0.98793, acc 0.748

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-4200

2016-09-05T18:01:23.203753: step 4201, loss 0.00797191, acc 1
2016-09-05T18:01:23.417409: step 4202, loss 0.00917853, acc 1
2016-09-05T18:01:23.635458: step 4203, loss 0.0103774, acc 1
2016-09-05T18:01:23.865231: step 4204, loss 0.0094325, acc 1
2016-09-05T18:01:24.093027: step 4205, loss 0.0152171, acc 1
2016-09-05T18:01:24.307838: step 4206, loss 0.0101816, acc 1
2016-09-05T18:01:24.565721: step 4207, loss 0.0142329, acc 1
2016-09-05T18:01:24.803035: step 4208, loss 0.0087457, acc 1
2016-09-05T18:01:24.999249: step 4209, loss 0.0115717, acc 1
2016-09-05T18:01:25.203959: step 4210, loss 0.00978882, acc 1
2016-09-05T18:01:25.413975: step 4211, loss 0.00823986, acc 1
2016-09-05T18:01:25.622889: step 4212, loss 0.00845923, acc 1
2016-09-05T18:01:25.826354: step 4213, loss 0.00945396, acc 1
2016-09-05T18:01:26.042770: step 4214, loss 0.00777049, acc 1
2016-09-05T18:01:26.270179: step 4215, loss 0.0101292, acc 1
2016-09-05T18:01:26.522134: step 4216, loss 0.00816061, acc 1
2016-09-05T18:01:26.735909: step 4217, loss 0.00987916, acc 1
2016-09-05T18:01:26.979971: step 4218, loss 0.00877902, acc 1
2016-09-05T18:01:27.205248: step 4219, loss 0.00816401, acc 1
2016-09-05T18:01:27.401794: step 4220, loss 0.00813825, acc 1
2016-09-05T18:01:27.601475: step 4221, loss 0.0101357, acc 1
2016-09-05T18:01:27.799586: step 4222, loss 0.0119152, acc 1
2016-09-05T18:01:28.043448: step 4223, loss 0.00895251, acc 1
2016-09-05T18:01:28.242493: step 4224, loss 0.00928334, acc 1
2016-09-05T18:01:28.455843: step 4225, loss 0.00821415, acc 1
2016-09-05T18:01:28.653732: step 4226, loss 0.00889838, acc 1
2016-09-05T18:01:28.881320: step 4227, loss 0.00870573, acc 1
2016-09-05T18:01:29.086270: step 4228, loss 0.00825146, acc 1
2016-09-05T18:01:29.314198: step 4229, loss 0.0101076, acc 1
2016-09-05T18:01:29.565905: step 4230, loss 0.0101934, acc 1
2016-09-05T18:01:29.812150: step 4231, loss 0.00850164, acc 1
2016-09-05T18:01:30.062509: step 4232, loss 0.0124355, acc 1
2016-09-05T18:01:30.285153: step 4233, loss 0.00985253, acc 1
2016-09-05T18:01:30.519887: step 4234, loss 0.0105386, acc 1
2016-09-05T18:01:30.752805: step 4235, loss 0.00842158, acc 1
2016-09-05T18:01:30.976648: step 4236, loss 0.00858462, acc 1
2016-09-05T18:01:31.182047: step 4237, loss 0.0107179, acc 1
2016-09-05T18:01:31.399340: step 4238, loss 0.0121741, acc 1
2016-09-05T18:01:31.623753: step 4239, loss 0.0118173, acc 1
2016-09-05T18:01:31.826639: step 4240, loss 0.00865123, acc 1
2016-09-05T18:01:32.061184: step 4241, loss 0.00902376, acc 1
2016-09-05T18:01:32.262150: step 4242, loss 0.0108507, acc 1
2016-09-05T18:01:32.475169: step 4243, loss 0.00896222, acc 1
2016-09-05T18:01:32.696818: step 4244, loss 0.00829045, acc 1
2016-09-05T18:01:32.947248: step 4245, loss 0.007477, acc 1
2016-09-05T18:01:33.176660: step 4246, loss 0.00925216, acc 1
2016-09-05T18:01:33.392271: step 4247, loss 0.00823875, acc 1
2016-09-05T18:01:33.594474: step 4248, loss 0.00996618, acc 1
2016-09-05T18:01:33.801032: step 4249, loss 0.00968233, acc 1
2016-09-05T18:01:34.010331: step 4250, loss 0.0183864, acc 1
2016-09-05T18:01:34.253819: step 4251, loss 0.0108132, acc 1
2016-09-05T18:01:34.489434: step 4252, loss 0.0104789, acc 1
2016-09-05T18:01:34.689241: step 4253, loss 0.00974438, acc 1
2016-09-05T18:01:34.884966: step 4254, loss 0.00798297, acc 1
2016-09-05T18:01:35.121149: step 4255, loss 0.00993574, acc 1
2016-09-05T18:01:35.321119: step 4256, loss 0.00819036, acc 1
2016-09-05T18:01:35.525017: step 4257, loss 0.00738577, acc 1
2016-09-05T18:01:35.746349: step 4258, loss 0.0110652, acc 1
2016-09-05T18:01:35.958281: step 4259, loss 0.00916843, acc 1
2016-09-05T18:01:36.168733: step 4260, loss 0.0093487, acc 1
2016-09-05T18:01:36.367355: step 4261, loss 0.0082866, acc 1
2016-09-05T18:01:36.621538: step 4262, loss 0.00776228, acc 1
2016-09-05T18:01:36.827409: step 4263, loss 0.00790014, acc 1
2016-09-05T18:01:37.056933: step 4264, loss 0.00980134, acc 1
2016-09-05T18:01:37.266005: step 4265, loss 0.0106698, acc 1
2016-09-05T18:01:37.479981: step 4266, loss 0.00839722, acc 1
2016-09-05T18:01:37.732944: step 4267, loss 0.0098479, acc 1
2016-09-05T18:01:37.854817: step 4268, loss 0.00872867, acc 1
2016-09-05T18:01:38.085819: step 4269, loss 0.0107516, acc 1
2016-09-05T18:01:38.300143: step 4270, loss 0.00852714, acc 1
2016-09-05T18:01:38.537448: step 4271, loss 0.00742427, acc 1
2016-09-05T18:01:38.763370: step 4272, loss 0.00684258, acc 1
2016-09-05T18:01:38.985245: step 4273, loss 0.00864467, acc 1
2016-09-05T18:01:39.208101: step 4274, loss 0.00886661, acc 1
2016-09-05T18:01:39.436656: step 4275, loss 0.00746216, acc 1
2016-09-05T18:01:39.653423: step 4276, loss 0.00862786, acc 1
2016-09-05T18:01:39.870476: step 4277, loss 0.0118324, acc 1
2016-09-05T18:01:40.082910: step 4278, loss 0.0089571, acc 1
2016-09-05T18:01:40.312189: step 4279, loss 0.00784359, acc 1
2016-09-05T18:01:40.541192: step 4280, loss 0.00834009, acc 1
2016-09-05T18:01:40.738540: step 4281, loss 0.00880931, acc 1
2016-09-05T18:01:40.931390: step 4282, loss 0.00854017, acc 1
2016-09-05T18:01:41.179605: step 4283, loss 0.00988103, acc 1
2016-09-05T18:01:41.402403: step 4284, loss 0.00851216, acc 1
2016-09-05T18:01:41.611435: step 4285, loss 0.00758183, acc 1
2016-09-05T18:01:41.836257: step 4286, loss 0.00705364, acc 1
2016-09-05T18:01:42.045713: step 4287, loss 0.00876088, acc 1
2016-09-05T18:01:42.275669: step 4288, loss 0.0086528, acc 1
2016-09-05T18:01:42.488437: step 4289, loss 0.00967694, acc 1
2016-09-05T18:01:42.706548: step 4290, loss 0.0081789, acc 1
2016-09-05T18:01:42.919811: step 4291, loss 0.0102426, acc 1
2016-09-05T18:01:43.144123: step 4292, loss 0.0077891, acc 1
2016-09-05T18:01:43.363440: step 4293, loss 0.00924617, acc 1
2016-09-05T18:01:43.587370: step 4294, loss 0.00772015, acc 1
2016-09-05T18:01:43.799134: step 4295, loss 0.0133336, acc 1
2016-09-05T18:01:43.999830: step 4296, loss 0.00844899, acc 1
2016-09-05T18:01:44.233414: step 4297, loss 0.00830548, acc 1
2016-09-05T18:01:44.432915: step 4298, loss 0.00754675, acc 1
2016-09-05T18:01:44.639623: step 4299, loss 0.00701143, acc 1
2016-09-05T18:01:44.852354: step 4300, loss 0.00705677, acc 1

Evaluation:
2016-09-05T18:01:45.461361: step 4300, loss 0.972545, acc 0.751

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-4300

2016-09-05T18:01:46.132948: step 4301, loss 0.00836372, acc 1
2016-09-05T18:01:46.358327: step 4302, loss 0.00715537, acc 1
2016-09-05T18:01:46.569066: step 4303, loss 0.00842434, acc 1
2016-09-05T18:01:46.811946: step 4304, loss 0.0103337, acc 1
2016-09-05T18:01:47.013298: step 4305, loss 0.00722346, acc 1
2016-09-05T18:01:47.231284: step 4306, loss 0.00843996, acc 1
2016-09-05T18:01:47.459956: step 4307, loss 0.00835393, acc 1
2016-09-05T18:01:47.698807: step 4308, loss 0.0114414, acc 1
2016-09-05T18:01:47.913108: step 4309, loss 0.00969852, acc 1
2016-09-05T18:01:48.129431: step 4310, loss 0.0102639, acc 1
2016-09-05T18:01:48.344567: step 4311, loss 0.00793444, acc 1
2016-09-05T18:01:48.548691: step 4312, loss 0.00854731, acc 1
2016-09-05T18:01:48.769811: step 4313, loss 0.00847695, acc 1
2016-09-05T18:01:48.979825: step 4314, loss 0.00673385, acc 1
2016-09-05T18:01:49.206884: step 4315, loss 0.00781525, acc 1
2016-09-05T18:01:49.429443: step 4316, loss 0.00874909, acc 1
2016-09-05T18:01:49.644383: step 4317, loss 0.00952571, acc 1
2016-09-05T18:01:49.856292: step 4318, loss 0.00705675, acc 1
2016-09-05T18:01:50.073941: step 4319, loss 0.00872668, acc 1
2016-09-05T18:01:50.292421: step 4320, loss 0.00847868, acc 1
2016-09-05T18:01:50.525663: step 4321, loss 0.00839114, acc 1
2016-09-05T18:01:50.739507: step 4322, loss 0.00770725, acc 1
2016-09-05T18:01:50.966063: step 4323, loss 0.00884285, acc 1
2016-09-05T18:01:51.186202: step 4324, loss 0.0092892, acc 1
2016-09-05T18:01:51.397110: step 4325, loss 0.00727362, acc 1
2016-09-05T18:01:51.625645: step 4326, loss 0.00719476, acc 1
2016-09-05T18:01:51.851069: step 4327, loss 0.00930288, acc 1
2016-09-05T18:01:52.064778: step 4328, loss 0.00691699, acc 1
2016-09-05T18:01:52.282894: step 4329, loss 0.00889856, acc 1
2016-09-05T18:01:52.511921: step 4330, loss 0.00792544, acc 1
2016-09-05T18:01:52.732556: step 4331, loss 0.00941836, acc 1
2016-09-05T18:01:52.941951: step 4332, loss 0.011069, acc 1
2016-09-05T18:01:53.161038: step 4333, loss 0.00856654, acc 1
2016-09-05T18:01:53.382395: step 4334, loss 0.00893708, acc 1
2016-09-05T18:01:53.599833: step 4335, loss 0.00719825, acc 1
2016-09-05T18:01:53.801782: step 4336, loss 0.00814714, acc 1
2016-09-05T18:01:54.012564: step 4337, loss 0.00943696, acc 1
2016-09-05T18:01:54.214097: step 4338, loss 0.00809705, acc 1
2016-09-05T18:01:54.426779: step 4339, loss 0.00744653, acc 1
2016-09-05T18:01:54.639276: step 4340, loss 0.00853072, acc 1
2016-09-05T18:01:54.893886: step 4341, loss 0.006804, acc 1
2016-09-05T18:01:55.103055: step 4342, loss 0.00780242, acc 1
2016-09-05T18:01:55.314122: step 4343, loss 0.00842149, acc 1
2016-09-05T18:01:55.520836: step 4344, loss 0.00811761, acc 1
2016-09-05T18:01:55.730000: step 4345, loss 0.00833116, acc 1
2016-09-05T18:01:55.949160: step 4346, loss 0.00769561, acc 1
2016-09-05T18:01:56.177477: step 4347, loss 0.009565, acc 1
2016-09-05T18:01:56.420607: step 4348, loss 0.00828288, acc 1
2016-09-05T18:01:56.631614: step 4349, loss 0.00739804, acc 1
2016-09-05T18:01:56.859251: step 4350, loss 0.00735198, acc 1
2016-09-05T18:01:57.065136: step 4351, loss 0.00764155, acc 1
2016-09-05T18:01:57.300942: step 4352, loss 0.00915348, acc 1
2016-09-05T18:01:57.498209: step 4353, loss 0.00739538, acc 1
2016-09-05T18:01:57.724664: step 4354, loss 0.00900855, acc 1
2016-09-05T18:01:57.932882: step 4355, loss 0.00977892, acc 1
2016-09-05T18:01:58.168088: step 4356, loss 0.00807314, acc 1
2016-09-05T18:01:58.392336: step 4357, loss 0.00740594, acc 1
2016-09-05T18:01:58.609746: step 4358, loss 0.00887198, acc 1
2016-09-05T18:01:58.854718: step 4359, loss 0.00699478, acc 1
2016-09-05T18:01:59.077403: step 4360, loss 0.00663239, acc 1
2016-09-05T18:01:59.293538: step 4361, loss 0.0083834, acc 1
2016-09-05T18:01:59.506494: step 4362, loss 0.011099, acc 1
2016-09-05T18:01:59.748784: step 4363, loss 0.0076955, acc 1
2016-09-05T18:01:59.957370: step 4364, loss 0.00792265, acc 1
2016-09-05T18:02:00.177191: step 4365, loss 0.00756988, acc 1
2016-09-05T18:02:00.383832: step 4366, loss 0.0110372, acc 1
2016-09-05T18:02:00.580819: step 4367, loss 0.00784608, acc 1
2016-09-05T18:02:00.777965: step 4368, loss 0.0073494, acc 1
2016-09-05T18:02:01.001757: step 4369, loss 0.0100384, acc 1
2016-09-05T18:02:01.221152: step 4370, loss 0.00847752, acc 1
2016-09-05T18:02:01.430656: step 4371, loss 0.00740446, acc 1
2016-09-05T18:02:01.670977: step 4372, loss 0.00758434, acc 1
2016-09-05T18:02:01.879268: step 4373, loss 0.00671799, acc 1
2016-09-05T18:02:02.084854: step 4374, loss 0.00865342, acc 1
2016-09-05T18:02:02.289747: step 4375, loss 0.00928679, acc 1
2016-09-05T18:02:02.508006: step 4376, loss 0.0105307, acc 1
2016-09-05T18:02:02.716484: step 4377, loss 0.00931844, acc 1
2016-09-05T18:02:02.932151: step 4378, loss 0.00695347, acc 1
2016-09-05T18:02:03.181477: step 4379, loss 0.00836158, acc 1
2016-09-05T18:02:03.408734: step 4380, loss 0.00844928, acc 1
2016-09-05T18:02:03.625478: step 4381, loss 0.00761372, acc 1
2016-09-05T18:02:03.831077: step 4382, loss 0.00751963, acc 1
2016-09-05T18:02:04.055549: step 4383, loss 0.00873094, acc 1
2016-09-05T18:02:04.284871: step 4384, loss 0.00865221, acc 1
2016-09-05T18:02:04.517851: step 4385, loss 0.00895231, acc 1
2016-09-05T18:02:04.715990: step 4386, loss 0.00841296, acc 1
2016-09-05T18:02:04.947734: step 4387, loss 0.00675667, acc 1
2016-09-05T18:02:05.164966: step 4388, loss 0.00944544, acc 1
2016-09-05T18:02:05.392245: step 4389, loss 0.00814983, acc 1
2016-09-05T18:02:05.639078: step 4390, loss 0.00969308, acc 1
2016-09-05T18:02:05.867812: step 4391, loss 0.0094516, acc 1
2016-09-05T18:02:06.115938: step 4392, loss 0.00933972, acc 1
2016-09-05T18:02:06.318921: step 4393, loss 0.00775606, acc 1
2016-09-05T18:02:06.528157: step 4394, loss 0.00933588, acc 1
2016-09-05T18:02:06.784556: step 4395, loss 0.00920533, acc 1
2016-09-05T18:02:07.024959: step 4396, loss 0.0114664, acc 1
2016-09-05T18:02:07.227562: step 4397, loss 0.00850907, acc 1
2016-09-05T18:02:07.438632: step 4398, loss 0.0109517, acc 1
2016-09-05T18:02:07.658009: step 4399, loss 0.00807786, acc 1
2016-09-05T18:02:07.866656: step 4400, loss 0.0128811, acc 1

Evaluation:
2016-09-05T18:02:08.477027: step 4400, loss 1.03752, acc 0.742

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-4400

2016-09-05T18:02:09.175300: step 4401, loss 0.00778321, acc 1
2016-09-05T18:02:09.408857: step 4402, loss 0.0073375, acc 1
2016-09-05T18:02:09.618763: step 4403, loss 0.011394, acc 1
2016-09-05T18:02:09.878740: step 4404, loss 0.0147143, acc 1
2016-09-05T18:02:10.097337: step 4405, loss 0.0106408, acc 1
2016-09-05T18:02:10.312701: step 4406, loss 0.00884235, acc 1
2016-09-05T18:02:10.523869: step 4407, loss 0.00992731, acc 1
2016-09-05T18:02:10.776923: step 4408, loss 0.00932027, acc 1
2016-09-05T18:02:10.975940: step 4409, loss 0.00837602, acc 1
2016-09-05T18:02:11.197965: step 4410, loss 0.00768074, acc 1
2016-09-05T18:02:11.416787: step 4411, loss 0.010892, acc 1
2016-09-05T18:02:11.622817: step 4412, loss 0.00799906, acc 1
2016-09-05T18:02:11.832447: step 4413, loss 0.00837469, acc 1
2016-09-05T18:02:12.043092: step 4414, loss 0.00773788, acc 1
2016-09-05T18:02:12.275384: step 4415, loss 0.0111356, acc 1
2016-09-05T18:02:12.489552: step 4416, loss 0.00738681, acc 1
2016-09-05T18:02:12.692535: step 4417, loss 0.00772306, acc 1
2016-09-05T18:02:12.895822: step 4418, loss 0.00843219, acc 1
2016-09-05T18:02:13.116486: step 4419, loss 0.00861371, acc 1
2016-09-05T18:02:13.325623: step 4420, loss 0.0085208, acc 1
2016-09-05T18:02:13.563185: step 4421, loss 0.0122447, acc 1
2016-09-05T18:02:13.791926: step 4422, loss 0.0135359, acc 1
2016-09-05T18:02:14.029089: step 4423, loss 0.0082393, acc 1
2016-09-05T18:02:14.255216: step 4424, loss 0.00959467, acc 1
2016-09-05T18:02:14.458884: step 4425, loss 0.00914723, acc 1
2016-09-05T18:02:14.716247: step 4426, loss 0.00910835, acc 1
2016-09-05T18:02:14.928400: step 4427, loss 0.0116626, acc 1
2016-09-05T18:02:15.138908: step 4428, loss 0.00824644, acc 1
2016-09-05T18:02:15.342460: step 4429, loss 0.0127752, acc 1
2016-09-05T18:02:15.579853: step 4430, loss 0.00885048, acc 1
2016-09-05T18:02:15.808853: step 4431, loss 0.00802901, acc 1
2016-09-05T18:02:16.027799: step 4432, loss 0.0080047, acc 1
2016-09-05T18:02:16.237917: step 4433, loss 0.00718774, acc 1
2016-09-05T18:02:16.453230: step 4434, loss 0.00727218, acc 1
2016-09-05T18:02:16.680169: step 4435, loss 0.014002, acc 1
2016-09-05T18:02:16.885400: step 4436, loss 0.00887398, acc 1
2016-09-05T18:02:17.092922: step 4437, loss 0.0105412, acc 1
2016-09-05T18:02:17.288948: step 4438, loss 0.0101887, acc 1
2016-09-05T18:02:17.506345: step 4439, loss 0.00719844, acc 1
2016-09-05T18:02:17.721386: step 4440, loss 0.00897549, acc 1
2016-09-05T18:02:17.934780: step 4441, loss 0.0129303, acc 1
2016-09-05T18:02:18.141809: step 4442, loss 0.00764616, acc 1
2016-09-05T18:02:18.355863: step 4443, loss 0.00742907, acc 1
2016-09-05T18:02:18.560859: step 4444, loss 0.0081208, acc 1
2016-09-05T18:02:18.766742: step 4445, loss 0.00837192, acc 1
2016-09-05T18:02:18.983876: step 4446, loss 0.00851839, acc 1
2016-09-05T18:02:19.195009: step 4447, loss 0.00906463, acc 1
2016-09-05T18:02:19.401668: step 4448, loss 0.00778313, acc 1
2016-09-05T18:02:19.646764: step 4449, loss 0.00745483, acc 1
2016-09-05T18:02:19.859155: step 4450, loss 0.00946623, acc 1
2016-09-05T18:02:20.062111: step 4451, loss 0.00793419, acc 1
2016-09-05T18:02:20.274972: step 4452, loss 0.0107085, acc 1
2016-09-05T18:02:20.509652: step 4453, loss 0.0078562, acc 1
2016-09-05T18:02:20.728564: step 4454, loss 0.00697297, acc 1
2016-09-05T18:02:20.955961: step 4455, loss 0.00764157, acc 1
2016-09-05T18:02:21.162514: step 4456, loss 0.00915692, acc 1
2016-09-05T18:02:21.363607: step 4457, loss 0.008472, acc 1
2016-09-05T18:02:21.585993: step 4458, loss 0.00867261, acc 1
2016-09-05T18:02:21.791670: step 4459, loss 0.00991314, acc 1
2016-09-05T18:02:22.012026: step 4460, loss 0.0172838, acc 1
2016-09-05T18:02:22.236392: step 4461, loss 0.00898134, acc 1
2016-09-05T18:02:22.373354: step 4462, loss 0.0071544, acc 1
2016-09-05T18:02:22.582927: step 4463, loss 0.00874505, acc 1
2016-09-05T18:02:22.794567: step 4464, loss 0.0125337, acc 1
2016-09-05T18:02:22.988055: step 4465, loss 0.0100824, acc 1
2016-09-05T18:02:23.199049: step 4466, loss 0.0151238, acc 1
2016-09-05T18:02:23.413329: step 4467, loss 0.00797352, acc 1
2016-09-05T18:02:23.623625: step 4468, loss 0.00871845, acc 1
2016-09-05T18:02:23.832232: step 4469, loss 0.00959321, acc 1
2016-09-05T18:02:24.061698: step 4470, loss 0.00774228, acc 1
2016-09-05T18:02:24.289960: step 4471, loss 0.010728, acc 1
2016-09-05T18:02:24.517637: step 4472, loss 0.00840115, acc 1
2016-09-05T18:02:24.732378: step 4473, loss 0.00769072, acc 1
2016-09-05T18:02:24.956906: step 4474, loss 0.0128565, acc 1
2016-09-05T18:02:25.189489: step 4475, loss 0.00767727, acc 1
2016-09-05T18:02:25.388275: step 4476, loss 0.00811976, acc 1
2016-09-05T18:02:25.597871: step 4477, loss 0.00762555, acc 1
2016-09-05T18:02:25.801121: step 4478, loss 0.00848694, acc 1
2016-09-05T18:02:25.999831: step 4479, loss 0.00938131, acc 1
2016-09-05T18:02:26.199865: step 4480, loss 0.00846201, acc 1
2016-09-05T18:02:26.405754: step 4481, loss 0.00767966, acc 1
2016-09-05T18:02:26.623937: step 4482, loss 0.00826137, acc 1
2016-09-05T18:02:26.845880: step 4483, loss 0.008425, acc 1
2016-09-05T18:02:27.064040: step 4484, loss 0.00875644, acc 1
2016-09-05T18:02:27.286039: step 4485, loss 0.00756394, acc 1
2016-09-05T18:02:27.513895: step 4486, loss 0.00782964, acc 1
2016-09-05T18:02:27.738295: step 4487, loss 0.00863223, acc 1
2016-09-05T18:02:27.950028: step 4488, loss 0.00778959, acc 1
2016-09-05T18:02:28.181915: step 4489, loss 0.00836876, acc 1
2016-09-05T18:02:28.409890: step 4490, loss 0.00757254, acc 1
2016-09-05T18:02:28.625076: step 4491, loss 0.0100019, acc 1
2016-09-05T18:02:28.864532: step 4492, loss 0.0132618, acc 1
2016-09-05T18:02:29.072841: step 4493, loss 0.00992343, acc 1
2016-09-05T18:02:29.295755: step 4494, loss 0.00717856, acc 1
2016-09-05T18:02:29.525902: step 4495, loss 0.00855755, acc 1
2016-09-05T18:02:29.739356: step 4496, loss 0.00757939, acc 1
2016-09-05T18:02:29.948725: step 4497, loss 0.00863064, acc 1
2016-09-05T18:02:30.219302: step 4498, loss 0.00804543, acc 1
2016-09-05T18:02:30.445444: step 4499, loss 0.00672386, acc 1
2016-09-05T18:02:30.644068: step 4500, loss 0.00759254, acc 1

Evaluation:
2016-09-05T18:02:31.240746: step 4500, loss 0.996598, acc 0.746

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-4500

2016-09-05T18:02:31.989752: step 4501, loss 0.0101154, acc 1
2016-09-05T18:02:32.198844: step 4502, loss 0.00884108, acc 1
2016-09-05T18:02:32.447835: step 4503, loss 0.00702401, acc 1
2016-09-05T18:02:32.637417: step 4504, loss 0.00706986, acc 1
2016-09-05T18:02:32.873116: step 4505, loss 0.007474, acc 1
2016-09-05T18:02:33.077970: step 4506, loss 0.00667474, acc 1
2016-09-05T18:02:33.289237: step 4507, loss 0.00758026, acc 1
2016-09-05T18:02:33.499525: step 4508, loss 0.00764578, acc 1
2016-09-05T18:02:33.733281: step 4509, loss 0.00966247, acc 1
2016-09-05T18:02:33.958827: step 4510, loss 0.00728877, acc 1
2016-09-05T18:02:34.174084: step 4511, loss 0.0140056, acc 1
2016-09-05T18:02:34.373923: step 4512, loss 0.00821652, acc 1
2016-09-05T18:02:34.583889: step 4513, loss 0.0147607, acc 1
2016-09-05T18:02:34.792117: step 4514, loss 0.00988477, acc 1
2016-09-05T18:02:35.017667: step 4515, loss 0.00877285, acc 1
2016-09-05T18:02:35.243367: step 4516, loss 0.00708981, acc 1
2016-09-05T18:02:35.457461: step 4517, loss 0.00847647, acc 1
2016-09-05T18:02:35.669375: step 4518, loss 0.0109566, acc 1
2016-09-05T18:02:35.884696: step 4519, loss 0.00664385, acc 1
2016-09-05T18:02:36.099590: step 4520, loss 0.00822826, acc 1
2016-09-05T18:02:36.300531: step 4521, loss 0.00906168, acc 1
2016-09-05T18:02:36.516209: step 4522, loss 0.00767784, acc 1
2016-09-05T18:02:36.741851: step 4523, loss 0.0068835, acc 1
2016-09-05T18:02:36.957229: step 4524, loss 0.00667099, acc 1
2016-09-05T18:02:37.200167: step 4525, loss 0.00938884, acc 1
2016-09-05T18:02:37.435626: step 4526, loss 0.007294, acc 1
2016-09-05T18:02:37.664413: step 4527, loss 0.00730039, acc 1
2016-09-05T18:02:37.874023: step 4528, loss 0.00923209, acc 1
2016-09-05T18:02:38.089918: step 4529, loss 0.0073206, acc 1
2016-09-05T18:02:38.298280: step 4530, loss 0.00715548, acc 1
2016-09-05T18:02:38.512444: step 4531, loss 0.00750578, acc 1
2016-09-05T18:02:38.720550: step 4532, loss 0.00678194, acc 1
2016-09-05T18:02:38.927881: step 4533, loss 0.00858457, acc 1
2016-09-05T18:02:39.136858: step 4534, loss 0.00720065, acc 1
2016-09-05T18:02:39.341800: step 4535, loss 0.00752895, acc 1
2016-09-05T18:02:39.566918: step 4536, loss 0.00940002, acc 1
2016-09-05T18:02:39.790927: step 4537, loss 0.00676944, acc 1
2016-09-05T18:02:40.021961: step 4538, loss 0.00841867, acc 1
2016-09-05T18:02:40.243230: step 4539, loss 0.00678843, acc 1
2016-09-05T18:02:40.451789: step 4540, loss 0.0082932, acc 1
2016-09-05T18:02:40.668455: step 4541, loss 0.00815336, acc 1
2016-09-05T18:02:40.879958: step 4542, loss 0.0076522, acc 1
2016-09-05T18:02:41.075904: step 4543, loss 0.00826563, acc 1
2016-09-05T18:02:41.300429: step 4544, loss 0.00747306, acc 1
2016-09-05T18:02:41.530437: step 4545, loss 0.00637782, acc 1
2016-09-05T18:02:41.756257: step 4546, loss 0.00710197, acc 1
2016-09-05T18:02:41.971548: step 4547, loss 0.00820357, acc 1
2016-09-05T18:02:42.207331: step 4548, loss 0.00718337, acc 1
2016-09-05T18:02:42.419192: step 4549, loss 0.017464, acc 1
2016-09-05T18:02:42.661763: step 4550, loss 0.00841082, acc 1
2016-09-05T18:02:42.868494: step 4551, loss 0.00912913, acc 1
2016-09-05T18:02:43.090961: step 4552, loss 0.00680948, acc 1
2016-09-05T18:02:43.292486: step 4553, loss 0.0092294, acc 1
2016-09-05T18:02:43.513735: step 4554, loss 0.00950655, acc 1
2016-09-05T18:02:43.731875: step 4555, loss 0.00883634, acc 1
2016-09-05T18:02:43.955775: step 4556, loss 0.00673671, acc 1
2016-09-05T18:02:44.181091: step 4557, loss 0.0109319, acc 1
2016-09-05T18:02:44.396127: step 4558, loss 0.00759476, acc 1
2016-09-05T18:02:44.612558: step 4559, loss 0.0107424, acc 1
2016-09-05T18:02:44.828934: step 4560, loss 0.00809366, acc 1
2016-09-05T18:02:45.050613: step 4561, loss 0.00972331, acc 1
2016-09-05T18:02:45.284652: step 4562, loss 0.0102462, acc 1
2016-09-05T18:02:45.491989: step 4563, loss 0.00911151, acc 1
2016-09-05T18:02:45.703108: step 4564, loss 0.00740436, acc 1
2016-09-05T18:02:45.909639: step 4565, loss 0.0103316, acc 1
2016-09-05T18:02:46.125511: step 4566, loss 0.00815272, acc 1
2016-09-05T18:02:46.358058: step 4567, loss 0.0100582, acc 1
2016-09-05T18:02:46.593131: step 4568, loss 0.0105582, acc 1
2016-09-05T18:02:46.811024: step 4569, loss 0.00759183, acc 1
2016-09-05T18:02:47.012067: step 4570, loss 0.0129202, acc 1
2016-09-05T18:02:47.244050: step 4571, loss 0.00783401, acc 1
2016-09-05T18:02:47.467509: step 4572, loss 0.00807015, acc 1
2016-09-05T18:02:47.678241: step 4573, loss 0.00880488, acc 1
2016-09-05T18:02:47.900549: step 4574, loss 0.00948832, acc 1
2016-09-05T18:02:48.101395: step 4575, loss 0.0112758, acc 1
2016-09-05T18:02:48.302522: step 4576, loss 0.00728967, acc 1
2016-09-05T18:02:48.501409: step 4577, loss 0.00923414, acc 1
2016-09-05T18:02:48.712280: step 4578, loss 0.00736406, acc 1
2016-09-05T18:02:48.907289: step 4579, loss 0.00722752, acc 1
2016-09-05T18:02:49.122361: step 4580, loss 0.00947197, acc 1
2016-09-05T18:02:49.341295: step 4581, loss 0.00800068, acc 1
2016-09-05T18:02:49.573473: step 4582, loss 0.00876339, acc 1
2016-09-05T18:02:49.813456: step 4583, loss 0.00912793, acc 1
2016-09-05T18:02:50.037155: step 4584, loss 0.00860733, acc 1
2016-09-05T18:02:50.236487: step 4585, loss 0.00914205, acc 1
2016-09-05T18:02:50.444586: step 4586, loss 0.00805888, acc 1
2016-09-05T18:02:50.650087: step 4587, loss 0.00978077, acc 1
2016-09-05T18:02:50.862781: step 4588, loss 0.00758175, acc 1
2016-09-05T18:02:51.070155: step 4589, loss 0.00955842, acc 1
2016-09-05T18:02:51.283496: step 4590, loss 0.0124199, acc 1
2016-09-05T18:02:51.498709: step 4591, loss 0.0116462, acc 1
2016-09-05T18:02:51.737662: step 4592, loss 0.0067824, acc 1
2016-09-05T18:02:51.959482: step 4593, loss 0.00937713, acc 1
2016-09-05T18:02:52.175517: step 4594, loss 0.00873595, acc 1
2016-09-05T18:02:52.404931: step 4595, loss 0.00730471, acc 1
2016-09-05T18:02:52.646735: step 4596, loss 0.00846266, acc 1
2016-09-05T18:02:52.856821: step 4597, loss 0.00875733, acc 1
2016-09-05T18:02:53.061801: step 4598, loss 0.0102166, acc 1
2016-09-05T18:02:53.273320: step 4599, loss 0.0123162, acc 1
2016-09-05T18:02:53.485668: step 4600, loss 0.00732795, acc 1

Evaluation:
2016-09-05T18:02:54.111041: step 4600, loss 1.03281, acc 0.744

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-4600

2016-09-05T18:02:54.828532: step 4601, loss 0.00886744, acc 1
2016-09-05T18:02:55.043569: step 4602, loss 0.00783486, acc 1
2016-09-05T18:02:55.273873: step 4603, loss 0.00708984, acc 1
2016-09-05T18:02:55.487180: step 4604, loss 0.00758079, acc 1
2016-09-05T18:02:55.707189: step 4605, loss 0.010141, acc 1
2016-09-05T18:02:55.971037: step 4606, loss 0.0115488, acc 1
2016-09-05T18:02:56.206207: step 4607, loss 0.00816914, acc 1
2016-09-05T18:02:56.425594: step 4608, loss 0.0211211, acc 1
2016-09-05T18:02:56.655105: step 4609, loss 0.00759322, acc 1
2016-09-05T18:02:56.906806: step 4610, loss 0.010322, acc 1
2016-09-05T18:02:57.141002: step 4611, loss 0.0103018, acc 1
2016-09-05T18:02:57.372075: step 4612, loss 0.00766641, acc 1
2016-09-05T18:02:57.585264: step 4613, loss 0.0109288, acc 1
2016-09-05T18:02:57.811093: step 4614, loss 0.00830315, acc 1
2016-09-05T18:02:58.014947: step 4615, loss 0.0109341, acc 1
2016-09-05T18:02:58.214974: step 4616, loss 0.0096331, acc 1
2016-09-05T18:02:58.442525: step 4617, loss 0.0105561, acc 1
2016-09-05T18:02:58.645662: step 4618, loss 0.0118082, acc 1
2016-09-05T18:02:58.853972: step 4619, loss 0.0076085, acc 1
2016-09-05T18:02:59.076469: step 4620, loss 0.00826793, acc 1
2016-09-05T18:02:59.294253: step 4621, loss 0.00918906, acc 1
2016-09-05T18:02:59.532853: step 4622, loss 0.00875519, acc 1
2016-09-05T18:02:59.729582: step 4623, loss 0.0099515, acc 1
2016-09-05T18:02:59.934268: step 4624, loss 0.0103928, acc 1
2016-09-05T18:03:00.148022: step 4625, loss 0.00824248, acc 1
2016-09-05T18:03:00.366072: step 4626, loss 0.00906216, acc 1
2016-09-05T18:03:00.578708: step 4627, loss 0.0096026, acc 1
2016-09-05T18:03:00.807900: step 4628, loss 0.00844976, acc 1
2016-09-05T18:03:01.031391: step 4629, loss 0.00784116, acc 1
2016-09-05T18:03:01.246118: step 4630, loss 0.00818107, acc 1
2016-09-05T18:03:01.453260: step 4631, loss 0.00755991, acc 1
2016-09-05T18:03:01.665719: step 4632, loss 0.00906751, acc 1
2016-09-05T18:03:01.867401: step 4633, loss 0.00808638, acc 1
2016-09-05T18:03:02.080294: step 4634, loss 0.00918328, acc 1
2016-09-05T18:03:02.283701: step 4635, loss 0.0075123, acc 1
2016-09-05T18:03:02.493508: step 4636, loss 0.00739398, acc 1
2016-09-05T18:03:02.720300: step 4637, loss 0.0080834, acc 1
2016-09-05T18:03:02.959047: step 4638, loss 0.00909449, acc 1
2016-09-05T18:03:03.171445: step 4639, loss 0.00906554, acc 1
2016-09-05T18:03:03.403089: step 4640, loss 0.0075635, acc 1
2016-09-05T18:03:03.632700: step 4641, loss 0.00717726, acc 1
2016-09-05T18:03:03.867243: step 4642, loss 0.00714065, acc 1
2016-09-05T18:03:04.086408: step 4643, loss 0.00667267, acc 1
2016-09-05T18:03:04.292405: step 4644, loss 0.0125871, acc 1
2016-09-05T18:03:04.492433: step 4645, loss 0.00716982, acc 1
2016-09-05T18:03:04.690406: step 4646, loss 0.00774247, acc 1
2016-09-05T18:03:04.904773: step 4647, loss 0.00774458, acc 1
2016-09-05T18:03:05.122181: step 4648, loss 0.0085119, acc 1
2016-09-05T18:03:05.337650: step 4649, loss 0.008123, acc 1
2016-09-05T18:03:05.578810: step 4650, loss 0.00683609, acc 1
2016-09-05T18:03:05.780909: step 4651, loss 0.0121585, acc 1
2016-09-05T18:03:05.996437: step 4652, loss 0.00947029, acc 1
2016-09-05T18:03:06.202757: step 4653, loss 0.00830722, acc 1
2016-09-05T18:03:06.407886: step 4654, loss 0.00791579, acc 1
2016-09-05T18:03:06.628805: step 4655, loss 0.00665655, acc 1
2016-09-05T18:03:06.746081: step 4656, loss 0.0064499, acc 1
2016-09-05T18:03:06.999972: step 4657, loss 0.00654392, acc 1
2016-09-05T18:03:07.201820: step 4658, loss 0.00752993, acc 1
2016-09-05T18:03:07.402238: step 4659, loss 0.00806706, acc 1
2016-09-05T18:03:07.617631: step 4660, loss 0.0100792, acc 1
2016-09-05T18:03:07.843864: step 4661, loss 0.00680557, acc 1
2016-09-05T18:03:08.069874: step 4662, loss 0.00709109, acc 1
2016-09-05T18:03:08.269800: step 4663, loss 0.00872631, acc 1
2016-09-05T18:03:08.497868: step 4664, loss 0.00648088, acc 1
2016-09-05T18:03:08.725380: step 4665, loss 0.00697299, acc 1
2016-09-05T18:03:08.938000: step 4666, loss 0.00904352, acc 1
2016-09-05T18:03:09.150499: step 4667, loss 0.00624205, acc 1
2016-09-05T18:03:09.381465: step 4668, loss 0.00736165, acc 1
2016-09-05T18:03:09.611809: step 4669, loss 0.00677095, acc 1
2016-09-05T18:03:09.808461: step 4670, loss 0.00895811, acc 1
2016-09-05T18:03:10.025654: step 4671, loss 0.00685997, acc 1
2016-09-05T18:03:10.238660: step 4672, loss 0.00728091, acc 1
2016-09-05T18:03:10.442238: step 4673, loss 0.00958674, acc 1
2016-09-05T18:03:10.676816: step 4674, loss 0.00772885, acc 1
2016-09-05T18:03:10.922402: step 4675, loss 0.00881245, acc 1
2016-09-05T18:03:11.148239: step 4676, loss 0.00732162, acc 1
2016-09-05T18:03:11.365901: step 4677, loss 0.00603346, acc 1
2016-09-05T18:03:11.564712: step 4678, loss 0.00621674, acc 1
2016-09-05T18:03:11.788992: step 4679, loss 0.00678357, acc 1
2016-09-05T18:03:12.002305: step 4680, loss 0.00869716, acc 1
2016-09-05T18:03:12.226210: step 4681, loss 0.00674436, acc 1
2016-09-05T18:03:12.448561: step 4682, loss 0.00716714, acc 1
2016-09-05T18:03:12.660809: step 4683, loss 0.00710876, acc 1
2016-09-05T18:03:12.861688: step 4684, loss 0.0068655, acc 1
2016-09-05T18:03:13.080464: step 4685, loss 0.00618876, acc 1
2016-09-05T18:03:13.282359: step 4686, loss 0.00633814, acc 1
2016-09-05T18:03:13.488473: step 4687, loss 0.00866837, acc 1
2016-09-05T18:03:13.691618: step 4688, loss 0.00900202, acc 1
2016-09-05T18:03:13.902866: step 4689, loss 0.00787586, acc 1
2016-09-05T18:03:14.124877: step 4690, loss 0.00905627, acc 1
2016-09-05T18:03:14.349459: step 4691, loss 0.0113609, acc 1
2016-09-05T18:03:14.584562: step 4692, loss 0.00844028, acc 1
2016-09-05T18:03:14.814903: step 4693, loss 0.00699366, acc 1
2016-09-05T18:03:15.075475: step 4694, loss 0.00659795, acc 1
2016-09-05T18:03:15.285931: step 4695, loss 0.00631474, acc 1
2016-09-05T18:03:15.508233: step 4696, loss 0.00797474, acc 1
2016-09-05T18:03:15.719493: step 4697, loss 0.0071376, acc 1
2016-09-05T18:03:15.934430: step 4698, loss 0.00657417, acc 1
2016-09-05T18:03:16.182396: step 4699, loss 0.00649265, acc 1
2016-09-05T18:03:16.389362: step 4700, loss 0.00587597, acc 1

Evaluation:
2016-09-05T18:03:16.983850: step 4700, loss 0.991274, acc 0.744

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-4700

2016-09-05T18:03:17.785311: step 4701, loss 0.00677033, acc 1
2016-09-05T18:03:17.996999: step 4702, loss 0.00843679, acc 1
2016-09-05T18:03:18.189303: step 4703, loss 0.00600786, acc 1
2016-09-05T18:03:18.387321: step 4704, loss 0.0108275, acc 1
2016-09-05T18:03:18.601648: step 4705, loss 0.00921316, acc 1
2016-09-05T18:03:18.817253: step 4706, loss 0.00708401, acc 1
2016-09-05T18:03:19.090605: step 4707, loss 0.00636466, acc 1
2016-09-05T18:03:19.309883: step 4708, loss 0.0109716, acc 1
2016-09-05T18:03:19.529009: step 4709, loss 0.00605058, acc 1
2016-09-05T18:03:19.750185: step 4710, loss 0.00624149, acc 1
2016-09-05T18:03:19.988841: step 4711, loss 0.00789625, acc 1
2016-09-05T18:03:20.205186: step 4712, loss 0.00699979, acc 1
2016-09-05T18:03:20.423729: step 4713, loss 0.00903496, acc 1
2016-09-05T18:03:20.634442: step 4714, loss 0.00756903, acc 1
2016-09-05T18:03:20.857643: step 4715, loss 0.00650499, acc 1
2016-09-05T18:03:21.095438: step 4716, loss 0.00834683, acc 1
2016-09-05T18:03:21.342175: step 4717, loss 0.00641516, acc 1
2016-09-05T18:03:21.567084: step 4718, loss 0.00717986, acc 1
2016-09-05T18:03:21.775770: step 4719, loss 0.00850088, acc 1
2016-09-05T18:03:21.988476: step 4720, loss 0.00828154, acc 1
2016-09-05T18:03:22.197462: step 4721, loss 0.00869622, acc 1
2016-09-05T18:03:22.433913: step 4722, loss 0.00708338, acc 1
2016-09-05T18:03:22.640880: step 4723, loss 0.00771534, acc 1
2016-09-05T18:03:22.845504: step 4724, loss 0.00814098, acc 1
2016-09-05T18:03:23.041499: step 4725, loss 0.00669673, acc 1
2016-09-05T18:03:23.249923: step 4726, loss 0.00655645, acc 1
2016-09-05T18:03:23.457971: step 4727, loss 0.0072501, acc 1
2016-09-05T18:03:23.701494: step 4728, loss 0.00852807, acc 1
2016-09-05T18:03:23.947510: step 4729, loss 0.00737298, acc 1
2016-09-05T18:03:24.152757: step 4730, loss 0.00939638, acc 1
2016-09-05T18:03:24.367289: step 4731, loss 0.00718817, acc 1
2016-09-05T18:03:24.590367: step 4732, loss 0.00754059, acc 1
2016-09-05T18:03:24.852628: step 4733, loss 0.00888979, acc 1
2016-09-05T18:03:25.070576: step 4734, loss 0.00812442, acc 1
2016-09-05T18:03:25.290844: step 4735, loss 0.00787056, acc 1
2016-09-05T18:03:25.504664: step 4736, loss 0.010944, acc 1
2016-09-05T18:03:25.717192: step 4737, loss 0.00920049, acc 1
2016-09-05T18:03:25.933347: step 4738, loss 0.00662085, acc 1
2016-09-05T18:03:26.209990: step 4739, loss 0.00956012, acc 1
2016-09-05T18:03:26.415982: step 4740, loss 0.00671121, acc 1
2016-09-05T18:03:26.648980: step 4741, loss 0.0062254, acc 1
2016-09-05T18:03:26.883144: step 4742, loss 0.0102149, acc 1
2016-09-05T18:03:27.090610: step 4743, loss 0.00636042, acc 1
2016-09-05T18:03:27.298472: step 4744, loss 0.00729098, acc 1
2016-09-05T18:03:27.498602: step 4745, loss 0.00727739, acc 1
2016-09-05T18:03:27.743199: step 4746, loss 0.00928431, acc 1
2016-09-05T18:03:27.969962: step 4747, loss 0.00764646, acc 1
2016-09-05T18:03:28.189388: step 4748, loss 0.00691622, acc 1
2016-09-05T18:03:28.398386: step 4749, loss 0.00967375, acc 1
2016-09-05T18:03:28.605014: step 4750, loss 0.00735379, acc 1
2016-09-05T18:03:28.808402: step 4751, loss 0.00781469, acc 1
2016-09-05T18:03:29.030994: step 4752, loss 0.00766013, acc 1
2016-09-05T18:03:29.249915: step 4753, loss 0.00720155, acc 1
2016-09-05T18:03:29.493549: step 4754, loss 0.00720201, acc 1
2016-09-05T18:03:29.729649: step 4755, loss 0.00806921, acc 1
2016-09-05T18:03:29.950045: step 4756, loss 0.00654554, acc 1
2016-09-05T18:03:30.190561: step 4757, loss 0.00635722, acc 1
2016-09-05T18:03:30.395545: step 4758, loss 0.0066881, acc 1
2016-09-05T18:03:30.632129: step 4759, loss 0.00702734, acc 1
2016-09-05T18:03:30.834841: step 4760, loss 0.00688963, acc 1
2016-09-05T18:03:31.059955: step 4761, loss 0.00920598, acc 1
2016-09-05T18:03:31.275667: step 4762, loss 0.00711945, acc 1
2016-09-05T18:03:31.517381: step 4763, loss 0.00696286, acc 1
2016-09-05T18:03:31.738447: step 4764, loss 0.00618718, acc 1
2016-09-05T18:03:31.950761: step 4765, loss 0.00735425, acc 1
2016-09-05T18:03:32.177032: step 4766, loss 0.00725791, acc 1
2016-09-05T18:03:32.376729: step 4767, loss 0.0074906, acc 1
2016-09-05T18:03:32.602263: step 4768, loss 0.00584181, acc 1
2016-09-05T18:03:32.842341: step 4769, loss 0.00767549, acc 1
2016-09-05T18:03:33.058132: step 4770, loss 0.00855658, acc 1
2016-09-05T18:03:33.289432: step 4771, loss 0.00731366, acc 1
2016-09-05T18:03:33.533443: step 4772, loss 0.00545309, acc 1
2016-09-05T18:03:33.751765: step 4773, loss 0.00751251, acc 1
2016-09-05T18:03:33.961559: step 4774, loss 0.00828419, acc 1
2016-09-05T18:03:34.169203: step 4775, loss 0.00680399, acc 1
2016-09-05T18:03:34.392497: step 4776, loss 0.00726695, acc 1
2016-09-05T18:03:34.600987: step 4777, loss 0.00994316, acc 1
2016-09-05T18:03:34.814809: step 4778, loss 0.00679147, acc 1
2016-09-05T18:03:35.074563: step 4779, loss 0.00594357, acc 1
2016-09-05T18:03:35.284553: step 4780, loss 0.00799723, acc 1
2016-09-05T18:03:35.492990: step 4781, loss 0.020644, acc 1
2016-09-05T18:03:35.714624: step 4782, loss 0.00790558, acc 1
2016-09-05T18:03:35.950863: step 4783, loss 0.00911426, acc 1
2016-09-05T18:03:36.209872: step 4784, loss 0.0265933, acc 1
2016-09-05T18:03:36.442195: step 4785, loss 0.00828707, acc 1
2016-09-05T18:03:36.679503: step 4786, loss 0.00846252, acc 1
2016-09-05T18:03:36.899483: step 4787, loss 0.00769337, acc 1
2016-09-05T18:03:37.120867: step 4788, loss 0.010699, acc 1
2016-09-05T18:03:37.331890: step 4789, loss 0.010063, acc 1
2016-09-05T18:03:37.556373: step 4790, loss 0.00864331, acc 1
2016-09-05T18:03:37.792321: step 4791, loss 0.0102308, acc 1
2016-09-05T18:03:38.005087: step 4792, loss 0.0101344, acc 1
2016-09-05T18:03:38.206633: step 4793, loss 0.00916369, acc 1
2016-09-05T18:03:38.403486: step 4794, loss 0.0104728, acc 1
2016-09-05T18:03:38.611498: step 4795, loss 0.0123379, acc 1
2016-09-05T18:03:38.822092: step 4796, loss 0.0129851, acc 1
2016-09-05T18:03:39.056491: step 4797, loss 0.0114408, acc 1
2016-09-05T18:03:39.292301: step 4798, loss 0.00894452, acc 1
2016-09-05T18:03:39.521753: step 4799, loss 0.00932422, acc 1
2016-09-05T18:03:39.719312: step 4800, loss 0.00859881, acc 1

Evaluation:
2016-09-05T18:03:40.333386: step 4800, loss 1.18371, acc 0.749

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-4800

2016-09-05T18:03:41.051779: step 4801, loss 0.00891648, acc 1
2016-09-05T18:03:41.260095: step 4802, loss 0.0121584, acc 1
2016-09-05T18:03:41.478779: step 4803, loss 0.0154954, acc 1
2016-09-05T18:03:41.689733: step 4804, loss 0.0128405, acc 1
2016-09-05T18:03:41.911415: step 4805, loss 0.00958823, acc 1
2016-09-05T18:03:42.121404: step 4806, loss 0.0131115, acc 1
2016-09-05T18:03:42.371670: step 4807, loss 0.00940723, acc 1
2016-09-05T18:03:42.591101: step 4808, loss 0.00973244, acc 1
2016-09-05T18:03:42.798948: step 4809, loss 0.0110957, acc 1
2016-09-05T18:03:43.037350: step 4810, loss 0.00919056, acc 1
2016-09-05T18:03:43.252479: step 4811, loss 0.00908511, acc 1
2016-09-05T18:03:43.457010: step 4812, loss 0.00940275, acc 1
2016-09-05T18:03:43.675221: step 4813, loss 0.0098027, acc 1
2016-09-05T18:03:43.882937: step 4814, loss 0.0095855, acc 1
2016-09-05T18:03:44.087233: step 4815, loss 0.0101394, acc 1
2016-09-05T18:03:44.296090: step 4816, loss 0.0097388, acc 1
2016-09-05T18:03:44.512462: step 4817, loss 0.00905714, acc 1
2016-09-05T18:03:44.740694: step 4818, loss 0.0119141, acc 1
2016-09-05T18:03:44.931729: step 4819, loss 0.00870821, acc 1
2016-09-05T18:03:45.169964: step 4820, loss 0.0100467, acc 1
2016-09-05T18:03:45.392439: step 4821, loss 0.00886754, acc 1
2016-09-05T18:03:45.619586: step 4822, loss 0.00833363, acc 1
2016-09-05T18:03:45.829075: step 4823, loss 0.00774282, acc 1
2016-09-05T18:03:46.069365: step 4824, loss 0.00816296, acc 1
2016-09-05T18:03:46.277487: step 4825, loss 0.00862133, acc 1
2016-09-05T18:03:46.490539: step 4826, loss 0.00868528, acc 1
2016-09-05T18:03:46.705367: step 4827, loss 0.0074385, acc 1
2016-09-05T18:03:46.929387: step 4828, loss 0.00714813, acc 1
2016-09-05T18:03:47.157727: step 4829, loss 0.00843767, acc 1
2016-09-05T18:03:47.384642: step 4830, loss 0.00903264, acc 1
2016-09-05T18:03:47.609846: step 4831, loss 0.00784743, acc 1
2016-09-05T18:03:47.804616: step 4832, loss 0.00847121, acc 1
2016-09-05T18:03:48.011393: step 4833, loss 0.00800611, acc 1
2016-09-05T18:03:48.228064: step 4834, loss 0.00942562, acc 1
2016-09-05T18:03:48.455607: step 4835, loss 0.00739365, acc 1
2016-09-05T18:03:48.656636: step 4836, loss 0.00755281, acc 1
2016-09-05T18:03:48.870880: step 4837, loss 0.00731098, acc 1
2016-09-05T18:03:49.076991: step 4838, loss 0.00657676, acc 1
2016-09-05T18:03:49.315057: step 4839, loss 0.0082183, acc 1
2016-09-05T18:03:49.534092: step 4840, loss 0.00902231, acc 1
2016-09-05T18:03:49.773810: step 4841, loss 0.00823055, acc 1
2016-09-05T18:03:49.980116: step 4842, loss 0.00730992, acc 1
2016-09-05T18:03:50.215991: step 4843, loss 0.00662131, acc 1
2016-09-05T18:03:50.426013: step 4844, loss 0.00675629, acc 1
2016-09-05T18:03:50.628483: step 4845, loss 0.00816169, acc 1
2016-09-05T18:03:50.836207: step 4846, loss 0.00835618, acc 1
2016-09-05T18:03:51.033424: step 4847, loss 0.00715146, acc 1
2016-09-05T18:03:51.232413: step 4848, loss 0.0079602, acc 1
2016-09-05T18:03:51.442504: step 4849, loss 0.00855505, acc 1
2016-09-05T18:03:51.578029: step 4850, loss 0.00588593, acc 1
2016-09-05T18:03:51.793807: step 4851, loss 0.00631109, acc 1
2016-09-05T18:03:52.034802: step 4852, loss 0.0149861, acc 1
2016-09-05T18:03:52.235891: step 4853, loss 0.00701494, acc 1
2016-09-05T18:03:52.448803: step 4854, loss 0.00664719, acc 1
2016-09-05T18:03:52.647841: step 4855, loss 0.00800324, acc 1
2016-09-05T18:03:52.858516: step 4856, loss 0.00666893, acc 1
2016-09-05T18:03:53.061627: step 4857, loss 0.00762125, acc 1
2016-09-05T18:03:53.272803: step 4858, loss 0.00846655, acc 1
2016-09-05T18:03:53.478789: step 4859, loss 0.00753574, acc 1
2016-09-05T18:03:53.698722: step 4860, loss 0.00694858, acc 1
2016-09-05T18:03:53.915357: step 4861, loss 0.00752902, acc 1
2016-09-05T18:03:54.150478: step 4862, loss 0.00937748, acc 1
2016-09-05T18:03:54.353337: step 4863, loss 0.00706517, acc 1
2016-09-05T18:03:54.565763: step 4864, loss 0.0079375, acc 1
2016-09-05T18:03:54.763647: step 4865, loss 0.00806853, acc 1
2016-09-05T18:03:54.964768: step 4866, loss 0.00712285, acc 1
2016-09-05T18:03:55.163018: step 4867, loss 0.00611833, acc 1
2016-09-05T18:03:55.386080: step 4868, loss 0.00654272, acc 1
2016-09-05T18:03:55.641075: step 4869, loss 0.00600872, acc 1
2016-09-05T18:03:55.856544: step 4870, loss 0.00786474, acc 1
2016-09-05T18:03:56.095591: step 4871, loss 0.00663046, acc 1
2016-09-05T18:03:56.314721: step 4872, loss 0.00664587, acc 1
2016-09-05T18:03:56.548699: step 4873, loss 0.0063443, acc 1
2016-09-05T18:03:56.797117: step 4874, loss 0.0079206, acc 1
2016-09-05T18:03:57.044508: step 4875, loss 0.00715697, acc 1
2016-09-05T18:03:57.259690: step 4876, loss 0.00656589, acc 1
2016-09-05T18:03:57.500515: step 4877, loss 0.00626496, acc 1
2016-09-05T18:03:57.708592: step 4878, loss 0.00921575, acc 1
2016-09-05T18:03:57.908517: step 4879, loss 0.00643795, acc 1
2016-09-05T18:03:58.123743: step 4880, loss 0.00679939, acc 1
2016-09-05T18:03:58.336684: step 4881, loss 0.00601193, acc 1
2016-09-05T18:03:58.547717: step 4882, loss 0.00666589, acc 1
2016-09-05T18:03:58.774622: step 4883, loss 0.00548327, acc 1
2016-09-05T18:03:59.014267: step 4884, loss 0.00807284, acc 1
2016-09-05T18:03:59.216162: step 4885, loss 0.00571422, acc 1
2016-09-05T18:03:59.426074: step 4886, loss 0.00610749, acc 1
2016-09-05T18:03:59.634672: step 4887, loss 0.0057305, acc 1
2016-09-05T18:03:59.851698: step 4888, loss 0.00726537, acc 1
2016-09-05T18:04:00.073389: step 4889, loss 0.00577599, acc 1
2016-09-05T18:04:00.329808: step 4890, loss 0.00799475, acc 1
2016-09-05T18:04:00.534159: step 4891, loss 0.00881101, acc 1
2016-09-05T18:04:00.734145: step 4892, loss 0.00644204, acc 1
2016-09-05T18:04:00.946807: step 4893, loss 0.00655637, acc 1
2016-09-05T18:04:01.163847: step 4894, loss 0.00702994, acc 1
2016-09-05T18:04:01.390346: step 4895, loss 0.00747305, acc 1
2016-09-05T18:04:01.610020: step 4896, loss 0.00659002, acc 1
2016-09-05T18:04:01.865397: step 4897, loss 0.00571186, acc 1
2016-09-05T18:04:02.084986: step 4898, loss 0.00520999, acc 1
2016-09-05T18:04:02.331358: step 4899, loss 0.00660293, acc 1
2016-09-05T18:04:02.558426: step 4900, loss 0.00590765, acc 1

Evaluation:
2016-09-05T18:04:03.164784: step 4900, loss 1.00887, acc 0.745

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-4900

2016-09-05T18:04:03.875211: step 4901, loss 0.00581174, acc 1
2016-09-05T18:04:04.076975: step 4902, loss 0.00626961, acc 1
2016-09-05T18:04:04.302087: step 4903, loss 0.00665877, acc 1
2016-09-05T18:04:04.507905: step 4904, loss 0.00531195, acc 1
2016-09-05T18:04:04.727591: step 4905, loss 0.00680085, acc 1
2016-09-05T18:04:04.965429: step 4906, loss 0.0095923, acc 1
2016-09-05T18:04:05.176722: step 4907, loss 0.00625809, acc 1
2016-09-05T18:04:05.393794: step 4908, loss 0.00598746, acc 1
2016-09-05T18:04:05.589075: step 4909, loss 0.00554076, acc 1
2016-09-05T18:04:05.796053: step 4910, loss 0.0106633, acc 1
2016-09-05T18:04:06.003785: step 4911, loss 0.0100382, acc 1
2016-09-05T18:04:06.246352: step 4912, loss 0.00761024, acc 1
2016-09-05T18:04:06.481477: step 4913, loss 0.00984319, acc 1
2016-09-05T18:04:06.710055: step 4914, loss 0.00794971, acc 1
2016-09-05T18:04:06.913476: step 4915, loss 0.00740204, acc 1
2016-09-05T18:04:07.123352: step 4916, loss 0.00584474, acc 1
2016-09-05T18:04:07.349514: step 4917, loss 0.00629005, acc 1
2016-09-05T18:04:07.593591: step 4918, loss 0.00615034, acc 1
2016-09-05T18:04:07.827693: step 4919, loss 0.00601116, acc 1
2016-09-05T18:04:08.038311: step 4920, loss 0.00570223, acc 1
2016-09-05T18:04:08.260170: step 4921, loss 0.00682679, acc 1
2016-09-05T18:04:08.479090: step 4922, loss 0.00623731, acc 1
2016-09-05T18:04:08.713643: step 4923, loss 0.00650312, acc 1
2016-09-05T18:04:08.923137: step 4924, loss 0.00731253, acc 1
2016-09-05T18:04:09.143153: step 4925, loss 0.00755794, acc 1
2016-09-05T18:04:09.359792: step 4926, loss 0.00575095, acc 1
2016-09-05T18:04:09.574028: step 4927, loss 0.00569076, acc 1
2016-09-05T18:04:09.798417: step 4928, loss 0.00577656, acc 1
2016-09-05T18:04:10.012176: step 4929, loss 0.00697103, acc 1
2016-09-05T18:04:10.232228: step 4930, loss 0.00636165, acc 1
2016-09-05T18:04:10.436108: step 4931, loss 0.00620676, acc 1
2016-09-05T18:04:10.660165: step 4932, loss 0.00768483, acc 1
2016-09-05T18:04:10.872762: step 4933, loss 0.00642149, acc 1
2016-09-05T18:04:11.098223: step 4934, loss 0.00579797, acc 1
2016-09-05T18:04:11.306036: step 4935, loss 0.00774381, acc 1
2016-09-05T18:04:11.539471: step 4936, loss 0.00558296, acc 1
2016-09-05T18:04:11.754145: step 4937, loss 0.0102392, acc 1
2016-09-05T18:04:11.952908: step 4938, loss 0.00651417, acc 1
2016-09-05T18:04:12.163756: step 4939, loss 0.00773156, acc 1
2016-09-05T18:04:12.386331: step 4940, loss 0.00606444, acc 1
2016-09-05T18:04:12.600294: step 4941, loss 0.00597354, acc 1
2016-09-05T18:04:12.828007: step 4942, loss 0.00786499, acc 1
2016-09-05T18:04:13.054393: step 4943, loss 0.00579447, acc 1
2016-09-05T18:04:13.266169: step 4944, loss 0.00627023, acc 1
2016-09-05T18:04:13.481484: step 4945, loss 0.00578079, acc 1
2016-09-05T18:04:13.690272: step 4946, loss 0.00603821, acc 1
2016-09-05T18:04:13.907746: step 4947, loss 0.00681027, acc 1
2016-09-05T18:04:14.115044: step 4948, loss 0.00575361, acc 1
2016-09-05T18:04:14.335611: step 4949, loss 0.00540998, acc 1
2016-09-05T18:04:14.568059: step 4950, loss 0.00689467, acc 1
2016-09-05T18:04:14.786613: step 4951, loss 0.00663584, acc 1
2016-09-05T18:04:14.984558: step 4952, loss 0.00626341, acc 1
2016-09-05T18:04:15.221536: step 4953, loss 0.00660296, acc 1
2016-09-05T18:04:15.474033: step 4954, loss 0.00520123, acc 1
2016-09-05T18:04:15.690874: step 4955, loss 0.00960875, acc 1
2016-09-05T18:04:15.942341: step 4956, loss 0.00695235, acc 1
2016-09-05T18:04:16.152429: step 4957, loss 0.00701589, acc 1
2016-09-05T18:04:16.397729: step 4958, loss 0.00662599, acc 1
2016-09-05T18:04:16.602313: step 4959, loss 0.00823956, acc 1
2016-09-05T18:04:16.797873: step 4960, loss 0.00659583, acc 1
2016-09-05T18:04:17.001016: step 4961, loss 0.00609428, acc 1
2016-09-05T18:04:17.214021: step 4962, loss 0.00742039, acc 1
2016-09-05T18:04:17.426344: step 4963, loss 0.0120936, acc 1
2016-09-05T18:04:17.657499: step 4964, loss 0.00827305, acc 1
2016-09-05T18:04:17.873143: step 4965, loss 0.00711244, acc 1
2016-09-05T18:04:18.085201: step 4966, loss 0.00595406, acc 1
2016-09-05T18:04:18.296347: step 4967, loss 0.00592295, acc 1
2016-09-05T18:04:18.513849: step 4968, loss 0.00778087, acc 1
2016-09-05T18:04:18.717398: step 4969, loss 0.00656239, acc 1
2016-09-05T18:04:18.917886: step 4970, loss 0.00660101, acc 1
2016-09-05T18:04:19.127104: step 4971, loss 0.0077529, acc 1
2016-09-05T18:04:19.359459: step 4972, loss 0.00736711, acc 1
2016-09-05T18:04:19.586235: step 4973, loss 0.00715789, acc 1
2016-09-05T18:04:19.808187: step 4974, loss 0.00765444, acc 1
2016-09-05T18:04:20.032017: step 4975, loss 0.0063806, acc 1
2016-09-05T18:04:20.235669: step 4976, loss 0.00684073, acc 1
2016-09-05T18:04:20.438959: step 4977, loss 0.00711317, acc 1
2016-09-05T18:04:20.661348: step 4978, loss 0.00694997, acc 1
2016-09-05T18:04:20.892047: step 4979, loss 0.00735404, acc 1
2016-09-05T18:04:21.111767: step 4980, loss 0.00736528, acc 1
2016-09-05T18:04:21.339286: step 4981, loss 0.00715795, acc 1
2016-09-05T18:04:21.537834: step 4982, loss 0.00566248, acc 1
2016-09-05T18:04:21.743072: step 4983, loss 0.00769321, acc 1
2016-09-05T18:04:21.960088: step 4984, loss 0.00689407, acc 1
2016-09-05T18:04:22.186980: step 4985, loss 0.00645285, acc 1
2016-09-05T18:04:22.421274: step 4986, loss 0.0076481, acc 1
2016-09-05T18:04:22.612923: step 4987, loss 0.00636536, acc 1
2016-09-05T18:04:22.855539: step 4988, loss 0.00693737, acc 1
2016-09-05T18:04:23.062402: step 4989, loss 0.00805165, acc 1
2016-09-05T18:04:23.271103: step 4990, loss 0.00638658, acc 1
2016-09-05T18:04:23.485920: step 4991, loss 0.0091963, acc 1
2016-09-05T18:04:23.720296: step 4992, loss 0.00735739, acc 1
2016-09-05T18:04:23.950918: step 4993, loss 0.00728522, acc 1
2016-09-05T18:04:24.161952: step 4994, loss 0.00678721, acc 1
2016-09-05T18:04:24.370589: step 4995, loss 0.00924908, acc 1
2016-09-05T18:04:24.574746: step 4996, loss 0.00866289, acc 1
2016-09-05T18:04:24.780111: step 4997, loss 0.00968446, acc 1
2016-09-05T18:04:24.988734: step 4998, loss 0.00704061, acc 1
2016-09-05T18:04:25.190914: step 4999, loss 0.00628812, acc 1
2016-09-05T18:04:25.395036: step 5000, loss 0.00685441, acc 1

Evaluation:
2016-09-05T18:04:25.988859: step 5000, loss 1.07175, acc 0.741

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-5000

2016-09-05T18:04:26.684473: step 5001, loss 0.00707768, acc 1
2016-09-05T18:04:26.918523: step 5002, loss 0.00616026, acc 1
2016-09-05T18:04:27.161078: step 5003, loss 0.00672482, acc 1
2016-09-05T18:04:27.377010: step 5004, loss 0.00748148, acc 1
2016-09-05T18:04:27.586322: step 5005, loss 0.00650588, acc 1
2016-09-05T18:04:27.786600: step 5006, loss 0.00849398, acc 1
2016-09-05T18:04:28.000256: step 5007, loss 0.00651407, acc 1
2016-09-05T18:04:28.216059: step 5008, loss 0.00708342, acc 1
2016-09-05T18:04:28.433451: step 5009, loss 0.0061897, acc 1
2016-09-05T18:04:28.673498: step 5010, loss 0.00676031, acc 1
2016-09-05T18:04:28.891887: step 5011, loss 0.00721938, acc 1
2016-09-05T18:04:29.110385: step 5012, loss 0.00705105, acc 1
2016-09-05T18:04:29.336196: step 5013, loss 0.0101175, acc 1
2016-09-05T18:04:29.541505: step 5014, loss 0.00663223, acc 1
2016-09-05T18:04:29.779576: step 5015, loss 0.00748756, acc 1
2016-09-05T18:04:29.996590: step 5016, loss 0.00601745, acc 1
2016-09-05T18:04:30.211175: step 5017, loss 0.00792683, acc 1
2016-09-05T18:04:30.438162: step 5018, loss 0.00602018, acc 1
2016-09-05T18:04:30.662193: step 5019, loss 0.00850023, acc 1
2016-09-05T18:04:30.905974: step 5020, loss 0.0072356, acc 1
2016-09-05T18:04:31.109204: step 5021, loss 0.0114933, acc 1
2016-09-05T18:04:31.317880: step 5022, loss 0.00653375, acc 1
2016-09-05T18:04:31.524336: step 5023, loss 0.00742101, acc 1
2016-09-05T18:04:31.744958: step 5024, loss 0.00668772, acc 1
2016-09-05T18:04:31.960134: step 5025, loss 0.00597726, acc 1
2016-09-05T18:04:32.214363: step 5026, loss 0.00764764, acc 1
2016-09-05T18:04:32.428026: step 5027, loss 0.00701874, acc 1
2016-09-05T18:04:32.635230: step 5028, loss 0.00682789, acc 1
2016-09-05T18:04:32.839894: step 5029, loss 0.00859183, acc 1
2016-09-05T18:04:33.058191: step 5030, loss 0.00635893, acc 1
2016-09-05T18:04:33.264702: step 5031, loss 0.00642403, acc 1
2016-09-05T18:04:33.498841: step 5032, loss 0.00723998, acc 1
2016-09-05T18:04:33.727453: step 5033, loss 0.00573838, acc 1
2016-09-05T18:04:33.945445: step 5034, loss 0.00623747, acc 1
2016-09-05T18:04:34.157485: step 5035, loss 0.00641032, acc 1
2016-09-05T18:04:34.360596: step 5036, loss 0.00632524, acc 1
2016-09-05T18:04:34.585552: step 5037, loss 0.00650546, acc 1
2016-09-05T18:04:34.802250: step 5038, loss 0.00708576, acc 1
2016-09-05T18:04:35.043835: step 5039, loss 0.0079509, acc 1
2016-09-05T18:04:35.243328: step 5040, loss 0.00533748, acc 1
2016-09-05T18:04:35.452923: step 5041, loss 0.006675, acc 1
2016-09-05T18:04:35.643120: step 5042, loss 0.0064121, acc 1
2016-09-05T18:04:35.864808: step 5043, loss 0.00715818, acc 1
2016-09-05T18:04:35.983277: step 5044, loss 0.00577932, acc 1
2016-09-05T18:04:36.194588: step 5045, loss 0.00697376, acc 1
2016-09-05T18:04:36.413049: step 5046, loss 0.0056481, acc 1
2016-09-05T18:04:36.663946: step 5047, loss 0.00596877, acc 1
2016-09-05T18:04:36.864115: step 5048, loss 0.00595608, acc 1
2016-09-05T18:04:37.080334: step 5049, loss 0.0057099, acc 1
2016-09-05T18:04:37.288237: step 5050, loss 0.0062199, acc 1
2016-09-05T18:04:37.502214: step 5051, loss 0.00720017, acc 1
2016-09-05T18:04:37.716161: step 5052, loss 0.00689333, acc 1
2016-09-05T18:04:37.945804: step 5053, loss 0.00593475, acc 1
2016-09-05T18:04:38.181953: step 5054, loss 0.00605689, acc 1
2016-09-05T18:04:38.396866: step 5055, loss 0.00689108, acc 1
2016-09-05T18:04:38.639927: step 5056, loss 0.00575769, acc 1
2016-09-05T18:04:38.880985: step 5057, loss 0.00654834, acc 1
2016-09-05T18:04:39.086693: step 5058, loss 0.00521072, acc 1
2016-09-05T18:04:39.297264: step 5059, loss 0.00576949, acc 1
2016-09-05T18:04:39.502515: step 5060, loss 0.00611763, acc 1
2016-09-05T18:04:39.723311: step 5061, loss 0.00740019, acc 1
2016-09-05T18:04:39.948432: step 5062, loss 0.00641761, acc 1
2016-09-05T18:04:40.184580: step 5063, loss 0.00655609, acc 1
2016-09-05T18:04:40.372465: step 5064, loss 0.00640006, acc 1
2016-09-05T18:04:40.599524: step 5065, loss 0.00527705, acc 1
2016-09-05T18:04:40.802290: step 5066, loss 0.00626851, acc 1
2016-09-05T18:04:41.014760: step 5067, loss 0.00582648, acc 1
2016-09-05T18:04:41.231959: step 5068, loss 0.00618185, acc 1
2016-09-05T18:04:41.455480: step 5069, loss 0.00526203, acc 1
2016-09-05T18:04:41.682626: step 5070, loss 0.00617442, acc 1
2016-09-05T18:04:41.924105: step 5071, loss 0.0060807, acc 1
2016-09-05T18:04:42.136038: step 5072, loss 0.00619721, acc 1
2016-09-05T18:04:42.338337: step 5073, loss 0.00635753, acc 1
2016-09-05T18:04:42.546498: step 5074, loss 0.00784026, acc 1
2016-09-05T18:04:42.784309: step 5075, loss 0.00510496, acc 1
2016-09-05T18:04:43.002175: step 5076, loss 0.00650365, acc 1
2016-09-05T18:04:43.245056: step 5077, loss 0.00696644, acc 1
2016-09-05T18:04:43.446426: step 5078, loss 0.00549926, acc 1
2016-09-05T18:04:43.656700: step 5079, loss 0.00854721, acc 1
2016-09-05T18:04:43.897715: step 5080, loss 0.00571001, acc 1
2016-09-05T18:04:44.132018: step 5081, loss 0.0071651, acc 1
2016-09-05T18:04:44.348890: step 5082, loss 0.00581667, acc 1
2016-09-05T18:04:44.558379: step 5083, loss 0.00565669, acc 1
2016-09-05T18:04:44.772549: step 5084, loss 0.00617784, acc 1
2016-09-05T18:04:44.980507: step 5085, loss 0.0105224, acc 1
2016-09-05T18:04:45.203277: step 5086, loss 0.00556225, acc 1
2016-09-05T18:04:45.437724: step 5087, loss 0.00584913, acc 1
2016-09-05T18:04:45.648969: step 5088, loss 0.00722739, acc 1
2016-09-05T18:04:45.855765: step 5089, loss 0.00704545, acc 1
2016-09-05T18:04:46.069782: step 5090, loss 0.00772905, acc 1
2016-09-05T18:04:46.287055: step 5091, loss 0.00525928, acc 1
2016-09-05T18:04:46.489533: step 5092, loss 0.00558806, acc 1
2016-09-05T18:04:46.741400: step 5093, loss 0.00548248, acc 1
2016-09-05T18:04:46.966986: step 5094, loss 0.0094156, acc 1
2016-09-05T18:04:47.179866: step 5095, loss 0.00694653, acc 1
2016-09-05T18:04:47.428462: step 5096, loss 0.00591551, acc 1
2016-09-05T18:04:47.679696: step 5097, loss 0.00740206, acc 1
2016-09-05T18:04:47.907412: step 5098, loss 0.00735611, acc 1
2016-09-05T18:04:48.105705: step 5099, loss 0.00665207, acc 1
2016-09-05T18:04:48.316277: step 5100, loss 0.00777417, acc 1

Evaluation:
2016-09-05T18:04:48.938428: step 5100, loss 1.0801, acc 0.744

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-5100

2016-09-05T18:04:49.666138: step 5101, loss 0.00530429, acc 1
2016-09-05T18:04:49.917797: step 5102, loss 0.00542855, acc 1
2016-09-05T18:04:50.139699: step 5103, loss 0.00562512, acc 1
2016-09-05T18:04:50.354528: step 5104, loss 0.00689835, acc 1
2016-09-05T18:04:50.570943: step 5105, loss 0.00652002, acc 1
2016-09-05T18:04:50.793274: step 5106, loss 0.00729778, acc 1
2016-09-05T18:04:51.005551: step 5107, loss 0.00531542, acc 1
2016-09-05T18:04:51.227347: step 5108, loss 0.00545, acc 1
2016-09-05T18:04:51.431983: step 5109, loss 0.00588878, acc 1
2016-09-05T18:04:51.666011: step 5110, loss 0.00558406, acc 1
2016-09-05T18:04:51.893045: step 5111, loss 0.00580166, acc 1
2016-09-05T18:04:52.130209: step 5112, loss 0.00677052, acc 1
2016-09-05T18:04:52.334706: step 5113, loss 0.00542511, acc 1
2016-09-05T18:04:52.536326: step 5114, loss 0.00766365, acc 1
2016-09-05T18:04:52.762462: step 5115, loss 0.00705003, acc 1
2016-09-05T18:04:52.966622: step 5116, loss 0.00674572, acc 1
2016-09-05T18:04:53.170127: step 5117, loss 0.00644596, acc 1
2016-09-05T18:04:53.385341: step 5118, loss 0.00844321, acc 1
2016-09-05T18:04:53.603667: step 5119, loss 0.00600173, acc 1
2016-09-05T18:04:53.829397: step 5120, loss 0.00836567, acc 1
2016-09-05T18:04:54.019253: step 5121, loss 0.0055522, acc 1
2016-09-05T18:04:54.218577: step 5122, loss 0.00532395, acc 1
2016-09-05T18:04:54.453161: step 5123, loss 0.00574672, acc 1
2016-09-05T18:04:54.678397: step 5124, loss 0.00521616, acc 1
2016-09-05T18:04:54.886492: step 5125, loss 0.0101039, acc 1
2016-09-05T18:04:55.109355: step 5126, loss 0.00679276, acc 1
2016-09-05T18:04:55.339076: step 5127, loss 0.00572675, acc 1
2016-09-05T18:04:55.556668: step 5128, loss 0.00523561, acc 1
2016-09-05T18:04:55.770327: step 5129, loss 0.0116807, acc 1
2016-09-05T18:04:55.983145: step 5130, loss 0.00555008, acc 1
2016-09-05T18:04:56.187553: step 5131, loss 0.00672884, acc 1
2016-09-05T18:04:56.437912: step 5132, loss 0.00672465, acc 1
2016-09-05T18:04:56.659940: step 5133, loss 0.00664774, acc 1
2016-09-05T18:04:56.869961: step 5134, loss 0.00727922, acc 1
2016-09-05T18:04:57.071982: step 5135, loss 0.00675103, acc 1
2016-09-05T18:04:57.290145: step 5136, loss 0.0127583, acc 1
2016-09-05T18:04:57.510854: step 5137, loss 0.00567917, acc 1
2016-09-05T18:04:57.741681: step 5138, loss 0.00584028, acc 1
2016-09-05T18:04:57.965773: step 5139, loss 0.00603549, acc 1
2016-09-05T18:04:58.188753: step 5140, loss 0.00716139, acc 1
2016-09-05T18:04:58.392557: step 5141, loss 0.00863398, acc 1
2016-09-05T18:04:58.594251: step 5142, loss 0.00688532, acc 1
2016-09-05T18:04:58.803963: step 5143, loss 0.00668369, acc 1
2016-09-05T18:04:59.017338: step 5144, loss 0.0124571, acc 1
2016-09-05T18:04:59.221426: step 5145, loss 0.00744023, acc 1
2016-09-05T18:04:59.419505: step 5146, loss 0.00680173, acc 1
2016-09-05T18:04:59.651454: step 5147, loss 0.00609222, acc 1
2016-09-05T18:04:59.852911: step 5148, loss 0.00820812, acc 1
2016-09-05T18:05:00.101724: step 5149, loss 0.00755341, acc 1
2016-09-05T18:05:00.316741: step 5150, loss 0.00598518, acc 1
2016-09-05T18:05:00.521997: step 5151, loss 0.00668918, acc 1
2016-09-05T18:05:00.743947: step 5152, loss 0.00865834, acc 1
2016-09-05T18:05:00.983129: step 5153, loss 0.00859656, acc 1
2016-09-05T18:05:01.211515: step 5154, loss 0.00745576, acc 1
2016-09-05T18:05:01.415476: step 5155, loss 0.00944045, acc 1
2016-09-05T18:05:01.628406: step 5156, loss 0.00670371, acc 1
2016-09-05T18:05:01.856707: step 5157, loss 0.00632463, acc 1
2016-09-05T18:05:02.081887: step 5158, loss 0.00706727, acc 1
2016-09-05T18:05:02.290176: step 5159, loss 0.00608881, acc 1
2016-09-05T18:05:02.520175: step 5160, loss 0.00796733, acc 1
2016-09-05T18:05:02.733803: step 5161, loss 0.00777188, acc 1
2016-09-05T18:05:02.938943: step 5162, loss 0.00624335, acc 1
2016-09-05T18:05:03.157300: step 5163, loss 0.00701035, acc 1
2016-09-05T18:05:03.383969: step 5164, loss 0.00683282, acc 1
2016-09-05T18:05:03.585745: step 5165, loss 0.00667219, acc 1
2016-09-05T18:05:03.828668: step 5166, loss 0.0064533, acc 1
2016-09-05T18:05:04.043016: step 5167, loss 0.00732071, acc 1
2016-09-05T18:05:04.254172: step 5168, loss 0.00709015, acc 1
2016-09-05T18:05:04.475817: step 5169, loss 0.00618046, acc 1
2016-09-05T18:05:04.725498: step 5170, loss 0.00640227, acc 1
2016-09-05T18:05:04.944538: step 5171, loss 0.0058923, acc 1
2016-09-05T18:05:05.151269: step 5172, loss 0.00749249, acc 1
2016-09-05T18:05:05.366963: step 5173, loss 0.0083855, acc 1
2016-09-05T18:05:05.585119: step 5174, loss 0.00619271, acc 1
2016-09-05T18:05:05.813775: step 5175, loss 0.00671026, acc 1
2016-09-05T18:05:06.023254: step 5176, loss 0.00638992, acc 1
2016-09-05T18:05:06.231165: step 5177, loss 0.00587087, acc 1
2016-09-05T18:05:06.447832: step 5178, loss 0.00676662, acc 1
2016-09-05T18:05:06.661129: step 5179, loss 0.00918701, acc 1
2016-09-05T18:05:06.877328: step 5180, loss 0.0062007, acc 1
2016-09-05T18:05:07.074324: step 5181, loss 0.00565904, acc 1
2016-09-05T18:05:07.301696: step 5182, loss 0.00749665, acc 1
2016-09-05T18:05:07.524209: step 5183, loss 0.00609985, acc 1
2016-09-05T18:05:07.753400: step 5184, loss 0.0065652, acc 1
2016-09-05T18:05:07.992852: step 5185, loss 0.00650064, acc 1
2016-09-05T18:05:08.213311: step 5186, loss 0.00918714, acc 1
2016-09-05T18:05:08.422188: step 5187, loss 0.0060897, acc 1
2016-09-05T18:05:08.654715: step 5188, loss 0.00654428, acc 1
2016-09-05T18:05:08.885422: step 5189, loss 0.00691581, acc 1
2016-09-05T18:05:09.096132: step 5190, loss 0.00579366, acc 1
2016-09-05T18:05:09.308976: step 5191, loss 0.0100354, acc 1
2016-09-05T18:05:09.504672: step 5192, loss 0.00658898, acc 1
2016-09-05T18:05:09.716316: step 5193, loss 0.0070619, acc 1
2016-09-05T18:05:09.919315: step 5194, loss 0.00589731, acc 1
2016-09-05T18:05:10.121285: step 5195, loss 0.00703089, acc 1
2016-09-05T18:05:10.343375: step 5196, loss 0.00674815, acc 1
2016-09-05T18:05:10.565346: step 5197, loss 0.00610659, acc 1
2016-09-05T18:05:10.788589: step 5198, loss 0.00563143, acc 1
2016-09-05T18:05:11.042849: step 5199, loss 0.00689259, acc 1
2016-09-05T18:05:11.247166: step 5200, loss 0.00649245, acc 1

Evaluation:
2016-09-05T18:05:11.860534: step 5200, loss 1.0749, acc 0.74

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-5200

2016-09-05T18:05:12.550148: step 5201, loss 0.00569776, acc 1
2016-09-05T18:05:12.764040: step 5202, loss 0.00731331, acc 1
2016-09-05T18:05:12.978472: step 5203, loss 0.0104549, acc 1
2016-09-05T18:05:13.209613: step 5204, loss 0.00616892, acc 1
2016-09-05T18:05:13.446893: step 5205, loss 0.0072427, acc 1
2016-09-05T18:05:13.659675: step 5206, loss 0.00608389, acc 1
2016-09-05T18:05:13.877702: step 5207, loss 0.00689822, acc 1
2016-09-05T18:05:14.088204: step 5208, loss 0.00560337, acc 1
2016-09-05T18:05:14.308332: step 5209, loss 0.00937597, acc 1
2016-09-05T18:05:14.532992: step 5210, loss 0.00614381, acc 1
2016-09-05T18:05:14.773284: step 5211, loss 0.00586049, acc 1
2016-09-05T18:05:14.982712: step 5212, loss 0.00650213, acc 1
2016-09-05T18:05:15.227230: step 5213, loss 0.00625176, acc 1
2016-09-05T18:05:15.479846: step 5214, loss 0.00767421, acc 1
2016-09-05T18:05:15.682568: step 5215, loss 0.00608514, acc 1
2016-09-05T18:05:15.893802: step 5216, loss 0.00720327, acc 1
2016-09-05T18:05:16.102181: step 5217, loss 0.00667189, acc 1
2016-09-05T18:05:16.323103: step 5218, loss 0.00590437, acc 1
2016-09-05T18:05:16.530278: step 5219, loss 0.00575683, acc 1
2016-09-05T18:05:16.771187: step 5220, loss 0.0109175, acc 1
2016-09-05T18:05:16.987653: step 5221, loss 0.00618454, acc 1
2016-09-05T18:05:17.205331: step 5222, loss 0.00625433, acc 1
2016-09-05T18:05:17.418610: step 5223, loss 0.0071731, acc 1
2016-09-05T18:05:17.642865: step 5224, loss 0.00823958, acc 1
2016-09-05T18:05:17.858318: step 5225, loss 0.0079178, acc 1
2016-09-05T18:05:18.058742: step 5226, loss 0.00823496, acc 1
2016-09-05T18:05:18.303317: step 5227, loss 0.00635214, acc 1
2016-09-05T18:05:18.504727: step 5228, loss 0.00545901, acc 1
2016-09-05T18:05:18.711660: step 5229, loss 0.00586556, acc 1
2016-09-05T18:05:18.923605: step 5230, loss 0.00572129, acc 1
2016-09-05T18:05:19.145471: step 5231, loss 0.00681537, acc 1
2016-09-05T18:05:19.352308: step 5232, loss 0.00658627, acc 1
2016-09-05T18:05:19.576318: step 5233, loss 0.00632335, acc 1
2016-09-05T18:05:19.797457: step 5234, loss 0.00862946, acc 1
2016-09-05T18:05:20.018573: step 5235, loss 0.0117857, acc 1
2016-09-05T18:05:20.225723: step 5236, loss 0.0059323, acc 1
2016-09-05T18:05:20.458572: step 5237, loss 0.00733478, acc 1
2016-09-05T18:05:20.656459: step 5238, loss 0.00536767, acc 1
2016-09-05T18:05:20.897698: step 5239, loss 0.00543754, acc 1
2016-09-05T18:05:21.126211: step 5240, loss 0.005459, acc 1
2016-09-05T18:05:21.347039: step 5241, loss 0.00533416, acc 1
2016-09-05T18:05:21.597665: step 5242, loss 0.00603052, acc 1
2016-09-05T18:05:21.840748: step 5243, loss 0.00540949, acc 1
2016-09-05T18:05:22.057899: step 5244, loss 0.00723401, acc 1
2016-09-05T18:05:22.268102: step 5245, loss 0.00659929, acc 1
2016-09-05T18:05:22.494207: step 5246, loss 0.00571208, acc 1
2016-09-05T18:05:22.736307: step 5247, loss 0.00600433, acc 1
2016-09-05T18:05:22.940559: step 5248, loss 0.00592582, acc 1
2016-09-05T18:05:23.158762: step 5249, loss 0.00592057, acc 1
2016-09-05T18:05:23.366802: step 5250, loss 0.00626396, acc 1
2016-09-05T18:05:23.574080: step 5251, loss 0.00579398, acc 1
2016-09-05T18:05:23.776614: step 5252, loss 0.00547181, acc 1
2016-09-05T18:05:23.992015: step 5253, loss 0.00727956, acc 1
2016-09-05T18:05:24.209512: step 5254, loss 0.00604055, acc 1
2016-09-05T18:05:24.448196: step 5255, loss 0.00678417, acc 1
2016-09-05T18:05:24.660042: step 5256, loss 0.00567385, acc 1
2016-09-05T18:05:24.876258: step 5257, loss 0.00580727, acc 1
2016-09-05T18:05:25.092636: step 5258, loss 0.00548159, acc 1
2016-09-05T18:05:25.327050: step 5259, loss 0.00616243, acc 1
2016-09-05T18:05:25.562634: step 5260, loss 0.0051358, acc 1
2016-09-05T18:05:25.761922: step 5261, loss 0.00548673, acc 1
2016-09-05T18:05:25.972725: step 5262, loss 0.00692016, acc 1
2016-09-05T18:05:26.197163: step 5263, loss 0.00586445, acc 1
2016-09-05T18:05:26.423142: step 5264, loss 0.00581598, acc 1
2016-09-05T18:05:26.651753: step 5265, loss 0.0053986, acc 1
2016-09-05T18:05:26.882139: step 5266, loss 0.00536394, acc 1
2016-09-05T18:05:27.081891: step 5267, loss 0.0065895, acc 1
2016-09-05T18:05:27.291169: step 5268, loss 0.00557823, acc 1
2016-09-05T18:05:27.489494: step 5269, loss 0.00584031, acc 1
2016-09-05T18:05:27.732229: step 5270, loss 0.00593319, acc 1
2016-09-05T18:05:27.992932: step 5271, loss 0.00612706, acc 1
2016-09-05T18:05:28.195943: step 5272, loss 0.00597315, acc 1
2016-09-05T18:05:28.408382: step 5273, loss 0.00829514, acc 1
2016-09-05T18:05:28.626977: step 5274, loss 0.00527713, acc 1
2016-09-05T18:05:28.892373: step 5275, loss 0.0066893, acc 1
2016-09-05T18:05:29.111744: step 5276, loss 0.00517121, acc 1
2016-09-05T18:05:29.358627: step 5277, loss 0.00667463, acc 1
2016-09-05T18:05:29.571038: step 5278, loss 0.0055014, acc 1
2016-09-05T18:05:29.801987: step 5279, loss 0.00501372, acc 1
2016-09-05T18:05:30.024345: step 5280, loss 0.00609356, acc 1
2016-09-05T18:05:30.227402: step 5281, loss 0.0053544, acc 1
2016-09-05T18:05:30.445766: step 5282, loss 0.00568826, acc 1
2016-09-05T18:05:30.678791: step 5283, loss 0.00753782, acc 1
2016-09-05T18:05:30.909848: step 5284, loss 0.00575078, acc 1
2016-09-05T18:05:31.128353: step 5285, loss 0.00615611, acc 1
2016-09-05T18:05:31.382274: step 5286, loss 0.00570285, acc 1
2016-09-05T18:05:31.629655: step 5287, loss 0.00839304, acc 1
2016-09-05T18:05:31.844775: step 5288, loss 0.00649155, acc 1
2016-09-05T18:05:32.068478: step 5289, loss 0.00498182, acc 1
2016-09-05T18:05:32.279230: step 5290, loss 0.00566325, acc 1
2016-09-05T18:05:32.524356: step 5291, loss 0.00586219, acc 1
2016-09-05T18:05:32.730576: step 5292, loss 0.00673859, acc 1
2016-09-05T18:05:32.952899: step 5293, loss 0.00483731, acc 1
2016-09-05T18:05:33.164335: step 5294, loss 0.00593151, acc 1
2016-09-05T18:05:33.393464: step 5295, loss 0.00565224, acc 1
2016-09-05T18:05:33.626599: step 5296, loss 0.0053455, acc 1
2016-09-05T18:05:33.821463: step 5297, loss 0.00604257, acc 1
2016-09-05T18:05:34.042551: step 5298, loss 0.0117507, acc 1
2016-09-05T18:05:34.243567: step 5299, loss 0.00542957, acc 1
2016-09-05T18:05:34.446577: step 5300, loss 0.00710164, acc 1

Evaluation:
2016-09-05T18:05:35.041648: step 5300, loss 1.08522, acc 0.744

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-5300

2016-09-05T18:05:35.757400: step 5301, loss 0.00666889, acc 1
2016-09-05T18:05:35.977456: step 5302, loss 0.00557129, acc 1
2016-09-05T18:05:36.208460: step 5303, loss 0.00727475, acc 1
2016-09-05T18:05:36.407542: step 5304, loss 0.00568941, acc 1
2016-09-05T18:05:36.629821: step 5305, loss 0.0059875, acc 1
2016-09-05T18:05:36.861301: step 5306, loss 0.00565038, acc 1
2016-09-05T18:05:37.078980: step 5307, loss 0.00524183, acc 1
2016-09-05T18:05:37.293299: step 5308, loss 0.00603396, acc 1
2016-09-05T18:05:37.505317: step 5309, loss 0.00788556, acc 1
2016-09-05T18:05:37.730963: step 5310, loss 0.00694873, acc 1
2016-09-05T18:05:37.944255: step 5311, loss 0.00523717, acc 1
2016-09-05T18:05:38.173392: step 5312, loss 0.00557747, acc 1
2016-09-05T18:05:38.389256: step 5313, loss 0.00571095, acc 1
2016-09-05T18:05:38.603203: step 5314, loss 0.00499016, acc 1
2016-09-05T18:05:38.808951: step 5315, loss 0.005522, acc 1
2016-09-05T18:05:39.016888: step 5316, loss 0.00665664, acc 1
2016-09-05T18:05:39.237537: step 5317, loss 0.00548082, acc 1
2016-09-05T18:05:39.433902: step 5318, loss 0.00595248, acc 1
2016-09-05T18:05:39.656830: step 5319, loss 0.00661209, acc 1
2016-09-05T18:05:39.863671: step 5320, loss 0.00622793, acc 1
2016-09-05T18:05:40.101612: step 5321, loss 0.00564498, acc 1
2016-09-05T18:05:40.299495: step 5322, loss 0.00528352, acc 1
2016-09-05T18:05:40.517317: step 5323, loss 0.0062487, acc 1
2016-09-05T18:05:40.740739: step 5324, loss 0.00511499, acc 1
2016-09-05T18:05:40.975150: step 5325, loss 0.00576529, acc 1
2016-09-05T18:05:41.217187: step 5326, loss 0.00573422, acc 1
2016-09-05T18:05:41.477498: step 5327, loss 0.00530085, acc 1
2016-09-05T18:05:41.710573: step 5328, loss 0.00583311, acc 1
2016-09-05T18:05:41.931246: step 5329, loss 0.00552842, acc 1
2016-09-05T18:05:42.186063: step 5330, loss 0.0051033, acc 1
2016-09-05T18:05:42.412284: step 5331, loss 0.00624954, acc 1
2016-09-05T18:05:42.615874: step 5332, loss 0.00610069, acc 1
2016-09-05T18:05:42.817763: step 5333, loss 0.00616779, acc 1
2016-09-05T18:05:43.030459: step 5334, loss 0.00553615, acc 1
2016-09-05T18:05:43.244621: step 5335, loss 0.00586657, acc 1
2016-09-05T18:05:43.473498: step 5336, loss 0.00532672, acc 1
2016-09-05T18:05:43.685436: step 5337, loss 0.00765578, acc 1
2016-09-05T18:05:43.909091: step 5338, loss 0.0060646, acc 1
2016-09-05T18:05:44.135255: step 5339, loss 0.00543739, acc 1
2016-09-05T18:05:44.341285: step 5340, loss 0.0064639, acc 1
2016-09-05T18:05:44.546143: step 5341, loss 0.0053774, acc 1
2016-09-05T18:05:44.753546: step 5342, loss 0.00609541, acc 1
2016-09-05T18:05:44.971975: step 5343, loss 0.00572686, acc 1
2016-09-05T18:05:45.203957: step 5344, loss 0.00478912, acc 1
2016-09-05T18:05:45.445456: step 5345, loss 0.00717117, acc 1
2016-09-05T18:05:45.669284: step 5346, loss 0.0050221, acc 1
2016-09-05T18:05:45.920843: step 5347, loss 0.00533948, acc 1
2016-09-05T18:05:46.166018: step 5348, loss 0.00594675, acc 1
2016-09-05T18:05:46.368353: step 5349, loss 0.00790494, acc 1
2016-09-05T18:05:46.572802: step 5350, loss 0.00673479, acc 1
2016-09-05T18:05:46.826510: step 5351, loss 0.00506896, acc 1
2016-09-05T18:05:47.063552: step 5352, loss 0.00501936, acc 1
2016-09-05T18:05:47.262158: step 5353, loss 0.00564398, acc 1
2016-09-05T18:05:47.466625: step 5354, loss 0.00544934, acc 1
2016-09-05T18:05:47.672858: step 5355, loss 0.00875059, acc 1
2016-09-05T18:05:47.875894: step 5356, loss 0.00611225, acc 1
2016-09-05T18:05:48.074258: step 5357, loss 0.00723682, acc 1
2016-09-05T18:05:48.298348: step 5358, loss 0.00567125, acc 1
2016-09-05T18:05:48.524590: step 5359, loss 0.00506805, acc 1
2016-09-05T18:05:48.735629: step 5360, loss 0.00528896, acc 1
2016-09-05T18:05:48.970249: step 5361, loss 0.00482376, acc 1
2016-09-05T18:05:49.180450: step 5362, loss 0.00500593, acc 1
2016-09-05T18:05:49.394178: step 5363, loss 0.00767863, acc 1
2016-09-05T18:05:49.594213: step 5364, loss 0.00492705, acc 1
2016-09-05T18:05:49.835233: step 5365, loss 0.00515074, acc 1
2016-09-05T18:05:50.051566: step 5366, loss 0.00575946, acc 1
2016-09-05T18:05:50.292626: step 5367, loss 0.00542926, acc 1
2016-09-05T18:05:50.507277: step 5368, loss 0.00879573, acc 1
2016-09-05T18:05:50.729009: step 5369, loss 0.00849718, acc 1
2016-09-05T18:05:50.942605: step 5370, loss 0.00540031, acc 1
2016-09-05T18:05:51.162454: step 5371, loss 0.0050558, acc 1
2016-09-05T18:05:51.368384: step 5372, loss 0.00633094, acc 1
2016-09-05T18:05:51.574303: step 5373, loss 0.00818037, acc 1
2016-09-05T18:05:51.792260: step 5374, loss 0.00537248, acc 1
2016-09-05T18:05:51.989439: step 5375, loss 0.00528939, acc 1
2016-09-05T18:05:52.203161: step 5376, loss 0.00615135, acc 1
2016-09-05T18:05:52.400703: step 5377, loss 0.00697241, acc 1
2016-09-05T18:05:52.610906: step 5378, loss 0.00520702, acc 1
2016-09-05T18:05:52.819681: step 5379, loss 0.00534619, acc 1
2016-09-05T18:05:53.026957: step 5380, loss 0.00542229, acc 1
2016-09-05T18:05:53.244336: step 5381, loss 0.00501147, acc 1
2016-09-05T18:05:53.476379: step 5382, loss 0.00565922, acc 1
2016-09-05T18:05:53.696536: step 5383, loss 0.0064855, acc 1
2016-09-05T18:05:53.896525: step 5384, loss 0.00537744, acc 1
2016-09-05T18:05:54.121799: step 5385, loss 0.00548003, acc 1
2016-09-05T18:05:54.354425: step 5386, loss 0.00817, acc 1
2016-09-05T18:05:54.582538: step 5387, loss 0.00574175, acc 1
2016-09-05T18:05:54.781355: step 5388, loss 0.00566414, acc 1
2016-09-05T18:05:55.000342: step 5389, loss 0.00651672, acc 1
2016-09-05T18:05:55.212749: step 5390, loss 0.00558488, acc 1
2016-09-05T18:05:55.408719: step 5391, loss 0.0057495, acc 1
2016-09-05T18:05:55.616438: step 5392, loss 0.00721122, acc 1
2016-09-05T18:05:55.851382: step 5393, loss 0.00690834, acc 1
2016-09-05T18:05:56.053981: step 5394, loss 0.00574799, acc 1
2016-09-05T18:05:56.293803: step 5395, loss 0.00540498, acc 1
2016-09-05T18:05:56.551635: step 5396, loss 0.00820166, acc 1
2016-09-05T18:05:56.778491: step 5397, loss 0.00606304, acc 1
2016-09-05T18:05:57.010351: step 5398, loss 0.00691093, acc 1
2016-09-05T18:05:57.251331: step 5399, loss 0.0051633, acc 1
2016-09-05T18:05:57.464270: step 5400, loss 0.00523786, acc 1

Evaluation:
2016-09-05T18:05:58.086809: step 5400, loss 1.07949, acc 0.742

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-5400

2016-09-05T18:05:58.870589: step 5401, loss 0.00616752, acc 1
2016-09-05T18:05:59.103624: step 5402, loss 0.00536504, acc 1
2016-09-05T18:05:59.308744: step 5403, loss 0.00575744, acc 1
2016-09-05T18:05:59.514973: step 5404, loss 0.00526339, acc 1
2016-09-05T18:05:59.715417: step 5405, loss 0.00569849, acc 1
2016-09-05T18:05:59.928513: step 5406, loss 0.00754036, acc 1
2016-09-05T18:06:00.146530: step 5407, loss 0.00702826, acc 1
2016-09-05T18:06:00.397908: step 5408, loss 0.00534896, acc 1
2016-09-05T18:06:00.602014: step 5409, loss 0.00881401, acc 1
2016-09-05T18:06:00.818942: step 5410, loss 0.00643896, acc 1
2016-09-05T18:06:01.027367: step 5411, loss 0.00898641, acc 1
2016-09-05T18:06:01.252629: step 5412, loss 0.00834071, acc 1
2016-09-05T18:06:01.486726: step 5413, loss 0.00490917, acc 1
2016-09-05T18:06:01.684226: step 5414, loss 0.00652165, acc 1
2016-09-05T18:06:01.906161: step 5415, loss 0.0057674, acc 1
2016-09-05T18:06:02.110183: step 5416, loss 0.00594865, acc 1
2016-09-05T18:06:02.316051: step 5417, loss 0.00605562, acc 1
2016-09-05T18:06:02.529146: step 5418, loss 0.00671876, acc 1
2016-09-05T18:06:02.757256: step 5419, loss 0.00596512, acc 1
2016-09-05T18:06:02.962148: step 5420, loss 0.00534594, acc 1
2016-09-05T18:06:03.202621: step 5421, loss 0.00510522, acc 1
2016-09-05T18:06:03.425691: step 5422, loss 0.00693374, acc 1
2016-09-05T18:06:03.640808: step 5423, loss 0.00532091, acc 1
2016-09-05T18:06:03.853660: step 5424, loss 0.00552889, acc 1
2016-09-05T18:06:04.083271: step 5425, loss 0.00741706, acc 1
2016-09-05T18:06:04.331663: step 5426, loss 0.0064238, acc 1
2016-09-05T18:06:04.532297: step 5427, loss 0.00602616, acc 1
2016-09-05T18:06:04.748306: step 5428, loss 0.00636379, acc 1
2016-09-05T18:06:04.954761: step 5429, loss 0.00671466, acc 1
2016-09-05T18:06:05.178253: step 5430, loss 0.00525794, acc 1
2016-09-05T18:06:05.395598: step 5431, loss 0.0062096, acc 1
2016-09-05T18:06:05.556536: step 5432, loss 0.006065, acc 1
2016-09-05T18:06:05.779391: step 5433, loss 0.00499549, acc 1
2016-09-05T18:06:05.989437: step 5434, loss 0.00644662, acc 1
2016-09-05T18:06:06.245495: step 5435, loss 0.00636054, acc 1
2016-09-05T18:06:06.461465: step 5436, loss 0.00488975, acc 1
2016-09-05T18:06:06.677384: step 5437, loss 0.00550317, acc 1
2016-09-05T18:06:06.894484: step 5438, loss 0.00557009, acc 1
2016-09-05T18:06:07.120213: step 5439, loss 0.00485925, acc 1
2016-09-05T18:06:07.330698: step 5440, loss 0.00505796, acc 1
2016-09-05T18:06:07.549662: step 5441, loss 0.0049748, acc 1
2016-09-05T18:06:07.758101: step 5442, loss 0.00472013, acc 1
2016-09-05T18:06:07.969502: step 5443, loss 0.00723611, acc 1
2016-09-05T18:06:08.168379: step 5444, loss 0.00639173, acc 1
2016-09-05T18:06:08.376839: step 5445, loss 0.00572321, acc 1
2016-09-05T18:06:08.571807: step 5446, loss 0.00509881, acc 1
2016-09-05T18:06:08.797843: step 5447, loss 0.00497891, acc 1
2016-09-05T18:06:09.010994: step 5448, loss 0.00577872, acc 1
2016-09-05T18:06:09.257385: step 5449, loss 0.00486478, acc 1
2016-09-05T18:06:09.461045: step 5450, loss 0.00714802, acc 1
2016-09-05T18:06:09.671355: step 5451, loss 0.00765405, acc 1
2016-09-05T18:06:09.880155: step 5452, loss 0.00664568, acc 1
2016-09-05T18:06:10.098228: step 5453, loss 0.0148985, acc 1
2016-09-05T18:06:10.327695: step 5454, loss 0.00555184, acc 1
2016-09-05T18:06:10.560499: step 5455, loss 0.0049358, acc 1
2016-09-05T18:06:10.773393: step 5456, loss 0.00610301, acc 1
2016-09-05T18:06:10.987275: step 5457, loss 0.00665582, acc 1
2016-09-05T18:06:11.198139: step 5458, loss 0.00763565, acc 1
2016-09-05T18:06:11.396864: step 5459, loss 0.00670516, acc 1
2016-09-05T18:06:11.606147: step 5460, loss 0.00838165, acc 1
2016-09-05T18:06:11.815720: step 5461, loss 0.00555753, acc 1
2016-09-05T18:06:12.036769: step 5462, loss 0.00687207, acc 1
2016-09-05T18:06:12.245215: step 5463, loss 0.00637852, acc 1
2016-09-05T18:06:12.484383: step 5464, loss 0.00519997, acc 1
2016-09-05T18:06:12.692357: step 5465, loss 0.00561891, acc 1
2016-09-05T18:06:12.900106: step 5466, loss 0.00583247, acc 1
2016-09-05T18:06:13.091277: step 5467, loss 0.00612274, acc 1
2016-09-05T18:06:13.299186: step 5468, loss 0.00966705, acc 1
2016-09-05T18:06:13.505149: step 5469, loss 0.0061953, acc 1
2016-09-05T18:06:13.728826: step 5470, loss 0.00583443, acc 1
2016-09-05T18:06:13.968213: step 5471, loss 0.00645162, acc 1
2016-09-05T18:06:14.178130: step 5472, loss 0.00586233, acc 1
2016-09-05T18:06:14.414949: step 5473, loss 0.00693381, acc 1
2016-09-05T18:06:14.629022: step 5474, loss 0.00624997, acc 1
2016-09-05T18:06:14.851878: step 5475, loss 0.00549921, acc 1
2016-09-05T18:06:15.075263: step 5476, loss 0.00642467, acc 1
2016-09-05T18:06:15.295156: step 5477, loss 0.00548056, acc 1
2016-09-05T18:06:15.531628: step 5478, loss 0.00665373, acc 1
2016-09-05T18:06:15.753560: step 5479, loss 0.00844482, acc 1
2016-09-05T18:06:15.995652: step 5480, loss 0.00543742, acc 1
2016-09-05T18:06:16.233677: step 5481, loss 0.00607074, acc 1
2016-09-05T18:06:16.448485: step 5482, loss 0.00533647, acc 1
2016-09-05T18:06:16.654946: step 5483, loss 0.00521123, acc 1
2016-09-05T18:06:16.898256: step 5484, loss 0.00606824, acc 1
2016-09-05T18:06:17.113811: step 5485, loss 0.00526251, acc 1
2016-09-05T18:06:17.351293: step 5486, loss 0.00555178, acc 1
2016-09-05T18:06:17.556887: step 5487, loss 0.00522578, acc 1
2016-09-05T18:06:17.771394: step 5488, loss 0.00562308, acc 1
2016-09-05T18:06:17.981098: step 5489, loss 0.00581255, acc 1
2016-09-05T18:06:18.189771: step 5490, loss 0.00600128, acc 1
2016-09-05T18:06:18.431841: step 5491, loss 0.00626965, acc 1
2016-09-05T18:06:18.636057: step 5492, loss 0.00622387, acc 1
2016-09-05T18:06:18.879685: step 5493, loss 0.00653711, acc 1
2016-09-05T18:06:19.121531: step 5494, loss 0.00547648, acc 1
2016-09-05T18:06:19.336622: step 5495, loss 0.00557502, acc 1
2016-09-05T18:06:19.563721: step 5496, loss 0.0066784, acc 1
2016-09-05T18:06:19.786151: step 5497, loss 0.00923185, acc 1
2016-09-05T18:06:19.991147: step 5498, loss 0.0051254, acc 1
2016-09-05T18:06:20.219106: step 5499, loss 0.00616387, acc 1
2016-09-05T18:06:20.425297: step 5500, loss 0.00567195, acc 1

Evaluation:
2016-09-05T18:06:21.030676: step 5500, loss 1.07095, acc 0.742

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-5500

2016-09-05T18:06:21.777441: step 5501, loss 0.00526001, acc 1
2016-09-05T18:06:22.005748: step 5502, loss 0.00564547, acc 1
2016-09-05T18:06:22.219790: step 5503, loss 0.00503882, acc 1
2016-09-05T18:06:22.438672: step 5504, loss 0.00619457, acc 1
2016-09-05T18:06:22.671257: step 5505, loss 0.00587645, acc 1
2016-09-05T18:06:22.880415: step 5506, loss 0.00615489, acc 1
2016-09-05T18:06:23.104616: step 5507, loss 0.00496971, acc 1
2016-09-05T18:06:23.332651: step 5508, loss 0.00534537, acc 1
2016-09-05T18:06:23.536874: step 5509, loss 0.00759303, acc 1
2016-09-05T18:06:23.767204: step 5510, loss 0.00524273, acc 1
2016-09-05T18:06:23.987117: step 5511, loss 0.00514607, acc 1
2016-09-05T18:06:24.189528: step 5512, loss 0.005802, acc 1
2016-09-05T18:06:24.427609: step 5513, loss 0.0045721, acc 1
2016-09-05T18:06:24.646365: step 5514, loss 0.00537104, acc 1
2016-09-05T18:06:24.858166: step 5515, loss 0.0045478, acc 1
2016-09-05T18:06:25.137317: step 5516, loss 0.00487769, acc 1
2016-09-05T18:06:25.347263: step 5517, loss 0.00562584, acc 1
2016-09-05T18:06:25.560769: step 5518, loss 0.00484446, acc 1
2016-09-05T18:06:25.794638: step 5519, loss 0.00595424, acc 1
2016-09-05T18:06:26.020975: step 5520, loss 0.00580995, acc 1
2016-09-05T18:06:26.257291: step 5521, loss 0.00526293, acc 1
2016-09-05T18:06:26.459348: step 5522, loss 0.00482147, acc 1
2016-09-05T18:06:26.668164: step 5523, loss 0.00583871, acc 1
2016-09-05T18:06:26.888019: step 5524, loss 0.00471516, acc 1
2016-09-05T18:06:27.114623: step 5525, loss 0.00542795, acc 1
2016-09-05T18:06:27.330799: step 5526, loss 0.00552719, acc 1
2016-09-05T18:06:27.538595: step 5527, loss 0.00556674, acc 1
2016-09-05T18:06:27.765002: step 5528, loss 0.00618448, acc 1
2016-09-05T18:06:27.970825: step 5529, loss 0.00532822, acc 1
2016-09-05T18:06:28.192968: step 5530, loss 0.00530573, acc 1
2016-09-05T18:06:28.400025: step 5531, loss 0.00598995, acc 1
2016-09-05T18:06:28.629484: step 5532, loss 0.00728526, acc 1
2016-09-05T18:06:28.865464: step 5533, loss 0.00470669, acc 1
2016-09-05T18:06:29.091367: step 5534, loss 0.00528848, acc 1
2016-09-05T18:06:29.314388: step 5535, loss 0.00682227, acc 1
2016-09-05T18:06:29.558997: step 5536, loss 0.00982436, acc 1
2016-09-05T18:06:29.792224: step 5537, loss 0.00449417, acc 1
2016-09-05T18:06:29.990901: step 5538, loss 0.00502095, acc 1
2016-09-05T18:06:30.197785: step 5539, loss 0.00687461, acc 1
2016-09-05T18:06:30.410833: step 5540, loss 0.00722748, acc 1
2016-09-05T18:06:30.619597: step 5541, loss 0.00751912, acc 1
2016-09-05T18:06:30.830021: step 5542, loss 0.00576533, acc 1
2016-09-05T18:06:31.062315: step 5543, loss 0.00532341, acc 1
2016-09-05T18:06:31.271718: step 5544, loss 0.00560524, acc 1
2016-09-05T18:06:31.510887: step 5545, loss 0.00538188, acc 1
2016-09-05T18:06:31.722413: step 5546, loss 0.00511253, acc 1
2016-09-05T18:06:31.952910: step 5547, loss 0.00538394, acc 1
2016-09-05T18:06:32.165140: step 5548, loss 0.00617255, acc 1
2016-09-05T18:06:32.362853: step 5549, loss 0.00595859, acc 1
2016-09-05T18:06:32.571583: step 5550, loss 0.00524789, acc 1
2016-09-05T18:06:32.786340: step 5551, loss 0.00560139, acc 1
2016-09-05T18:06:33.013448: step 5552, loss 0.00956448, acc 1
2016-09-05T18:06:33.208040: step 5553, loss 0.00557978, acc 1
2016-09-05T18:06:33.424636: step 5554, loss 0.00646214, acc 1
2016-09-05T18:06:33.630116: step 5555, loss 0.0053469, acc 1
2016-09-05T18:06:33.837999: step 5556, loss 0.0049661, acc 1
2016-09-05T18:06:34.048172: step 5557, loss 0.00713666, acc 1
2016-09-05T18:06:34.264662: step 5558, loss 0.0204786, acc 1
2016-09-05T18:06:34.476235: step 5559, loss 0.00513854, acc 1
2016-09-05T18:06:34.708912: step 5560, loss 0.00585226, acc 1
2016-09-05T18:06:34.932682: step 5561, loss 0.00662184, acc 1
2016-09-05T18:06:35.142634: step 5562, loss 0.0075513, acc 1
2016-09-05T18:06:35.356041: step 5563, loss 0.00558085, acc 1
2016-09-05T18:06:35.590287: step 5564, loss 0.00667498, acc 1
2016-09-05T18:06:35.806850: step 5565, loss 0.00694467, acc 1
2016-09-05T18:06:36.018105: step 5566, loss 0.00747894, acc 1
2016-09-05T18:06:36.220485: step 5567, loss 0.00603915, acc 1
2016-09-05T18:06:36.452386: step 5568, loss 0.0132922, acc 1
2016-09-05T18:06:36.666306: step 5569, loss 0.00669211, acc 1
2016-09-05T18:06:36.870675: step 5570, loss 0.00736842, acc 1
2016-09-05T18:06:37.091272: step 5571, loss 0.00587984, acc 1
2016-09-05T18:06:37.299628: step 5572, loss 0.0127522, acc 1
2016-09-05T18:06:37.538269: step 5573, loss 0.0068133, acc 1
2016-09-05T18:06:37.738005: step 5574, loss 0.00699846, acc 1
2016-09-05T18:06:37.963655: step 5575, loss 0.00656599, acc 1
2016-09-05T18:06:38.169930: step 5576, loss 0.00627603, acc 1
2016-09-05T18:06:38.428023: step 5577, loss 0.00747721, acc 1
2016-09-05T18:06:38.640195: step 5578, loss 0.00730604, acc 1
2016-09-05T18:06:38.863449: step 5579, loss 0.00658959, acc 1
2016-09-05T18:06:39.073606: step 5580, loss 0.00638074, acc 1
2016-09-05T18:06:39.291195: step 5581, loss 0.00737908, acc 1
2016-09-05T18:06:39.523611: step 5582, loss 0.00909068, acc 1
2016-09-05T18:06:39.788119: step 5583, loss 0.00853701, acc 1
2016-09-05T18:06:40.018844: step 5584, loss 0.00613597, acc 1
2016-09-05T18:06:40.262481: step 5585, loss 0.00666564, acc 1
2016-09-05T18:06:40.476928: step 5586, loss 0.00631467, acc 1
2016-09-05T18:06:40.679707: step 5587, loss 0.00610203, acc 1
2016-09-05T18:06:40.889974: step 5588, loss 0.00643192, acc 1
2016-09-05T18:06:41.116500: step 5589, loss 0.0075073, acc 1
2016-09-05T18:06:41.352168: step 5590, loss 0.00696121, acc 1
2016-09-05T18:06:41.580707: step 5591, loss 0.00757955, acc 1
2016-09-05T18:06:41.762321: step 5592, loss 0.00581127, acc 1
2016-09-05T18:06:41.988393: step 5593, loss 0.00660148, acc 1
2016-09-05T18:06:42.188647: step 5594, loss 0.00630051, acc 1
2016-09-05T18:06:42.392920: step 5595, loss 0.00721367, acc 1
2016-09-05T18:06:42.592630: step 5596, loss 0.00594665, acc 1
2016-09-05T18:06:42.813646: step 5597, loss 0.00853099, acc 1
2016-09-05T18:06:43.023220: step 5598, loss 0.00697634, acc 1
2016-09-05T18:06:43.245339: step 5599, loss 0.00547288, acc 1
2016-09-05T18:06:43.450829: step 5600, loss 0.00609943, acc 1

Evaluation:
2016-09-05T18:06:44.044890: step 5600, loss 1.11733, acc 0.743

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-5600

2016-09-05T18:06:44.717757: step 5601, loss 0.00694158, acc 1
2016-09-05T18:06:44.927390: step 5602, loss 0.00615735, acc 1
2016-09-05T18:06:45.138258: step 5603, loss 0.00726277, acc 1
2016-09-05T18:06:45.376619: step 5604, loss 0.0056787, acc 1
2016-09-05T18:06:45.602083: step 5605, loss 0.00960529, acc 1
2016-09-05T18:06:45.840203: step 5606, loss 0.00824411, acc 1
2016-09-05T18:06:46.072485: step 5607, loss 0.00616399, acc 1
2016-09-05T18:06:46.297074: step 5608, loss 0.0116232, acc 1
2016-09-05T18:06:46.531650: step 5609, loss 0.00599763, acc 1
2016-09-05T18:06:46.744765: step 5610, loss 0.00611377, acc 1
2016-09-05T18:06:46.969803: step 5611, loss 0.00733294, acc 1
2016-09-05T18:06:47.196000: step 5612, loss 0.00755865, acc 1
2016-09-05T18:06:47.418116: step 5613, loss 0.0063019, acc 1
2016-09-05T18:06:47.654377: step 5614, loss 0.0082928, acc 1
2016-09-05T18:06:47.858043: step 5615, loss 0.00573631, acc 1
2016-09-05T18:06:48.066362: step 5616, loss 0.00615897, acc 1
2016-09-05T18:06:48.258153: step 5617, loss 0.00578653, acc 1
2016-09-05T18:06:48.463412: step 5618, loss 0.0057627, acc 1
2016-09-05T18:06:48.678374: step 5619, loss 0.00663522, acc 1
2016-09-05T18:06:48.921393: step 5620, loss 0.00540867, acc 1
2016-09-05T18:06:49.135257: step 5621, loss 0.00630283, acc 1
2016-09-05T18:06:49.360727: step 5622, loss 0.00586995, acc 1
2016-09-05T18:06:49.561818: step 5623, loss 0.00681372, acc 1
2016-09-05T18:06:49.768340: step 5624, loss 0.00724628, acc 1
2016-09-05T18:06:49.972904: step 5625, loss 0.00605453, acc 1
2016-09-05T18:06:50.112528: step 5626, loss 0.00541068, acc 1
2016-09-05T18:06:50.337524: step 5627, loss 0.00575698, acc 1
2016-09-05T18:06:50.564030: step 5628, loss 0.00549091, acc 1
2016-09-05T18:06:50.774812: step 5629, loss 0.00570086, acc 1
2016-09-05T18:06:50.981736: step 5630, loss 0.00541129, acc 1
2016-09-05T18:06:51.191838: step 5631, loss 0.00598369, acc 1
2016-09-05T18:06:51.417687: step 5632, loss 0.00556859, acc 1
2016-09-05T18:06:51.646905: step 5633, loss 0.00622643, acc 1
2016-09-05T18:06:51.882590: step 5634, loss 0.00588255, acc 1
2016-09-05T18:06:52.095132: step 5635, loss 0.00639525, acc 1
2016-09-05T18:06:52.291528: step 5636, loss 0.00537448, acc 1
2016-09-05T18:06:52.502692: step 5637, loss 0.00569163, acc 1
2016-09-05T18:06:52.700737: step 5638, loss 0.00543684, acc 1
2016-09-05T18:06:52.920663: step 5639, loss 0.00524191, acc 1
2016-09-05T18:06:53.125616: step 5640, loss 0.00548324, acc 1
2016-09-05T18:06:53.337148: step 5641, loss 0.00469355, acc 1
2016-09-05T18:06:53.559481: step 5642, loss 0.0050113, acc 1
2016-09-05T18:06:53.793710: step 5643, loss 0.00600245, acc 1
2016-09-05T18:06:53.994340: step 5644, loss 0.00605831, acc 1
2016-09-05T18:06:54.207138: step 5645, loss 0.00470024, acc 1
2016-09-05T18:06:54.421392: step 5646, loss 0.00606965, acc 1
2016-09-05T18:06:54.630884: step 5647, loss 0.00501458, acc 1
2016-09-05T18:06:54.866248: step 5648, loss 0.00637013, acc 1
2016-09-05T18:06:55.101612: step 5649, loss 0.00467577, acc 1
2016-09-05T18:06:55.319041: step 5650, loss 0.00474231, acc 1
2016-09-05T18:06:55.518234: step 5651, loss 0.00438623, acc 1
2016-09-05T18:06:55.721879: step 5652, loss 0.00464678, acc 1
2016-09-05T18:06:55.937824: step 5653, loss 0.00475428, acc 1
2016-09-05T18:06:56.205369: step 5654, loss 0.0057409, acc 1
2016-09-05T18:06:56.423011: step 5655, loss 0.00587273, acc 1
2016-09-05T18:06:56.639285: step 5656, loss 0.00545622, acc 1
2016-09-05T18:06:56.840331: step 5657, loss 0.00568936, acc 1
2016-09-05T18:06:57.039036: step 5658, loss 0.00687916, acc 1
2016-09-05T18:06:57.245464: step 5659, loss 0.00455934, acc 1
2016-09-05T18:06:57.465151: step 5660, loss 0.00588795, acc 1
2016-09-05T18:06:57.681777: step 5661, loss 0.00451025, acc 1
2016-09-05T18:06:57.917454: step 5662, loss 0.00485519, acc 1
2016-09-05T18:06:58.126460: step 5663, loss 0.00584313, acc 1
2016-09-05T18:06:58.346542: step 5664, loss 0.00488083, acc 1
2016-09-05T18:06:58.578759: step 5665, loss 0.00492876, acc 1
2016-09-05T18:06:58.779757: step 5666, loss 0.00531847, acc 1
2016-09-05T18:06:59.009406: step 5667, loss 0.00668232, acc 1
2016-09-05T18:06:59.224321: step 5668, loss 0.00601081, acc 1
2016-09-05T18:06:59.445182: step 5669, loss 0.00495347, acc 1
2016-09-05T18:06:59.649428: step 5670, loss 0.00478473, acc 1
2016-09-05T18:06:59.864460: step 5671, loss 0.0046081, acc 1
2016-09-05T18:07:00.078113: step 5672, loss 0.00598803, acc 1
2016-09-05T18:07:00.345380: step 5673, loss 0.00497838, acc 1
2016-09-05T18:07:00.545465: step 5674, loss 0.00632454, acc 1
2016-09-05T18:07:00.757273: step 5675, loss 0.00552739, acc 1
2016-09-05T18:07:00.969560: step 5676, loss 0.00549252, acc 1
2016-09-05T18:07:01.182322: step 5677, loss 0.00629715, acc 1
2016-09-05T18:07:01.408407: step 5678, loss 0.00467115, acc 1
2016-09-05T18:07:01.616464: step 5679, loss 0.0050167, acc 1
2016-09-05T18:07:01.831628: step 5680, loss 0.005161, acc 1
2016-09-05T18:07:02.056357: step 5681, loss 0.00519625, acc 1
2016-09-05T18:07:02.280049: step 5682, loss 0.0050144, acc 1
2016-09-05T18:07:02.485602: step 5683, loss 0.00498424, acc 1
2016-09-05T18:07:02.719587: step 5684, loss 0.00553134, acc 1
2016-09-05T18:07:02.942389: step 5685, loss 0.00600128, acc 1
2016-09-05T18:07:03.186359: step 5686, loss 0.00457591, acc 1
2016-09-05T18:07:03.412157: step 5687, loss 0.00518654, acc 1
2016-09-05T18:07:03.621499: step 5688, loss 0.00635799, acc 1
2016-09-05T18:07:03.859617: step 5689, loss 0.00453554, acc 1
2016-09-05T18:07:04.095755: step 5690, loss 0.00569936, acc 1
2016-09-05T18:07:04.308695: step 5691, loss 0.00785822, acc 1
2016-09-05T18:07:04.530794: step 5692, loss 0.00443893, acc 1
2016-09-05T18:07:04.794003: step 5693, loss 0.00443555, acc 1
2016-09-05T18:07:05.017845: step 5694, loss 0.00536912, acc 1
2016-09-05T18:07:05.209684: step 5695, loss 0.00624912, acc 1
2016-09-05T18:07:05.418856: step 5696, loss 0.00456344, acc 1
2016-09-05T18:07:05.625645: step 5697, loss 0.00440889, acc 1
2016-09-05T18:07:05.870562: step 5698, loss 0.00818441, acc 1
2016-09-05T18:07:06.105026: step 5699, loss 0.00608672, acc 1
2016-09-05T18:07:06.319087: step 5700, loss 0.00530669, acc 1

Evaluation:
2016-09-05T18:07:06.946096: step 5700, loss 1.10056, acc 0.74

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-5700

2016-09-05T18:07:07.655302: step 5701, loss 0.00516074, acc 1
2016-09-05T18:07:07.878069: step 5702, loss 0.00409858, acc 1
2016-09-05T18:07:08.124838: step 5703, loss 0.00499218, acc 1
2016-09-05T18:07:08.346202: step 5704, loss 0.0046706, acc 1
2016-09-05T18:07:08.544184: step 5705, loss 0.00584481, acc 1
2016-09-05T18:07:08.767336: step 5706, loss 0.00448985, acc 1
2016-09-05T18:07:09.004924: step 5707, loss 0.00596351, acc 1
2016-09-05T18:07:09.270616: step 5708, loss 0.00438454, acc 1
2016-09-05T18:07:09.520892: step 5709, loss 0.0100081, acc 1
2016-09-05T18:07:09.751391: step 5710, loss 0.00473406, acc 1
2016-09-05T18:07:09.976525: step 5711, loss 0.00605147, acc 1
2016-09-05T18:07:10.200604: step 5712, loss 0.00486899, acc 1
2016-09-05T18:07:10.413022: step 5713, loss 0.00710266, acc 1
2016-09-05T18:07:10.634732: step 5714, loss 0.00436105, acc 1
2016-09-05T18:07:10.838464: step 5715, loss 0.00612026, acc 1
2016-09-05T18:07:11.076672: step 5716, loss 0.00493372, acc 1
2016-09-05T18:07:11.277087: step 5717, loss 0.00532228, acc 1
2016-09-05T18:07:11.485943: step 5718, loss 0.00455912, acc 1
2016-09-05T18:07:11.713420: step 5719, loss 0.00505333, acc 1
2016-09-05T18:07:11.953352: step 5720, loss 0.00626627, acc 1
2016-09-05T18:07:12.169048: step 5721, loss 0.00456202, acc 1
2016-09-05T18:07:12.389202: step 5722, loss 0.00536472, acc 1
2016-09-05T18:07:12.591217: step 5723, loss 0.00560841, acc 1
2016-09-05T18:07:12.794374: step 5724, loss 0.00444173, acc 1
2016-09-05T18:07:12.999871: step 5725, loss 0.00516284, acc 1
2016-09-05T18:07:13.232080: step 5726, loss 0.00450199, acc 1
2016-09-05T18:07:13.503878: step 5727, loss 0.00633678, acc 1
2016-09-05T18:07:13.708308: step 5728, loss 0.00717632, acc 1
2016-09-05T18:07:13.924336: step 5729, loss 0.00447403, acc 1
2016-09-05T18:07:14.139680: step 5730, loss 0.00537962, acc 1
2016-09-05T18:07:14.385408: step 5731, loss 0.00560584, acc 1
2016-09-05T18:07:14.611675: step 5732, loss 0.00488999, acc 1
2016-09-05T18:07:14.833205: step 5733, loss 0.00565192, acc 1
2016-09-05T18:07:15.037143: step 5734, loss 0.00447201, acc 1
2016-09-05T18:07:15.248152: step 5735, loss 0.0055132, acc 1
2016-09-05T18:07:15.441271: step 5736, loss 0.00495862, acc 1
2016-09-05T18:07:15.671288: step 5737, loss 0.00525451, acc 1
2016-09-05T18:07:15.909429: step 5738, loss 0.00531656, acc 1
2016-09-05T18:07:16.128840: step 5739, loss 0.00432975, acc 1
2016-09-05T18:07:16.343229: step 5740, loss 0.00578384, acc 1
2016-09-05T18:07:16.564413: step 5741, loss 0.00545294, acc 1
2016-09-05T18:07:16.815318: step 5742, loss 0.0050728, acc 1
2016-09-05T18:07:17.044291: step 5743, loss 0.00533134, acc 1
2016-09-05T18:07:17.266485: step 5744, loss 0.00443721, acc 1
2016-09-05T18:07:17.472910: step 5745, loss 0.00573516, acc 1
2016-09-05T18:07:17.690708: step 5746, loss 0.00437285, acc 1
2016-09-05T18:07:17.908924: step 5747, loss 0.00454918, acc 1
2016-09-05T18:07:18.110797: step 5748, loss 0.00467137, acc 1
2016-09-05T18:07:18.347189: step 5749, loss 0.00489588, acc 1
2016-09-05T18:07:18.546979: step 5750, loss 0.00674691, acc 1
2016-09-05T18:07:18.768186: step 5751, loss 0.00474216, acc 1
2016-09-05T18:07:18.984046: step 5752, loss 0.00447992, acc 1
2016-09-05T18:07:19.219907: step 5753, loss 0.00505904, acc 1
2016-09-05T18:07:19.456505: step 5754, loss 0.00656058, acc 1
2016-09-05T18:07:19.654563: step 5755, loss 0.00491847, acc 1
2016-09-05T18:07:19.866412: step 5756, loss 0.00514988, acc 1
2016-09-05T18:07:20.068252: step 5757, loss 0.00510888, acc 1
2016-09-05T18:07:20.272394: step 5758, loss 0.00473739, acc 1
2016-09-05T18:07:20.485656: step 5759, loss 0.00545321, acc 1
2016-09-05T18:07:20.692655: step 5760, loss 0.00465281, acc 1
2016-09-05T18:07:20.923469: step 5761, loss 0.00612764, acc 1
2016-09-05T18:07:21.152382: step 5762, loss 0.00454291, acc 1
2016-09-05T18:07:21.379558: step 5763, loss 0.00544394, acc 1
2016-09-05T18:07:21.597162: step 5764, loss 0.00496106, acc 1
2016-09-05T18:07:21.799920: step 5765, loss 0.00476127, acc 1
2016-09-05T18:07:22.025924: step 5766, loss 0.00548649, acc 1
2016-09-05T18:07:22.242535: step 5767, loss 0.00523605, acc 1
2016-09-05T18:07:22.467403: step 5768, loss 0.00590447, acc 1
2016-09-05T18:07:22.686758: step 5769, loss 0.00529836, acc 1
2016-09-05T18:07:22.904639: step 5770, loss 0.0052782, acc 1
2016-09-05T18:07:23.117502: step 5771, loss 0.0045338, acc 1
2016-09-05T18:07:23.330625: step 5772, loss 0.00482279, acc 1
2016-09-05T18:07:23.543730: step 5773, loss 0.00475053, acc 1
2016-09-05T18:07:23.782833: step 5774, loss 0.00452736, acc 1
2016-09-05T18:07:24.018884: step 5775, loss 0.00434782, acc 1
2016-09-05T18:07:24.217699: step 5776, loss 0.00510217, acc 1
2016-09-05T18:07:24.438271: step 5777, loss 0.00657391, acc 1
2016-09-05T18:07:24.669845: step 5778, loss 0.00569454, acc 1
2016-09-05T18:07:24.881009: step 5779, loss 0.00490383, acc 1
2016-09-05T18:07:25.117880: step 5780, loss 0.00516958, acc 1
2016-09-05T18:07:25.322781: step 5781, loss 0.00543822, acc 1
2016-09-05T18:07:25.527541: step 5782, loss 0.00491641, acc 1
2016-09-05T18:07:25.742136: step 5783, loss 0.00534507, acc 1
2016-09-05T18:07:25.952408: step 5784, loss 0.00476872, acc 1
2016-09-05T18:07:26.167288: step 5785, loss 0.0076324, acc 1
2016-09-05T18:07:26.409815: step 5786, loss 0.00530693, acc 1
2016-09-05T18:07:26.604905: step 5787, loss 0.00447478, acc 1
2016-09-05T18:07:26.824045: step 5788, loss 0.00570474, acc 1
2016-09-05T18:07:27.033301: step 5789, loss 0.00659163, acc 1
2016-09-05T18:07:27.247281: step 5790, loss 0.00495183, acc 1
2016-09-05T18:07:27.505234: step 5791, loss 0.00496826, acc 1
2016-09-05T18:07:27.740396: step 5792, loss 0.00441918, acc 1
2016-09-05T18:07:27.949498: step 5793, loss 0.00447681, acc 1
2016-09-05T18:07:28.171788: step 5794, loss 0.00532146, acc 1
2016-09-05T18:07:28.383670: step 5795, loss 0.00481609, acc 1
2016-09-05T18:07:28.605933: step 5796, loss 0.00704942, acc 1
2016-09-05T18:07:28.825392: step 5797, loss 0.00575728, acc 1
2016-09-05T18:07:29.033428: step 5798, loss 0.00506235, acc 1
2016-09-05T18:07:29.242530: step 5799, loss 0.00821195, acc 1
2016-09-05T18:07:29.444075: step 5800, loss 0.00439588, acc 1

Evaluation:
2016-09-05T18:07:30.031350: step 5800, loss 1.11103, acc 0.739

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-5800

2016-09-05T18:07:30.717849: step 5801, loss 0.00545568, acc 1
2016-09-05T18:07:30.950427: step 5802, loss 0.00454387, acc 1
2016-09-05T18:07:31.183006: step 5803, loss 0.00577632, acc 1
2016-09-05T18:07:31.405946: step 5804, loss 0.00503496, acc 1
2016-09-05T18:07:31.632120: step 5805, loss 0.0046298, acc 1
2016-09-05T18:07:31.874251: step 5806, loss 0.00576215, acc 1
2016-09-05T18:07:32.071741: step 5807, loss 0.00463112, acc 1
2016-09-05T18:07:32.284074: step 5808, loss 0.00455026, acc 1
2016-09-05T18:07:32.500511: step 5809, loss 0.00685527, acc 1
2016-09-05T18:07:32.700829: step 5810, loss 0.00559167, acc 1
2016-09-05T18:07:32.931278: step 5811, loss 0.00447921, acc 1
2016-09-05T18:07:33.159237: step 5812, loss 0.0046946, acc 1
2016-09-05T18:07:33.384321: step 5813, loss 0.00653129, acc 1
2016-09-05T18:07:33.593721: step 5814, loss 0.00528928, acc 1
2016-09-05T18:07:33.812272: step 5815, loss 0.00513164, acc 1
2016-09-05T18:07:34.026177: step 5816, loss 0.00546139, acc 1
2016-09-05T18:07:34.247035: step 5817, loss 0.00469179, acc 1
2016-09-05T18:07:34.499708: step 5818, loss 0.00744477, acc 1
2016-09-05T18:07:34.728952: step 5819, loss 0.00567842, acc 1
2016-09-05T18:07:34.875110: step 5820, loss 0.00410504, acc 1
2016-09-05T18:07:35.088554: step 5821, loss 0.00465248, acc 1
2016-09-05T18:07:35.307538: step 5822, loss 0.0052048, acc 1
2016-09-05T18:07:35.506013: step 5823, loss 0.0049586, acc 1
2016-09-05T18:07:35.708018: step 5824, loss 0.00589449, acc 1
2016-09-05T18:07:35.914404: step 5825, loss 0.00482592, acc 1
2016-09-05T18:07:36.126161: step 5826, loss 0.00568225, acc 1
2016-09-05T18:07:36.333911: step 5827, loss 0.00559265, acc 1
2016-09-05T18:07:36.547054: step 5828, loss 0.00457323, acc 1
2016-09-05T18:07:36.746723: step 5829, loss 0.00454505, acc 1
2016-09-05T18:07:36.965663: step 5830, loss 0.00422686, acc 1
2016-09-05T18:07:37.181527: step 5831, loss 0.00477219, acc 1
2016-09-05T18:07:37.426808: step 5832, loss 0.00532763, acc 1
2016-09-05T18:07:37.635008: step 5833, loss 0.00562073, acc 1
2016-09-05T18:07:37.851777: step 5834, loss 0.00545469, acc 1
2016-09-05T18:07:38.062774: step 5835, loss 0.00475992, acc 1
2016-09-05T18:07:38.269433: step 5836, loss 0.00444611, acc 1
2016-09-05T18:07:38.479391: step 5837, loss 0.00435173, acc 1
2016-09-05T18:07:38.721391: step 5838, loss 0.0048548, acc 1
2016-09-05T18:07:38.967160: step 5839, loss 0.00445367, acc 1
2016-09-05T18:07:39.186107: step 5840, loss 0.00421249, acc 1
2016-09-05T18:07:39.431917: step 5841, loss 0.00427062, acc 1
2016-09-05T18:07:39.649425: step 5842, loss 0.00492235, acc 1
2016-09-05T18:07:39.870592: step 5843, loss 0.00487034, acc 1
2016-09-05T18:07:40.093386: step 5844, loss 0.00468747, acc 1
2016-09-05T18:07:40.328037: step 5845, loss 0.00462371, acc 1
2016-09-05T18:07:40.557412: step 5846, loss 0.0056228, acc 1
2016-09-05T18:07:40.771815: step 5847, loss 0.00471457, acc 1
2016-09-05T18:07:40.990767: step 5848, loss 0.00478985, acc 1
2016-09-05T18:07:41.198841: step 5849, loss 0.0062522, acc 1
2016-09-05T18:07:41.431735: step 5850, loss 0.00444632, acc 1
2016-09-05T18:07:41.661205: step 5851, loss 0.00392547, acc 1
2016-09-05T18:07:41.892991: step 5852, loss 0.00437135, acc 1
2016-09-05T18:07:42.112939: step 5853, loss 0.00451744, acc 1
2016-09-05T18:07:42.369587: step 5854, loss 0.00448648, acc 1
2016-09-05T18:07:42.579544: step 5855, loss 0.00540709, acc 1
2016-09-05T18:07:42.794467: step 5856, loss 0.00440486, acc 1
2016-09-05T18:07:43.004003: step 5857, loss 0.00477858, acc 1
2016-09-05T18:07:43.212115: step 5858, loss 0.00634575, acc 1
2016-09-05T18:07:43.428130: step 5859, loss 0.00446168, acc 1
2016-09-05T18:07:43.633691: step 5860, loss 0.00444619, acc 1
2016-09-05T18:07:43.865387: step 5861, loss 0.00511072, acc 1
2016-09-05T18:07:44.077210: step 5862, loss 0.00564114, acc 1
2016-09-05T18:07:44.297760: step 5863, loss 0.00406313, acc 1
2016-09-05T18:07:44.503389: step 5864, loss 0.00491232, acc 1
2016-09-05T18:07:44.703913: step 5865, loss 0.00422967, acc 1
2016-09-05T18:07:44.911977: step 5866, loss 0.00466365, acc 1
2016-09-05T18:07:45.124435: step 5867, loss 0.00591087, acc 1
2016-09-05T18:07:45.343320: step 5868, loss 0.00448865, acc 1
2016-09-05T18:07:45.564914: step 5869, loss 0.00473613, acc 1
2016-09-05T18:07:45.781220: step 5870, loss 0.00486396, acc 1
2016-09-05T18:07:46.011357: step 5871, loss 0.00886088, acc 1
2016-09-05T18:07:46.219631: step 5872, loss 0.00510019, acc 1
2016-09-05T18:07:46.444439: step 5873, loss 0.00421783, acc 1
2016-09-05T18:07:46.660493: step 5874, loss 0.00471395, acc 1
2016-09-05T18:07:46.891228: step 5875, loss 0.00480275, acc 1
2016-09-05T18:07:47.138048: step 5876, loss 0.00408456, acc 1
2016-09-05T18:07:47.343220: step 5877, loss 0.00507031, acc 1
2016-09-05T18:07:47.561903: step 5878, loss 0.00416, acc 1
2016-09-05T18:07:47.785262: step 5879, loss 0.00554993, acc 1
2016-09-05T18:07:48.020535: step 5880, loss 0.00454139, acc 1
2016-09-05T18:07:48.241732: step 5881, loss 0.00505129, acc 1
2016-09-05T18:07:48.450541: step 5882, loss 0.00457556, acc 1
2016-09-05T18:07:48.659326: step 5883, loss 0.00473405, acc 1
2016-09-05T18:07:48.886813: step 5884, loss 0.0056766, acc 1
2016-09-05T18:07:49.080324: step 5885, loss 0.00461526, acc 1
2016-09-05T18:07:49.281107: step 5886, loss 0.00487921, acc 1
2016-09-05T18:07:49.505681: step 5887, loss 0.00443556, acc 1
2016-09-05T18:07:49.705292: step 5888, loss 0.00702973, acc 1
2016-09-05T18:07:49.939638: step 5889, loss 0.00407643, acc 1
2016-09-05T18:07:50.146957: step 5890, loss 0.00589687, acc 1
2016-09-05T18:07:50.359495: step 5891, loss 0.0046184, acc 1
2016-09-05T18:07:50.584618: step 5892, loss 0.00553185, acc 1
2016-09-05T18:07:50.810205: step 5893, loss 0.00475875, acc 1
2016-09-05T18:07:51.025857: step 5894, loss 0.00434973, acc 1
2016-09-05T18:07:51.269864: step 5895, loss 0.0045055, acc 1
2016-09-05T18:07:51.481861: step 5896, loss 0.00533479, acc 1
2016-09-05T18:07:51.698812: step 5897, loss 0.00587849, acc 1
2016-09-05T18:07:51.946514: step 5898, loss 0.00524308, acc 1
2016-09-05T18:07:52.162292: step 5899, loss 0.00457087, acc 1
2016-09-05T18:07:52.375106: step 5900, loss 0.00525409, acc 1

Evaluation:
2016-09-05T18:07:52.955219: step 5900, loss 1.11475, acc 0.742

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-5900

2016-09-05T18:07:53.685848: step 5901, loss 0.00487059, acc 1
2016-09-05T18:07:53.920455: step 5902, loss 0.00529465, acc 1
2016-09-05T18:07:54.139973: step 5903, loss 0.00415016, acc 1
2016-09-05T18:07:54.368552: step 5904, loss 0.00462192, acc 1
2016-09-05T18:07:54.601826: step 5905, loss 0.00405255, acc 1
2016-09-05T18:07:54.797519: step 5906, loss 0.00504203, acc 1
2016-09-05T18:07:55.020262: step 5907, loss 0.00703527, acc 1
2016-09-05T18:07:55.250465: step 5908, loss 0.00486009, acc 1
2016-09-05T18:07:55.497111: step 5909, loss 0.00443975, acc 1
2016-09-05T18:07:55.724108: step 5910, loss 0.00407098, acc 1
2016-09-05T18:07:55.945518: step 5911, loss 0.00456994, acc 1
2016-09-05T18:07:56.172439: step 5912, loss 0.00593315, acc 1
2016-09-05T18:07:56.420652: step 5913, loss 0.00460735, acc 1
2016-09-05T18:07:56.631971: step 5914, loss 0.00527755, acc 1
2016-09-05T18:07:56.836247: step 5915, loss 0.0051398, acc 1
2016-09-05T18:07:57.034385: step 5916, loss 0.00423994, acc 1
2016-09-05T18:07:57.256312: step 5917, loss 0.00519938, acc 1
2016-09-05T18:07:57.473350: step 5918, loss 0.00515333, acc 1
2016-09-05T18:07:57.692863: step 5919, loss 0.00718775, acc 1
2016-09-05T18:07:57.932974: step 5920, loss 0.00416062, acc 1
2016-09-05T18:07:58.146530: step 5921, loss 0.0043308, acc 1
2016-09-05T18:07:58.348338: step 5922, loss 0.00633924, acc 1
2016-09-05T18:07:58.548515: step 5923, loss 0.00421459, acc 1
2016-09-05T18:07:58.747140: step 5924, loss 0.00507752, acc 1
2016-09-05T18:07:58.956905: step 5925, loss 0.00403827, acc 1
2016-09-05T18:07:59.156860: step 5926, loss 0.00477446, acc 1
2016-09-05T18:07:59.374025: step 5927, loss 0.00530553, acc 1
2016-09-05T18:07:59.590375: step 5928, loss 0.00493155, acc 1
2016-09-05T18:07:59.802192: step 5929, loss 0.00417879, acc 1
2016-09-05T18:08:00.033124: step 5930, loss 0.00558773, acc 1
2016-09-05T18:08:00.258901: step 5931, loss 0.00501103, acc 1
2016-09-05T18:08:00.466135: step 5932, loss 0.00476461, acc 1
2016-09-05T18:08:00.673898: step 5933, loss 0.00451728, acc 1
2016-09-05T18:08:00.888286: step 5934, loss 0.00488574, acc 1
2016-09-05T18:08:01.090913: step 5935, loss 0.00560527, acc 1
2016-09-05T18:08:01.299760: step 5936, loss 0.00427868, acc 1
2016-09-05T18:08:01.513864: step 5937, loss 0.00654425, acc 1
2016-09-05T18:08:01.755079: step 5938, loss 0.00402602, acc 1
2016-09-05T18:08:01.962276: step 5939, loss 0.00412143, acc 1
2016-09-05T18:08:02.189815: step 5940, loss 0.00618386, acc 1
2016-09-05T18:08:02.399139: step 5941, loss 0.00478314, acc 1
2016-09-05T18:08:02.604224: step 5942, loss 0.00373576, acc 1
2016-09-05T18:08:02.850190: step 5943, loss 0.00420844, acc 1
2016-09-05T18:08:03.076592: step 5944, loss 0.00416417, acc 1
2016-09-05T18:08:03.301224: step 5945, loss 0.00559571, acc 1
2016-09-05T18:08:03.510783: step 5946, loss 0.00479721, acc 1
2016-09-05T18:08:03.719600: step 5947, loss 0.00424139, acc 1
2016-09-05T18:08:03.931354: step 5948, loss 0.00469108, acc 1
2016-09-05T18:08:04.170741: step 5949, loss 0.00477961, acc 1
2016-09-05T18:08:04.389511: step 5950, loss 0.00480586, acc 1
2016-09-05T18:08:04.601524: step 5951, loss 0.00498229, acc 1
2016-09-05T18:08:04.819136: step 5952, loss 0.00474892, acc 1
2016-09-05T18:08:05.045159: step 5953, loss 0.00442758, acc 1
2016-09-05T18:08:05.283236: step 5954, loss 0.00433295, acc 1
2016-09-05T18:08:05.489516: step 5955, loss 0.00588405, acc 1
2016-09-05T18:08:05.705476: step 5956, loss 0.00518021, acc 1
2016-09-05T18:08:05.919834: step 5957, loss 0.00490139, acc 1
2016-09-05T18:08:06.130623: step 5958, loss 0.00571187, acc 1
2016-09-05T18:08:06.329773: step 5959, loss 0.00475102, acc 1
2016-09-05T18:08:06.554026: step 5960, loss 0.00508364, acc 1
2016-09-05T18:08:06.797922: step 5961, loss 0.00602254, acc 1
2016-09-05T18:08:07.026965: step 5962, loss 0.00419284, acc 1
2016-09-05T18:08:07.238221: step 5963, loss 0.0058516, acc 1
2016-09-05T18:08:07.463985: step 5964, loss 0.00445015, acc 1
2016-09-05T18:08:07.686346: step 5965, loss 0.00605652, acc 1
2016-09-05T18:08:07.898178: step 5966, loss 0.00427287, acc 1
2016-09-05T18:08:08.112535: step 5967, loss 0.00507652, acc 1
2016-09-05T18:08:08.311822: step 5968, loss 0.00479271, acc 1
2016-09-05T18:08:08.514502: step 5969, loss 0.0047169, acc 1
2016-09-05T18:08:08.721301: step 5970, loss 0.00473359, acc 1
2016-09-05T18:08:08.944837: step 5971, loss 0.00400495, acc 1
2016-09-05T18:08:09.147717: step 5972, loss 0.00444904, acc 1
2016-09-05T18:08:09.364174: step 5973, loss 0.00449081, acc 1
2016-09-05T18:08:09.581737: step 5974, loss 0.00441114, acc 1
2016-09-05T18:08:09.808893: step 5975, loss 0.00550369, acc 1
2016-09-05T18:08:10.029537: step 5976, loss 0.00479004, acc 1
2016-09-05T18:08:10.247706: step 5977, loss 0.00510907, acc 1
2016-09-05T18:08:10.467993: step 5978, loss 0.0044375, acc 1
2016-09-05T18:08:10.694442: step 5979, loss 0.0060045, acc 1
2016-09-05T18:08:10.917017: step 5980, loss 0.00453011, acc 1
2016-09-05T18:08:11.126478: step 5981, loss 0.00588659, acc 1
2016-09-05T18:08:11.343417: step 5982, loss 0.00534683, acc 1
2016-09-05T18:08:11.540531: step 5983, loss 0.0050072, acc 1
2016-09-05T18:08:11.746199: step 5984, loss 0.00471448, acc 1
2016-09-05T18:08:11.947069: step 5985, loss 0.00517144, acc 1
2016-09-05T18:08:12.177444: step 5986, loss 0.00501504, acc 1
2016-09-05T18:08:12.398744: step 5987, loss 0.00615301, acc 1
2016-09-05T18:08:12.635352: step 5988, loss 0.00475407, acc 1
2016-09-05T18:08:12.850822: step 5989, loss 0.00391703, acc 1
2016-09-05T18:08:13.070004: step 5990, loss 0.00514196, acc 1
2016-09-05T18:08:13.285518: step 5991, loss 0.00452996, acc 1
2016-09-05T18:08:13.514719: step 5992, loss 0.00395661, acc 1
2016-09-05T18:08:13.762796: step 5993, loss 0.00531901, acc 1
2016-09-05T18:08:13.955045: step 5994, loss 0.00461251, acc 1
2016-09-05T18:08:14.166759: step 5995, loss 0.00422534, acc 1
2016-09-05T18:08:14.388705: step 5996, loss 0.00501403, acc 1
2016-09-05T18:08:14.613539: step 5997, loss 0.00465086, acc 1
2016-09-05T18:08:14.843728: step 5998, loss 0.00522486, acc 1
2016-09-05T18:08:15.082094: step 5999, loss 0.00437514, acc 1
2016-09-05T18:08:15.290398: step 6000, loss 0.0040649, acc 1

Evaluation:
2016-09-05T18:08:15.911670: step 6000, loss 1.1152, acc 0.737

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-6000

2016-09-05T18:08:16.729657: step 6001, loss 0.00710055, acc 1
2016-09-05T18:08:16.973029: step 6002, loss 0.00497881, acc 1
2016-09-05T18:08:17.207802: step 6003, loss 0.00483074, acc 1
2016-09-05T18:08:17.452558: step 6004, loss 0.00464901, acc 1
2016-09-05T18:08:17.693715: step 6005, loss 0.0045476, acc 1
2016-09-05T18:08:17.899422: step 6006, loss 0.00560683, acc 1
2016-09-05T18:08:18.104378: step 6007, loss 0.00418192, acc 1
2016-09-05T18:08:18.297608: step 6008, loss 0.00513923, acc 1
2016-09-05T18:08:18.507857: step 6009, loss 0.00385631, acc 1
2016-09-05T18:08:18.756096: step 6010, loss 0.00618921, acc 1
2016-09-05T18:08:18.978664: step 6011, loss 0.00933087, acc 1
2016-09-05T18:08:19.213813: step 6012, loss 0.00442482, acc 1
2016-09-05T18:08:19.430668: step 6013, loss 0.00525703, acc 1
2016-09-05T18:08:19.592752: step 6014, loss 0.0123549, acc 1
2016-09-05T18:08:19.819846: step 6015, loss 0.00456745, acc 1
2016-09-05T18:08:20.052569: step 6016, loss 0.00610469, acc 1
2016-09-05T18:08:20.263998: step 6017, loss 0.00444978, acc 1
2016-09-05T18:08:20.483710: step 6018, loss 0.00533662, acc 1
2016-09-05T18:08:20.690010: step 6019, loss 0.00493917, acc 1
2016-09-05T18:08:20.914666: step 6020, loss 0.00617606, acc 1
2016-09-05T18:08:21.136500: step 6021, loss 0.00473744, acc 1
2016-09-05T18:08:21.344191: step 6022, loss 0.00517424, acc 1
2016-09-05T18:08:21.565355: step 6023, loss 0.0072, acc 1
2016-09-05T18:08:21.781263: step 6024, loss 0.0051854, acc 1
2016-09-05T18:08:22.010775: step 6025, loss 0.00726238, acc 1
2016-09-05T18:08:22.229485: step 6026, loss 0.00485683, acc 1
2016-09-05T18:08:22.447918: step 6027, loss 0.00581606, acc 1
2016-09-05T18:08:22.665748: step 6028, loss 0.00550253, acc 1
2016-09-05T18:08:22.897613: step 6029, loss 0.00618491, acc 1
2016-09-05T18:08:23.145115: step 6030, loss 0.00570189, acc 1
2016-09-05T18:08:23.358273: step 6031, loss 0.00671762, acc 1
2016-09-05T18:08:23.579239: step 6032, loss 0.00732673, acc 1
2016-09-05T18:08:23.794590: step 6033, loss 0.00539098, acc 1
2016-09-05T18:08:24.028527: step 6034, loss 0.00507537, acc 1
2016-09-05T18:08:24.249452: step 6035, loss 0.0086379, acc 1
2016-09-05T18:08:24.470674: step 6036, loss 0.00508729, acc 1
2016-09-05T18:08:24.683725: step 6037, loss 0.00497697, acc 1
2016-09-05T18:08:24.913261: step 6038, loss 0.00483345, acc 1
2016-09-05T18:08:25.157438: step 6039, loss 0.00567292, acc 1
2016-09-05T18:08:25.384298: step 6040, loss 0.00505208, acc 1
2016-09-05T18:08:25.580291: step 6041, loss 0.00567845, acc 1
2016-09-05T18:08:25.794770: step 6042, loss 0.00596996, acc 1
2016-09-05T18:08:26.029437: step 6043, loss 0.00728691, acc 1
2016-09-05T18:08:26.232459: step 6044, loss 0.00467312, acc 1
2016-09-05T18:08:26.454451: step 6045, loss 0.00508713, acc 1
2016-09-05T18:08:26.665450: step 6046, loss 0.0048334, acc 1
2016-09-05T18:08:26.888280: step 6047, loss 0.00524072, acc 1
2016-09-05T18:08:27.095491: step 6048, loss 0.00540849, acc 1
2016-09-05T18:08:27.303655: step 6049, loss 0.00484648, acc 1
2016-09-05T18:08:27.503668: step 6050, loss 0.00516684, acc 1
2016-09-05T18:08:27.743610: step 6051, loss 0.00520247, acc 1
2016-09-05T18:08:27.989442: step 6052, loss 0.00669686, acc 1
2016-09-05T18:08:28.221347: step 6053, loss 0.00576712, acc 1
2016-09-05T18:08:28.434641: step 6054, loss 0.00463745, acc 1
2016-09-05T18:08:28.641000: step 6055, loss 0.00498467, acc 1
2016-09-05T18:08:28.862422: step 6056, loss 0.00514018, acc 1
2016-09-05T18:08:29.063105: step 6057, loss 0.00509674, acc 1
2016-09-05T18:08:29.288789: step 6058, loss 0.0052724, acc 1
2016-09-05T18:08:29.509146: step 6059, loss 0.00412617, acc 1
2016-09-05T18:08:29.732401: step 6060, loss 0.00652496, acc 1
2016-09-05T18:08:29.942652: step 6061, loss 0.00544445, acc 1
2016-09-05T18:08:30.178867: step 6062, loss 0.0042813, acc 1
2016-09-05T18:08:30.409295: step 6063, loss 0.00472871, acc 1
2016-09-05T18:08:30.641459: step 6064, loss 0.00450443, acc 1
2016-09-05T18:08:30.850978: step 6065, loss 0.00520334, acc 1
2016-09-05T18:08:31.053907: step 6066, loss 0.0040723, acc 1
2016-09-05T18:08:31.273976: step 6067, loss 0.00451729, acc 1
2016-09-05T18:08:31.467113: step 6068, loss 0.00455209, acc 1
2016-09-05T18:08:31.677228: step 6069, loss 0.00451327, acc 1
2016-09-05T18:08:31.882345: step 6070, loss 0.00457241, acc 1
2016-09-05T18:08:32.108040: step 6071, loss 0.00652419, acc 1
2016-09-05T18:08:32.337289: step 6072, loss 0.00466983, acc 1
2016-09-05T18:08:32.563080: step 6073, loss 0.00415674, acc 1
2016-09-05T18:08:32.765127: step 6074, loss 0.00467756, acc 1
2016-09-05T18:08:32.967347: step 6075, loss 0.00480843, acc 1
2016-09-05T18:08:33.188142: step 6076, loss 0.00481353, acc 1
2016-09-05T18:08:33.432342: step 6077, loss 0.00438347, acc 1
2016-09-05T18:08:33.683161: step 6078, loss 0.00635485, acc 1
2016-09-05T18:08:33.888253: step 6079, loss 0.00505185, acc 1
2016-09-05T18:08:34.092057: step 6080, loss 0.00381902, acc 1
2016-09-05T18:08:34.317307: step 6081, loss 0.00405425, acc 1
2016-09-05T18:08:34.539455: step 6082, loss 0.00393788, acc 1
2016-09-05T18:08:34.758090: step 6083, loss 0.0037549, acc 1
2016-09-05T18:08:34.983797: step 6084, loss 0.00418042, acc 1
2016-09-05T18:08:35.219188: step 6085, loss 0.00493378, acc 1
2016-09-05T18:08:35.435139: step 6086, loss 0.00459344, acc 1
2016-09-05T18:08:35.670105: step 6087, loss 0.00417094, acc 1
2016-09-05T18:08:35.873357: step 6088, loss 0.0051494, acc 1
2016-09-05T18:08:36.088596: step 6089, loss 0.00478047, acc 1
2016-09-05T18:08:36.291642: step 6090, loss 0.00454437, acc 1
2016-09-05T18:08:36.504165: step 6091, loss 0.00411976, acc 1
2016-09-05T18:08:36.712408: step 6092, loss 0.00394954, acc 1
2016-09-05T18:08:36.923094: step 6093, loss 0.0035696, acc 1
2016-09-05T18:08:37.120689: step 6094, loss 0.00433469, acc 1
2016-09-05T18:08:37.338407: step 6095, loss 0.00629342, acc 1
2016-09-05T18:08:37.563084: step 6096, loss 0.00419481, acc 1
2016-09-05T18:08:37.778368: step 6097, loss 0.00427378, acc 1
2016-09-05T18:08:37.999860: step 6098, loss 0.00464732, acc 1
2016-09-05T18:08:38.225016: step 6099, loss 0.00370337, acc 1
2016-09-05T18:08:38.464696: step 6100, loss 0.00386541, acc 1

Evaluation:
2016-09-05T18:08:39.069588: step 6100, loss 1.10086, acc 0.736

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-6100

2016-09-05T18:08:39.798132: step 6101, loss 0.00443491, acc 1
2016-09-05T18:08:40.024471: step 6102, loss 0.00431017, acc 1
2016-09-05T18:08:40.246519: step 6103, loss 0.00455894, acc 1
2016-09-05T18:08:40.454707: step 6104, loss 0.00431375, acc 1
2016-09-05T18:08:40.737941: step 6105, loss 0.00455845, acc 1
2016-09-05T18:08:40.957276: step 6106, loss 0.00387403, acc 1
2016-09-05T18:08:41.159482: step 6107, loss 0.00380082, acc 1
2016-09-05T18:08:41.376743: step 6108, loss 0.00515872, acc 1
2016-09-05T18:08:41.584420: step 6109, loss 0.00394323, acc 1
2016-09-05T18:08:41.794749: step 6110, loss 0.0046826, acc 1
2016-09-05T18:08:42.007126: step 6111, loss 0.00427349, acc 1
2016-09-05T18:08:42.254773: step 6112, loss 0.00446774, acc 1
2016-09-05T18:08:42.453405: step 6113, loss 0.00414773, acc 1
2016-09-05T18:08:42.671727: step 6114, loss 0.00494009, acc 1
2016-09-05T18:08:42.879857: step 6115, loss 0.00454663, acc 1
2016-09-05T18:08:43.123734: step 6116, loss 0.00379703, acc 1
2016-09-05T18:08:43.357326: step 6117, loss 0.00551202, acc 1
2016-09-05T18:08:43.542684: step 6118, loss 0.00421586, acc 1
2016-09-05T18:08:43.750271: step 6119, loss 0.00362369, acc 1
2016-09-05T18:08:43.996662: step 6120, loss 0.00440806, acc 1
2016-09-05T18:08:44.245515: step 6121, loss 0.00408669, acc 1
2016-09-05T18:08:44.484991: step 6122, loss 0.00451587, acc 1
2016-09-05T18:08:44.725207: step 6123, loss 0.00556932, acc 1
2016-09-05T18:08:44.947834: step 6124, loss 0.00420659, acc 1
2016-09-05T18:08:45.189799: step 6125, loss 0.00430806, acc 1
2016-09-05T18:08:45.405391: step 6126, loss 0.00363396, acc 1
2016-09-05T18:08:45.604670: step 6127, loss 0.00475607, acc 1
2016-09-05T18:08:45.814302: step 6128, loss 0.00424787, acc 1
2016-09-05T18:08:46.017613: step 6129, loss 0.00375303, acc 1
2016-09-05T18:08:46.223572: step 6130, loss 0.00485823, acc 1
2016-09-05T18:08:46.433369: step 6131, loss 0.00548234, acc 1
2016-09-05T18:08:46.650767: step 6132, loss 0.00439878, acc 1
2016-09-05T18:08:46.870752: step 6133, loss 0.0051097, acc 1
2016-09-05T18:08:47.110128: step 6134, loss 0.00363713, acc 1
2016-09-05T18:08:47.310639: step 6135, loss 0.00517586, acc 1
2016-09-05T18:08:47.517733: step 6136, loss 0.00367965, acc 1
2016-09-05T18:08:47.734983: step 6137, loss 0.0115945, acc 1
2016-09-05T18:08:47.960488: step 6138, loss 0.00451612, acc 1
2016-09-05T18:08:48.179085: step 6139, loss 0.00684296, acc 1
2016-09-05T18:08:48.418848: step 6140, loss 0.00511141, acc 1
2016-09-05T18:08:48.624273: step 6141, loss 0.011893, acc 1
2016-09-05T18:08:48.824704: step 6142, loss 0.00830461, acc 1
2016-09-05T18:08:49.037127: step 6143, loss 0.00448201, acc 1
2016-09-05T18:08:49.249054: step 6144, loss 0.00527215, acc 1
2016-09-05T18:08:49.486832: step 6145, loss 0.0061267, acc 1
2016-09-05T18:08:49.729947: step 6146, loss 0.00639972, acc 1
2016-09-05T18:08:49.939537: step 6147, loss 0.013339, acc 1
2016-09-05T18:08:50.144240: step 6148, loss 0.00635492, acc 1
2016-09-05T18:08:50.367678: step 6149, loss 0.00600039, acc 1
2016-09-05T18:08:50.565425: step 6150, loss 0.00573122, acc 1
2016-09-05T18:08:50.780576: step 6151, loss 0.00557243, acc 1
2016-09-05T18:08:50.997508: step 6152, loss 0.0057608, acc 1
2016-09-05T18:08:51.226999: step 6153, loss 0.00660015, acc 1
2016-09-05T18:08:51.453762: step 6154, loss 0.00703582, acc 1
2016-09-05T18:08:51.658083: step 6155, loss 0.00644369, acc 1
2016-09-05T18:08:51.879933: step 6156, loss 0.00716855, acc 1
2016-09-05T18:08:52.114993: step 6157, loss 0.0073452, acc 1
2016-09-05T18:08:52.358083: step 6158, loss 0.00835341, acc 1
2016-09-05T18:08:52.574724: step 6159, loss 0.00752385, acc 1
2016-09-05T18:08:52.864184: step 6160, loss 0.00819357, acc 1
2016-09-05T18:08:53.088950: step 6161, loss 0.00648622, acc 1
2016-09-05T18:08:53.287925: step 6162, loss 0.00703726, acc 1
2016-09-05T18:08:53.506315: step 6163, loss 0.00638088, acc 1
2016-09-05T18:08:53.725017: step 6164, loss 0.00619419, acc 1
2016-09-05T18:08:53.944913: step 6165, loss 0.00655164, acc 1
2016-09-05T18:08:54.159399: step 6166, loss 0.00596193, acc 1
2016-09-05T18:08:54.390259: step 6167, loss 0.00634837, acc 1
2016-09-05T18:08:54.608790: step 6168, loss 0.00603856, acc 1
2016-09-05T18:08:54.838126: step 6169, loss 0.00603136, acc 1
2016-09-05T18:08:55.061384: step 6170, loss 0.00612507, acc 1
2016-09-05T18:08:55.272972: step 6171, loss 0.00545852, acc 1
2016-09-05T18:08:55.478074: step 6172, loss 0.00574447, acc 1
2016-09-05T18:08:55.673295: step 6173, loss 0.00613164, acc 1
2016-09-05T18:08:55.888623: step 6174, loss 0.00709759, acc 1
2016-09-05T18:08:56.107898: step 6175, loss 0.00630113, acc 1
2016-09-05T18:08:56.332628: step 6176, loss 0.00569181, acc 1
2016-09-05T18:08:56.555360: step 6177, loss 0.00561543, acc 1
2016-09-05T18:08:56.808595: step 6178, loss 0.0052158, acc 1
2016-09-05T18:08:57.030699: step 6179, loss 0.00583394, acc 1
2016-09-05T18:08:57.256224: step 6180, loss 0.0051044, acc 1
2016-09-05T18:08:57.507767: step 6181, loss 0.00619121, acc 1
2016-09-05T18:08:57.713905: step 6182, loss 0.0047095, acc 1
2016-09-05T18:08:57.941277: step 6183, loss 0.00548399, acc 1
2016-09-05T18:08:58.142454: step 6184, loss 0.00475739, acc 1
2016-09-05T18:08:58.357416: step 6185, loss 0.00593396, acc 1
2016-09-05T18:08:58.591350: step 6186, loss 0.00531397, acc 1
2016-09-05T18:08:58.816792: step 6187, loss 0.00500965, acc 1
2016-09-05T18:08:59.048291: step 6188, loss 0.00493131, acc 1
2016-09-05T18:08:59.283956: step 6189, loss 0.00509247, acc 1
2016-09-05T18:08:59.505354: step 6190, loss 0.00652532, acc 1
2016-09-05T18:08:59.721402: step 6191, loss 0.00466027, acc 1
2016-09-05T18:08:59.925119: step 6192, loss 0.00475902, acc 1
2016-09-05T18:09:00.125153: step 6193, loss 0.00477406, acc 1
2016-09-05T18:09:00.346040: step 6194, loss 0.00454191, acc 1
2016-09-05T18:09:00.563600: step 6195, loss 0.00480395, acc 1
2016-09-05T18:09:00.797441: step 6196, loss 0.00403178, acc 1
2016-09-05T18:09:01.025471: step 6197, loss 0.00540402, acc 1
2016-09-05T18:09:01.257336: step 6198, loss 0.00437469, acc 1
2016-09-05T18:09:01.481463: step 6199, loss 0.0055431, acc 1
2016-09-05T18:09:01.723263: step 6200, loss 0.00465472, acc 1

Evaluation:
2016-09-05T18:09:02.336208: step 6200, loss 1.13165, acc 0.739

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-6200

2016-09-05T18:09:03.060344: step 6201, loss 0.00473035, acc 1
2016-09-05T18:09:03.284416: step 6202, loss 0.00447883, acc 1
2016-09-05T18:09:03.521439: step 6203, loss 0.00540917, acc 1
2016-09-05T18:09:03.757046: step 6204, loss 0.00384665, acc 1
2016-09-05T18:09:03.957389: step 6205, loss 0.00366353, acc 1
2016-09-05T18:09:04.173313: step 6206, loss 0.00374064, acc 1
2016-09-05T18:09:04.392735: step 6207, loss 0.00536167, acc 1
2016-09-05T18:09:04.532043: step 6208, loss 0.00339107, acc 1
2016-09-05T18:09:04.767600: step 6209, loss 0.00480412, acc 1
2016-09-05T18:09:04.969100: step 6210, loss 0.00440762, acc 1
2016-09-05T18:09:05.177826: step 6211, loss 0.00422538, acc 1
2016-09-05T18:09:05.379341: step 6212, loss 0.00419198, acc 1
2016-09-05T18:09:05.603612: step 6213, loss 0.00468477, acc 1
2016-09-05T18:09:05.857507: step 6214, loss 0.00351369, acc 1
2016-09-05T18:09:06.080074: step 6215, loss 0.00357166, acc 1
2016-09-05T18:09:06.277881: step 6216, loss 0.00379874, acc 1
2016-09-05T18:09:06.492662: step 6217, loss 0.00378546, acc 1
2016-09-05T18:09:06.695610: step 6218, loss 0.0041787, acc 1
2016-09-05T18:09:06.903682: step 6219, loss 0.00480018, acc 1
2016-09-05T18:09:07.116761: step 6220, loss 0.00366865, acc 1
2016-09-05T18:09:07.353921: step 6221, loss 0.00452364, acc 1
2016-09-05T18:09:07.565963: step 6222, loss 0.00448876, acc 1
2016-09-05T18:09:07.780677: step 6223, loss 0.0044207, acc 1
2016-09-05T18:09:07.983065: step 6224, loss 0.00358571, acc 1
2016-09-05T18:09:08.198964: step 6225, loss 0.00434112, acc 1
2016-09-05T18:09:08.430757: step 6226, loss 0.00392233, acc 1
2016-09-05T18:09:08.664866: step 6227, loss 0.00419549, acc 1
2016-09-05T18:09:08.900656: step 6228, loss 0.00346832, acc 1
2016-09-05T18:09:09.098114: step 6229, loss 0.00379856, acc 1
2016-09-05T18:09:09.301545: step 6230, loss 0.00582635, acc 1
2016-09-05T18:09:09.512694: step 6231, loss 0.00405851, acc 1
2016-09-05T18:09:09.734346: step 6232, loss 0.00381224, acc 1
2016-09-05T18:09:09.965678: step 6233, loss 0.00389886, acc 1
2016-09-05T18:09:10.169702: step 6234, loss 0.00439405, acc 1
2016-09-05T18:09:10.405498: step 6235, loss 0.00382791, acc 1
2016-09-05T18:09:10.612766: step 6236, loss 0.00359776, acc 1
2016-09-05T18:09:10.819994: step 6237, loss 0.00467426, acc 1
2016-09-05T18:09:11.015455: step 6238, loss 0.00355257, acc 1
2016-09-05T18:09:11.232579: step 6239, loss 0.0038972, acc 1
2016-09-05T18:09:11.438439: step 6240, loss 0.0038729, acc 1
2016-09-05T18:09:11.663335: step 6241, loss 0.00493256, acc 1
2016-09-05T18:09:11.880030: step 6242, loss 0.00362448, acc 1
2016-09-05T18:09:12.118773: step 6243, loss 0.00339282, acc 1
2016-09-05T18:09:12.321396: step 6244, loss 0.00532856, acc 1
2016-09-05T18:09:12.545244: step 6245, loss 0.00413515, acc 1
2016-09-05T18:09:12.749985: step 6246, loss 0.00353403, acc 1
2016-09-05T18:09:12.956154: step 6247, loss 0.00370387, acc 1
2016-09-05T18:09:13.172773: step 6248, loss 0.003804, acc 1
2016-09-05T18:09:13.420634: step 6249, loss 0.00382042, acc 1
2016-09-05T18:09:13.638202: step 6250, loss 0.0038283, acc 1
2016-09-05T18:09:13.842264: step 6251, loss 0.00361085, acc 1
2016-09-05T18:09:14.051408: step 6252, loss 0.00472579, acc 1
2016-09-05T18:09:14.267821: step 6253, loss 0.00476107, acc 1
2016-09-05T18:09:14.494290: step 6254, loss 0.00383908, acc 1
2016-09-05T18:09:14.720357: step 6255, loss 0.00410735, acc 1
2016-09-05T18:09:14.952301: step 6256, loss 0.00383447, acc 1
2016-09-05T18:09:15.152841: step 6257, loss 0.00355198, acc 1
2016-09-05T18:09:15.355433: step 6258, loss 0.00349811, acc 1
2016-09-05T18:09:15.568005: step 6259, loss 0.00398355, acc 1
2016-09-05T18:09:15.785716: step 6260, loss 0.00437394, acc 1
2016-09-05T18:09:15.999273: step 6261, loss 0.00485527, acc 1
2016-09-05T18:09:16.223374: step 6262, loss 0.00445245, acc 1
2016-09-05T18:09:16.463601: step 6263, loss 0.00391713, acc 1
2016-09-05T18:09:16.667329: step 6264, loss 0.00505636, acc 1
2016-09-05T18:09:16.877558: step 6265, loss 0.00530115, acc 1
2016-09-05T18:09:17.079017: step 6266, loss 0.00445636, acc 1
2016-09-05T18:09:17.294643: step 6267, loss 0.00395969, acc 1
2016-09-05T18:09:17.506144: step 6268, loss 0.00493649, acc 1
2016-09-05T18:09:17.737321: step 6269, loss 0.00447641, acc 1
2016-09-05T18:09:17.958080: step 6270, loss 0.00410486, acc 1
2016-09-05T18:09:18.182471: step 6271, loss 0.00500892, acc 1
2016-09-05T18:09:18.397690: step 6272, loss 0.00375465, acc 1
2016-09-05T18:09:18.625062: step 6273, loss 0.00418723, acc 1
2016-09-05T18:09:18.859914: step 6274, loss 0.0038137, acc 1
2016-09-05T18:09:19.089050: step 6275, loss 0.00495536, acc 1
2016-09-05T18:09:19.314383: step 6276, loss 0.00443508, acc 1
2016-09-05T18:09:19.570982: step 6277, loss 0.00369629, acc 1
2016-09-05T18:09:19.787886: step 6278, loss 0.005845, acc 1
2016-09-05T18:09:19.982825: step 6279, loss 0.00389676, acc 1
2016-09-05T18:09:20.192806: step 6280, loss 0.00386323, acc 1
2016-09-05T18:09:20.404894: step 6281, loss 0.00388321, acc 1
2016-09-05T18:09:20.643491: step 6282, loss 0.00461244, acc 1
2016-09-05T18:09:20.868219: step 6283, loss 0.00491865, acc 1
2016-09-05T18:09:21.090589: step 6284, loss 0.00555484, acc 1
2016-09-05T18:09:21.304945: step 6285, loss 0.00351682, acc 1
2016-09-05T18:09:21.512100: step 6286, loss 0.00379288, acc 1
2016-09-05T18:09:21.726456: step 6287, loss 0.00427009, acc 1
2016-09-05T18:09:21.924185: step 6288, loss 0.00435316, acc 1
2016-09-05T18:09:22.125512: step 6289, loss 0.00502305, acc 1
2016-09-05T18:09:22.341414: step 6290, loss 0.00405006, acc 1
2016-09-05T18:09:22.560775: step 6291, loss 0.00632806, acc 1
2016-09-05T18:09:22.776685: step 6292, loss 0.00656065, acc 1
2016-09-05T18:09:23.026092: step 6293, loss 0.00438243, acc 1
2016-09-05T18:09:23.229256: step 6294, loss 0.00430987, acc 1
2016-09-05T18:09:23.426785: step 6295, loss 0.00459819, acc 1
2016-09-05T18:09:23.629091: step 6296, loss 0.00524602, acc 1
2016-09-05T18:09:23.837004: step 6297, loss 0.00468189, acc 1
2016-09-05T18:09:24.047846: step 6298, loss 0.00428656, acc 1
2016-09-05T18:09:24.298374: step 6299, loss 0.00384721, acc 1
2016-09-05T18:09:24.528761: step 6300, loss 0.00383172, acc 1

Evaluation:
2016-09-05T18:09:25.137287: step 6300, loss 1.14808, acc 0.736

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-6300

2016-09-05T18:09:25.852913: step 6301, loss 0.00445123, acc 1
2016-09-05T18:09:26.081624: step 6302, loss 0.00498229, acc 1
2016-09-05T18:09:26.324301: step 6303, loss 0.00369265, acc 1
2016-09-05T18:09:26.552132: step 6304, loss 0.00389513, acc 1
2016-09-05T18:09:26.755326: step 6305, loss 0.00436597, acc 1
2016-09-05T18:09:26.959262: step 6306, loss 0.00422724, acc 1
2016-09-05T18:09:27.180630: step 6307, loss 0.00385537, acc 1
2016-09-05T18:09:27.393402: step 6308, loss 0.0047099, acc 1
2016-09-05T18:09:27.615247: step 6309, loss 0.00380428, acc 1
2016-09-05T18:09:27.853423: step 6310, loss 0.00347172, acc 1
2016-09-05T18:09:28.067805: step 6311, loss 0.00437681, acc 1
2016-09-05T18:09:28.276940: step 6312, loss 0.00376088, acc 1
2016-09-05T18:09:28.479959: step 6313, loss 0.00520118, acc 1
2016-09-05T18:09:28.698106: step 6314, loss 0.00477385, acc 1
2016-09-05T18:09:28.921186: step 6315, loss 0.0051049, acc 1
2016-09-05T18:09:29.157432: step 6316, loss 0.00428541, acc 1
2016-09-05T18:09:29.350540: step 6317, loss 0.00550099, acc 1
2016-09-05T18:09:29.594871: step 6318, loss 0.00465128, acc 1
2016-09-05T18:09:29.841453: step 6319, loss 0.00425848, acc 1
2016-09-05T18:09:30.099672: step 6320, loss 0.00425916, acc 1
2016-09-05T18:09:30.337556: step 6321, loss 0.00395077, acc 1
2016-09-05T18:09:30.584763: step 6322, loss 0.00387597, acc 1
2016-09-05T18:09:30.832099: step 6323, loss 0.00373192, acc 1
2016-09-05T18:09:31.045375: step 6324, loss 0.00439204, acc 1
2016-09-05T18:09:31.274202: step 6325, loss 0.00488356, acc 1
2016-09-05T18:09:31.505133: step 6326, loss 0.00537836, acc 1
2016-09-05T18:09:31.711635: step 6327, loss 0.00387292, acc 1
2016-09-05T18:09:31.926720: step 6328, loss 0.00697478, acc 1
2016-09-05T18:09:32.133122: step 6329, loss 0.00420326, acc 1
2016-09-05T18:09:32.343387: step 6330, loss 0.00399324, acc 1
2016-09-05T18:09:32.546046: step 6331, loss 0.0047617, acc 1
2016-09-05T18:09:32.764729: step 6332, loss 0.00636334, acc 1
2016-09-05T18:09:32.977721: step 6333, loss 0.00402194, acc 1
2016-09-05T18:09:33.220952: step 6334, loss 0.00409308, acc 1
2016-09-05T18:09:33.431904: step 6335, loss 0.00672016, acc 1
2016-09-05T18:09:33.629584: step 6336, loss 0.00390276, acc 1
2016-09-05T18:09:33.843764: step 6337, loss 0.00603933, acc 1
2016-09-05T18:09:34.090986: step 6338, loss 0.00950943, acc 1
2016-09-05T18:09:34.342047: step 6339, loss 0.00614318, acc 1
2016-09-05T18:09:34.543860: step 6340, loss 0.0041116, acc 1
2016-09-05T18:09:34.747395: step 6341, loss 0.00449833, acc 1
2016-09-05T18:09:34.994666: step 6342, loss 0.00418073, acc 1
2016-09-05T18:09:35.222804: step 6343, loss 0.00475411, acc 1
2016-09-05T18:09:35.443545: step 6344, loss 0.0046182, acc 1
2016-09-05T18:09:35.661608: step 6345, loss 0.00417667, acc 1
2016-09-05T18:09:35.882138: step 6346, loss 0.00470332, acc 1
2016-09-05T18:09:36.105955: step 6347, loss 0.00404418, acc 1
2016-09-05T18:09:36.373340: step 6348, loss 0.00533143, acc 1
2016-09-05T18:09:36.578617: step 6349, loss 0.00542698, acc 1
2016-09-05T18:09:36.801360: step 6350, loss 0.00409716, acc 1
2016-09-05T18:09:37.018288: step 6351, loss 0.0042655, acc 1
2016-09-05T18:09:37.222858: step 6352, loss 0.00482923, acc 1
2016-09-05T18:09:37.462007: step 6353, loss 0.0044544, acc 1
2016-09-05T18:09:37.675610: step 6354, loss 0.00394021, acc 1
2016-09-05T18:09:37.881322: step 6355, loss 0.00428467, acc 1
2016-09-05T18:09:38.097460: step 6356, loss 0.00490813, acc 1
2016-09-05T18:09:38.311928: step 6357, loss 0.00799135, acc 1
2016-09-05T18:09:38.538165: step 6358, loss 0.00424154, acc 1
2016-09-05T18:09:38.774353: step 6359, loss 0.0042534, acc 1
2016-09-05T18:09:38.987442: step 6360, loss 0.00381909, acc 1
2016-09-05T18:09:39.210757: step 6361, loss 0.00436409, acc 1
2016-09-05T18:09:39.418882: step 6362, loss 0.00618111, acc 1
2016-09-05T18:09:39.644412: step 6363, loss 0.00426496, acc 1
2016-09-05T18:09:39.877464: step 6364, loss 0.00527757, acc 1
2016-09-05T18:09:40.080706: step 6365, loss 0.0049626, acc 1
2016-09-05T18:09:40.284295: step 6366, loss 0.00552417, acc 1
2016-09-05T18:09:40.488649: step 6367, loss 0.00471313, acc 1
2016-09-05T18:09:40.692888: step 6368, loss 0.00561662, acc 1
2016-09-05T18:09:40.902799: step 6369, loss 0.0039883, acc 1
2016-09-05T18:09:41.105847: step 6370, loss 0.00372306, acc 1
2016-09-05T18:09:41.321938: step 6371, loss 0.0040577, acc 1
2016-09-05T18:09:41.528168: step 6372, loss 0.00442381, acc 1
2016-09-05T18:09:41.750597: step 6373, loss 0.00491754, acc 1
2016-09-05T18:09:41.957486: step 6374, loss 0.00534782, acc 1
2016-09-05T18:09:42.176714: step 6375, loss 0.00459611, acc 1
2016-09-05T18:09:42.417065: step 6376, loss 0.00430497, acc 1
2016-09-05T18:09:42.615356: step 6377, loss 0.00450449, acc 1
2016-09-05T18:09:42.833022: step 6378, loss 0.00407252, acc 1
2016-09-05T18:09:43.044637: step 6379, loss 0.00395295, acc 1
2016-09-05T18:09:43.238282: step 6380, loss 0.00419662, acc 1
2016-09-05T18:09:43.439911: step 6381, loss 0.00498807, acc 1
2016-09-05T18:09:43.652621: step 6382, loss 0.00393071, acc 1
2016-09-05T18:09:43.860275: step 6383, loss 0.00480301, acc 1
2016-09-05T18:09:44.077948: step 6384, loss 0.00456723, acc 1
2016-09-05T18:09:44.308096: step 6385, loss 0.004551, acc 1
2016-09-05T18:09:44.532878: step 6386, loss 0.0039648, acc 1
2016-09-05T18:09:44.743178: step 6387, loss 0.00401336, acc 1
2016-09-05T18:09:44.959755: step 6388, loss 0.00404946, acc 1
2016-09-05T18:09:45.162971: step 6389, loss 0.00421208, acc 1
2016-09-05T18:09:45.389545: step 6390, loss 0.00411287, acc 1
2016-09-05T18:09:45.605085: step 6391, loss 0.0038911, acc 1
2016-09-05T18:09:45.823122: step 6392, loss 0.00449932, acc 1
2016-09-05T18:09:46.064027: step 6393, loss 0.00397508, acc 1
2016-09-05T18:09:46.269072: step 6394, loss 0.00456675, acc 1
2016-09-05T18:09:46.487823: step 6395, loss 0.00449364, acc 1
2016-09-05T18:09:46.688933: step 6396, loss 0.0036505, acc 1
2016-09-05T18:09:46.917106: step 6397, loss 0.00391462, acc 1
2016-09-05T18:09:47.146261: step 6398, loss 0.00638886, acc 1
2016-09-05T18:09:47.360586: step 6399, loss 0.00423249, acc 1
2016-09-05T18:09:47.569249: step 6400, loss 0.00357582, acc 1

Evaluation:
2016-09-05T18:09:48.179022: step 6400, loss 1.14104, acc 0.744

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-6400

2016-09-05T18:09:48.971126: step 6401, loss 0.00447374, acc 1
2016-09-05T18:09:49.115933: step 6402, loss 0.00357107, acc 1
2016-09-05T18:09:49.328800: step 6403, loss 0.00368028, acc 1
2016-09-05T18:09:49.553384: step 6404, loss 0.0035615, acc 1
2016-09-05T18:09:49.773462: step 6405, loss 0.00469239, acc 1
2016-09-05T18:09:49.995119: step 6406, loss 0.00512942, acc 1
2016-09-05T18:09:50.210015: step 6407, loss 0.00328676, acc 1
2016-09-05T18:09:50.420627: step 6408, loss 0.00353001, acc 1
2016-09-05T18:09:50.623945: step 6409, loss 0.00497102, acc 1
2016-09-05T18:09:50.823026: step 6410, loss 0.00338384, acc 1
2016-09-05T18:09:51.053785: step 6411, loss 0.00374931, acc 1
2016-09-05T18:09:51.275319: step 6412, loss 0.00402121, acc 1
2016-09-05T18:09:51.527345: step 6413, loss 0.00402426, acc 1
2016-09-05T18:09:51.745064: step 6414, loss 0.00380512, acc 1
2016-09-05T18:09:51.938125: step 6415, loss 0.00449413, acc 1
2016-09-05T18:09:52.141970: step 6416, loss 0.00345678, acc 1
2016-09-05T18:09:52.369698: step 6417, loss 0.00368573, acc 1
2016-09-05T18:09:52.589668: step 6418, loss 0.00459982, acc 1
2016-09-05T18:09:52.816965: step 6419, loss 0.00385303, acc 1
2016-09-05T18:09:53.058700: step 6420, loss 0.00350335, acc 1
2016-09-05T18:09:53.299587: step 6421, loss 0.00362037, acc 1
2016-09-05T18:09:53.533476: step 6422, loss 0.00400342, acc 1
2016-09-05T18:09:53.734905: step 6423, loss 0.00432846, acc 1
2016-09-05T18:09:53.954244: step 6424, loss 0.00396008, acc 1
2016-09-05T18:09:54.163220: step 6425, loss 0.00380239, acc 1
2016-09-05T18:09:54.363116: step 6426, loss 0.00392829, acc 1
2016-09-05T18:09:54.574718: step 6427, loss 0.00393884, acc 1
2016-09-05T18:09:54.796510: step 6428, loss 0.00314165, acc 1
2016-09-05T18:09:55.028851: step 6429, loss 0.00489444, acc 1
2016-09-05T18:09:55.250367: step 6430, loss 0.00421728, acc 1
2016-09-05T18:09:55.485721: step 6431, loss 0.00368171, acc 1
2016-09-05T18:09:55.757250: step 6432, loss 0.00360509, acc 1
2016-09-05T18:09:55.981680: step 6433, loss 0.00426234, acc 1
2016-09-05T18:09:56.186345: step 6434, loss 0.00431513, acc 1
2016-09-05T18:09:56.421290: step 6435, loss 0.00484571, acc 1
2016-09-05T18:09:56.631119: step 6436, loss 0.00442289, acc 1
2016-09-05T18:09:56.847118: step 6437, loss 0.00380093, acc 1
2016-09-05T18:09:57.085104: step 6438, loss 0.00384392, acc 1
2016-09-05T18:09:57.286304: step 6439, loss 0.00372734, acc 1
2016-09-05T18:09:57.510325: step 6440, loss 0.00464248, acc 1
2016-09-05T18:09:57.720543: step 6441, loss 0.00342832, acc 1
2016-09-05T18:09:57.939946: step 6442, loss 0.00366465, acc 1
2016-09-05T18:09:58.172051: step 6443, loss 0.0043745, acc 1
2016-09-05T18:09:58.414111: step 6444, loss 0.00358658, acc 1
2016-09-05T18:09:58.623870: step 6445, loss 0.00553089, acc 1
2016-09-05T18:09:58.863614: step 6446, loss 0.00586221, acc 1
2016-09-05T18:09:59.097457: step 6447, loss 0.00382754, acc 1
2016-09-05T18:09:59.332145: step 6448, loss 0.00461712, acc 1
2016-09-05T18:09:59.558204: step 6449, loss 0.00346321, acc 1
2016-09-05T18:09:59.780127: step 6450, loss 0.00360441, acc 1
2016-09-05T18:10:00.009015: step 6451, loss 0.00389245, acc 1
2016-09-05T18:10:00.217323: step 6452, loss 0.00406118, acc 1
2016-09-05T18:10:00.416008: step 6453, loss 0.00361144, acc 1
2016-09-05T18:10:00.617515: step 6454, loss 0.00376515, acc 1
2016-09-05T18:10:00.825183: step 6455, loss 0.00344829, acc 1
2016-09-05T18:10:01.028639: step 6456, loss 0.0040713, acc 1
2016-09-05T18:10:01.241656: step 6457, loss 0.0045352, acc 1
2016-09-05T18:10:01.463624: step 6458, loss 0.00642053, acc 1
2016-09-05T18:10:01.686878: step 6459, loss 0.00399738, acc 1
2016-09-05T18:10:01.916698: step 6460, loss 0.003484, acc 1
2016-09-05T18:10:02.141779: step 6461, loss 0.00476197, acc 1
2016-09-05T18:10:02.339967: step 6462, loss 0.0035744, acc 1
2016-09-05T18:10:02.554822: step 6463, loss 0.00396631, acc 1
2016-09-05T18:10:02.780301: step 6464, loss 0.00421934, acc 1
2016-09-05T18:10:02.980967: step 6465, loss 0.00346558, acc 1
2016-09-05T18:10:03.201346: step 6466, loss 0.00517037, acc 1
2016-09-05T18:10:03.431940: step 6467, loss 0.0041665, acc 1
2016-09-05T18:10:03.652441: step 6468, loss 0.00402837, acc 1
2016-09-05T18:10:03.866394: step 6469, loss 0.00387938, acc 1
2016-09-05T18:10:04.079651: step 6470, loss 0.00398778, acc 1
2016-09-05T18:10:04.291066: step 6471, loss 0.00403524, acc 1
2016-09-05T18:10:04.525623: step 6472, loss 0.00322245, acc 1
2016-09-05T18:10:04.747006: step 6473, loss 0.00485363, acc 1
2016-09-05T18:10:04.964772: step 6474, loss 0.00384239, acc 1
2016-09-05T18:10:05.174288: step 6475, loss 0.00487706, acc 1
2016-09-05T18:10:05.391141: step 6476, loss 0.00405969, acc 1
2016-09-05T18:10:05.615095: step 6477, loss 0.003556, acc 1
2016-09-05T18:10:05.825415: step 6478, loss 0.00370782, acc 1
2016-09-05T18:10:06.052571: step 6479, loss 0.00347907, acc 1
2016-09-05T18:10:06.257443: step 6480, loss 0.00410892, acc 1
2016-09-05T18:10:06.477033: step 6481, loss 0.0034356, acc 1
2016-09-05T18:10:06.690171: step 6482, loss 0.0044414, acc 1
2016-09-05T18:10:06.910371: step 6483, loss 0.00536152, acc 1
2016-09-05T18:10:07.137248: step 6484, loss 0.00583423, acc 1
2016-09-05T18:10:07.376076: step 6485, loss 0.00507465, acc 1
2016-09-05T18:10:07.590187: step 6486, loss 0.00411975, acc 1
2016-09-05T18:10:07.804764: step 6487, loss 0.0036111, acc 1
2016-09-05T18:10:08.013804: step 6488, loss 0.00356263, acc 1
2016-09-05T18:10:08.246498: step 6489, loss 0.00517974, acc 1
2016-09-05T18:10:08.482947: step 6490, loss 0.00628563, acc 1
2016-09-05T18:10:08.695607: step 6491, loss 0.0052077, acc 1
2016-09-05T18:10:08.907061: step 6492, loss 0.00923402, acc 1
2016-09-05T18:10:09.127004: step 6493, loss 0.00429949, acc 1
2016-09-05T18:10:09.396438: step 6494, loss 0.00369861, acc 1
2016-09-05T18:10:09.605384: step 6495, loss 0.00423621, acc 1
2016-09-05T18:10:09.818580: step 6496, loss 0.00475608, acc 1
2016-09-05T18:10:10.030232: step 6497, loss 0.00483227, acc 1
2016-09-05T18:10:10.245398: step 6498, loss 0.00622314, acc 1
2016-09-05T18:10:10.456577: step 6499, loss 0.0101198, acc 1
2016-09-05T18:10:10.691968: step 6500, loss 0.00605889, acc 1

Evaluation:
2016-09-05T18:10:11.287441: step 6500, loss 1.35808, acc 0.741

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-6500

2016-09-05T18:10:12.044607: step 6501, loss 0.00473695, acc 1
2016-09-05T18:10:12.296360: step 6502, loss 0.00497043, acc 1
2016-09-05T18:10:12.513437: step 6503, loss 0.00454954, acc 1
2016-09-05T18:10:12.754477: step 6504, loss 0.00508392, acc 1
2016-09-05T18:10:12.989780: step 6505, loss 0.00533456, acc 1
2016-09-05T18:10:13.211789: step 6506, loss 0.0055079, acc 1
2016-09-05T18:10:13.474062: step 6507, loss 0.00618491, acc 1
2016-09-05T18:10:13.675122: step 6508, loss 0.0080093, acc 1
2016-09-05T18:10:13.886330: step 6509, loss 0.00633861, acc 1
2016-09-05T18:10:14.112435: step 6510, loss 0.00525384, acc 1
2016-09-05T18:10:14.327385: step 6511, loss 0.00672727, acc 1
2016-09-05T18:10:14.553330: step 6512, loss 0.00510464, acc 1
2016-09-05T18:10:14.744341: step 6513, loss 0.00624418, acc 1
2016-09-05T18:10:14.953701: step 6514, loss 0.00536743, acc 1
2016-09-05T18:10:15.167186: step 6515, loss 0.00493853, acc 1
2016-09-05T18:10:15.380671: step 6516, loss 0.00612234, acc 1
2016-09-05T18:10:15.584289: step 6517, loss 0.00549186, acc 1
2016-09-05T18:10:15.794790: step 6518, loss 0.00648295, acc 1
2016-09-05T18:10:16.008340: step 6519, loss 0.00505104, acc 1
2016-09-05T18:10:16.233164: step 6520, loss 0.00477804, acc 1
2016-09-05T18:10:16.465110: step 6521, loss 0.00479933, acc 1
2016-09-05T18:10:16.683079: step 6522, loss 0.00498531, acc 1
2016-09-05T18:10:16.884456: step 6523, loss 0.00474042, acc 1
2016-09-05T18:10:17.111494: step 6524, loss 0.00513711, acc 1
2016-09-05T18:10:17.331255: step 6525, loss 0.00604472, acc 1
2016-09-05T18:10:17.561422: step 6526, loss 0.00459778, acc 1
2016-09-05T18:10:17.803034: step 6527, loss 0.00413989, acc 1
2016-09-05T18:10:18.019232: step 6528, loss 0.0042285, acc 1
2016-09-05T18:10:18.249924: step 6529, loss 0.00437218, acc 1
2016-09-05T18:10:18.466980: step 6530, loss 0.0055, acc 1
2016-09-05T18:10:18.692524: step 6531, loss 0.00410164, acc 1
2016-09-05T18:10:18.907575: step 6532, loss 0.00492205, acc 1
2016-09-05T18:10:19.139875: step 6533, loss 0.00525388, acc 1
2016-09-05T18:10:19.370865: step 6534, loss 0.00403778, acc 1
2016-09-05T18:10:19.589532: step 6535, loss 0.00405541, acc 1
2016-09-05T18:10:19.794317: step 6536, loss 0.00415957, acc 1
2016-09-05T18:10:19.992362: step 6537, loss 0.00424162, acc 1
2016-09-05T18:10:20.198882: step 6538, loss 0.00360182, acc 1
2016-09-05T18:10:20.398649: step 6539, loss 0.00382628, acc 1
2016-09-05T18:10:20.615569: step 6540, loss 0.00399414, acc 1
2016-09-05T18:10:20.833205: step 6541, loss 0.0033508, acc 1
2016-09-05T18:10:21.037575: step 6542, loss 0.00433388, acc 1
2016-09-05T18:10:21.250087: step 6543, loss 0.00482432, acc 1
2016-09-05T18:10:21.496674: step 6544, loss 0.00497371, acc 1
2016-09-05T18:10:21.715883: step 6545, loss 0.00503009, acc 1
2016-09-05T18:10:21.943568: step 6546, loss 0.00506108, acc 1
2016-09-05T18:10:22.158978: step 6547, loss 0.00820788, acc 1
2016-09-05T18:10:22.384591: step 6548, loss 0.00414684, acc 1
2016-09-05T18:10:22.614608: step 6549, loss 0.0039949, acc 1
2016-09-05T18:10:22.814802: step 6550, loss 0.00419195, acc 1
2016-09-05T18:10:23.031305: step 6551, loss 0.00469525, acc 1
2016-09-05T18:10:23.229729: step 6552, loss 0.00375814, acc 1
2016-09-05T18:10:23.438565: step 6553, loss 0.0041501, acc 1
2016-09-05T18:10:23.657729: step 6554, loss 0.00479573, acc 1
2016-09-05T18:10:23.879586: step 6555, loss 0.00449437, acc 1
2016-09-05T18:10:24.089526: step 6556, loss 0.0037762, acc 1
2016-09-05T18:10:24.307792: step 6557, loss 0.00430874, acc 1
2016-09-05T18:10:24.518316: step 6558, loss 0.00410686, acc 1
2016-09-05T18:10:24.734260: step 6559, loss 0.00366948, acc 1
2016-09-05T18:10:24.934864: step 6560, loss 0.00350747, acc 1
2016-09-05T18:10:25.160128: step 6561, loss 0.00373617, acc 1
2016-09-05T18:10:25.410875: step 6562, loss 0.00383272, acc 1
2016-09-05T18:10:25.629457: step 6563, loss 0.00366233, acc 1
2016-09-05T18:10:25.850322: step 6564, loss 0.00367659, acc 1
2016-09-05T18:10:26.085607: step 6565, loss 0.00439965, acc 1
2016-09-05T18:10:26.305925: step 6566, loss 0.00397224, acc 1
2016-09-05T18:10:26.535369: step 6567, loss 0.00378699, acc 1
2016-09-05T18:10:26.790047: step 6568, loss 0.00327566, acc 1
2016-09-05T18:10:27.010868: step 6569, loss 0.00384922, acc 1
2016-09-05T18:10:27.231853: step 6570, loss 0.00358712, acc 1
2016-09-05T18:10:27.458042: step 6571, loss 0.00328022, acc 1
2016-09-05T18:10:27.649397: step 6572, loss 0.00341581, acc 1
2016-09-05T18:10:27.901159: step 6573, loss 0.00359492, acc 1
2016-09-05T18:10:28.127538: step 6574, loss 0.00388228, acc 1
2016-09-05T18:10:28.385852: step 6575, loss 0.00412569, acc 1
2016-09-05T18:10:28.598122: step 6576, loss 0.00402872, acc 1
2016-09-05T18:10:28.835028: step 6577, loss 0.00387057, acc 1
2016-09-05T18:10:29.073531: step 6578, loss 0.00302995, acc 1
2016-09-05T18:10:29.276354: step 6579, loss 0.00595838, acc 1
2016-09-05T18:10:29.490507: step 6580, loss 0.00525533, acc 1
2016-09-05T18:10:29.705603: step 6581, loss 0.00354955, acc 1
2016-09-05T18:10:29.914165: step 6582, loss 0.0048174, acc 1
2016-09-05T18:10:30.117966: step 6583, loss 0.00430839, acc 1
2016-09-05T18:10:30.333847: step 6584, loss 0.00512251, acc 1
2016-09-05T18:10:30.554214: step 6585, loss 0.00332188, acc 1
2016-09-05T18:10:30.768586: step 6586, loss 0.00407367, acc 1
2016-09-05T18:10:30.980839: step 6587, loss 0.00558555, acc 1
2016-09-05T18:10:31.212987: step 6588, loss 0.00410893, acc 1
2016-09-05T18:10:31.419650: step 6589, loss 0.0039687, acc 1
2016-09-05T18:10:31.649403: step 6590, loss 0.004828, acc 1
2016-09-05T18:10:31.879832: step 6591, loss 0.00475846, acc 1
2016-09-05T18:10:32.101408: step 6592, loss 0.00380916, acc 1
2016-09-05T18:10:32.313144: step 6593, loss 0.00394311, acc 1
2016-09-05T18:10:32.515695: step 6594, loss 0.00465928, acc 1
2016-09-05T18:10:32.734725: step 6595, loss 0.00401188, acc 1
2016-09-05T18:10:32.857548: step 6596, loss 0.00397253, acc 1
2016-09-05T18:10:33.125331: step 6597, loss 0.0036982, acc 1
2016-09-05T18:10:33.329921: step 6598, loss 0.00359124, acc 1
2016-09-05T18:10:33.545447: step 6599, loss 0.00374879, acc 1
2016-09-05T18:10:33.752673: step 6600, loss 0.00355502, acc 1

Evaluation:
2016-09-05T18:10:34.367640: step 6600, loss 1.23294, acc 0.738

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-6600

2016-09-05T18:10:35.085689: step 6601, loss 0.00405184, acc 1
2016-09-05T18:10:35.325425: step 6602, loss 0.00394956, acc 1
2016-09-05T18:10:35.564547: step 6603, loss 0.00395246, acc 1
2016-09-05T18:10:35.782614: step 6604, loss 0.003757, acc 1
2016-09-05T18:10:36.004190: step 6605, loss 0.0040377, acc 1
2016-09-05T18:10:36.203762: step 6606, loss 0.00354291, acc 1
2016-09-05T18:10:36.445405: step 6607, loss 0.00333583, acc 1
2016-09-05T18:10:36.661305: step 6608, loss 0.00617948, acc 1
2016-09-05T18:10:36.889676: step 6609, loss 0.00329651, acc 1
2016-09-05T18:10:37.101956: step 6610, loss 0.00455671, acc 1
2016-09-05T18:10:37.316260: step 6611, loss 0.00385804, acc 1
2016-09-05T18:10:37.545023: step 6612, loss 0.0039236, acc 1
2016-09-05T18:10:37.805843: step 6613, loss 0.00557394, acc 1
2016-09-05T18:10:38.025726: step 6614, loss 0.00335096, acc 1
2016-09-05T18:10:38.264926: step 6615, loss 0.00353095, acc 1
2016-09-05T18:10:38.506317: step 6616, loss 0.00376412, acc 1
2016-09-05T18:10:38.745275: step 6617, loss 0.00381362, acc 1
2016-09-05T18:10:38.987083: step 6618, loss 0.00425027, acc 1
2016-09-05T18:10:39.204165: step 6619, loss 0.00340889, acc 1
2016-09-05T18:10:39.413423: step 6620, loss 0.00485986, acc 1
2016-09-05T18:10:39.626615: step 6621, loss 0.00377012, acc 1
2016-09-05T18:10:39.843333: step 6622, loss 0.0044398, acc 1
2016-09-05T18:10:40.067668: step 6623, loss 0.00349491, acc 1
2016-09-05T18:10:40.273439: step 6624, loss 0.00460547, acc 1
2016-09-05T18:10:40.487592: step 6625, loss 0.00412419, acc 1
2016-09-05T18:10:40.707317: step 6626, loss 0.00484531, acc 1
2016-09-05T18:10:40.938507: step 6627, loss 0.00512934, acc 1
2016-09-05T18:10:41.156231: step 6628, loss 0.0036967, acc 1
2016-09-05T18:10:41.367270: step 6629, loss 0.00392079, acc 1
2016-09-05T18:10:41.611560: step 6630, loss 0.00440181, acc 1
2016-09-05T18:10:41.814632: step 6631, loss 0.0034366, acc 1
2016-09-05T18:10:42.034183: step 6632, loss 0.00396413, acc 1
2016-09-05T18:10:42.248543: step 6633, loss 0.00351052, acc 1
2016-09-05T18:10:42.469302: step 6634, loss 0.00568764, acc 1
2016-09-05T18:10:42.684441: step 6635, loss 0.00344826, acc 1
2016-09-05T18:10:42.940105: step 6636, loss 0.00478671, acc 1
2016-09-05T18:10:43.151368: step 6637, loss 0.00383811, acc 1
2016-09-05T18:10:43.401372: step 6638, loss 0.003523, acc 1
2016-09-05T18:10:43.649351: step 6639, loss 0.00364453, acc 1
2016-09-05T18:10:43.890125: step 6640, loss 0.00416376, acc 1
2016-09-05T18:10:44.105012: step 6641, loss 0.00368685, acc 1
2016-09-05T18:10:44.343488: step 6642, loss 0.00394031, acc 1
2016-09-05T18:10:44.567317: step 6643, loss 0.0032816, acc 1
2016-09-05T18:10:44.780531: step 6644, loss 0.00390906, acc 1
2016-09-05T18:10:44.997291: step 6645, loss 0.00424567, acc 1
2016-09-05T18:10:45.208220: step 6646, loss 0.0041475, acc 1
2016-09-05T18:10:45.444022: step 6647, loss 0.00410431, acc 1
2016-09-05T18:10:45.657917: step 6648, loss 0.00422524, acc 1
2016-09-05T18:10:45.863839: step 6649, loss 0.00371537, acc 1
2016-09-05T18:10:46.087911: step 6650, loss 0.00404849, acc 1
2016-09-05T18:10:46.300790: step 6651, loss 0.00374393, acc 1
2016-09-05T18:10:46.517254: step 6652, loss 0.00388779, acc 1
2016-09-05T18:10:46.755492: step 6653, loss 0.00460775, acc 1
2016-09-05T18:10:46.990060: step 6654, loss 0.00332616, acc 1
2016-09-05T18:10:47.223214: step 6655, loss 0.00435066, acc 1
2016-09-05T18:10:47.452791: step 6656, loss 0.00356426, acc 1
2016-09-05T18:10:47.672422: step 6657, loss 0.00386772, acc 1
2016-09-05T18:10:47.898528: step 6658, loss 0.00489741, acc 1
2016-09-05T18:10:48.134545: step 6659, loss 0.00444767, acc 1
2016-09-05T18:10:48.348601: step 6660, loss 0.00414071, acc 1
2016-09-05T18:10:48.590317: step 6661, loss 0.00343631, acc 1
2016-09-05T18:10:48.796194: step 6662, loss 0.0035066, acc 1
2016-09-05T18:10:49.001222: step 6663, loss 0.00373903, acc 1
2016-09-05T18:10:49.204263: step 6664, loss 0.00388986, acc 1
2016-09-05T18:10:49.426086: step 6665, loss 0.00360135, acc 1
2016-09-05T18:10:49.673402: step 6666, loss 0.0044736, acc 1
2016-09-05T18:10:49.869201: step 6667, loss 0.00397159, acc 1
2016-09-05T18:10:50.105243: step 6668, loss 0.00355272, acc 1
2016-09-05T18:10:50.310925: step 6669, loss 0.00390822, acc 1
2016-09-05T18:10:50.543609: step 6670, loss 0.00382377, acc 1
2016-09-05T18:10:50.775465: step 6671, loss 0.0036623, acc 1
2016-09-05T18:10:51.023299: step 6672, loss 0.00383531, acc 1
2016-09-05T18:10:51.251066: step 6673, loss 0.00477703, acc 1
2016-09-05T18:10:51.453909: step 6674, loss 0.00368242, acc 1
2016-09-05T18:10:51.688505: step 6675, loss 0.00401788, acc 1
2016-09-05T18:10:51.887408: step 6676, loss 0.00400271, acc 1
2016-09-05T18:10:52.135383: step 6677, loss 0.00340935, acc 1
2016-09-05T18:10:52.353200: step 6678, loss 0.00463342, acc 1
2016-09-05T18:10:52.594506: step 6679, loss 0.00415424, acc 1
2016-09-05T18:10:52.846836: step 6680, loss 0.00357594, acc 1
2016-09-05T18:10:53.085129: step 6681, loss 0.0035685, acc 1
2016-09-05T18:10:53.298222: step 6682, loss 0.00341365, acc 1
2016-09-05T18:10:53.544854: step 6683, loss 0.0043559, acc 1
2016-09-05T18:10:53.760894: step 6684, loss 0.00332299, acc 1
2016-09-05T18:10:53.976870: step 6685, loss 0.00399084, acc 1
2016-09-05T18:10:54.191377: step 6686, loss 0.00396988, acc 1
2016-09-05T18:10:54.391330: step 6687, loss 0.00375953, acc 1
2016-09-05T18:10:54.640215: step 6688, loss 0.003814, acc 1
2016-09-05T18:10:54.839670: step 6689, loss 0.00319196, acc 1
2016-09-05T18:10:55.052571: step 6690, loss 0.00560729, acc 1
2016-09-05T18:10:55.263839: step 6691, loss 0.00366745, acc 1
2016-09-05T18:10:55.491690: step 6692, loss 0.00340921, acc 1
2016-09-05T18:10:55.696314: step 6693, loss 0.00325948, acc 1
2016-09-05T18:10:55.921241: step 6694, loss 0.00302842, acc 1
2016-09-05T18:10:56.152268: step 6695, loss 0.00354403, acc 1
2016-09-05T18:10:56.362541: step 6696, loss 0.0035856, acc 1
2016-09-05T18:10:56.580815: step 6697, loss 0.00417847, acc 1
2016-09-05T18:10:56.798497: step 6698, loss 0.00326463, acc 1
2016-09-05T18:10:57.008987: step 6699, loss 0.00314804, acc 1
2016-09-05T18:10:57.261787: step 6700, loss 0.00298039, acc 1

Evaluation:
2016-09-05T18:10:57.888842: step 6700, loss 1.14009, acc 0.737

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-6700

2016-09-05T18:10:58.632720: step 6701, loss 0.00432035, acc 1
2016-09-05T18:10:58.869498: step 6702, loss 0.00347499, acc 1
2016-09-05T18:10:59.103506: step 6703, loss 0.00303697, acc 1
2016-09-05T18:10:59.381977: step 6704, loss 0.00308905, acc 1
2016-09-05T18:10:59.607887: step 6705, loss 0.00349755, acc 1
2016-09-05T18:10:59.825684: step 6706, loss 0.00409639, acc 1
2016-09-05T18:11:00.032349: step 6707, loss 0.00314746, acc 1
2016-09-05T18:11:00.259912: step 6708, loss 0.00302976, acc 1
2016-09-05T18:11:00.485271: step 6709, loss 0.00388803, acc 1
2016-09-05T18:11:00.701576: step 6710, loss 0.00318279, acc 1
2016-09-05T18:11:00.931560: step 6711, loss 0.00322351, acc 1
2016-09-05T18:11:01.144646: step 6712, loss 0.00452997, acc 1
2016-09-05T18:11:01.363167: step 6713, loss 0.0029439, acc 1
2016-09-05T18:11:01.606126: step 6714, loss 0.00309736, acc 1
2016-09-05T18:11:01.807969: step 6715, loss 0.00331452, acc 1
2016-09-05T18:11:02.019448: step 6716, loss 0.00539599, acc 1
2016-09-05T18:11:02.225656: step 6717, loss 0.00309591, acc 1
2016-09-05T18:11:02.453386: step 6718, loss 0.00546288, acc 1
2016-09-05T18:11:02.687327: step 6719, loss 0.00372261, acc 1
2016-09-05T18:11:02.928264: step 6720, loss 0.00335981, acc 1
2016-09-05T18:11:03.134794: step 6721, loss 0.00593929, acc 1
2016-09-05T18:11:03.376496: step 6722, loss 0.00317128, acc 1
2016-09-05T18:11:03.596106: step 6723, loss 0.00361689, acc 1
2016-09-05T18:11:03.843496: step 6724, loss 0.00423738, acc 1
2016-09-05T18:11:04.075496: step 6725, loss 0.00382285, acc 1
2016-09-05T18:11:04.315648: step 6726, loss 0.00408594, acc 1
2016-09-05T18:11:04.537497: step 6727, loss 0.00414105, acc 1
2016-09-05T18:11:04.746899: step 6728, loss 0.00361287, acc 1
2016-09-05T18:11:04.946302: step 6729, loss 0.00430858, acc 1
2016-09-05T18:11:05.149582: step 6730, loss 0.00358371, acc 1
2016-09-05T18:11:05.371257: step 6731, loss 0.00378779, acc 1
2016-09-05T18:11:05.594953: step 6732, loss 0.00416199, acc 1
2016-09-05T18:11:05.819143: step 6733, loss 0.00392947, acc 1
2016-09-05T18:11:06.044211: step 6734, loss 0.00378783, acc 1
2016-09-05T18:11:06.262802: step 6735, loss 0.00435882, acc 1
2016-09-05T18:11:06.489969: step 6736, loss 0.00382801, acc 1
2016-09-05T18:11:06.687752: step 6737, loss 0.00369912, acc 1
2016-09-05T18:11:06.910396: step 6738, loss 0.00425667, acc 1
2016-09-05T18:11:07.132466: step 6739, loss 0.0035792, acc 1
2016-09-05T18:11:07.377381: step 6740, loss 0.00422764, acc 1
2016-09-05T18:11:07.637393: step 6741, loss 0.00378361, acc 1
2016-09-05T18:11:07.879946: step 6742, loss 0.00665833, acc 1
2016-09-05T18:11:08.091485: step 6743, loss 0.00432412, acc 1
2016-09-05T18:11:08.292588: step 6744, loss 0.00362195, acc 1
2016-09-05T18:11:08.507162: step 6745, loss 0.00438551, acc 1
2016-09-05T18:11:08.721849: step 6746, loss 0.00580265, acc 1
2016-09-05T18:11:08.969912: step 6747, loss 0.00457807, acc 1
2016-09-05T18:11:09.167415: step 6748, loss 0.00472052, acc 1
2016-09-05T18:11:09.389315: step 6749, loss 0.003379, acc 1
2016-09-05T18:11:09.604285: step 6750, loss 0.00325981, acc 1
2016-09-05T18:11:09.819525: step 6751, loss 0.00499117, acc 1
2016-09-05T18:11:10.038746: step 6752, loss 0.00329751, acc 1
2016-09-05T18:11:10.284304: step 6753, loss 0.00525735, acc 1
2016-09-05T18:11:10.495872: step 6754, loss 0.00357973, acc 1
2016-09-05T18:11:10.698746: step 6755, loss 0.00390661, acc 1
2016-09-05T18:11:10.907200: step 6756, loss 0.00341111, acc 1
2016-09-05T18:11:11.127807: step 6757, loss 0.00377676, acc 1
2016-09-05T18:11:11.356361: step 6758, loss 0.00314538, acc 1
2016-09-05T18:11:11.572354: step 6759, loss 0.00350939, acc 1
2016-09-05T18:11:11.803673: step 6760, loss 0.0033877, acc 1
2016-09-05T18:11:12.055148: step 6761, loss 0.00391555, acc 1
2016-09-05T18:11:12.283468: step 6762, loss 0.00324243, acc 1
2016-09-05T18:11:12.503320: step 6763, loss 0.00445384, acc 1
2016-09-05T18:11:12.701363: step 6764, loss 0.00408167, acc 1
2016-09-05T18:11:12.910830: step 6765, loss 0.00399612, acc 1
2016-09-05T18:11:13.111085: step 6766, loss 0.004015, acc 1
2016-09-05T18:11:13.320981: step 6767, loss 0.00359032, acc 1
2016-09-05T18:11:13.522147: step 6768, loss 0.00424338, acc 1
2016-09-05T18:11:13.753124: step 6769, loss 0.00347307, acc 1
2016-09-05T18:11:13.957838: step 6770, loss 0.00298343, acc 1
2016-09-05T18:11:14.197099: step 6771, loss 0.00365973, acc 1
2016-09-05T18:11:14.420817: step 6772, loss 0.0044427, acc 1
2016-09-05T18:11:14.634780: step 6773, loss 0.00367268, acc 1
2016-09-05T18:11:14.871705: step 6774, loss 0.00490141, acc 1
2016-09-05T18:11:15.069756: step 6775, loss 0.00446037, acc 1
2016-09-05T18:11:15.301049: step 6776, loss 0.00350955, acc 1
2016-09-05T18:11:15.533002: step 6777, loss 0.00364448, acc 1
2016-09-05T18:11:15.750133: step 6778, loss 0.00457722, acc 1
2016-09-05T18:11:15.946090: step 6779, loss 0.00329421, acc 1
2016-09-05T18:11:16.165089: step 6780, loss 0.00377471, acc 1
2016-09-05T18:11:16.379264: step 6781, loss 0.00367897, acc 1
2016-09-05T18:11:16.606849: step 6782, loss 0.00627935, acc 1
2016-09-05T18:11:16.817427: step 6783, loss 0.00439157, acc 1
2016-09-05T18:11:17.038182: step 6784, loss 0.00369668, acc 1
2016-09-05T18:11:17.235142: step 6785, loss 0.00380436, acc 1
2016-09-05T18:11:17.451826: step 6786, loss 0.0032497, acc 1
2016-09-05T18:11:17.665438: step 6787, loss 0.00342308, acc 1
2016-09-05T18:11:17.898090: step 6788, loss 0.00322421, acc 1
2016-09-05T18:11:18.115548: step 6789, loss 0.00349498, acc 1
2016-09-05T18:11:18.277191: step 6790, loss 0.00329372, acc 1
2016-09-05T18:11:18.471316: step 6791, loss 0.00347298, acc 1
2016-09-05T18:11:18.686408: step 6792, loss 0.00341638, acc 1
2016-09-05T18:11:18.912047: step 6793, loss 0.00345217, acc 1
2016-09-05T18:11:19.128870: step 6794, loss 0.00338912, acc 1
2016-09-05T18:11:19.339335: step 6795, loss 0.00306272, acc 1
2016-09-05T18:11:19.576996: step 6796, loss 0.00335056, acc 1
2016-09-05T18:11:19.790263: step 6797, loss 0.00357083, acc 1
2016-09-05T18:11:19.998202: step 6798, loss 0.00357081, acc 1
2016-09-05T18:11:20.224038: step 6799, loss 0.00318928, acc 1
2016-09-05T18:11:20.443119: step 6800, loss 0.00328916, acc 1

Evaluation:
2016-09-05T18:11:21.060548: step 6800, loss 1.13984, acc 0.736

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-6800

2016-09-05T18:11:21.721948: step 6801, loss 0.00345758, acc 1
2016-09-05T18:11:21.934285: step 6802, loss 0.00331759, acc 1
2016-09-05T18:11:22.193437: step 6803, loss 0.00500045, acc 1
2016-09-05T18:11:22.407721: step 6804, loss 0.00350818, acc 1
2016-09-05T18:11:22.623558: step 6805, loss 0.00388386, acc 1
2016-09-05T18:11:22.863295: step 6806, loss 0.00331776, acc 1
2016-09-05T18:11:23.085521: step 6807, loss 0.00337742, acc 1
2016-09-05T18:11:23.320011: step 6808, loss 0.00328918, acc 1
2016-09-05T18:11:23.542414: step 6809, loss 0.00309492, acc 1
2016-09-05T18:11:23.756376: step 6810, loss 0.00332767, acc 1
2016-09-05T18:11:23.966611: step 6811, loss 0.00443783, acc 1
2016-09-05T18:11:24.220888: step 6812, loss 0.00331239, acc 1
2016-09-05T18:11:24.442273: step 6813, loss 0.00695052, acc 1
2016-09-05T18:11:24.662832: step 6814, loss 0.00304308, acc 1
2016-09-05T18:11:24.883324: step 6815, loss 0.00346882, acc 1
2016-09-05T18:11:25.121424: step 6816, loss 0.00943628, acc 1
2016-09-05T18:11:25.338281: step 6817, loss 0.00384147, acc 1
2016-09-05T18:11:25.545538: step 6818, loss 0.00318675, acc 1
2016-09-05T18:11:25.750236: step 6819, loss 0.00511134, acc 1
2016-09-05T18:11:25.975658: step 6820, loss 0.00368017, acc 1
2016-09-05T18:11:26.192651: step 6821, loss 0.0036079, acc 1
2016-09-05T18:11:26.410272: step 6822, loss 0.003859, acc 1
2016-09-05T18:11:26.629398: step 6823, loss 0.00512149, acc 1
2016-09-05T18:11:26.852457: step 6824, loss 0.00534483, acc 1
2016-09-05T18:11:27.059046: step 6825, loss 0.0068795, acc 1
2016-09-05T18:11:27.258438: step 6826, loss 0.00578072, acc 1
2016-09-05T18:11:27.474841: step 6827, loss 0.00456715, acc 1
2016-09-05T18:11:27.698068: step 6828, loss 0.00453354, acc 1
2016-09-05T18:11:27.909835: step 6829, loss 0.0044302, acc 1
2016-09-05T18:11:28.143364: step 6830, loss 0.00565889, acc 1
2016-09-05T18:11:28.369893: step 6831, loss 0.00500526, acc 1
2016-09-05T18:11:28.572856: step 6832, loss 0.00479, acc 1
2016-09-05T18:11:28.789801: step 6833, loss 0.00499425, acc 1
2016-09-05T18:11:28.999578: step 6834, loss 0.00506972, acc 1
2016-09-05T18:11:29.215004: step 6835, loss 0.00485977, acc 1
2016-09-05T18:11:29.434052: step 6836, loss 0.00514347, acc 1
2016-09-05T18:11:29.639196: step 6837, loss 0.00471961, acc 1
2016-09-05T18:11:29.875054: step 6838, loss 0.00456717, acc 1
2016-09-05T18:11:30.079584: step 6839, loss 0.00453583, acc 1
2016-09-05T18:11:30.286964: step 6840, loss 0.00450501, acc 1
2016-09-05T18:11:30.507866: step 6841, loss 0.00459094, acc 1
2016-09-05T18:11:30.730971: step 6842, loss 0.00481602, acc 1
2016-09-05T18:11:30.949464: step 6843, loss 0.00456219, acc 1
2016-09-05T18:11:31.188018: step 6844, loss 0.00430784, acc 1
2016-09-05T18:11:31.407589: step 6845, loss 0.00745142, acc 1
2016-09-05T18:11:31.630698: step 6846, loss 0.00484035, acc 1
2016-09-05T18:11:31.871982: step 6847, loss 0.00430928, acc 1
2016-09-05T18:11:32.096496: step 6848, loss 0.00423721, acc 1
2016-09-05T18:11:32.309302: step 6849, loss 0.00396538, acc 1
2016-09-05T18:11:32.512602: step 6850, loss 0.00584534, acc 1
2016-09-05T18:11:32.736915: step 6851, loss 0.00359522, acc 1
2016-09-05T18:11:32.930057: step 6852, loss 0.00386533, acc 1
2016-09-05T18:11:33.156662: step 6853, loss 0.00424351, acc 1
2016-09-05T18:11:33.377263: step 6854, loss 0.00398825, acc 1
2016-09-05T18:11:33.604431: step 6855, loss 0.00367674, acc 1
2016-09-05T18:11:33.800704: step 6856, loss 0.00385973, acc 1
2016-09-05T18:11:34.011200: step 6857, loss 0.00360483, acc 1
2016-09-05T18:11:34.224830: step 6858, loss 0.00349255, acc 1
2016-09-05T18:11:34.437678: step 6859, loss 0.00348731, acc 1
2016-09-05T18:11:34.669732: step 6860, loss 0.00715992, acc 1
2016-09-05T18:11:34.883325: step 6861, loss 0.00324716, acc 1
2016-09-05T18:11:35.130043: step 6862, loss 0.00402409, acc 1
2016-09-05T18:11:35.349584: step 6863, loss 0.00418864, acc 1
2016-09-05T18:11:35.559452: step 6864, loss 0.00335628, acc 1
2016-09-05T18:11:35.776345: step 6865, loss 0.0037751, acc 1
2016-09-05T18:11:35.976753: step 6866, loss 0.00545501, acc 1
2016-09-05T18:11:36.194079: step 6867, loss 0.00432863, acc 1
2016-09-05T18:11:36.417195: step 6868, loss 0.00309328, acc 1
2016-09-05T18:11:36.637965: step 6869, loss 0.00383653, acc 1
2016-09-05T18:11:36.859667: step 6870, loss 0.00407764, acc 1
2016-09-05T18:11:37.064101: step 6871, loss 0.00342155, acc 1
2016-09-05T18:11:37.284420: step 6872, loss 0.00545471, acc 1
2016-09-05T18:11:37.503655: step 6873, loss 0.00311967, acc 1
2016-09-05T18:11:37.745772: step 6874, loss 0.00313305, acc 1
2016-09-05T18:11:37.960489: step 6875, loss 0.00350642, acc 1
2016-09-05T18:11:38.189117: step 6876, loss 0.00368891, acc 1
2016-09-05T18:11:38.421810: step 6877, loss 0.00477268, acc 1
2016-09-05T18:11:38.617962: step 6878, loss 0.00321147, acc 1
2016-09-05T18:11:38.827417: step 6879, loss 0.00316943, acc 1
2016-09-05T18:11:39.061976: step 6880, loss 0.00376703, acc 1
2016-09-05T18:11:39.278262: step 6881, loss 0.0034059, acc 1
2016-09-05T18:11:39.492696: step 6882, loss 0.00319671, acc 1
2016-09-05T18:11:39.724128: step 6883, loss 0.00426172, acc 1
2016-09-05T18:11:39.963068: step 6884, loss 0.00335113, acc 1
2016-09-05T18:11:40.188276: step 6885, loss 0.0034374, acc 1
2016-09-05T18:11:40.438857: step 6886, loss 0.00346484, acc 1
2016-09-05T18:11:40.657403: step 6887, loss 0.00327144, acc 1
2016-09-05T18:11:40.882109: step 6888, loss 0.003005, acc 1
2016-09-05T18:11:41.094220: step 6889, loss 0.00407981, acc 1
2016-09-05T18:11:41.302149: step 6890, loss 0.00356005, acc 1
2016-09-05T18:11:41.508207: step 6891, loss 0.00369813, acc 1
2016-09-05T18:11:41.742549: step 6892, loss 0.00330629, acc 1
2016-09-05T18:11:41.971264: step 6893, loss 0.00377212, acc 1
2016-09-05T18:11:42.181879: step 6894, loss 0.00327617, acc 1
2016-09-05T18:11:42.377772: step 6895, loss 0.00568453, acc 1
2016-09-05T18:11:42.585371: step 6896, loss 0.00515354, acc 1
2016-09-05T18:11:42.794309: step 6897, loss 0.00370123, acc 1
2016-09-05T18:11:43.010945: step 6898, loss 0.00353842, acc 1
2016-09-05T18:11:43.212171: step 6899, loss 0.00487748, acc 1
2016-09-05T18:11:43.437282: step 6900, loss 0.00630659, acc 1

Evaluation:
2016-09-05T18:11:44.046126: step 6900, loss 1.20606, acc 0.736

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-6900

2016-09-05T18:11:44.716166: step 6901, loss 0.00350047, acc 1
2016-09-05T18:11:44.924899: step 6902, loss 0.00357048, acc 1
2016-09-05T18:11:45.123593: step 6903, loss 0.00432145, acc 1
2016-09-05T18:11:45.347280: step 6904, loss 0.00417851, acc 1
2016-09-05T18:11:45.560504: step 6905, loss 0.00426569, acc 1
2016-09-05T18:11:45.782209: step 6906, loss 0.00347209, acc 1
2016-09-05T18:11:46.013408: step 6907, loss 0.0044618, acc 1
2016-09-05T18:11:46.229772: step 6908, loss 0.00788296, acc 1
2016-09-05T18:11:46.436594: step 6909, loss 0.00362625, acc 1
2016-09-05T18:11:46.660399: step 6910, loss 0.00382822, acc 1
2016-09-05T18:11:46.887424: step 6911, loss 0.00431443, acc 1
2016-09-05T18:11:47.103137: step 6912, loss 0.00446727, acc 1
2016-09-05T18:11:47.339117: step 6913, loss 0.00384296, acc 1
2016-09-05T18:11:47.569707: step 6914, loss 0.00433054, acc 1
2016-09-05T18:11:47.796804: step 6915, loss 0.00579995, acc 1
2016-09-05T18:11:48.004343: step 6916, loss 0.00460089, acc 1
2016-09-05T18:11:48.246196: step 6917, loss 0.00999756, acc 1
2016-09-05T18:11:48.449430: step 6918, loss 0.00397785, acc 1
2016-09-05T18:11:48.671122: step 6919, loss 0.00458484, acc 1
2016-09-05T18:11:48.867475: step 6920, loss 0.0043791, acc 1
2016-09-05T18:11:49.071031: step 6921, loss 0.00390971, acc 1
2016-09-05T18:11:49.260929: step 6922, loss 0.00423488, acc 1
2016-09-05T18:11:49.453411: step 6923, loss 0.00661862, acc 1
2016-09-05T18:11:49.659458: step 6924, loss 0.00426641, acc 1
2016-09-05T18:11:49.868488: step 6925, loss 0.0040292, acc 1
2016-09-05T18:11:50.080708: step 6926, loss 0.00400947, acc 1
2016-09-05T18:11:50.299633: step 6927, loss 0.00397833, acc 1
2016-09-05T18:11:50.518870: step 6928, loss 0.00482663, acc 1
2016-09-05T18:11:50.753302: step 6929, loss 0.00427918, acc 1
2016-09-05T18:11:50.959978: step 6930, loss 0.00436738, acc 1
2016-09-05T18:11:51.184955: step 6931, loss 0.0040223, acc 1
2016-09-05T18:11:51.394656: step 6932, loss 0.00420744, acc 1
2016-09-05T18:11:51.603934: step 6933, loss 0.00434567, acc 1
2016-09-05T18:11:51.822144: step 6934, loss 0.00416964, acc 1
2016-09-05T18:11:52.051889: step 6935, loss 0.0041063, acc 1
2016-09-05T18:11:52.260928: step 6936, loss 0.00419428, acc 1
2016-09-05T18:11:52.492578: step 6937, loss 0.0051402, acc 1
2016-09-05T18:11:52.720262: step 6938, loss 0.00353658, acc 1
2016-09-05T18:11:52.933430: step 6939, loss 0.00390633, acc 1
2016-09-05T18:11:53.159225: step 6940, loss 0.00402346, acc 1
2016-09-05T18:11:53.373242: step 6941, loss 0.00356007, acc 1
2016-09-05T18:11:53.621880: step 6942, loss 0.00344841, acc 1
2016-09-05T18:11:53.833339: step 6943, loss 0.0032732, acc 1
2016-09-05T18:11:54.044637: step 6944, loss 0.00390291, acc 1
2016-09-05T18:11:54.253673: step 6945, loss 0.00368758, acc 1
2016-09-05T18:11:54.461632: step 6946, loss 0.00396793, acc 1
2016-09-05T18:11:54.668368: step 6947, loss 0.00337972, acc 1
2016-09-05T18:11:54.887690: step 6948, loss 0.00343996, acc 1
2016-09-05T18:11:55.127471: step 6949, loss 0.00287457, acc 1
2016-09-05T18:11:55.340777: step 6950, loss 0.00415349, acc 1
2016-09-05T18:11:55.571751: step 6951, loss 0.00472837, acc 1
2016-09-05T18:11:55.787512: step 6952, loss 0.00298859, acc 1
2016-09-05T18:11:55.991525: step 6953, loss 0.00381522, acc 1
2016-09-05T18:11:56.215712: step 6954, loss 0.00385294, acc 1
2016-09-05T18:11:56.428625: step 6955, loss 0.00336422, acc 1
2016-09-05T18:11:56.650232: step 6956, loss 0.00329941, acc 1
2016-09-05T18:11:56.849655: step 6957, loss 0.00289424, acc 1
2016-09-05T18:11:57.061295: step 6958, loss 0.0042075, acc 1
2016-09-05T18:11:57.284092: step 6959, loss 0.00474587, acc 1
2016-09-05T18:11:57.519509: step 6960, loss 0.00354777, acc 1
2016-09-05T18:11:57.749505: step 6961, loss 0.00503033, acc 1
2016-09-05T18:11:57.971950: step 6962, loss 0.00313715, acc 1
2016-09-05T18:11:58.172465: step 6963, loss 0.00337235, acc 1
2016-09-05T18:11:58.385756: step 6964, loss 0.00661304, acc 1
2016-09-05T18:11:58.613056: step 6965, loss 0.0040872, acc 1
2016-09-05T18:11:58.847314: step 6966, loss 0.00354694, acc 1
2016-09-05T18:11:59.045460: step 6967, loss 0.0100121, acc 1
2016-09-05T18:11:59.279744: step 6968, loss 0.00659597, acc 1
2016-09-05T18:11:59.484902: step 6969, loss 0.00566326, acc 1
2016-09-05T18:11:59.686046: step 6970, loss 0.00401077, acc 1
2016-09-05T18:11:59.910569: step 6971, loss 0.0056418, acc 1
2016-09-05T18:12:00.120853: step 6972, loss 0.0108743, acc 1
2016-09-05T18:12:00.358549: step 6973, loss 0.00455968, acc 1
2016-09-05T18:12:00.570099: step 6974, loss 0.00890273, acc 1
2016-09-05T18:12:00.777633: step 6975, loss 0.0042832, acc 1
2016-09-05T18:12:01.004053: step 6976, loss 0.00440658, acc 1
2016-09-05T18:12:01.219736: step 6977, loss 0.00449415, acc 1
2016-09-05T18:12:01.436856: step 6978, loss 0.00481019, acc 1
2016-09-05T18:12:01.667246: step 6979, loss 0.00493938, acc 1
2016-09-05T18:12:01.882707: step 6980, loss 0.00502517, acc 1
2016-09-05T18:12:02.087925: step 6981, loss 0.00508547, acc 1
2016-09-05T18:12:02.291190: step 6982, loss 0.00813177, acc 1
2016-09-05T18:12:02.504727: step 6983, loss 0.00603383, acc 1
2016-09-05T18:12:02.627714: step 6984, loss 0.00503444, acc 1
2016-09-05T18:12:02.858162: step 6985, loss 0.0054391, acc 1
2016-09-05T18:12:03.071821: step 6986, loss 0.00518535, acc 1
2016-09-05T18:12:03.297706: step 6987, loss 0.00509877, acc 1
2016-09-05T18:12:03.511423: step 6988, loss 0.0053033, acc 1
2016-09-05T18:12:03.708740: step 6989, loss 0.00507088, acc 1
2016-09-05T18:12:03.910967: step 6990, loss 0.00547626, acc 1
2016-09-05T18:12:04.130006: step 6991, loss 0.00487055, acc 1
2016-09-05T18:12:04.351221: step 6992, loss 0.00488045, acc 1
2016-09-05T18:12:04.564027: step 6993, loss 0.00474651, acc 1
2016-09-05T18:12:04.782856: step 6994, loss 0.0048521, acc 1
2016-09-05T18:12:04.983037: step 6995, loss 0.00663993, acc 1
2016-09-05T18:12:05.199117: step 6996, loss 0.0048928, acc 1
2016-09-05T18:12:05.410405: step 6997, loss 0.00447496, acc 1
2016-09-05T18:12:05.639033: step 6998, loss 0.0045453, acc 1
2016-09-05T18:12:05.855608: step 6999, loss 0.00443434, acc 1
2016-09-05T18:12:06.090628: step 7000, loss 0.00461209, acc 1

Evaluation:
2016-09-05T18:12:06.697148: step 7000, loss 1.3362, acc 0.731

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-7000

2016-09-05T18:12:07.400647: step 7001, loss 0.00557149, acc 1
2016-09-05T18:12:07.618543: step 7002, loss 0.0047229, acc 1
2016-09-05T18:12:07.839274: step 7003, loss 0.00386005, acc 1
2016-09-05T18:12:08.055904: step 7004, loss 0.00429683, acc 1
2016-09-05T18:12:08.255277: step 7005, loss 0.00407114, acc 1
2016-09-05T18:12:08.454663: step 7006, loss 0.00423806, acc 1
2016-09-05T18:12:08.643142: step 7007, loss 0.00598569, acc 1
2016-09-05T18:12:08.863518: step 7008, loss 0.00416226, acc 1
2016-09-05T18:12:09.072166: step 7009, loss 0.0040313, acc 1
2016-09-05T18:12:09.285643: step 7010, loss 0.00378841, acc 1
2016-09-05T18:12:09.487984: step 7011, loss 0.00422212, acc 1
2016-09-05T18:12:09.695483: step 7012, loss 0.00360646, acc 1
2016-09-05T18:12:09.896132: step 7013, loss 0.00514326, acc 1
2016-09-05T18:12:10.123129: step 7014, loss 0.003959, acc 1
2016-09-05T18:12:10.330697: step 7015, loss 0.00821634, acc 1
2016-09-05T18:12:10.551805: step 7016, loss 0.00434739, acc 1
2016-09-05T18:12:10.807453: step 7017, loss 0.00384061, acc 1
2016-09-05T18:12:11.071698: step 7018, loss 0.00530115, acc 1
2016-09-05T18:12:11.332886: step 7019, loss 0.00404862, acc 1
2016-09-05T18:12:11.549623: step 7020, loss 0.0039803, acc 1
2016-09-05T18:12:11.767416: step 7021, loss 0.00445448, acc 1
2016-09-05T18:12:12.010460: step 7022, loss 0.00368779, acc 1
2016-09-05T18:12:12.250966: step 7023, loss 0.00439585, acc 1
2016-09-05T18:12:12.485420: step 7024, loss 0.00519466, acc 1
2016-09-05T18:12:12.696876: step 7025, loss 0.00447602, acc 1
2016-09-05T18:12:12.906639: step 7026, loss 0.00395734, acc 1
2016-09-05T18:12:13.111606: step 7027, loss 0.00447426, acc 1
2016-09-05T18:12:13.330480: step 7028, loss 0.00397092, acc 1
2016-09-05T18:12:13.540833: step 7029, loss 0.00362131, acc 1
2016-09-05T18:12:13.763476: step 7030, loss 0.00361873, acc 1
2016-09-05T18:12:13.976509: step 7031, loss 0.00399335, acc 1
2016-09-05T18:12:14.197916: step 7032, loss 0.00374401, acc 1
2016-09-05T18:12:14.432676: step 7033, loss 0.0068371, acc 1
2016-09-05T18:12:14.693685: step 7034, loss 0.00479193, acc 1
2016-09-05T18:12:14.915730: step 7035, loss 0.00465371, acc 1
2016-09-05T18:12:15.113437: step 7036, loss 0.00359632, acc 1
2016-09-05T18:12:15.329110: step 7037, loss 0.0043883, acc 1
2016-09-05T18:12:15.544150: step 7038, loss 0.00388093, acc 1
2016-09-05T18:12:15.776862: step 7039, loss 0.0044272, acc 1
2016-09-05T18:12:16.000622: step 7040, loss 0.00355935, acc 1
2016-09-05T18:12:16.220583: step 7041, loss 0.00346065, acc 1
2016-09-05T18:12:16.447977: step 7042, loss 0.00367692, acc 1
2016-09-05T18:12:16.654117: step 7043, loss 0.00334558, acc 1
2016-09-05T18:12:16.867877: step 7044, loss 0.00347278, acc 1
2016-09-05T18:12:17.086243: step 7045, loss 0.00362977, acc 1
2016-09-05T18:12:17.297118: step 7046, loss 0.00341532, acc 1
2016-09-05T18:12:17.500331: step 7047, loss 0.00318872, acc 1
2016-09-05T18:12:17.722107: step 7048, loss 0.003606, acc 1
2016-09-05T18:12:17.966019: step 7049, loss 0.00312038, acc 1
2016-09-05T18:12:18.181038: step 7050, loss 0.00313327, acc 1
2016-09-05T18:12:18.393479: step 7051, loss 0.00352791, acc 1
2016-09-05T18:12:18.625992: step 7052, loss 0.00477654, acc 1
2016-09-05T18:12:18.853433: step 7053, loss 0.00498869, acc 1
2016-09-05T18:12:19.062970: step 7054, loss 0.00318129, acc 1
2016-09-05T18:12:19.276939: step 7055, loss 0.00416744, acc 1
2016-09-05T18:12:19.491258: step 7056, loss 0.0029746, acc 1
2016-09-05T18:12:19.702420: step 7057, loss 0.00405893, acc 1
2016-09-05T18:12:19.926050: step 7058, loss 0.00365597, acc 1
2016-09-05T18:12:20.129425: step 7059, loss 0.00330579, acc 1
2016-09-05T18:12:20.347891: step 7060, loss 0.00352144, acc 1
2016-09-05T18:12:20.590709: step 7061, loss 0.00326417, acc 1
2016-09-05T18:12:20.796281: step 7062, loss 0.00414643, acc 1
2016-09-05T18:12:21.022331: step 7063, loss 0.00336925, acc 1
2016-09-05T18:12:21.236191: step 7064, loss 0.00451801, acc 1
2016-09-05T18:12:21.464723: step 7065, loss 0.00399926, acc 1
2016-09-05T18:12:21.698217: step 7066, loss 0.00456016, acc 1
2016-09-05T18:12:21.911717: step 7067, loss 0.0029974, acc 1
2016-09-05T18:12:22.120298: step 7068, loss 0.0033267, acc 1
2016-09-05T18:12:22.343584: step 7069, loss 0.00356646, acc 1
2016-09-05T18:12:22.554093: step 7070, loss 0.00350322, acc 1
2016-09-05T18:12:22.789583: step 7071, loss 0.00416206, acc 1
2016-09-05T18:12:23.007710: step 7072, loss 0.00363421, acc 1
2016-09-05T18:12:23.219037: step 7073, loss 0.00321331, acc 1
2016-09-05T18:12:23.426710: step 7074, loss 0.00364898, acc 1
2016-09-05T18:12:23.638977: step 7075, loss 0.0032387, acc 1
2016-09-05T18:12:23.853978: step 7076, loss 0.00466813, acc 1
2016-09-05T18:12:24.076063: step 7077, loss 0.00366092, acc 1
2016-09-05T18:12:24.301420: step 7078, loss 0.00366207, acc 1
2016-09-05T18:12:24.524825: step 7079, loss 0.0102214, acc 1
2016-09-05T18:12:24.744878: step 7080, loss 0.00423362, acc 1
2016-09-05T18:12:24.949259: step 7081, loss 0.00355332, acc 1
2016-09-05T18:12:25.157966: step 7082, loss 0.00579439, acc 1
2016-09-05T18:12:25.384377: step 7083, loss 0.00657252, acc 1
2016-09-05T18:12:25.625696: step 7084, loss 0.00318766, acc 1
2016-09-05T18:12:25.822378: step 7085, loss 0.00372811, acc 1
2016-09-05T18:12:26.037831: step 7086, loss 0.0039833, acc 1
2016-09-05T18:12:26.248879: step 7087, loss 0.00380185, acc 1
2016-09-05T18:12:26.451509: step 7088, loss 0.00357081, acc 1
2016-09-05T18:12:26.655058: step 7089, loss 0.0055655, acc 1
2016-09-05T18:12:26.894254: step 7090, loss 0.00354352, acc 1
2016-09-05T18:12:27.111607: step 7091, loss 0.00443354, acc 1
2016-09-05T18:12:27.311539: step 7092, loss 0.00351496, acc 1
2016-09-05T18:12:27.516362: step 7093, loss 0.00536495, acc 1
2016-09-05T18:12:27.745092: step 7094, loss 0.00369016, acc 1
2016-09-05T18:12:27.947083: step 7095, loss 0.00775148, acc 1
2016-09-05T18:12:28.139863: step 7096, loss 0.00377563, acc 1
2016-09-05T18:12:28.358781: step 7097, loss 0.00363901, acc 1
2016-09-05T18:12:28.554748: step 7098, loss 0.00948291, acc 1
2016-09-05T18:12:28.758226: step 7099, loss 0.00463924, acc 1
2016-09-05T18:12:28.966014: step 7100, loss 0.00348239, acc 1

Evaluation:
2016-09-05T18:12:29.575475: step 7100, loss 1.34097, acc 0.734

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-7100

2016-09-05T18:12:30.292924: step 7101, loss 0.00363568, acc 1
2016-09-05T18:12:30.528386: step 7102, loss 0.00359445, acc 1
2016-09-05T18:12:30.757453: step 7103, loss 0.00394459, acc 1
2016-09-05T18:12:30.991320: step 7104, loss 0.00365579, acc 1
2016-09-05T18:12:31.189658: step 7105, loss 0.00371191, acc 1
2016-09-05T18:12:31.403701: step 7106, loss 0.00404666, acc 1
2016-09-05T18:12:31.628950: step 7107, loss 0.00414096, acc 1
2016-09-05T18:12:31.828611: step 7108, loss 0.00490952, acc 1
2016-09-05T18:12:32.061854: step 7109, loss 0.00345469, acc 1
2016-09-05T18:12:32.281385: step 7110, loss 0.00362525, acc 1
2016-09-05T18:12:32.487317: step 7111, loss 0.00348431, acc 1
2016-09-05T18:12:32.695973: step 7112, loss 0.00464049, acc 1
2016-09-05T18:12:32.914048: step 7113, loss 0.00358339, acc 1
2016-09-05T18:12:33.114880: step 7114, loss 0.00390166, acc 1
2016-09-05T18:12:33.351572: step 7115, loss 0.00383136, acc 1
2016-09-05T18:12:33.595304: step 7116, loss 0.00338111, acc 1
2016-09-05T18:12:33.806487: step 7117, loss 0.00372003, acc 1
2016-09-05T18:12:34.021957: step 7118, loss 0.00702557, acc 1
2016-09-05T18:12:34.237407: step 7119, loss 0.00333633, acc 1
2016-09-05T18:12:34.451354: step 7120, loss 0.00405558, acc 1
2016-09-05T18:12:34.675965: step 7121, loss 0.00335989, acc 1
2016-09-05T18:12:34.914678: step 7122, loss 0.00527266, acc 1
2016-09-05T18:12:35.129055: step 7123, loss 0.0031297, acc 1
2016-09-05T18:12:35.335622: step 7124, loss 0.00387072, acc 1
2016-09-05T18:12:35.533194: step 7125, loss 0.00487294, acc 1
2016-09-05T18:12:35.789808: step 7126, loss 0.00327435, acc 1
2016-09-05T18:12:36.013266: step 7127, loss 0.0039462, acc 1
2016-09-05T18:12:36.241654: step 7128, loss 0.00495004, acc 1
2016-09-05T18:12:36.467153: step 7129, loss 0.00409931, acc 1
2016-09-05T18:12:36.705594: step 7130, loss 0.00477133, acc 1
2016-09-05T18:12:36.939109: step 7131, loss 0.00425644, acc 1
2016-09-05T18:12:37.167308: step 7132, loss 0.0059577, acc 1
2016-09-05T18:12:37.389504: step 7133, loss 0.00317967, acc 1
2016-09-05T18:12:37.614603: step 7134, loss 0.00364275, acc 1
2016-09-05T18:12:37.834559: step 7135, loss 0.0035999, acc 1
2016-09-05T18:12:38.044431: step 7136, loss 0.00361937, acc 1
2016-09-05T18:12:38.261279: step 7137, loss 0.00392653, acc 1
2016-09-05T18:12:38.467718: step 7138, loss 0.00419692, acc 1
2016-09-05T18:12:38.691471: step 7139, loss 0.00354648, acc 1
2016-09-05T18:12:38.924179: step 7140, loss 0.00357809, acc 1
2016-09-05T18:12:39.149931: step 7141, loss 0.00518497, acc 1
2016-09-05T18:12:39.350794: step 7142, loss 0.00393093, acc 1
2016-09-05T18:12:39.565783: step 7143, loss 0.00359001, acc 1
2016-09-05T18:12:39.765837: step 7144, loss 0.0035263, acc 1
2016-09-05T18:12:39.970525: step 7145, loss 0.00369568, acc 1
2016-09-05T18:12:40.187344: step 7146, loss 0.00350763, acc 1
2016-09-05T18:12:40.417888: step 7147, loss 0.00390137, acc 1
2016-09-05T18:12:40.640160: step 7148, loss 0.0031949, acc 1
2016-09-05T18:12:40.861645: step 7149, loss 0.00339822, acc 1
2016-09-05T18:12:41.085648: step 7150, loss 0.00326339, acc 1
2016-09-05T18:12:41.312122: step 7151, loss 0.0034096, acc 1
2016-09-05T18:12:41.532654: step 7152, loss 0.00391237, acc 1
2016-09-05T18:12:41.755687: step 7153, loss 0.00313945, acc 1
2016-09-05T18:12:42.019059: step 7154, loss 0.00351436, acc 1
2016-09-05T18:12:42.237146: step 7155, loss 0.00390501, acc 1
2016-09-05T18:12:42.443211: step 7156, loss 0.0032929, acc 1
2016-09-05T18:12:42.660345: step 7157, loss 0.00427824, acc 1
2016-09-05T18:12:42.860297: step 7158, loss 0.00384348, acc 1
2016-09-05T18:12:43.106123: step 7159, loss 0.00499335, acc 1
2016-09-05T18:12:43.317130: step 7160, loss 0.00465343, acc 1
2016-09-05T18:12:43.532745: step 7161, loss 0.00344408, acc 1
2016-09-05T18:12:43.746602: step 7162, loss 0.00299409, acc 1
2016-09-05T18:12:43.977676: step 7163, loss 0.00298189, acc 1
2016-09-05T18:12:44.198119: step 7164, loss 0.00288523, acc 1
2016-09-05T18:12:44.417527: step 7165, loss 0.00332787, acc 1
2016-09-05T18:12:44.624767: step 7166, loss 0.00349161, acc 1
2016-09-05T18:12:44.864258: step 7167, loss 0.00314992, acc 1
2016-09-05T18:12:45.089189: step 7168, loss 0.00391781, acc 1
2016-09-05T18:12:45.305410: step 7169, loss 0.00446735, acc 1
2016-09-05T18:12:45.527979: step 7170, loss 0.0028216, acc 1
2016-09-05T18:12:45.729714: step 7171, loss 0.00474677, acc 1
2016-09-05T18:12:45.934779: step 7172, loss 0.00369376, acc 1
2016-09-05T18:12:46.150963: step 7173, loss 0.00336844, acc 1
2016-09-05T18:12:46.378723: step 7174, loss 0.00427421, acc 1
2016-09-05T18:12:46.605395: step 7175, loss 0.00473193, acc 1
2016-09-05T18:12:46.832679: step 7176, loss 0.00327163, acc 1
2016-09-05T18:12:47.032820: step 7177, loss 0.00302709, acc 1
2016-09-05T18:12:47.153553: step 7178, loss 0.00313499, acc 1
2016-09-05T18:12:47.373263: step 7179, loss 0.00426298, acc 1
2016-09-05T18:12:47.598763: step 7180, loss 0.00329626, acc 1
2016-09-05T18:12:47.856443: step 7181, loss 0.00366864, acc 1
2016-09-05T18:12:48.072979: step 7182, loss 0.00336417, acc 1
2016-09-05T18:12:48.280176: step 7183, loss 0.00306755, acc 1
2016-09-05T18:12:48.505519: step 7184, loss 0.00299915, acc 1
2016-09-05T18:12:48.745393: step 7185, loss 0.0036117, acc 1
2016-09-05T18:12:48.965156: step 7186, loss 0.00309092, acc 1
2016-09-05T18:12:49.186554: step 7187, loss 0.00369064, acc 1
2016-09-05T18:12:49.397832: step 7188, loss 0.00340786, acc 1
2016-09-05T18:12:49.620168: step 7189, loss 0.00338396, acc 1
2016-09-05T18:12:49.862334: step 7190, loss 0.00301355, acc 1
2016-09-05T18:12:50.075277: step 7191, loss 0.00303017, acc 1
2016-09-05T18:12:50.277590: step 7192, loss 0.00303432, acc 1
2016-09-05T18:12:50.482818: step 7193, loss 0.00312641, acc 1
2016-09-05T18:12:50.709275: step 7194, loss 0.00362559, acc 1
2016-09-05T18:12:50.914276: step 7195, loss 0.00327507, acc 1
2016-09-05T18:12:51.163196: step 7196, loss 0.00340245, acc 1
2016-09-05T18:12:51.381431: step 7197, loss 0.00311971, acc 1
2016-09-05T18:12:51.604092: step 7198, loss 0.00337548, acc 1
2016-09-05T18:12:51.818655: step 7199, loss 0.00316233, acc 1
2016-09-05T18:12:52.042491: step 7200, loss 0.00345591, acc 1

Evaluation:
2016-09-05T18:12:52.658437: step 7200, loss 1.20028, acc 0.737

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-7200

2016-09-05T18:12:53.400337: step 7201, loss 0.00377077, acc 1
2016-09-05T18:12:53.621817: step 7202, loss 0.00691192, acc 1
2016-09-05T18:12:53.848571: step 7203, loss 0.0031361, acc 1
2016-09-05T18:12:54.055408: step 7204, loss 0.00396136, acc 1
2016-09-05T18:12:54.268632: step 7205, loss 0.00365514, acc 1
2016-09-05T18:12:54.501284: step 7206, loss 0.00338004, acc 1
2016-09-05T18:12:54.711998: step 7207, loss 0.0045611, acc 1
2016-09-05T18:12:54.936583: step 7208, loss 0.00600461, acc 1
2016-09-05T18:12:55.157557: step 7209, loss 0.00448728, acc 1
2016-09-05T18:12:55.408350: step 7210, loss 0.00321609, acc 1
2016-09-05T18:12:55.626294: step 7211, loss 0.00323238, acc 1
2016-09-05T18:12:55.832671: step 7212, loss 0.00446175, acc 1
2016-09-05T18:12:56.065441: step 7213, loss 0.00430496, acc 1
2016-09-05T18:12:56.283922: step 7214, loss 0.00384284, acc 1
2016-09-05T18:12:56.504882: step 7215, loss 0.00660225, acc 1
2016-09-05T18:12:56.726151: step 7216, loss 0.00383723, acc 1
2016-09-05T18:12:56.928707: step 7217, loss 0.00404107, acc 1
2016-09-05T18:12:57.136245: step 7218, loss 0.00512925, acc 1
2016-09-05T18:12:57.356473: step 7219, loss 0.00482301, acc 1
2016-09-05T18:12:57.564882: step 7220, loss 0.00370524, acc 1
2016-09-05T18:12:57.798563: step 7221, loss 0.00381785, acc 1
2016-09-05T18:12:58.031099: step 7222, loss 0.0049272, acc 1
2016-09-05T18:12:58.257482: step 7223, loss 0.00371311, acc 1
2016-09-05T18:12:58.503900: step 7224, loss 0.00426894, acc 1
2016-09-05T18:12:58.722854: step 7225, loss 0.00404495, acc 1
2016-09-05T18:12:58.952706: step 7226, loss 0.00373476, acc 1
2016-09-05T18:12:59.164961: step 7227, loss 0.0039819, acc 1
2016-09-05T18:12:59.386008: step 7228, loss 0.00575556, acc 1
2016-09-05T18:12:59.592890: step 7229, loss 0.00370938, acc 1
2016-09-05T18:12:59.807605: step 7230, loss 0.00364707, acc 1
2016-09-05T18:13:00.018782: step 7231, loss 0.00390078, acc 1
2016-09-05T18:13:00.265966: step 7232, loss 0.00410654, acc 1
2016-09-05T18:13:00.473672: step 7233, loss 0.00569032, acc 1
2016-09-05T18:13:00.684731: step 7234, loss 0.00347884, acc 1
2016-09-05T18:13:00.931761: step 7235, loss 0.0039751, acc 1
2016-09-05T18:13:01.181382: step 7236, loss 0.00407767, acc 1
2016-09-05T18:13:01.412126: step 7237, loss 0.00521968, acc 1
2016-09-05T18:13:01.644389: step 7238, loss 0.00535082, acc 1
2016-09-05T18:13:01.876127: step 7239, loss 0.00367545, acc 1
2016-09-05T18:13:02.081672: step 7240, loss 0.00366266, acc 1
2016-09-05T18:13:02.300744: step 7241, loss 0.00366464, acc 1
2016-09-05T18:13:02.527261: step 7242, loss 0.00428374, acc 1
2016-09-05T18:13:02.751175: step 7243, loss 0.00348151, acc 1
2016-09-05T18:13:02.989487: step 7244, loss 0.00651468, acc 1
2016-09-05T18:13:03.201844: step 7245, loss 0.00351943, acc 1
2016-09-05T18:13:03.446037: step 7246, loss 0.00364258, acc 1
2016-09-05T18:13:03.650665: step 7247, loss 0.00343679, acc 1
2016-09-05T18:13:03.886356: step 7248, loss 0.00456978, acc 1
2016-09-05T18:13:04.101330: step 7249, loss 0.00361482, acc 1
2016-09-05T18:13:04.322399: step 7250, loss 0.00396998, acc 1
2016-09-05T18:13:04.549218: step 7251, loss 0.00385842, acc 1
2016-09-05T18:13:04.763243: step 7252, loss 0.00367224, acc 1
2016-09-05T18:13:04.983917: step 7253, loss 0.00504191, acc 1
2016-09-05T18:13:05.184832: step 7254, loss 0.00417538, acc 1
2016-09-05T18:13:05.406533: step 7255, loss 0.00414482, acc 1
2016-09-05T18:13:05.614593: step 7256, loss 0.00366681, acc 1
2016-09-05T18:13:05.834925: step 7257, loss 0.00353618, acc 1
2016-09-05T18:13:06.054801: step 7258, loss 0.00353053, acc 1
2016-09-05T18:13:06.268959: step 7259, loss 0.00327924, acc 1
2016-09-05T18:13:06.501882: step 7260, loss 0.00382471, acc 1
2016-09-05T18:13:06.720475: step 7261, loss 0.00333212, acc 1
2016-09-05T18:13:06.928530: step 7262, loss 0.00343554, acc 1
2016-09-05T18:13:07.188866: step 7263, loss 0.00431226, acc 1
2016-09-05T18:13:07.409340: step 7264, loss 0.0051978, acc 1
2016-09-05T18:13:07.616112: step 7265, loss 0.0033649, acc 1
2016-09-05T18:13:07.813646: step 7266, loss 0.00347107, acc 1
2016-09-05T18:13:08.020396: step 7267, loss 0.00339761, acc 1
2016-09-05T18:13:08.236940: step 7268, loss 0.00373371, acc 1
2016-09-05T18:13:08.437448: step 7269, loss 0.0036502, acc 1
2016-09-05T18:13:08.641697: step 7270, loss 0.00373544, acc 1
2016-09-05T18:13:08.845735: step 7271, loss 0.00390343, acc 1
2016-09-05T18:13:09.077262: step 7272, loss 0.00306456, acc 1
2016-09-05T18:13:09.340029: step 7273, loss 0.00347743, acc 1
2016-09-05T18:13:09.570976: step 7274, loss 0.0037573, acc 1
2016-09-05T18:13:09.807709: step 7275, loss 0.00325728, acc 1
2016-09-05T18:13:10.040994: step 7276, loss 0.00366655, acc 1
2016-09-05T18:13:10.271451: step 7277, loss 0.00315659, acc 1
2016-09-05T18:13:10.474463: step 7278, loss 0.00277127, acc 1
2016-09-05T18:13:10.698822: step 7279, loss 0.00320717, acc 1
2016-09-05T18:13:10.900726: step 7280, loss 0.0031551, acc 1
2016-09-05T18:13:11.146043: step 7281, loss 0.00348941, acc 1
2016-09-05T18:13:11.347131: step 7282, loss 0.00352407, acc 1
2016-09-05T18:13:11.561383: step 7283, loss 0.00416569, acc 1
2016-09-05T18:13:11.766533: step 7284, loss 0.00264016, acc 1
2016-09-05T18:13:11.975548: step 7285, loss 0.00389853, acc 1
2016-09-05T18:13:12.185536: step 7286, loss 0.00271333, acc 1
2016-09-05T18:13:12.409804: step 7287, loss 0.00312039, acc 1
2016-09-05T18:13:12.631014: step 7288, loss 0.00267715, acc 1
2016-09-05T18:13:12.858060: step 7289, loss 0.00347024, acc 1
2016-09-05T18:13:13.078659: step 7290, loss 0.00270122, acc 1
2016-09-05T18:13:13.281384: step 7291, loss 0.00609502, acc 1
2016-09-05T18:13:13.479687: step 7292, loss 0.00600126, acc 1
2016-09-05T18:13:13.690380: step 7293, loss 0.00323304, acc 1
2016-09-05T18:13:13.903740: step 7294, loss 0.00340269, acc 1
2016-09-05T18:13:14.122173: step 7295, loss 0.0032237, acc 1
2016-09-05T18:13:14.376340: step 7296, loss 0.00328772, acc 1
2016-09-05T18:13:14.595585: step 7297, loss 0.00372733, acc 1
2016-09-05T18:13:14.840232: step 7298, loss 0.0033391, acc 1
2016-09-05T18:13:15.087467: step 7299, loss 0.00298438, acc 1
2016-09-05T18:13:15.296279: step 7300, loss 0.00351994, acc 1

Evaluation:
2016-09-05T18:13:15.919263: step 7300, loss 1.24499, acc 0.737

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-7300

2016-09-05T18:13:16.624837: step 7301, loss 0.00385423, acc 1
2016-09-05T18:13:16.842855: step 7302, loss 0.00665109, acc 1
2016-09-05T18:13:17.068219: step 7303, loss 0.00320877, acc 1
2016-09-05T18:13:17.322337: step 7304, loss 0.00368784, acc 1
2016-09-05T18:13:17.526161: step 7305, loss 0.00305254, acc 1
2016-09-05T18:13:17.736185: step 7306, loss 0.00320391, acc 1
2016-09-05T18:13:17.961394: step 7307, loss 0.00489787, acc 1
2016-09-05T18:13:18.188230: step 7308, loss 0.00303383, acc 1
2016-09-05T18:13:18.428584: step 7309, loss 0.00414043, acc 1
2016-09-05T18:13:18.637794: step 7310, loss 0.00324965, acc 1
2016-09-05T18:13:18.836235: step 7311, loss 0.00292764, acc 1
2016-09-05T18:13:19.056104: step 7312, loss 0.00514232, acc 1
2016-09-05T18:13:19.287491: step 7313, loss 0.00323394, acc 1
2016-09-05T18:13:19.517385: step 7314, loss 0.00402246, acc 1
2016-09-05T18:13:19.758801: step 7315, loss 0.0033171, acc 1
2016-09-05T18:13:19.967707: step 7316, loss 0.00316173, acc 1
2016-09-05T18:13:20.190569: step 7317, loss 0.00328824, acc 1
2016-09-05T18:13:20.433729: step 7318, loss 0.00313627, acc 1
2016-09-05T18:13:20.639216: step 7319, loss 0.00364945, acc 1
2016-09-05T18:13:20.842699: step 7320, loss 0.00369795, acc 1
2016-09-05T18:13:21.054578: step 7321, loss 0.0039817, acc 1
2016-09-05T18:13:21.258740: step 7322, loss 0.00296981, acc 1
2016-09-05T18:13:21.475466: step 7323, loss 0.0034587, acc 1
2016-09-05T18:13:21.703548: step 7324, loss 0.00346622, acc 1
2016-09-05T18:13:21.946704: step 7325, loss 0.00329038, acc 1
2016-09-05T18:13:22.179533: step 7326, loss 0.00337075, acc 1
2016-09-05T18:13:22.403093: step 7327, loss 0.00291213, acc 1
2016-09-05T18:13:22.634359: step 7328, loss 0.00354291, acc 1
2016-09-05T18:13:22.870965: step 7329, loss 0.00271903, acc 1
2016-09-05T18:13:23.075018: step 7330, loss 0.00284907, acc 1
2016-09-05T18:13:23.284666: step 7331, loss 0.00358231, acc 1
2016-09-05T18:13:23.502032: step 7332, loss 0.00350597, acc 1
2016-09-05T18:13:23.715659: step 7333, loss 0.00417337, acc 1
2016-09-05T18:13:23.953434: step 7334, loss 0.0029323, acc 1
2016-09-05T18:13:24.162354: step 7335, loss 0.00296683, acc 1
2016-09-05T18:13:24.363298: step 7336, loss 0.00383826, acc 1
2016-09-05T18:13:24.581124: step 7337, loss 0.00356808, acc 1
2016-09-05T18:13:24.776286: step 7338, loss 0.00328992, acc 1
2016-09-05T18:13:24.975772: step 7339, loss 0.00350587, acc 1
2016-09-05T18:13:25.178258: step 7340, loss 0.00446984, acc 1
2016-09-05T18:13:25.396357: step 7341, loss 0.00355888, acc 1
2016-09-05T18:13:25.610712: step 7342, loss 0.00350659, acc 1
2016-09-05T18:13:25.839408: step 7343, loss 0.00448319, acc 1
2016-09-05T18:13:26.082901: step 7344, loss 0.00810755, acc 1
2016-09-05T18:13:26.290805: step 7345, loss 0.00343514, acc 1
2016-09-05T18:13:26.521786: step 7346, loss 0.00303886, acc 1
2016-09-05T18:13:26.730603: step 7347, loss 0.00342891, acc 1
2016-09-05T18:13:26.954256: step 7348, loss 0.00499441, acc 1
2016-09-05T18:13:27.164380: step 7349, loss 0.00443363, acc 1
2016-09-05T18:13:27.371609: step 7350, loss 0.00365665, acc 1
2016-09-05T18:13:27.603169: step 7351, loss 0.00360245, acc 1
2016-09-05T18:13:27.825240: step 7352, loss 0.00354046, acc 1
2016-09-05T18:13:28.031893: step 7353, loss 0.00446922, acc 1
2016-09-05T18:13:28.263396: step 7354, loss 0.00327362, acc 1
2016-09-05T18:13:28.480357: step 7355, loss 0.00409524, acc 1
2016-09-05T18:13:28.714828: step 7356, loss 0.00426712, acc 1
2016-09-05T18:13:28.931454: step 7357, loss 0.00398641, acc 1
2016-09-05T18:13:29.137200: step 7358, loss 0.00339295, acc 1
2016-09-05T18:13:29.357663: step 7359, loss 0.00343427, acc 1
2016-09-05T18:13:29.569267: step 7360, loss 0.0039208, acc 1
2016-09-05T18:13:29.786667: step 7361, loss 0.0032596, acc 1
2016-09-05T18:13:30.030908: step 7362, loss 0.00323217, acc 1
2016-09-05T18:13:30.254807: step 7363, loss 0.00409534, acc 1
2016-09-05T18:13:30.466789: step 7364, loss 0.00363618, acc 1
2016-09-05T18:13:30.702726: step 7365, loss 0.00305018, acc 1
2016-09-05T18:13:30.943974: step 7366, loss 0.00313657, acc 1
2016-09-05T18:13:31.166729: step 7367, loss 0.00380727, acc 1
2016-09-05T18:13:31.392614: step 7368, loss 0.00319002, acc 1
2016-09-05T18:13:31.609618: step 7369, loss 0.0044051, acc 1
2016-09-05T18:13:31.841534: step 7370, loss 0.00335162, acc 1
2016-09-05T18:13:32.044773: step 7371, loss 0.00402435, acc 1
2016-09-05T18:13:32.167479: step 7372, loss 0.00326163, acc 1
2016-09-05T18:13:32.386703: step 7373, loss 0.00281043, acc 1
2016-09-05T18:13:32.618327: step 7374, loss 0.00301061, acc 1
2016-09-05T18:13:32.837360: step 7375, loss 0.00307048, acc 1
2016-09-05T18:13:33.051584: step 7376, loss 0.00278665, acc 1
2016-09-05T18:13:33.263830: step 7377, loss 0.0032288, acc 1
2016-09-05T18:13:33.478153: step 7378, loss 0.00290838, acc 1
2016-09-05T18:13:33.693073: step 7379, loss 0.00283035, acc 1
2016-09-05T18:13:33.897401: step 7380, loss 0.00537547, acc 1
2016-09-05T18:13:34.111790: step 7381, loss 0.00262543, acc 1
2016-09-05T18:13:34.331559: step 7382, loss 0.00334158, acc 1
2016-09-05T18:13:34.563418: step 7383, loss 0.00289379, acc 1
2016-09-05T18:13:34.769516: step 7384, loss 0.00344589, acc 1
2016-09-05T18:13:34.987770: step 7385, loss 0.00279757, acc 1
2016-09-05T18:13:35.195902: step 7386, loss 0.00361582, acc 1
2016-09-05T18:13:35.429048: step 7387, loss 0.00338244, acc 1
2016-09-05T18:13:35.670225: step 7388, loss 0.00272928, acc 1
2016-09-05T18:13:35.881599: step 7389, loss 0.00279818, acc 1
2016-09-05T18:13:36.092979: step 7390, loss 0.0040976, acc 1
2016-09-05T18:13:36.311015: step 7391, loss 0.00269392, acc 1
2016-09-05T18:13:36.522405: step 7392, loss 0.00285041, acc 1
2016-09-05T18:13:36.773850: step 7393, loss 0.00383216, acc 1
2016-09-05T18:13:36.989902: step 7394, loss 0.00271718, acc 1
2016-09-05T18:13:37.217622: step 7395, loss 0.00393296, acc 1
2016-09-05T18:13:37.446790: step 7396, loss 0.00290159, acc 1
2016-09-05T18:13:37.668576: step 7397, loss 0.0027902, acc 1
2016-09-05T18:13:37.914694: step 7398, loss 0.00290559, acc 1
2016-09-05T18:13:38.132370: step 7399, loss 0.00315836, acc 1
2016-09-05T18:13:38.343726: step 7400, loss 0.00392996, acc 1

Evaluation:
2016-09-05T18:13:38.934853: step 7400, loss 1.22754, acc 0.732

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-7400

2016-09-05T18:13:39.671013: step 7401, loss 0.00286381, acc 1
2016-09-05T18:13:39.928331: step 7402, loss 0.00278987, acc 1
2016-09-05T18:13:40.148910: step 7403, loss 0.00286729, acc 1
2016-09-05T18:13:40.402665: step 7404, loss 0.00251134, acc 1
2016-09-05T18:13:40.605745: step 7405, loss 0.00256819, acc 1
2016-09-05T18:13:40.821425: step 7406, loss 0.00280506, acc 1
2016-09-05T18:13:41.027554: step 7407, loss 0.00293159, acc 1
2016-09-05T18:13:41.229982: step 7408, loss 0.00302018, acc 1
2016-09-05T18:13:41.438324: step 7409, loss 0.00275087, acc 1
2016-09-05T18:13:41.657969: step 7410, loss 0.00315634, acc 1
2016-09-05T18:13:41.864247: step 7411, loss 0.00270274, acc 1
2016-09-05T18:13:42.094906: step 7412, loss 0.00270983, acc 1
2016-09-05T18:13:42.318815: step 7413, loss 0.00299807, acc 1
2016-09-05T18:13:42.518754: step 7414, loss 0.00307316, acc 1
2016-09-05T18:13:42.728599: step 7415, loss 0.00355746, acc 1
2016-09-05T18:13:42.914194: step 7416, loss 0.00306398, acc 1
2016-09-05T18:13:43.132388: step 7417, loss 0.00383727, acc 1
2016-09-05T18:13:43.346315: step 7418, loss 0.00286696, acc 1
2016-09-05T18:13:43.573935: step 7419, loss 0.00335741, acc 1
2016-09-05T18:13:43.808435: step 7420, loss 0.0027746, acc 1
2016-09-05T18:13:44.026624: step 7421, loss 0.00361749, acc 1
2016-09-05T18:13:44.239912: step 7422, loss 0.00321287, acc 1
2016-09-05T18:13:44.454483: step 7423, loss 0.00366612, acc 1
2016-09-05T18:13:44.704995: step 7424, loss 0.00255362, acc 1
2016-09-05T18:13:44.901329: step 7425, loss 0.00364025, acc 1
2016-09-05T18:13:45.143206: step 7426, loss 0.00310664, acc 1
2016-09-05T18:13:45.353601: step 7427, loss 0.0025356, acc 1
2016-09-05T18:13:45.566822: step 7428, loss 0.00272816, acc 1
2016-09-05T18:13:45.775213: step 7429, loss 0.00326484, acc 1
2016-09-05T18:13:46.007898: step 7430, loss 0.00352064, acc 1
2016-09-05T18:13:46.240563: step 7431, loss 0.00259634, acc 1
2016-09-05T18:13:46.438315: step 7432, loss 0.00358047, acc 1
2016-09-05T18:13:46.654730: step 7433, loss 0.0027808, acc 1
2016-09-05T18:13:46.862422: step 7434, loss 0.00294535, acc 1
2016-09-05T18:13:47.068038: step 7435, loss 0.00426996, acc 1
2016-09-05T18:13:47.267314: step 7436, loss 0.00375828, acc 1
2016-09-05T18:13:47.472918: step 7437, loss 0.00330368, acc 1
2016-09-05T18:13:47.678989: step 7438, loss 0.00314992, acc 1
2016-09-05T18:13:47.896610: step 7439, loss 0.00269439, acc 1
2016-09-05T18:13:48.114019: step 7440, loss 0.0041703, acc 1
2016-09-05T18:13:48.364435: step 7441, loss 0.00283779, acc 1
2016-09-05T18:13:48.591256: step 7442, loss 0.0032187, acc 1
2016-09-05T18:13:48.813379: step 7443, loss 0.00292992, acc 1
2016-09-05T18:13:49.028293: step 7444, loss 0.00302764, acc 1
2016-09-05T18:13:49.248899: step 7445, loss 0.00316112, acc 1
2016-09-05T18:13:49.481198: step 7446, loss 0.00294325, acc 1
2016-09-05T18:13:49.684476: step 7447, loss 0.00368271, acc 1
2016-09-05T18:13:49.903344: step 7448, loss 0.00307054, acc 1
2016-09-05T18:13:50.101451: step 7449, loss 0.00346761, acc 1
2016-09-05T18:13:50.316053: step 7450, loss 0.00315176, acc 1
2016-09-05T18:13:50.550870: step 7451, loss 0.00328331, acc 1
2016-09-05T18:13:50.776669: step 7452, loss 0.0036492, acc 1
2016-09-05T18:13:50.981669: step 7453, loss 0.00389335, acc 1
2016-09-05T18:13:51.209109: step 7454, loss 0.0030707, acc 1
2016-09-05T18:13:51.410198: step 7455, loss 0.0028729, acc 1
2016-09-05T18:13:51.611845: step 7456, loss 0.00267547, acc 1
2016-09-05T18:13:51.812043: step 7457, loss 0.00297804, acc 1
2016-09-05T18:13:52.029030: step 7458, loss 0.00310616, acc 1
2016-09-05T18:13:52.260908: step 7459, loss 0.00470903, acc 1
2016-09-05T18:13:52.497313: step 7460, loss 0.00283885, acc 1
2016-09-05T18:13:52.749801: step 7461, loss 0.00341944, acc 1
2016-09-05T18:13:52.962423: step 7462, loss 0.00307664, acc 1
2016-09-05T18:13:53.197689: step 7463, loss 0.00536388, acc 1
2016-09-05T18:13:53.405525: step 7464, loss 0.00316354, acc 1
2016-09-05T18:13:53.641416: step 7465, loss 0.00284571, acc 1
2016-09-05T18:13:53.852127: step 7466, loss 0.00334402, acc 1
2016-09-05T18:13:54.059829: step 7467, loss 0.00305246, acc 1
2016-09-05T18:13:54.276255: step 7468, loss 0.00348346, acc 1
2016-09-05T18:13:54.537403: step 7469, loss 0.00340563, acc 1
2016-09-05T18:13:54.761403: step 7470, loss 0.00348467, acc 1
2016-09-05T18:13:54.960493: step 7471, loss 0.00357408, acc 1
2016-09-05T18:13:55.159008: step 7472, loss 0.00310049, acc 1
2016-09-05T18:13:55.365443: step 7473, loss 0.00315581, acc 1
2016-09-05T18:13:55.570401: step 7474, loss 0.00343282, acc 1
2016-09-05T18:13:55.783028: step 7475, loss 0.00360488, acc 1
2016-09-05T18:13:56.007637: step 7476, loss 0.00361428, acc 1
2016-09-05T18:13:56.215657: step 7477, loss 0.00286993, acc 1
2016-09-05T18:13:56.428377: step 7478, loss 0.00326909, acc 1
2016-09-05T18:13:56.660016: step 7479, loss 0.00303932, acc 1
2016-09-05T18:13:56.875172: step 7480, loss 0.00276044, acc 1
2016-09-05T18:13:57.085068: step 7481, loss 0.0047121, acc 1
2016-09-05T18:13:57.319453: step 7482, loss 0.00293017, acc 1
2016-09-05T18:13:57.547794: step 7483, loss 0.00294355, acc 1
2016-09-05T18:13:57.773493: step 7484, loss 0.00299138, acc 1
2016-09-05T18:13:57.994018: step 7485, loss 0.00745266, acc 1
2016-09-05T18:13:58.209038: step 7486, loss 0.00310114, acc 1
2016-09-05T18:13:58.441193: step 7487, loss 0.00296338, acc 1
2016-09-05T18:13:58.680789: step 7488, loss 0.00334747, acc 1
2016-09-05T18:13:58.907615: step 7489, loss 0.00318281, acc 1
2016-09-05T18:13:59.120607: step 7490, loss 0.00381544, acc 1
2016-09-05T18:13:59.369699: step 7491, loss 0.00362988, acc 1
2016-09-05T18:13:59.608023: step 7492, loss 0.00366348, acc 1
2016-09-05T18:13:59.818686: step 7493, loss 0.00332988, acc 1
2016-09-05T18:14:00.067663: step 7494, loss 0.00342634, acc 1
2016-09-05T18:14:00.298460: step 7495, loss 0.00354852, acc 1
2016-09-05T18:14:00.508994: step 7496, loss 0.00326906, acc 1
2016-09-05T18:14:00.723562: step 7497, loss 0.00325337, acc 1
2016-09-05T18:14:00.948334: step 7498, loss 0.00332653, acc 1
2016-09-05T18:14:01.161838: step 7499, loss 0.00332609, acc 1
2016-09-05T18:14:01.394586: step 7500, loss 0.00328695, acc 1

Evaluation:
2016-09-05T18:14:01.997234: step 7500, loss 1.28834, acc 0.734

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-7500

2016-09-05T18:14:02.751801: step 7501, loss 0.00377319, acc 1
2016-09-05T18:14:02.978556: step 7502, loss 0.00368145, acc 1
2016-09-05T18:14:03.209013: step 7503, loss 0.0032532, acc 1
2016-09-05T18:14:03.450788: step 7504, loss 0.00296388, acc 1
2016-09-05T18:14:03.682077: step 7505, loss 0.00352878, acc 1
2016-09-05T18:14:03.896220: step 7506, loss 0.00353635, acc 1
2016-09-05T18:14:04.144701: step 7507, loss 0.00321222, acc 1
2016-09-05T18:14:04.342872: step 7508, loss 0.00366541, acc 1
2016-09-05T18:14:04.564971: step 7509, loss 0.00324621, acc 1
2016-09-05T18:14:04.772928: step 7510, loss 0.00440952, acc 1
2016-09-05T18:14:04.979832: step 7511, loss 0.00315187, acc 1
2016-09-05T18:14:05.196374: step 7512, loss 0.00292613, acc 1
2016-09-05T18:14:05.401244: step 7513, loss 0.00296029, acc 1
2016-09-05T18:14:05.626289: step 7514, loss 0.00316028, acc 1
2016-09-05T18:14:05.869547: step 7515, loss 0.00393529, acc 1
2016-09-05T18:14:06.081694: step 7516, loss 0.0034364, acc 1
2016-09-05T18:14:06.303903: step 7517, loss 0.0029744, acc 1
2016-09-05T18:14:06.538524: step 7518, loss 0.00323581, acc 1
2016-09-05T18:14:06.753487: step 7519, loss 0.00539415, acc 1
2016-09-05T18:14:06.969851: step 7520, loss 0.00350568, acc 1
2016-09-05T18:14:07.170704: step 7521, loss 0.00372622, acc 1
2016-09-05T18:14:07.374859: step 7522, loss 0.00292442, acc 1
2016-09-05T18:14:07.587243: step 7523, loss 0.00344073, acc 1
2016-09-05T18:14:07.808981: step 7524, loss 0.00296355, acc 1
2016-09-05T18:14:08.025523: step 7525, loss 0.00284056, acc 1
2016-09-05T18:14:08.240346: step 7526, loss 0.00296325, acc 1
2016-09-05T18:14:08.452453: step 7527, loss 0.00274842, acc 1
2016-09-05T18:14:08.684501: step 7528, loss 0.00310435, acc 1
2016-09-05T18:14:08.895022: step 7529, loss 0.00276367, acc 1
2016-09-05T18:14:09.106546: step 7530, loss 0.00387172, acc 1
2016-09-05T18:14:09.306947: step 7531, loss 0.00262338, acc 1
2016-09-05T18:14:09.525408: step 7532, loss 0.00293954, acc 1
2016-09-05T18:14:09.733625: step 7533, loss 0.00466524, acc 1
2016-09-05T18:14:09.971900: step 7534, loss 0.00266008, acc 1
2016-09-05T18:14:10.204551: step 7535, loss 0.00385938, acc 1
2016-09-05T18:14:10.406905: step 7536, loss 0.00541561, acc 1
2016-09-05T18:14:10.631161: step 7537, loss 0.00319627, acc 1
2016-09-05T18:14:10.853181: step 7538, loss 0.0036002, acc 1
2016-09-05T18:14:11.081564: step 7539, loss 0.00305133, acc 1
2016-09-05T18:14:11.309998: step 7540, loss 0.00264559, acc 1
2016-09-05T18:14:11.544364: step 7541, loss 0.00428843, acc 1
2016-09-05T18:14:11.757282: step 7542, loss 0.00370717, acc 1
2016-09-05T18:14:11.969926: step 7543, loss 0.00285842, acc 1
2016-09-05T18:14:12.189307: step 7544, loss 0.0032261, acc 1
2016-09-05T18:14:12.405524: step 7545, loss 0.00469973, acc 1
2016-09-05T18:14:12.630184: step 7546, loss 0.003071, acc 1
2016-09-05T18:14:12.826622: step 7547, loss 0.00309712, acc 1
2016-09-05T18:14:13.027181: step 7548, loss 0.003136, acc 1
2016-09-05T18:14:13.232722: step 7549, loss 0.00293428, acc 1
2016-09-05T18:14:13.440665: step 7550, loss 0.0035308, acc 1
2016-09-05T18:14:13.640415: step 7551, loss 0.00344188, acc 1
2016-09-05T18:14:13.864015: step 7552, loss 0.00406306, acc 1
2016-09-05T18:14:14.083695: step 7553, loss 0.00323601, acc 1
2016-09-05T18:14:14.325663: step 7554, loss 0.00301962, acc 1
2016-09-05T18:14:14.547494: step 7555, loss 0.00333541, acc 1
2016-09-05T18:14:14.788519: step 7556, loss 0.00330963, acc 1
2016-09-05T18:14:15.002250: step 7557, loss 0.00313764, acc 1
2016-09-05T18:14:15.203301: step 7558, loss 0.00349041, acc 1
2016-09-05T18:14:15.425385: step 7559, loss 0.0029593, acc 1
2016-09-05T18:14:15.640569: step 7560, loss 0.00350593, acc 1
2016-09-05T18:14:15.852104: step 7561, loss 0.00369901, acc 1
2016-09-05T18:14:16.055226: step 7562, loss 0.00338978, acc 1
2016-09-05T18:14:16.279734: step 7563, loss 0.00349679, acc 1
2016-09-05T18:14:16.492069: step 7564, loss 0.00281023, acc 1
2016-09-05T18:14:16.728972: step 7565, loss 0.00295684, acc 1
2016-09-05T18:14:16.896059: step 7566, loss 0.00359527, acc 1
2016-09-05T18:14:17.131629: step 7567, loss 0.00273983, acc 1
2016-09-05T18:14:17.371929: step 7568, loss 0.00293246, acc 1
2016-09-05T18:14:17.572005: step 7569, loss 0.00271501, acc 1
2016-09-05T18:14:17.767166: step 7570, loss 0.00307562, acc 1
2016-09-05T18:14:17.985381: step 7571, loss 0.00294214, acc 1
2016-09-05T18:14:18.220266: step 7572, loss 0.00294458, acc 1
2016-09-05T18:14:18.425589: step 7573, loss 0.00260145, acc 1
2016-09-05T18:14:18.666086: step 7574, loss 0.00273486, acc 1
2016-09-05T18:14:18.886332: step 7575, loss 0.00356977, acc 1
2016-09-05T18:14:19.102568: step 7576, loss 0.00309872, acc 1
2016-09-05T18:14:19.321047: step 7577, loss 0.00426577, acc 1
2016-09-05T18:14:19.544493: step 7578, loss 0.00265465, acc 1
2016-09-05T18:14:19.765454: step 7579, loss 0.00316993, acc 1
2016-09-05T18:14:20.015739: step 7580, loss 0.0028326, acc 1
2016-09-05T18:14:20.228222: step 7581, loss 0.00293037, acc 1
2016-09-05T18:14:20.450764: step 7582, loss 0.00311176, acc 1
2016-09-05T18:14:20.697914: step 7583, loss 0.00387565, acc 1
2016-09-05T18:14:20.915325: step 7584, loss 0.00264653, acc 1
2016-09-05T18:14:21.132956: step 7585, loss 0.00262524, acc 1
2016-09-05T18:14:21.349666: step 7586, loss 0.00307417, acc 1
2016-09-05T18:14:21.591719: step 7587, loss 0.00239497, acc 1
2016-09-05T18:14:21.802284: step 7588, loss 0.00262358, acc 1
2016-09-05T18:14:22.012107: step 7589, loss 0.00254762, acc 1
2016-09-05T18:14:22.217768: step 7590, loss 0.00303896, acc 1
2016-09-05T18:14:22.448834: step 7591, loss 0.00282697, acc 1
2016-09-05T18:14:22.673447: step 7592, loss 0.00334524, acc 1
2016-09-05T18:14:22.915753: step 7593, loss 0.00306933, acc 1
2016-09-05T18:14:23.120015: step 7594, loss 0.00301279, acc 1
2016-09-05T18:14:23.332655: step 7595, loss 0.00300128, acc 1
2016-09-05T18:14:23.555539: step 7596, loss 0.00252888, acc 1
2016-09-05T18:14:23.766488: step 7597, loss 0.0031482, acc 1
2016-09-05T18:14:24.013042: step 7598, loss 0.00255417, acc 1
2016-09-05T18:14:24.221256: step 7599, loss 0.00311534, acc 1
2016-09-05T18:14:24.437838: step 7600, loss 0.00294241, acc 1

Evaluation:
2016-09-05T18:14:25.028577: step 7600, loss 1.22818, acc 0.738

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-7600

2016-09-05T18:14:25.742207: step 7601, loss 0.00295837, acc 1
2016-09-05T18:14:25.957349: step 7602, loss 0.0030361, acc 1
2016-09-05T18:14:26.156754: step 7603, loss 0.00242681, acc 1
2016-09-05T18:14:26.369054: step 7604, loss 0.00304428, acc 1
2016-09-05T18:14:26.585681: step 7605, loss 0.00267317, acc 1
2016-09-05T18:14:26.814239: step 7606, loss 0.00261896, acc 1
2016-09-05T18:14:27.044417: step 7607, loss 0.00291873, acc 1
2016-09-05T18:14:27.269663: step 7608, loss 0.00327872, acc 1
2016-09-05T18:14:27.476994: step 7609, loss 0.00336478, acc 1
2016-09-05T18:14:27.711424: step 7610, loss 0.00255918, acc 1
2016-09-05T18:14:27.917559: step 7611, loss 0.00267222, acc 1
2016-09-05T18:14:28.134448: step 7612, loss 0.00260218, acc 1
2016-09-05T18:14:28.334543: step 7613, loss 0.00289022, acc 1
2016-09-05T18:14:28.540196: step 7614, loss 0.00271918, acc 1
2016-09-05T18:14:28.770356: step 7615, loss 0.00258837, acc 1
2016-09-05T18:14:28.984636: step 7616, loss 0.00277117, acc 1
2016-09-05T18:14:29.208368: step 7617, loss 0.00283232, acc 1
2016-09-05T18:14:29.447099: step 7618, loss 0.00284477, acc 1
2016-09-05T18:14:29.691283: step 7619, loss 0.00273306, acc 1
2016-09-05T18:14:29.892181: step 7620, loss 0.00243179, acc 1
2016-09-05T18:14:30.110853: step 7621, loss 0.00333935, acc 1
2016-09-05T18:14:30.322597: step 7622, loss 0.00288647, acc 1
2016-09-05T18:14:30.529475: step 7623, loss 0.00310326, acc 1
2016-09-05T18:14:30.750307: step 7624, loss 0.00287616, acc 1
2016-09-05T18:14:30.965887: step 7625, loss 0.00319226, acc 1
2016-09-05T18:14:31.202788: step 7626, loss 0.0042529, acc 1
2016-09-05T18:14:31.407668: step 7627, loss 0.00319826, acc 1
2016-09-05T18:14:31.609276: step 7628, loss 0.00358232, acc 1
2016-09-05T18:14:31.819140: step 7629, loss 0.00384397, acc 1
2016-09-05T18:14:32.062951: step 7630, loss 0.00310504, acc 1
2016-09-05T18:14:32.279645: step 7631, loss 0.00295787, acc 1
2016-09-05T18:14:32.534479: step 7632, loss 0.00349375, acc 1
2016-09-05T18:14:32.788934: step 7633, loss 0.00303117, acc 1
2016-09-05T18:14:33.042330: step 7634, loss 0.00409785, acc 1
2016-09-05T18:14:33.263700: step 7635, loss 0.00346902, acc 1
2016-09-05T18:14:33.476844: step 7636, loss 0.00313109, acc 1
2016-09-05T18:14:33.727838: step 7637, loss 0.00281323, acc 1
2016-09-05T18:14:33.938041: step 7638, loss 0.00280394, acc 1
2016-09-05T18:14:34.181112: step 7639, loss 0.00310501, acc 1
2016-09-05T18:14:34.426161: step 7640, loss 0.00284895, acc 1
2016-09-05T18:14:34.622702: step 7641, loss 0.00312932, acc 1
2016-09-05T18:14:34.837134: step 7642, loss 0.00330024, acc 1
2016-09-05T18:14:35.054286: step 7643, loss 0.00362839, acc 1
2016-09-05T18:14:35.271063: step 7644, loss 0.00315147, acc 1
2016-09-05T18:14:35.490475: step 7645, loss 0.00298388, acc 1
2016-09-05T18:14:35.735229: step 7646, loss 0.00342549, acc 1
2016-09-05T18:14:35.947282: step 7647, loss 0.00324404, acc 1
2016-09-05T18:14:36.170326: step 7648, loss 0.00324077, acc 1
2016-09-05T18:14:36.366166: step 7649, loss 0.00292808, acc 1
2016-09-05T18:14:36.586283: step 7650, loss 0.00283216, acc 1
2016-09-05T18:14:36.818273: step 7651, loss 0.0029747, acc 1
2016-09-05T18:14:37.029480: step 7652, loss 0.0027149, acc 1
2016-09-05T18:14:37.247940: step 7653, loss 0.00290985, acc 1
2016-09-05T18:14:37.447367: step 7654, loss 0.00281427, acc 1
2016-09-05T18:14:37.655667: step 7655, loss 0.00359962, acc 1
2016-09-05T18:14:37.887940: step 7656, loss 0.00289387, acc 1
2016-09-05T18:14:38.109313: step 7657, loss 0.00363114, acc 1
2016-09-05T18:14:38.327726: step 7658, loss 0.00278301, acc 1
2016-09-05T18:14:38.551910: step 7659, loss 0.00264871, acc 1
2016-09-05T18:14:38.765916: step 7660, loss 0.00247655, acc 1
2016-09-05T18:14:38.970780: step 7661, loss 0.00358698, acc 1
2016-09-05T18:14:39.187536: step 7662, loss 0.00248971, acc 1
2016-09-05T18:14:39.419647: step 7663, loss 0.00243469, acc 1
2016-09-05T18:14:39.659433: step 7664, loss 0.00422397, acc 1
2016-09-05T18:14:39.870244: step 7665, loss 0.00279931, acc 1
2016-09-05T18:14:40.073031: step 7666, loss 0.00251159, acc 1
2016-09-05T18:14:40.290768: step 7667, loss 0.00258641, acc 1
2016-09-05T18:14:40.506970: step 7668, loss 0.00313816, acc 1
2016-09-05T18:14:40.718111: step 7669, loss 0.00373068, acc 1
2016-09-05T18:14:40.951509: step 7670, loss 0.00292668, acc 1
2016-09-05T18:14:41.172788: step 7671, loss 0.00311747, acc 1
2016-09-05T18:14:41.384905: step 7672, loss 0.0032791, acc 1
2016-09-05T18:14:41.585911: step 7673, loss 0.0024353, acc 1
2016-09-05T18:14:41.828888: step 7674, loss 0.00245232, acc 1
2016-09-05T18:14:42.093467: step 7675, loss 0.00372423, acc 1
2016-09-05T18:14:42.293994: step 7676, loss 0.00275964, acc 1
2016-09-05T18:14:42.500905: step 7677, loss 0.00241389, acc 1
2016-09-05T18:14:42.701388: step 7678, loss 0.00349688, acc 1
2016-09-05T18:14:42.909000: step 7679, loss 0.00370629, acc 1
2016-09-05T18:14:43.125432: step 7680, loss 0.00245646, acc 1
2016-09-05T18:14:43.369453: step 7681, loss 0.00318167, acc 1
2016-09-05T18:14:43.585240: step 7682, loss 0.00250263, acc 1
2016-09-05T18:14:43.809503: step 7683, loss 0.00296515, acc 1
2016-09-05T18:14:44.090827: step 7684, loss 0.00296025, acc 1
2016-09-05T18:14:44.303456: step 7685, loss 0.00253318, acc 1
2016-09-05T18:14:44.512723: step 7686, loss 0.00337698, acc 1
2016-09-05T18:14:44.717047: step 7687, loss 0.00282033, acc 1
2016-09-05T18:14:44.925362: step 7688, loss 0.00274205, acc 1
2016-09-05T18:14:45.132211: step 7689, loss 0.0031163, acc 1
2016-09-05T18:14:45.365271: step 7690, loss 0.00241602, acc 1
2016-09-05T18:14:45.574644: step 7691, loss 0.00320131, acc 1
2016-09-05T18:14:45.822830: step 7692, loss 0.00383273, acc 1
2016-09-05T18:14:46.031468: step 7693, loss 0.00292957, acc 1
2016-09-05T18:14:46.254114: step 7694, loss 0.00255384, acc 1
2016-09-05T18:14:46.486917: step 7695, loss 0.00239055, acc 1
2016-09-05T18:14:46.715390: step 7696, loss 0.00296201, acc 1
2016-09-05T18:14:46.937215: step 7697, loss 0.00261862, acc 1
2016-09-05T18:14:47.139259: step 7698, loss 0.00270788, acc 1
2016-09-05T18:14:47.358395: step 7699, loss 0.0027457, acc 1
2016-09-05T18:14:47.578127: step 7700, loss 0.00304579, acc 1

Evaluation:
2016-09-05T18:14:48.209793: step 7700, loss 1.25098, acc 0.732

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-7700

2016-09-05T18:14:48.930824: step 7701, loss 0.00281085, acc 1
2016-09-05T18:14:49.166287: step 7702, loss 0.00269511, acc 1
2016-09-05T18:14:49.379379: step 7703, loss 0.00238994, acc 1
2016-09-05T18:14:49.579271: step 7704, loss 0.00249239, acc 1
2016-09-05T18:14:49.790958: step 7705, loss 0.00290474, acc 1
2016-09-05T18:14:50.008159: step 7706, loss 0.00251295, acc 1
2016-09-05T18:14:50.240971: step 7707, loss 0.00522235, acc 1
2016-09-05T18:14:50.429383: step 7708, loss 0.00248623, acc 1
2016-09-05T18:14:50.655228: step 7709, loss 0.00273568, acc 1
2016-09-05T18:14:50.867307: step 7710, loss 0.00250809, acc 1
2016-09-05T18:14:51.085831: step 7711, loss 0.00288977, acc 1
2016-09-05T18:14:51.311521: step 7712, loss 0.00296203, acc 1
2016-09-05T18:14:51.574948: step 7713, loss 0.00347958, acc 1
2016-09-05T18:14:51.782449: step 7714, loss 0.00306047, acc 1
2016-09-05T18:14:52.011651: step 7715, loss 0.00262212, acc 1
2016-09-05T18:14:52.242656: step 7716, loss 0.00342638, acc 1
2016-09-05T18:14:52.483008: step 7717, loss 0.00282003, acc 1
2016-09-05T18:14:52.709941: step 7718, loss 0.00335253, acc 1
2016-09-05T18:14:52.927569: step 7719, loss 0.00288857, acc 1
2016-09-05T18:14:53.169787: step 7720, loss 0.00269206, acc 1
2016-09-05T18:14:53.373125: step 7721, loss 0.00306323, acc 1
2016-09-05T18:14:53.588543: step 7722, loss 0.00277206, acc 1
2016-09-05T18:14:53.788489: step 7723, loss 0.0027685, acc 1
2016-09-05T18:14:54.012817: step 7724, loss 0.00312817, acc 1
2016-09-05T18:14:54.226601: step 7725, loss 0.00256955, acc 1
2016-09-05T18:14:54.444125: step 7726, loss 0.00275387, acc 1
2016-09-05T18:14:54.649548: step 7727, loss 0.00293247, acc 1
2016-09-05T18:14:54.871947: step 7728, loss 0.00298984, acc 1
2016-09-05T18:14:55.100925: step 7729, loss 0.00323242, acc 1
2016-09-05T18:14:55.307254: step 7730, loss 0.00371994, acc 1
2016-09-05T18:14:55.521842: step 7731, loss 0.0029947, acc 1
2016-09-05T18:14:55.756866: step 7732, loss 0.0029719, acc 1
2016-09-05T18:14:55.971434: step 7733, loss 0.00402332, acc 1
2016-09-05T18:14:56.197907: step 7734, loss 0.00299713, acc 1
2016-09-05T18:14:56.410989: step 7735, loss 0.00272736, acc 1
2016-09-05T18:14:56.625419: step 7736, loss 0.00286987, acc 1
2016-09-05T18:14:56.859111: step 7737, loss 0.00268662, acc 1
2016-09-05T18:14:57.080241: step 7738, loss 0.00247963, acc 1
2016-09-05T18:14:57.312504: step 7739, loss 0.0035116, acc 1
2016-09-05T18:14:57.525917: step 7740, loss 0.00402269, acc 1
2016-09-05T18:14:57.714928: step 7741, loss 0.00327181, acc 1
2016-09-05T18:14:57.924048: step 7742, loss 0.00315784, acc 1
2016-09-05T18:14:58.130808: step 7743, loss 0.00508816, acc 1
2016-09-05T18:14:58.336515: step 7744, loss 0.00260273, acc 1
2016-09-05T18:14:58.563597: step 7745, loss 0.00452747, acc 1
2016-09-05T18:14:58.797294: step 7746, loss 0.00257609, acc 1
2016-09-05T18:14:59.025741: step 7747, loss 0.00321944, acc 1
2016-09-05T18:14:59.263332: step 7748, loss 0.00265671, acc 1
2016-09-05T18:14:59.479590: step 7749, loss 0.00285928, acc 1
2016-09-05T18:14:59.701140: step 7750, loss 0.00264932, acc 1
2016-09-05T18:14:59.945235: step 7751, loss 0.00253143, acc 1
2016-09-05T18:15:00.146315: step 7752, loss 0.00326386, acc 1
2016-09-05T18:15:00.378344: step 7753, loss 0.00302974, acc 1
2016-09-05T18:15:00.583687: step 7754, loss 0.00336084, acc 1
2016-09-05T18:15:00.777008: step 7755, loss 0.00399863, acc 1
2016-09-05T18:15:00.985270: step 7756, loss 0.00409531, acc 1
2016-09-05T18:15:01.204558: step 7757, loss 0.00264465, acc 1
2016-09-05T18:15:01.422119: step 7758, loss 0.00305296, acc 1
2016-09-05T18:15:01.651319: step 7759, loss 0.00305392, acc 1
2016-09-05T18:15:01.783202: step 7760, loss 0.00379617, acc 1
2016-09-05T18:15:02.000767: step 7761, loss 0.00311759, acc 1
2016-09-05T18:15:02.229163: step 7762, loss 0.00296547, acc 1
2016-09-05T18:15:02.477352: step 7763, loss 0.00282033, acc 1
2016-09-05T18:15:02.704684: step 7764, loss 0.0033458, acc 1
2016-09-05T18:15:02.920176: step 7765, loss 0.00265093, acc 1
2016-09-05T18:15:03.140498: step 7766, loss 0.00256094, acc 1
2016-09-05T18:15:03.370274: step 7767, loss 0.00392026, acc 1
2016-09-05T18:15:03.581842: step 7768, loss 0.00253886, acc 1
2016-09-05T18:15:03.791494: step 7769, loss 0.00288846, acc 1
2016-09-05T18:15:03.994983: step 7770, loss 0.00272228, acc 1
2016-09-05T18:15:04.200128: step 7771, loss 0.00312828, acc 1
2016-09-05T18:15:04.418566: step 7772, loss 0.00382994, acc 1
2016-09-05T18:15:04.648479: step 7773, loss 0.00255947, acc 1
2016-09-05T18:15:04.874574: step 7774, loss 0.00266441, acc 1
2016-09-05T18:15:05.093120: step 7775, loss 0.0033247, acc 1
2016-09-05T18:15:05.316647: step 7776, loss 0.00264668, acc 1
2016-09-05T18:15:05.523999: step 7777, loss 0.0036159, acc 1
2016-09-05T18:15:05.744883: step 7778, loss 0.00270267, acc 1
2016-09-05T18:15:05.957827: step 7779, loss 0.00240847, acc 1
2016-09-05T18:15:06.155868: step 7780, loss 0.00246021, acc 1
2016-09-05T18:15:06.383431: step 7781, loss 0.00300197, acc 1
2016-09-05T18:15:06.569906: step 7782, loss 0.00328371, acc 1
2016-09-05T18:15:06.815819: step 7783, loss 0.00246846, acc 1
2016-09-05T18:15:07.046478: step 7784, loss 0.00268276, acc 1
2016-09-05T18:15:07.273058: step 7785, loss 0.00226262, acc 1
2016-09-05T18:15:07.488159: step 7786, loss 0.0028558, acc 1
2016-09-05T18:15:07.726420: step 7787, loss 0.00260978, acc 1
2016-09-05T18:15:07.932433: step 7788, loss 0.00243553, acc 1
2016-09-05T18:15:08.143091: step 7789, loss 0.00248811, acc 1
2016-09-05T18:15:08.380516: step 7790, loss 0.0029882, acc 1
2016-09-05T18:15:08.605427: step 7791, loss 0.00288067, acc 1
2016-09-05T18:15:08.816370: step 7792, loss 0.00216418, acc 1
2016-09-05T18:15:09.002163: step 7793, loss 0.00274455, acc 1
2016-09-05T18:15:09.202845: step 7794, loss 0.00260872, acc 1
2016-09-05T18:15:09.413457: step 7795, loss 0.00365326, acc 1
2016-09-05T18:15:09.629439: step 7796, loss 0.00268316, acc 1
2016-09-05T18:15:09.834034: step 7797, loss 0.00243247, acc 1
2016-09-05T18:15:10.043930: step 7798, loss 0.00261257, acc 1
2016-09-05T18:15:10.240310: step 7799, loss 0.00239817, acc 1
2016-09-05T18:15:10.442684: step 7800, loss 0.00219616, acc 1

Evaluation:
2016-09-05T18:15:11.030739: step 7800, loss 1.20564, acc 0.739

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-7800

2016-09-05T18:15:11.766625: step 7801, loss 0.00227277, acc 1
2016-09-05T18:15:11.969488: step 7802, loss 0.00272764, acc 1
2016-09-05T18:15:12.181898: step 7803, loss 0.00274061, acc 1
2016-09-05T18:15:12.381270: step 7804, loss 0.00228944, acc 1
2016-09-05T18:15:12.584248: step 7805, loss 0.00244181, acc 1
2016-09-05T18:15:12.790085: step 7806, loss 0.00250122, acc 1
2016-09-05T18:15:13.005470: step 7807, loss 0.00298755, acc 1
2016-09-05T18:15:13.242663: step 7808, loss 0.0021416, acc 1
2016-09-05T18:15:13.464596: step 7809, loss 0.00259306, acc 1
2016-09-05T18:15:13.678565: step 7810, loss 0.00230928, acc 1
2016-09-05T18:15:13.896255: step 7811, loss 0.00256302, acc 1
2016-09-05T18:15:14.112216: step 7812, loss 0.00270816, acc 1
2016-09-05T18:15:14.331662: step 7813, loss 0.00290547, acc 1
2016-09-05T18:15:14.549356: step 7814, loss 0.00298308, acc 1
2016-09-05T18:15:14.757395: step 7815, loss 0.0032013, acc 1
2016-09-05T18:15:14.980206: step 7816, loss 0.00249858, acc 1
2016-09-05T18:15:15.186847: step 7817, loss 0.00268427, acc 1
2016-09-05T18:15:15.401357: step 7818, loss 0.00326845, acc 1
2016-09-05T18:15:15.610149: step 7819, loss 0.00249237, acc 1
2016-09-05T18:15:15.839436: step 7820, loss 0.0023452, acc 1
2016-09-05T18:15:16.049214: step 7821, loss 0.00311552, acc 1
2016-09-05T18:15:16.268956: step 7822, loss 0.0037493, acc 1
2016-09-05T18:15:16.471141: step 7823, loss 0.00250447, acc 1
2016-09-05T18:15:16.682713: step 7824, loss 0.00251438, acc 1
2016-09-05T18:15:16.898368: step 7825, loss 0.00278815, acc 1
2016-09-05T18:15:17.118889: step 7826, loss 0.00237339, acc 1
2016-09-05T18:15:17.322578: step 7827, loss 0.00298534, acc 1
2016-09-05T18:15:17.559283: step 7828, loss 0.002914, acc 1
2016-09-05T18:15:17.808753: step 7829, loss 0.00227923, acc 1
2016-09-05T18:15:18.021563: step 7830, loss 0.00268074, acc 1
2016-09-05T18:15:18.239959: step 7831, loss 0.00457046, acc 1
2016-09-05T18:15:18.454860: step 7832, loss 0.00257046, acc 1
2016-09-05T18:15:18.662881: step 7833, loss 0.00245899, acc 1
2016-09-05T18:15:18.884000: step 7834, loss 0.00269957, acc 1
2016-09-05T18:15:19.116247: step 7835, loss 0.00251431, acc 1
2016-09-05T18:15:19.340362: step 7836, loss 0.0105663, acc 1
2016-09-05T18:15:19.586320: step 7837, loss 0.0027248, acc 1
2016-09-05T18:15:19.835095: step 7838, loss 0.00253635, acc 1
2016-09-05T18:15:20.049734: step 7839, loss 0.00273414, acc 1
2016-09-05T18:15:20.263369: step 7840, loss 0.00422187, acc 1
2016-09-05T18:15:20.473830: step 7841, loss 0.00333747, acc 1
2016-09-05T18:15:20.690745: step 7842, loss 0.00297749, acc 1
2016-09-05T18:15:20.916750: step 7843, loss 0.00501858, acc 1
2016-09-05T18:15:21.146136: step 7844, loss 0.0029664, acc 1
2016-09-05T18:15:21.356714: step 7845, loss 0.00359185, acc 1
2016-09-05T18:15:21.629399: step 7846, loss 0.0038286, acc 1
2016-09-05T18:15:21.851081: step 7847, loss 0.00367551, acc 1
2016-09-05T18:15:22.043028: step 7848, loss 0.00418514, acc 1
2016-09-05T18:15:22.255165: step 7849, loss 0.00334514, acc 1
2016-09-05T18:15:22.460977: step 7850, loss 0.00403501, acc 1
2016-09-05T18:15:22.716081: step 7851, loss 0.0035304, acc 1
2016-09-05T18:15:22.958771: step 7852, loss 0.00583914, acc 1
2016-09-05T18:15:23.193628: step 7853, loss 0.00343133, acc 1
2016-09-05T18:15:23.412441: step 7854, loss 0.00450331, acc 1
2016-09-05T18:15:23.635367: step 7855, loss 0.00348841, acc 1
2016-09-05T18:15:23.847733: step 7856, loss 0.00431198, acc 1
2016-09-05T18:15:24.057523: step 7857, loss 0.00350715, acc 1
2016-09-05T18:15:24.267262: step 7858, loss 0.00434568, acc 1
2016-09-05T18:15:24.479431: step 7859, loss 0.00350294, acc 1
2016-09-05T18:15:24.704720: step 7860, loss 0.00369965, acc 1
2016-09-05T18:15:24.903885: step 7861, loss 0.00348798, acc 1
2016-09-05T18:15:25.109356: step 7862, loss 0.00326345, acc 1
2016-09-05T18:15:25.316778: step 7863, loss 0.0034165, acc 1
2016-09-05T18:15:25.537649: step 7864, loss 0.00400909, acc 1
2016-09-05T18:15:25.740053: step 7865, loss 0.00416942, acc 1
2016-09-05T18:15:25.965455: step 7866, loss 0.00357775, acc 1
2016-09-05T18:15:26.181394: step 7867, loss 0.0033909, acc 1
2016-09-05T18:15:26.394305: step 7868, loss 0.00308959, acc 1
2016-09-05T18:15:26.601000: step 7869, loss 0.0028059, acc 1
2016-09-05T18:15:26.820510: step 7870, loss 0.00280435, acc 1
2016-09-05T18:15:27.028698: step 7871, loss 0.00286554, acc 1
2016-09-05T18:15:27.261655: step 7872, loss 0.00271305, acc 1
2016-09-05T18:15:27.497417: step 7873, loss 0.00513424, acc 1
2016-09-05T18:15:27.713762: step 7874, loss 0.00287249, acc 1
2016-09-05T18:15:27.929213: step 7875, loss 0.00281106, acc 1
2016-09-05T18:15:28.133991: step 7876, loss 0.00340694, acc 1
2016-09-05T18:15:28.373053: step 7877, loss 0.00774069, acc 1
2016-09-05T18:15:28.589144: step 7878, loss 0.00325971, acc 1
2016-09-05T18:15:28.791245: step 7879, loss 0.00330662, acc 1
2016-09-05T18:15:29.008647: step 7880, loss 0.00321032, acc 1
2016-09-05T18:15:29.226531: step 7881, loss 0.00412165, acc 1
2016-09-05T18:15:29.433492: step 7882, loss 0.0031738, acc 1
2016-09-05T18:15:29.647871: step 7883, loss 0.00639331, acc 1
2016-09-05T18:15:29.856947: step 7884, loss 0.00422918, acc 1
2016-09-05T18:15:30.078692: step 7885, loss 0.00294275, acc 1
2016-09-05T18:15:30.301914: step 7886, loss 0.00321191, acc 1
2016-09-05T18:15:30.514031: step 7887, loss 0.00337138, acc 1
2016-09-05T18:15:30.745257: step 7888, loss 0.00746005, acc 1
2016-09-05T18:15:30.949790: step 7889, loss 0.00448998, acc 1
2016-09-05T18:15:31.169642: step 7890, loss 0.0115016, acc 1
2016-09-05T18:15:31.395127: step 7891, loss 0.00386353, acc 1
2016-09-05T18:15:31.623633: step 7892, loss 0.00394273, acc 1
2016-09-05T18:15:31.858151: step 7893, loss 0.00404921, acc 1
2016-09-05T18:15:32.077263: step 7894, loss 0.00442765, acc 1
2016-09-05T18:15:32.289940: step 7895, loss 0.00479435, acc 1
2016-09-05T18:15:32.525610: step 7896, loss 0.00647138, acc 1
2016-09-05T18:15:32.767044: step 7897, loss 0.00700889, acc 1
2016-09-05T18:15:32.981394: step 7898, loss 0.00552814, acc 1
2016-09-05T18:15:33.213077: step 7899, loss 0.00577786, acc 1
2016-09-05T18:15:33.442048: step 7900, loss 0.00577073, acc 1

Evaluation:
2016-09-05T18:15:34.052237: step 7900, loss 1.70743, acc 0.748

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-7900

2016-09-05T18:15:34.760718: step 7901, loss 0.00639597, acc 1
2016-09-05T18:15:35.001594: step 7902, loss 0.0055424, acc 1
2016-09-05T18:15:35.230215: step 7903, loss 0.00546899, acc 1
2016-09-05T18:15:35.498951: step 7904, loss 0.0055556, acc 1
2016-09-05T18:15:35.715255: step 7905, loss 0.00548653, acc 1
2016-09-05T18:15:35.943109: step 7906, loss 0.00556171, acc 1
2016-09-05T18:15:36.138804: step 7907, loss 0.00557323, acc 1
2016-09-05T18:15:36.352198: step 7908, loss 0.00536882, acc 1
2016-09-05T18:15:36.581204: step 7909, loss 0.00549687, acc 1
2016-09-05T18:15:36.796490: step 7910, loss 0.00550457, acc 1
2016-09-05T18:15:37.021100: step 7911, loss 0.00508969, acc 1
2016-09-05T18:15:37.219433: step 7912, loss 0.00519823, acc 1
2016-09-05T18:15:37.430599: step 7913, loss 0.00496428, acc 1
2016-09-05T18:15:37.645271: step 7914, loss 0.00503532, acc 1
2016-09-05T18:15:37.898128: step 7915, loss 0.00473648, acc 1
2016-09-05T18:15:38.111979: step 7916, loss 0.005031, acc 1
2016-09-05T18:15:38.339972: step 7917, loss 0.00524753, acc 1
2016-09-05T18:15:38.549643: step 7918, loss 0.00415724, acc 1
2016-09-05T18:15:38.757905: step 7919, loss 0.00403244, acc 1
2016-09-05T18:15:38.979593: step 7920, loss 0.00593765, acc 1
2016-09-05T18:15:39.192474: step 7921, loss 0.00490202, acc 1
2016-09-05T18:15:39.445184: step 7922, loss 0.00404551, acc 1
2016-09-05T18:15:39.646605: step 7923, loss 0.00397459, acc 1
2016-09-05T18:15:39.858035: step 7924, loss 0.00412994, acc 1
2016-09-05T18:15:40.089033: step 7925, loss 0.00379106, acc 1
2016-09-05T18:15:40.331343: step 7926, loss 0.00325866, acc 1
2016-09-05T18:15:40.533851: step 7927, loss 0.00413511, acc 1
2016-09-05T18:15:40.763524: step 7928, loss 0.00330885, acc 1
2016-09-05T18:15:40.963255: step 7929, loss 0.00438362, acc 1
2016-09-05T18:15:41.168144: step 7930, loss 0.00364938, acc 1
2016-09-05T18:15:41.363004: step 7931, loss 0.00378188, acc 1
2016-09-05T18:15:41.576069: step 7932, loss 0.00309989, acc 1
2016-09-05T18:15:41.784229: step 7933, loss 0.00353912, acc 1
2016-09-05T18:15:42.014076: step 7934, loss 0.00299422, acc 1
2016-09-05T18:15:42.237135: step 7935, loss 0.0029333, acc 1
2016-09-05T18:15:42.458845: step 7936, loss 0.00287113, acc 1
2016-09-05T18:15:42.670819: step 7937, loss 0.00343224, acc 1
2016-09-05T18:15:42.886685: step 7938, loss 0.00382441, acc 1
2016-09-05T18:15:43.117801: step 7939, loss 0.00315181, acc 1
2016-09-05T18:15:43.327906: step 7940, loss 0.00608036, acc 1
2016-09-05T18:15:43.537986: step 7941, loss 0.00473515, acc 1
2016-09-05T18:15:43.770397: step 7942, loss 0.00255112, acc 1
2016-09-05T18:15:44.003026: step 7943, loss 0.00296183, acc 1
2016-09-05T18:15:44.221018: step 7944, loss 0.0040739, acc 1
2016-09-05T18:15:44.419567: step 7945, loss 0.00268782, acc 1
2016-09-05T18:15:44.649454: step 7946, loss 0.00272057, acc 1
2016-09-05T18:15:44.888938: step 7947, loss 0.00271372, acc 1
2016-09-05T18:15:45.095105: step 7948, loss 0.0033378, acc 1
2016-09-05T18:15:45.301305: step 7949, loss 0.00270336, acc 1
2016-09-05T18:15:45.512477: step 7950, loss 0.00283045, acc 1
2016-09-05T18:15:45.710516: step 7951, loss 0.00282853, acc 1
2016-09-05T18:15:45.914569: step 7952, loss 0.00426685, acc 1
2016-09-05T18:15:46.116935: step 7953, loss 0.00296309, acc 1
2016-09-05T18:15:46.239280: step 7954, loss 0.00243456, acc 1
2016-09-05T18:15:46.462190: step 7955, loss 0.00341485, acc 1
2016-09-05T18:15:46.695115: step 7956, loss 0.00284901, acc 1
2016-09-05T18:15:46.903905: step 7957, loss 0.00249076, acc 1
2016-09-05T18:15:47.100064: step 7958, loss 0.00255252, acc 1
2016-09-05T18:15:47.306166: step 7959, loss 0.00246278, acc 1
2016-09-05T18:15:47.524130: step 7960, loss 0.00250541, acc 1
2016-09-05T18:15:47.728362: step 7961, loss 0.00296617, acc 1
2016-09-05T18:15:47.944449: step 7962, loss 0.00274023, acc 1
2016-09-05T18:15:48.159933: step 7963, loss 0.00286618, acc 1
2016-09-05T18:15:48.393233: step 7964, loss 0.00310708, acc 1
2016-09-05T18:15:48.631455: step 7965, loss 0.00259925, acc 1
2016-09-05T18:15:48.854813: step 7966, loss 0.00226515, acc 1
2016-09-05T18:15:49.069477: step 7967, loss 0.00278894, acc 1
2016-09-05T18:15:49.284649: step 7968, loss 0.00253618, acc 1
2016-09-05T18:15:49.506707: step 7969, loss 0.00216098, acc 1
2016-09-05T18:15:49.727160: step 7970, loss 0.00243408, acc 1
2016-09-05T18:15:49.946027: step 7971, loss 0.00240587, acc 1
2016-09-05T18:15:50.163849: step 7972, loss 0.00214573, acc 1
2016-09-05T18:15:50.379341: step 7973, loss 0.00233663, acc 1
2016-09-05T18:15:50.607578: step 7974, loss 0.00274444, acc 1
2016-09-05T18:15:50.820413: step 7975, loss 0.00529308, acc 1
2016-09-05T18:15:51.059223: step 7976, loss 0.00286459, acc 1
2016-09-05T18:15:51.272618: step 7977, loss 0.00250986, acc 1
2016-09-05T18:15:51.498166: step 7978, loss 0.00306392, acc 1
2016-09-05T18:15:51.743673: step 7979, loss 0.00263333, acc 1
2016-09-05T18:15:51.949508: step 7980, loss 0.00286639, acc 1
2016-09-05T18:15:52.149542: step 7981, loss 0.00414344, acc 1
2016-09-05T18:15:52.361553: step 7982, loss 0.0026214, acc 1
2016-09-05T18:15:52.589212: step 7983, loss 0.00244628, acc 1
2016-09-05T18:15:52.806305: step 7984, loss 0.00230067, acc 1
2016-09-05T18:15:53.035181: step 7985, loss 0.00339146, acc 1
2016-09-05T18:15:53.253462: step 7986, loss 0.00256776, acc 1
2016-09-05T18:15:53.476031: step 7987, loss 0.00296054, acc 1
2016-09-05T18:15:53.689650: step 7988, loss 0.00309273, acc 1
2016-09-05T18:15:53.895361: step 7989, loss 0.00244655, acc 1
2016-09-05T18:15:54.124258: step 7990, loss 0.00271175, acc 1
2016-09-05T18:15:54.333056: step 7991, loss 0.00246036, acc 1
2016-09-05T18:15:54.538830: step 7992, loss 0.00276532, acc 1
2016-09-05T18:15:54.776621: step 7993, loss 0.00296916, acc 1
2016-09-05T18:15:54.991242: step 7994, loss 0.00259928, acc 1
2016-09-05T18:15:55.198065: step 7995, loss 0.00276841, acc 1
2016-09-05T18:15:55.411545: step 7996, loss 0.00251565, acc 1
2016-09-05T18:15:55.618183: step 7997, loss 0.00238385, acc 1
2016-09-05T18:15:55.839698: step 7998, loss 0.0026085, acc 1
2016-09-05T18:15:56.092128: step 7999, loss 0.00282843, acc 1
2016-09-05T18:15:56.295060: step 8000, loss 0.00247329, acc 1

Evaluation:
2016-09-05T18:15:56.943646: step 8000, loss 1.27276, acc 0.735

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-8000

2016-09-05T18:15:57.670154: step 8001, loss 0.00250416, acc 1
2016-09-05T18:15:57.897385: step 8002, loss 0.00218628, acc 1
2016-09-05T18:15:58.101384: step 8003, loss 0.00274663, acc 1
2016-09-05T18:15:58.330325: step 8004, loss 0.00232375, acc 1
2016-09-05T18:15:58.537412: step 8005, loss 0.00266387, acc 1
2016-09-05T18:15:58.741823: step 8006, loss 0.00381214, acc 1
2016-09-05T18:15:58.942427: step 8007, loss 0.00309877, acc 1
2016-09-05T18:15:59.162522: step 8008, loss 0.00243961, acc 1
2016-09-05T18:15:59.374433: step 8009, loss 0.0039728, acc 1
2016-09-05T18:15:59.585794: step 8010, loss 0.00223619, acc 1
2016-09-05T18:15:59.806115: step 8011, loss 0.00220431, acc 1
2016-09-05T18:16:00.009451: step 8012, loss 0.00256138, acc 1
2016-09-05T18:16:00.249088: step 8013, loss 0.00263071, acc 1
2016-09-05T18:16:00.452161: step 8014, loss 0.00244093, acc 1
2016-09-05T18:16:00.655605: step 8015, loss 0.00220763, acc 1
2016-09-05T18:16:00.853086: step 8016, loss 0.00253506, acc 1
2016-09-05T18:16:01.066572: step 8017, loss 0.00349522, acc 1
2016-09-05T18:16:01.275322: step 8018, loss 0.00235192, acc 1
2016-09-05T18:16:01.478744: step 8019, loss 0.00242409, acc 1
2016-09-05T18:16:01.671105: step 8020, loss 0.00255577, acc 1
2016-09-05T18:16:01.888553: step 8021, loss 0.00227769, acc 1
2016-09-05T18:16:02.099312: step 8022, loss 0.00219092, acc 1
2016-09-05T18:16:02.320350: step 8023, loss 0.00307674, acc 1
2016-09-05T18:16:02.555706: step 8024, loss 0.00230492, acc 1
2016-09-05T18:16:02.780464: step 8025, loss 0.00255653, acc 1
2016-09-05T18:16:02.987125: step 8026, loss 0.0054053, acc 1
2016-09-05T18:16:03.222554: step 8027, loss 0.00246825, acc 1
2016-09-05T18:16:03.462733: step 8028, loss 0.00282233, acc 1
2016-09-05T18:16:03.677954: step 8029, loss 0.00251802, acc 1
2016-09-05T18:16:03.883925: step 8030, loss 0.00259839, acc 1
2016-09-05T18:16:04.078923: step 8031, loss 0.00317556, acc 1
2016-09-05T18:16:04.280203: step 8032, loss 0.00269682, acc 1
2016-09-05T18:16:04.498839: step 8033, loss 0.00458791, acc 1
2016-09-05T18:16:04.740125: step 8034, loss 0.00282029, acc 1
2016-09-05T18:16:04.946792: step 8035, loss 0.00261678, acc 1
2016-09-05T18:16:05.201246: step 8036, loss 0.00249753, acc 1
2016-09-05T18:16:05.419937: step 8037, loss 0.00259687, acc 1
2016-09-05T18:16:05.650738: step 8038, loss 0.0025565, acc 1
2016-09-05T18:16:05.922069: step 8039, loss 0.0037155, acc 1
2016-09-05T18:16:06.130406: step 8040, loss 0.00308103, acc 1
2016-09-05T18:16:06.365854: step 8041, loss 0.00342322, acc 1
2016-09-05T18:16:06.596913: step 8042, loss 0.00307184, acc 1
2016-09-05T18:16:06.814843: step 8043, loss 0.00298386, acc 1
2016-09-05T18:16:07.023755: step 8044, loss 0.00277391, acc 1
2016-09-05T18:16:07.255404: step 8045, loss 0.00314757, acc 1
2016-09-05T18:16:07.481898: step 8046, loss 0.00312482, acc 1
2016-09-05T18:16:07.682695: step 8047, loss 0.00261382, acc 1
2016-09-05T18:16:07.918204: step 8048, loss 0.00252538, acc 1
2016-09-05T18:16:08.141361: step 8049, loss 0.003135, acc 1
2016-09-05T18:16:08.372007: step 8050, loss 0.00335938, acc 1
2016-09-05T18:16:08.585591: step 8051, loss 0.00380952, acc 1
2016-09-05T18:16:08.813599: step 8052, loss 0.00295335, acc 1
2016-09-05T18:16:09.021648: step 8053, loss 0.00351, acc 1
2016-09-05T18:16:09.249334: step 8054, loss 0.0031841, acc 1
2016-09-05T18:16:09.480620: step 8055, loss 0.00368223, acc 1
2016-09-05T18:16:09.692608: step 8056, loss 0.0025498, acc 1
2016-09-05T18:16:09.924701: step 8057, loss 0.00250807, acc 1
2016-09-05T18:16:10.113388: step 8058, loss 0.00292558, acc 1
2016-09-05T18:16:10.337939: step 8059, loss 0.00299418, acc 1
2016-09-05T18:16:10.549571: step 8060, loss 0.00230314, acc 1
2016-09-05T18:16:10.794327: step 8061, loss 0.00305547, acc 1
2016-09-05T18:16:11.034404: step 8062, loss 0.00325256, acc 1
2016-09-05T18:16:11.259693: step 8063, loss 0.00246837, acc 1
2016-09-05T18:16:11.467796: step 8064, loss 0.00298002, acc 1
2016-09-05T18:16:11.688967: step 8065, loss 0.00366811, acc 1
2016-09-05T18:16:11.919103: step 8066, loss 0.00291154, acc 1
2016-09-05T18:16:12.169853: step 8067, loss 0.00261172, acc 1
2016-09-05T18:16:12.384055: step 8068, loss 0.00250167, acc 1
2016-09-05T18:16:12.592364: step 8069, loss 0.00312763, acc 1
2016-09-05T18:16:12.819800: step 8070, loss 0.00248256, acc 1
2016-09-05T18:16:13.047379: step 8071, loss 0.00747118, acc 1
2016-09-05T18:16:13.275946: step 8072, loss 0.00279917, acc 1
2016-09-05T18:16:13.485693: step 8073, loss 0.00259579, acc 1
2016-09-05T18:16:13.697442: step 8074, loss 0.0027612, acc 1
2016-09-05T18:16:13.904398: step 8075, loss 0.00475753, acc 1
2016-09-05T18:16:14.112786: step 8076, loss 0.00343093, acc 1
2016-09-05T18:16:14.336370: step 8077, loss 0.00335918, acc 1
2016-09-05T18:16:14.531254: step 8078, loss 0.00513669, acc 1
2016-09-05T18:16:14.767506: step 8079, loss 0.00370973, acc 1
2016-09-05T18:16:14.968805: step 8080, loss 0.00351196, acc 1
2016-09-05T18:16:15.183877: step 8081, loss 0.00419917, acc 1
2016-09-05T18:16:15.392432: step 8082, loss 0.00363332, acc 1
2016-09-05T18:16:15.612216: step 8083, loss 0.00385519, acc 1
2016-09-05T18:16:15.816622: step 8084, loss 0.00530473, acc 1
2016-09-05T18:16:16.031324: step 8085, loss 0.00388078, acc 1
2016-09-05T18:16:16.269551: step 8086, loss 0.00401037, acc 1
2016-09-05T18:16:16.484057: step 8087, loss 0.00640112, acc 1
2016-09-05T18:16:16.715864: step 8088, loss 0.00413945, acc 1
2016-09-05T18:16:16.962997: step 8089, loss 0.00423534, acc 1
2016-09-05T18:16:17.210911: step 8090, loss 0.00438996, acc 1
2016-09-05T18:16:17.408382: step 8091, loss 0.00399843, acc 1
2016-09-05T18:16:17.612511: step 8092, loss 0.00403326, acc 1
2016-09-05T18:16:17.818072: step 8093, loss 0.00412389, acc 1
2016-09-05T18:16:18.032461: step 8094, loss 0.00405871, acc 1
2016-09-05T18:16:18.262146: step 8095, loss 0.00424077, acc 1
2016-09-05T18:16:18.491116: step 8096, loss 0.00380943, acc 1
2016-09-05T18:16:18.699858: step 8097, loss 0.00368598, acc 1
2016-09-05T18:16:18.914336: step 8098, loss 0.00371174, acc 1
2016-09-05T18:16:19.126348: step 8099, loss 0.00486052, acc 1
2016-09-05T18:16:19.355549: step 8100, loss 0.00382751, acc 1

Evaluation:
2016-09-05T18:16:19.961476: step 8100, loss 1.44054, acc 0.743

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-8100

2016-09-05T18:16:20.736662: step 8101, loss 0.00344276, acc 1
2016-09-05T18:16:20.965459: step 8102, loss 0.00374561, acc 1
2016-09-05T18:16:21.182712: step 8103, loss 0.00369935, acc 1
2016-09-05T18:16:21.402331: step 8104, loss 0.00434081, acc 1
2016-09-05T18:16:21.637164: step 8105, loss 0.00333355, acc 1
2016-09-05T18:16:21.842134: step 8106, loss 0.00326196, acc 1
2016-09-05T18:16:22.055832: step 8107, loss 0.00379562, acc 1
2016-09-05T18:16:22.269148: step 8108, loss 0.00302048, acc 1
2016-09-05T18:16:22.495454: step 8109, loss 0.00354344, acc 1
2016-09-05T18:16:22.743896: step 8110, loss 0.00303467, acc 1
2016-09-05T18:16:22.972313: step 8111, loss 0.00286729, acc 1
2016-09-05T18:16:23.175510: step 8112, loss 0.00313439, acc 1
2016-09-05T18:16:23.401877: step 8113, loss 0.00344626, acc 1
2016-09-05T18:16:23.621357: step 8114, loss 0.00412171, acc 1
2016-09-05T18:16:23.835321: step 8115, loss 0.00270442, acc 1
2016-09-05T18:16:24.060765: step 8116, loss 0.00260431, acc 1
2016-09-05T18:16:24.261353: step 8117, loss 0.0023523, acc 1
2016-09-05T18:16:24.486948: step 8118, loss 0.0055407, acc 1
2016-09-05T18:16:24.704189: step 8119, loss 0.00259351, acc 1
2016-09-05T18:16:24.924924: step 8120, loss 0.00262959, acc 1
2016-09-05T18:16:25.157640: step 8121, loss 0.00392708, acc 1
2016-09-05T18:16:25.371264: step 8122, loss 0.00320624, acc 1
2016-09-05T18:16:25.571477: step 8123, loss 0.00346093, acc 1
2016-09-05T18:16:25.787237: step 8124, loss 0.00657945, acc 1
2016-09-05T18:16:25.990503: step 8125, loss 0.00240067, acc 1
2016-09-05T18:16:26.187808: step 8126, loss 0.00271135, acc 1
2016-09-05T18:16:26.407310: step 8127, loss 0.00261228, acc 1
2016-09-05T18:16:26.681076: step 8128, loss 0.00259901, acc 1
2016-09-05T18:16:26.892823: step 8129, loss 0.00343175, acc 1
2016-09-05T18:16:27.093048: step 8130, loss 0.00278675, acc 1
2016-09-05T18:16:27.303450: step 8131, loss 0.0028765, acc 1
2016-09-05T18:16:27.513157: step 8132, loss 0.00276929, acc 1
2016-09-05T18:16:27.730406: step 8133, loss 0.00468642, acc 1
2016-09-05T18:16:27.946325: step 8134, loss 0.00320563, acc 1
2016-09-05T18:16:28.164317: step 8135, loss 0.00369315, acc 1
2016-09-05T18:16:28.369638: step 8136, loss 0.00285408, acc 1
2016-09-05T18:16:28.614000: step 8137, loss 0.00430155, acc 1
2016-09-05T18:16:28.840560: step 8138, loss 0.00260925, acc 1
2016-09-05T18:16:29.064983: step 8139, loss 0.00263569, acc 1
2016-09-05T18:16:29.305543: step 8140, loss 0.00283445, acc 1
2016-09-05T18:16:29.527606: step 8141, loss 0.00263938, acc 1
2016-09-05T18:16:29.744785: step 8142, loss 0.00397372, acc 1
2016-09-05T18:16:29.967336: step 8143, loss 0.00251743, acc 1
2016-09-05T18:16:30.207639: step 8144, loss 0.0026116, acc 1
2016-09-05T18:16:30.421251: step 8145, loss 0.00273745, acc 1
2016-09-05T18:16:30.641472: step 8146, loss 0.00300049, acc 1
2016-09-05T18:16:30.874206: step 8147, loss 0.00266222, acc 1
2016-09-05T18:16:31.006360: step 8148, loss 0.00228526, acc 1
2016-09-05T18:16:31.224091: step 8149, loss 0.0024632, acc 1
2016-09-05T18:16:31.445658: step 8150, loss 0.00267106, acc 1
2016-09-05T18:16:31.657437: step 8151, loss 0.00240852, acc 1
2016-09-05T18:16:31.865583: step 8152, loss 0.00385402, acc 1
2016-09-05T18:16:32.081964: step 8153, loss 0.00226218, acc 1
2016-09-05T18:16:32.303200: step 8154, loss 0.00835679, acc 1
2016-09-05T18:16:32.526115: step 8155, loss 0.00228697, acc 1
2016-09-05T18:16:32.744851: step 8156, loss 0.0194479, acc 1
2016-09-05T18:16:32.972508: step 8157, loss 0.00248034, acc 1
2016-09-05T18:16:33.186464: step 8158, loss 0.00277609, acc 1
2016-09-05T18:16:33.420841: step 8159, loss 0.0251485, acc 0.98
2016-09-05T18:16:33.645388: step 8160, loss 0.00341298, acc 1
2016-09-05T18:16:33.867230: step 8161, loss 0.00387182, acc 1
2016-09-05T18:16:34.077444: step 8162, loss 0.00712427, acc 1
2016-09-05T18:16:34.288488: step 8163, loss 0.00684223, acc 1
2016-09-05T18:16:34.487412: step 8164, loss 0.0304236, acc 0.98
2016-09-05T18:16:34.692671: step 8165, loss 0.00656963, acc 1
2016-09-05T18:16:34.915660: step 8166, loss 0.00757681, acc 1
2016-09-05T18:16:35.142686: step 8167, loss 0.00804528, acc 1
2016-09-05T18:16:35.371098: step 8168, loss 0.00937437, acc 1
2016-09-05T18:16:35.567681: step 8169, loss 0.00964037, acc 1
2016-09-05T18:16:35.769969: step 8170, loss 0.0116572, acc 1
2016-09-05T18:16:35.983621: step 8171, loss 0.0112457, acc 1
2016-09-05T18:16:36.221809: step 8172, loss 0.0125723, acc 1
2016-09-05T18:16:36.419382: step 8173, loss 0.0234442, acc 1
2016-09-05T18:16:36.650793: step 8174, loss 0.0160593, acc 1
2016-09-05T18:16:36.881720: step 8175, loss 0.0128777, acc 1
2016-09-05T18:16:37.090469: step 8176, loss 0.0133084, acc 1
2016-09-05T18:16:37.310232: step 8177, loss 0.0135441, acc 1
2016-09-05T18:16:37.518361: step 8178, loss 0.0138871, acc 1
2016-09-05T18:16:37.756765: step 8179, loss 0.0142135, acc 1
2016-09-05T18:16:37.973405: step 8180, loss 0.0408961, acc 0.98
2016-09-05T18:16:38.179335: step 8181, loss 0.0147007, acc 1
2016-09-05T18:16:38.384565: step 8182, loss 0.0149624, acc 1
2016-09-05T18:16:38.596489: step 8183, loss 0.0155138, acc 1
2016-09-05T18:16:38.798423: step 8184, loss 0.0155361, acc 1
2016-09-05T18:16:39.016555: step 8185, loss 0.0156747, acc 1
2016-09-05T18:16:39.220239: step 8186, loss 0.0158602, acc 1
2016-09-05T18:16:39.433838: step 8187, loss 0.0160132, acc 1
2016-09-05T18:16:39.649566: step 8188, loss 0.0161215, acc 1
2016-09-05T18:16:39.873509: step 8189, loss 0.0161867, acc 1
2016-09-05T18:16:40.104869: step 8190, loss 0.0162086, acc 1
2016-09-05T18:16:40.318520: step 8191, loss 0.0161961, acc 1
2016-09-05T18:16:40.515392: step 8192, loss 0.0161473, acc 1
2016-09-05T18:16:40.725522: step 8193, loss 0.016055, acc 1
2016-09-05T18:16:40.936641: step 8194, loss 0.0159634, acc 1
2016-09-05T18:16:41.154079: step 8195, loss 0.0158016, acc 1
2016-09-05T18:16:41.377237: step 8196, loss 0.0156126, acc 1
2016-09-05T18:16:41.605480: step 8197, loss 0.0235301, acc 1
2016-09-05T18:16:41.845688: step 8198, loss 0.0151961, acc 1
2016-09-05T18:16:42.067691: step 8199, loss 0.0152118, acc 1
2016-09-05T18:16:42.297268: step 8200, loss 0.0149132, acc 1

Evaluation:
2016-09-05T18:16:42.898793: step 8200, loss 2.60681, acc 0.734

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-8200

2016-09-05T18:16:43.652974: step 8201, loss 0.0145583, acc 1
2016-09-05T18:16:43.872197: step 8202, loss 0.0142553, acc 1
2016-09-05T18:16:44.123275: step 8203, loss 0.0139673, acc 1
2016-09-05T18:16:44.392996: step 8204, loss 0.0136719, acc 1
2016-09-05T18:16:44.612881: step 8205, loss 0.0135201, acc 1
2016-09-05T18:16:44.850394: step 8206, loss 0.0131196, acc 1
2016-09-05T18:16:45.054804: step 8207, loss 0.0127878, acc 1
2016-09-05T18:16:45.286616: step 8208, loss 0.0124877, acc 1
2016-09-05T18:16:45.524453: step 8209, loss 0.0122014, acc 1
2016-09-05T18:16:45.744927: step 8210, loss 0.0119196, acc 1
2016-09-05T18:16:45.973986: step 8211, loss 0.0115872, acc 1
2016-09-05T18:16:46.170391: step 8212, loss 0.0112795, acc 1
2016-09-05T18:16:46.379934: step 8213, loss 0.0109912, acc 1
2016-09-05T18:16:46.585277: step 8214, loss 0.0107976, acc 1
2016-09-05T18:16:46.797905: step 8215, loss 0.0107693, acc 1
2016-09-05T18:16:47.067697: step 8216, loss 0.0101025, acc 1
2016-09-05T18:16:47.292559: step 8217, loss 0.00984953, acc 1
2016-09-05T18:16:47.497910: step 8218, loss 0.0097515, acc 1
2016-09-05T18:16:47.728567: step 8219, loss 0.00926915, acc 1
2016-09-05T18:16:47.946219: step 8220, loss 0.00900716, acc 1
2016-09-05T18:16:48.157112: step 8221, loss 0.00928202, acc 1
2016-09-05T18:16:48.405882: step 8222, loss 0.00849102, acc 1
2016-09-05T18:16:48.610266: step 8223, loss 0.00823351, acc 1
2016-09-05T18:16:48.821971: step 8224, loss 0.00801123, acc 1
2016-09-05T18:16:49.018230: step 8225, loss 0.00774329, acc 1
2016-09-05T18:16:49.228188: step 8226, loss 0.00756504, acc 1
2016-09-05T18:16:49.443277: step 8227, loss 0.00739775, acc 1
2016-09-05T18:16:49.667135: step 8228, loss 0.00716816, acc 1
2016-09-05T18:16:49.880774: step 8229, loss 0.00685, acc 1
2016-09-05T18:16:50.107205: step 8230, loss 0.0067003, acc 1
2016-09-05T18:16:50.313789: step 8231, loss 0.00648182, acc 1
2016-09-05T18:16:50.521896: step 8232, loss 0.00758137, acc 1
2016-09-05T18:16:50.728459: step 8233, loss 0.00612555, acc 1
2016-09-05T18:16:50.956767: step 8234, loss 0.00592426, acc 1
2016-09-05T18:16:51.182090: step 8235, loss 0.00714156, acc 1
2016-09-05T18:16:51.409582: step 8236, loss 0.00567782, acc 1
2016-09-05T18:16:51.634469: step 8237, loss 0.00551434, acc 1
2016-09-05T18:16:51.852899: step 8238, loss 0.00595703, acc 1
2016-09-05T18:16:52.090902: step 8239, loss 0.00524238, acc 1
2016-09-05T18:16:52.314787: step 8240, loss 0.00529184, acc 1
2016-09-05T18:16:52.541724: step 8241, loss 0.00570858, acc 1
2016-09-05T18:16:52.748533: step 8242, loss 0.00481592, acc 1
2016-09-05T18:16:52.975650: step 8243, loss 0.00529277, acc 1
2016-09-05T18:16:53.199169: step 8244, loss 0.00492969, acc 1
2016-09-05T18:16:53.434982: step 8245, loss 0.00441895, acc 1
2016-09-05T18:16:53.652351: step 8246, loss 0.00515285, acc 1
2016-09-05T18:16:53.847211: step 8247, loss 0.00422757, acc 1
2016-09-05T18:16:54.050526: step 8248, loss 0.00451258, acc 1
2016-09-05T18:16:54.260815: step 8249, loss 0.00399936, acc 1
2016-09-05T18:16:54.501034: step 8250, loss 0.00411832, acc 1
2016-09-05T18:16:54.723047: step 8251, loss 0.00395535, acc 1
2016-09-05T18:16:54.944774: step 8252, loss 0.00576156, acc 1
2016-09-05T18:16:55.145899: step 8253, loss 0.00440261, acc 1
2016-09-05T18:16:55.352948: step 8254, loss 0.00532013, acc 1
2016-09-05T18:16:55.562815: step 8255, loss 0.00361116, acc 1
2016-09-05T18:16:55.772541: step 8256, loss 0.00379468, acc 1
2016-09-05T18:16:55.983698: step 8257, loss 0.00339265, acc 1
2016-09-05T18:16:56.214074: step 8258, loss 0.00355759, acc 1
2016-09-05T18:16:56.441243: step 8259, loss 0.00399103, acc 1
2016-09-05T18:16:56.665437: step 8260, loss 0.00327519, acc 1
2016-09-05T18:16:56.867287: step 8261, loss 0.00332581, acc 1
2016-09-05T18:16:57.075165: step 8262, loss 0.00427038, acc 1
2016-09-05T18:16:57.319781: step 8263, loss 0.00319528, acc 1
2016-09-05T18:16:57.542784: step 8264, loss 0.00322056, acc 1
2016-09-05T18:16:57.789731: step 8265, loss 0.00347733, acc 1
2016-09-05T18:16:58.028960: step 8266, loss 0.0030536, acc 1
2016-09-05T18:16:58.248974: step 8267, loss 0.00487212, acc 1
2016-09-05T18:16:58.513207: step 8268, loss 0.00443344, acc 1
2016-09-05T18:16:58.743055: step 8269, loss 0.00297029, acc 1
2016-09-05T18:16:58.948540: step 8270, loss 0.00330376, acc 1
2016-09-05T18:16:59.163035: step 8271, loss 0.00306563, acc 1
2016-09-05T18:16:59.385430: step 8272, loss 0.00320075, acc 1
2016-09-05T18:16:59.604533: step 8273, loss 0.00354866, acc 1
2016-09-05T18:16:59.815771: step 8274, loss 0.00275363, acc 1
2016-09-05T18:17:00.021054: step 8275, loss 0.00285587, acc 1
2016-09-05T18:17:00.258359: step 8276, loss 0.00291964, acc 1
2016-09-05T18:17:00.461927: step 8277, loss 0.00457544, acc 1
2016-09-05T18:17:00.668703: step 8278, loss 0.00293355, acc 1
2016-09-05T18:17:00.874539: step 8279, loss 0.00338292, acc 1
2016-09-05T18:17:01.080343: step 8280, loss 0.00273003, acc 1
2016-09-05T18:17:01.309491: step 8281, loss 0.00465914, acc 1
2016-09-05T18:17:01.542330: step 8282, loss 0.00337387, acc 1
2016-09-05T18:17:01.785318: step 8283, loss 0.00340478, acc 1
2016-09-05T18:17:02.031279: step 8284, loss 0.00692255, acc 1
2016-09-05T18:17:02.242970: step 8285, loss 0.00300259, acc 1
2016-09-05T18:17:02.440088: step 8286, loss 0.00335895, acc 1
2016-09-05T18:17:02.645319: step 8287, loss 0.00275061, acc 1
2016-09-05T18:17:02.845229: step 8288, loss 0.00560938, acc 1
2016-09-05T18:17:03.069303: step 8289, loss 0.00322698, acc 1
2016-09-05T18:17:03.277358: step 8290, loss 0.00321653, acc 1
2016-09-05T18:17:03.506790: step 8291, loss 0.00298823, acc 1
2016-09-05T18:17:03.737396: step 8292, loss 0.00299294, acc 1
2016-09-05T18:17:03.946777: step 8293, loss 0.00251059, acc 1
2016-09-05T18:17:04.169470: step 8294, loss 0.00267309, acc 1
2016-09-05T18:17:04.378662: step 8295, loss 0.0031073, acc 1
2016-09-05T18:17:04.656035: step 8296, loss 0.00344506, acc 1
2016-09-05T18:17:04.864814: step 8297, loss 0.00315417, acc 1
2016-09-05T18:17:05.088918: step 8298, loss 0.002693, acc 1
2016-09-05T18:17:05.300725: step 8299, loss 0.0027163, acc 1
2016-09-05T18:17:05.545462: step 8300, loss 0.00276815, acc 1

Evaluation:
2016-09-05T18:17:06.135551: step 8300, loss 1.34177, acc 0.734

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-8300

2016-09-05T18:17:06.806655: step 8301, loss 0.00297044, acc 1
2016-09-05T18:17:07.018656: step 8302, loss 0.002442, acc 1
2016-09-05T18:17:07.223829: step 8303, loss 0.00255102, acc 1
2016-09-05T18:17:07.440893: step 8304, loss 0.00260246, acc 1
2016-09-05T18:17:07.654720: step 8305, loss 0.0027443, acc 1
2016-09-05T18:17:07.895303: step 8306, loss 0.00290455, acc 1
2016-09-05T18:17:08.098399: step 8307, loss 0.00278068, acc 1
2016-09-05T18:17:08.315098: step 8308, loss 0.00300309, acc 1
2016-09-05T18:17:08.522316: step 8309, loss 0.00240661, acc 1
2016-09-05T18:17:08.733966: step 8310, loss 0.00258933, acc 1
2016-09-05T18:17:08.946796: step 8311, loss 0.00260201, acc 1
2016-09-05T18:17:09.198691: step 8312, loss 0.00246375, acc 1
2016-09-05T18:17:09.417890: step 8313, loss 0.00268663, acc 1
2016-09-05T18:17:09.616464: step 8314, loss 0.00261623, acc 1
2016-09-05T18:17:09.829904: step 8315, loss 0.0027642, acc 1
2016-09-05T18:17:10.050562: step 8316, loss 0.00270909, acc 1
2016-09-05T18:17:10.288272: step 8317, loss 0.00279235, acc 1
2016-09-05T18:17:10.519927: step 8318, loss 0.00217898, acc 1
2016-09-05T18:17:10.740285: step 8319, loss 0.00246267, acc 1
2016-09-05T18:17:10.958598: step 8320, loss 0.00774212, acc 1
2016-09-05T18:17:11.194254: step 8321, loss 0.00263503, acc 1
2016-09-05T18:17:11.418079: step 8322, loss 0.00291922, acc 1
2016-09-05T18:17:11.618596: step 8323, loss 0.00239341, acc 1
2016-09-05T18:17:11.836393: step 8324, loss 0.00648359, acc 1
2016-09-05T18:17:12.037379: step 8325, loss 0.00263487, acc 1
2016-09-05T18:17:12.247016: step 8326, loss 0.00225949, acc 1
2016-09-05T18:17:12.459800: step 8327, loss 0.00344397, acc 1
2016-09-05T18:17:12.691908: step 8328, loss 0.00285304, acc 1
2016-09-05T18:17:12.909207: step 8329, loss 0.00233563, acc 1
2016-09-05T18:17:13.139983: step 8330, loss 0.00254426, acc 1
2016-09-05T18:17:13.353707: step 8331, loss 0.00241637, acc 1
2016-09-05T18:17:13.580301: step 8332, loss 0.00222905, acc 1
2016-09-05T18:17:13.816074: step 8333, loss 0.00308529, acc 1
2016-09-05T18:17:14.029406: step 8334, loss 0.00345629, acc 1
2016-09-05T18:17:14.254546: step 8335, loss 0.00264496, acc 1
2016-09-05T18:17:14.453829: step 8336, loss 0.00357287, acc 1
2016-09-05T18:17:14.666278: step 8337, loss 0.0026826, acc 1
2016-09-05T18:17:14.870825: step 8338, loss 0.00234613, acc 1
2016-09-05T18:17:15.098241: step 8339, loss 0.00231127, acc 1
2016-09-05T18:17:15.315775: step 8340, loss 0.00367918, acc 1
2016-09-05T18:17:15.549408: step 8341, loss 0.00298425, acc 1
2016-09-05T18:17:15.669867: step 8342, loss 0.00242176, acc 1
2016-09-05T18:17:15.893379: step 8343, loss 0.00306399, acc 1
2016-09-05T18:17:16.112349: step 8344, loss 0.00248109, acc 1
2016-09-05T18:17:16.341381: step 8345, loss 0.00239229, acc 1
2016-09-05T18:17:16.560577: step 8346, loss 0.00236644, acc 1
2016-09-05T18:17:16.769487: step 8347, loss 0.00292618, acc 1
2016-09-05T18:17:16.973105: step 8348, loss 0.00260043, acc 1
2016-09-05T18:17:17.174282: step 8349, loss 0.00226343, acc 1
2016-09-05T18:17:17.377717: step 8350, loss 0.00213829, acc 1
2016-09-05T18:17:17.581147: step 8351, loss 0.00231001, acc 1
2016-09-05T18:17:17.807503: step 8352, loss 0.00216947, acc 1
2016-09-05T18:17:18.052133: step 8353, loss 0.00348462, acc 1
2016-09-05T18:17:18.272831: step 8354, loss 0.00302801, acc 1
2016-09-05T18:17:18.489303: step 8355, loss 0.0021758, acc 1
2016-09-05T18:17:18.698143: step 8356, loss 0.00216861, acc 1
2016-09-05T18:17:18.902527: step 8357, loss 0.00202116, acc 1
2016-09-05T18:17:19.109714: step 8358, loss 0.00219361, acc 1
2016-09-05T18:17:19.301540: step 8359, loss 0.00204784, acc 1
2016-09-05T18:17:19.501283: step 8360, loss 0.00220357, acc 1
2016-09-05T18:17:19.700955: step 8361, loss 0.0028374, acc 1
2016-09-05T18:17:19.921626: step 8362, loss 0.00279013, acc 1
2016-09-05T18:17:20.137937: step 8363, loss 0.00276852, acc 1
2016-09-05T18:17:20.373456: step 8364, loss 0.00288708, acc 1
2016-09-05T18:17:20.595452: step 8365, loss 0.00295128, acc 1
2016-09-05T18:17:20.813540: step 8366, loss 0.00210401, acc 1
2016-09-05T18:17:21.020304: step 8367, loss 0.00263686, acc 1
2016-09-05T18:17:21.277418: step 8368, loss 0.00226232, acc 1
2016-09-05T18:17:21.501390: step 8369, loss 0.00470016, acc 1
2016-09-05T18:17:21.706783: step 8370, loss 0.00327884, acc 1
2016-09-05T18:17:21.918198: step 8371, loss 0.00274835, acc 1
2016-09-05T18:17:22.124055: step 8372, loss 0.00244784, acc 1
2016-09-05T18:17:22.329804: step 8373, loss 0.00226354, acc 1
2016-09-05T18:17:22.533130: step 8374, loss 0.00207161, acc 1
2016-09-05T18:17:22.755491: step 8375, loss 0.00329974, acc 1
2016-09-05T18:17:22.968118: step 8376, loss 0.00238278, acc 1
2016-09-05T18:17:23.177852: step 8377, loss 0.00216488, acc 1
2016-09-05T18:17:23.417399: step 8378, loss 0.00203054, acc 1
2016-09-05T18:17:23.617901: step 8379, loss 0.00238678, acc 1
2016-09-05T18:17:23.835044: step 8380, loss 0.00217981, acc 1
2016-09-05T18:17:24.040131: step 8381, loss 0.00235103, acc 1
2016-09-05T18:17:24.248269: step 8382, loss 0.00286772, acc 1
2016-09-05T18:17:24.469031: step 8383, loss 0.00263488, acc 1
2016-09-05T18:17:24.696604: step 8384, loss 0.00227613, acc 1
2016-09-05T18:17:24.938303: step 8385, loss 0.00343246, acc 1
2016-09-05T18:17:25.171804: step 8386, loss 0.00221577, acc 1
2016-09-05T18:17:25.374203: step 8387, loss 0.00218871, acc 1
2016-09-05T18:17:25.576515: step 8388, loss 0.00254429, acc 1
2016-09-05T18:17:25.787711: step 8389, loss 0.0023319, acc 1
2016-09-05T18:17:26.017001: step 8390, loss 0.00228118, acc 1
2016-09-05T18:17:26.243394: step 8391, loss 0.00238695, acc 1
2016-09-05T18:17:26.469482: step 8392, loss 0.0020788, acc 1
2016-09-05T18:17:26.673273: step 8393, loss 0.00244277, acc 1
2016-09-05T18:17:26.882403: step 8394, loss 0.00218284, acc 1
2016-09-05T18:17:27.095860: step 8395, loss 0.0023054, acc 1
2016-09-05T18:17:27.309980: step 8396, loss 0.00245565, acc 1
2016-09-05T18:17:27.519238: step 8397, loss 0.00221582, acc 1
2016-09-05T18:17:27.745418: step 8398, loss 0.00236209, acc 1
2016-09-05T18:17:27.952697: step 8399, loss 0.00214105, acc 1
2016-09-05T18:17:28.169853: step 8400, loss 0.00209926, acc 1

Evaluation:
2016-09-05T18:17:28.789743: step 8400, loss 1.25914, acc 0.729

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-8400

2016-09-05T18:17:29.544043: step 8401, loss 0.00354661, acc 1
2016-09-05T18:17:29.802906: step 8402, loss 0.00282568, acc 1
2016-09-05T18:17:30.020331: step 8403, loss 0.00259763, acc 1
2016-09-05T18:17:30.233825: step 8404, loss 0.00278576, acc 1
2016-09-05T18:17:30.455691: step 8405, loss 0.00593132, acc 1
2016-09-05T18:17:30.692922: step 8406, loss 0.00207501, acc 1
2016-09-05T18:17:30.908508: step 8407, loss 0.00208378, acc 1
2016-09-05T18:17:31.120108: step 8408, loss 0.00217805, acc 1
2016-09-05T18:17:31.362977: step 8409, loss 0.00261763, acc 1
2016-09-05T18:17:31.564886: step 8410, loss 0.00299973, acc 1
2016-09-05T18:17:31.796529: step 8411, loss 0.00265736, acc 1
2016-09-05T18:17:32.032676: step 8412, loss 0.0024159, acc 1
2016-09-05T18:17:32.236531: step 8413, loss 0.00234183, acc 1
2016-09-05T18:17:32.448887: step 8414, loss 0.0038986, acc 1
2016-09-05T18:17:32.679175: step 8415, loss 0.0029846, acc 1
2016-09-05T18:17:32.903228: step 8416, loss 0.00245274, acc 1
2016-09-05T18:17:33.121021: step 8417, loss 0.00225346, acc 1
2016-09-05T18:17:33.330167: step 8418, loss 0.0023803, acc 1
2016-09-05T18:17:33.535126: step 8419, loss 0.00399026, acc 1
2016-09-05T18:17:33.776234: step 8420, loss 0.00280687, acc 1
2016-09-05T18:17:34.020037: step 8421, loss 0.00230388, acc 1
2016-09-05T18:17:34.224518: step 8422, loss 0.00364063, acc 1
2016-09-05T18:17:34.428963: step 8423, loss 0.00276424, acc 1
2016-09-05T18:17:34.633350: step 8424, loss 0.0024284, acc 1
2016-09-05T18:17:34.845040: step 8425, loss 0.00263683, acc 1
2016-09-05T18:17:35.051138: step 8426, loss 0.00397275, acc 1
2016-09-05T18:17:35.261442: step 8427, loss 0.0029272, acc 1
2016-09-05T18:17:35.464465: step 8428, loss 0.00294789, acc 1
2016-09-05T18:17:35.686143: step 8429, loss 0.00245825, acc 1
2016-09-05T18:17:35.899586: step 8430, loss 0.00269043, acc 1
2016-09-05T18:17:36.135197: step 8431, loss 0.00228443, acc 1
2016-09-05T18:17:36.344491: step 8432, loss 0.00369258, acc 1
2016-09-05T18:17:36.552886: step 8433, loss 0.00240858, acc 1
2016-09-05T18:17:36.754412: step 8434, loss 0.00271192, acc 1
2016-09-05T18:17:36.979734: step 8435, loss 0.00388296, acc 1
2016-09-05T18:17:37.195190: step 8436, loss 0.00235844, acc 1
2016-09-05T18:17:37.448002: step 8437, loss 0.00255512, acc 1
2016-09-05T18:17:37.658578: step 8438, loss 0.00238989, acc 1
2016-09-05T18:17:37.871134: step 8439, loss 0.00281465, acc 1
2016-09-05T18:17:38.120351: step 8440, loss 0.00255063, acc 1
2016-09-05T18:17:38.341250: step 8441, loss 0.00365945, acc 1
2016-09-05T18:17:38.571928: step 8442, loss 0.00348267, acc 1
2016-09-05T18:17:38.778702: step 8443, loss 0.00282739, acc 1
2016-09-05T18:17:38.985802: step 8444, loss 0.00336651, acc 1
2016-09-05T18:17:39.203935: step 8445, loss 0.00240896, acc 1
2016-09-05T18:17:39.468114: step 8446, loss 0.00229704, acc 1
2016-09-05T18:17:39.680098: step 8447, loss 0.00237444, acc 1
2016-09-05T18:17:39.878247: step 8448, loss 0.00245482, acc 1
2016-09-05T18:17:40.084430: step 8449, loss 0.00285633, acc 1
2016-09-05T18:17:40.286076: step 8450, loss 0.00236231, acc 1
2016-09-05T18:17:40.492357: step 8451, loss 0.0023029, acc 1
2016-09-05T18:17:40.698694: step 8452, loss 0.00252663, acc 1
2016-09-05T18:17:40.912945: step 8453, loss 0.00284683, acc 1
2016-09-05T18:17:41.136451: step 8454, loss 0.00250654, acc 1
2016-09-05T18:17:41.360534: step 8455, loss 0.00243902, acc 1
2016-09-05T18:17:41.582435: step 8456, loss 0.00260438, acc 1
2016-09-05T18:17:41.804249: step 8457, loss 0.00222382, acc 1
2016-09-05T18:17:42.020283: step 8458, loss 0.00283591, acc 1
2016-09-05T18:17:42.270767: step 8459, loss 0.00301497, acc 1
2016-09-05T18:17:42.487754: step 8460, loss 0.00217014, acc 1
2016-09-05T18:17:42.709784: step 8461, loss 0.00242134, acc 1
2016-09-05T18:17:42.927471: step 8462, loss 0.00217547, acc 1
2016-09-05T18:17:43.133747: step 8463, loss 0.00225615, acc 1
2016-09-05T18:17:43.352785: step 8464, loss 0.00202129, acc 1
2016-09-05T18:17:43.551166: step 8465, loss 0.00202146, acc 1
2016-09-05T18:17:43.770737: step 8466, loss 0.00315291, acc 1
2016-09-05T18:17:44.010761: step 8467, loss 0.00247751, acc 1
2016-09-05T18:17:44.224242: step 8468, loss 0.00292513, acc 1
2016-09-05T18:17:44.432965: step 8469, loss 0.00223318, acc 1
2016-09-05T18:17:44.675103: step 8470, loss 0.00216839, acc 1
2016-09-05T18:17:44.921229: step 8471, loss 0.0025999, acc 1
2016-09-05T18:17:45.146522: step 8472, loss 0.00231071, acc 1
2016-09-05T18:17:45.384419: step 8473, loss 0.00200582, acc 1
2016-09-05T18:17:45.597136: step 8474, loss 0.00247434, acc 1
2016-09-05T18:17:45.820469: step 8475, loss 0.00232724, acc 1
2016-09-05T18:17:46.029788: step 8476, loss 0.00277986, acc 1
2016-09-05T18:17:46.262064: step 8477, loss 0.00259923, acc 1
2016-09-05T18:17:46.487601: step 8478, loss 0.00237652, acc 1
2016-09-05T18:17:46.717452: step 8479, loss 0.00257252, acc 1
2016-09-05T18:17:46.935495: step 8480, loss 0.0029609, acc 1
2016-09-05T18:17:47.155863: step 8481, loss 0.00223938, acc 1
2016-09-05T18:17:47.357294: step 8482, loss 0.00205784, acc 1
2016-09-05T18:17:47.625607: step 8483, loss 0.00375409, acc 1
2016-09-05T18:17:47.845093: step 8484, loss 0.00203575, acc 1
2016-09-05T18:17:48.048941: step 8485, loss 0.00214104, acc 1
2016-09-05T18:17:48.273490: step 8486, loss 0.00530158, acc 1
2016-09-05T18:17:48.490995: step 8487, loss 0.00262717, acc 1
2016-09-05T18:17:48.706084: step 8488, loss 0.00206714, acc 1
2016-09-05T18:17:48.924763: step 8489, loss 0.0021343, acc 1
2016-09-05T18:17:49.123929: step 8490, loss 0.00207623, acc 1
2016-09-05T18:17:49.365218: step 8491, loss 0.00265165, acc 1
2016-09-05T18:17:49.570531: step 8492, loss 0.00222186, acc 1
2016-09-05T18:17:49.781347: step 8493, loss 0.00243184, acc 1
2016-09-05T18:17:50.034540: step 8494, loss 0.0020966, acc 1
2016-09-05T18:17:50.290661: step 8495, loss 0.00369518, acc 1
2016-09-05T18:17:50.513161: step 8496, loss 0.00222111, acc 1
2016-09-05T18:17:50.739854: step 8497, loss 0.00215364, acc 1
2016-09-05T18:17:50.956900: step 8498, loss 0.00269971, acc 1
2016-09-05T18:17:51.177472: step 8499, loss 0.00276852, acc 1
2016-09-05T18:17:51.386757: step 8500, loss 0.00228903, acc 1

Evaluation:
2016-09-05T18:17:51.967140: step 8500, loss 1.29947, acc 0.735

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-8500

2016-09-05T18:17:52.715287: step 8501, loss 0.00297552, acc 1
2016-09-05T18:17:52.926340: step 8502, loss 0.00233412, acc 1
2016-09-05T18:17:53.154809: step 8503, loss 0.00246509, acc 1
2016-09-05T18:17:53.385736: step 8504, loss 0.00244918, acc 1
2016-09-05T18:17:53.607418: step 8505, loss 0.00412621, acc 1
2016-09-05T18:17:53.814901: step 8506, loss 0.00225687, acc 1
2016-09-05T18:17:54.020802: step 8507, loss 0.00219399, acc 1
2016-09-05T18:17:54.243539: step 8508, loss 0.00218058, acc 1
2016-09-05T18:17:54.456617: step 8509, loss 0.00272899, acc 1
2016-09-05T18:17:54.676279: step 8510, loss 0.00302223, acc 1
2016-09-05T18:17:54.893390: step 8511, loss 0.00216228, acc 1
2016-09-05T18:17:55.126406: step 8512, loss 0.00316023, acc 1
2016-09-05T18:17:55.329985: step 8513, loss 0.00249775, acc 1
2016-09-05T18:17:55.565335: step 8514, loss 0.0020698, acc 1
2016-09-05T18:17:55.773993: step 8515, loss 0.00256222, acc 1
2016-09-05T18:17:56.009423: step 8516, loss 0.00248746, acc 1
2016-09-05T18:17:56.242190: step 8517, loss 0.00345055, acc 1
2016-09-05T18:17:56.447208: step 8518, loss 0.00246529, acc 1
2016-09-05T18:17:56.673666: step 8519, loss 0.00216456, acc 1
2016-09-05T18:17:56.889937: step 8520, loss 0.00311991, acc 1
2016-09-05T18:17:57.102445: step 8521, loss 0.00239092, acc 1
2016-09-05T18:17:57.336066: step 8522, loss 0.00226508, acc 1
2016-09-05T18:17:57.561157: step 8523, loss 0.00219373, acc 1
2016-09-05T18:17:57.762829: step 8524, loss 0.00223696, acc 1
2016-09-05T18:17:57.983553: step 8525, loss 0.00280716, acc 1
2016-09-05T18:17:58.195995: step 8526, loss 0.00223251, acc 1
2016-09-05T18:17:58.423725: step 8527, loss 0.00291071, acc 1
2016-09-05T18:17:58.668031: step 8528, loss 0.00234655, acc 1
2016-09-05T18:17:58.869417: step 8529, loss 0.00208028, acc 1
2016-09-05T18:17:59.095129: step 8530, loss 0.00194886, acc 1
2016-09-05T18:17:59.301746: step 8531, loss 0.00301897, acc 1
2016-09-05T18:17:59.516616: step 8532, loss 0.00196536, acc 1
2016-09-05T18:17:59.735405: step 8533, loss 0.00209573, acc 1
2016-09-05T18:17:59.960865: step 8534, loss 0.00237888, acc 1
2016-09-05T18:18:00.168490: step 8535, loss 0.0021465, acc 1
2016-09-05T18:18:00.310815: step 8536, loss 0.00185374, acc 1
2016-09-05T18:18:00.533334: step 8537, loss 0.00238154, acc 1
2016-09-05T18:18:00.765418: step 8538, loss 0.00245014, acc 1
2016-09-05T18:18:00.979710: step 8539, loss 0.00215277, acc 1
2016-09-05T18:18:01.190239: step 8540, loss 0.00210555, acc 1
2016-09-05T18:18:01.398091: step 8541, loss 0.00212989, acc 1
2016-09-05T18:18:01.618891: step 8542, loss 0.00220106, acc 1
2016-09-05T18:18:01.834464: step 8543, loss 0.00250086, acc 1
2016-09-05T18:18:02.056117: step 8544, loss 0.0022929, acc 1
2016-09-05T18:18:02.293959: step 8545, loss 0.00230472, acc 1
2016-09-05T18:18:02.501502: step 8546, loss 0.00237898, acc 1
2016-09-05T18:18:02.707288: step 8547, loss 0.00207167, acc 1
2016-09-05T18:18:02.963250: step 8548, loss 0.00207394, acc 1
2016-09-05T18:18:03.205489: step 8549, loss 0.0020701, acc 1
2016-09-05T18:18:03.415452: step 8550, loss 0.00197953, acc 1
2016-09-05T18:18:03.625403: step 8551, loss 0.00273982, acc 1
2016-09-05T18:18:03.837133: step 8552, loss 0.0022296, acc 1
2016-09-05T18:18:04.048870: step 8553, loss 0.00188383, acc 1
2016-09-05T18:18:04.263866: step 8554, loss 0.00225755, acc 1
2016-09-05T18:18:04.500830: step 8555, loss 0.00229047, acc 1
2016-09-05T18:18:04.706934: step 8556, loss 0.002771, acc 1
2016-09-05T18:18:04.915232: step 8557, loss 0.00195003, acc 1
2016-09-05T18:18:05.113585: step 8558, loss 0.00225052, acc 1
2016-09-05T18:18:05.330414: step 8559, loss 0.00198192, acc 1
2016-09-05T18:18:05.535043: step 8560, loss 0.00183234, acc 1
2016-09-05T18:18:05.745101: step 8561, loss 0.00208911, acc 1
2016-09-05T18:18:05.990951: step 8562, loss 0.00255882, acc 1
2016-09-05T18:18:06.208530: step 8563, loss 0.00182276, acc 1
2016-09-05T18:18:06.430656: step 8564, loss 0.00200931, acc 1
2016-09-05T18:18:06.633299: step 8565, loss 0.00221459, acc 1
2016-09-05T18:18:06.840303: step 8566, loss 0.0021441, acc 1
2016-09-05T18:18:07.045548: step 8567, loss 0.00206101, acc 1
2016-09-05T18:18:07.259224: step 8568, loss 0.0020216, acc 1
2016-09-05T18:18:07.469344: step 8569, loss 0.00247797, acc 1
2016-09-05T18:18:07.707662: step 8570, loss 0.00193649, acc 1
2016-09-05T18:18:07.936199: step 8571, loss 0.00284326, acc 1
2016-09-05T18:18:08.154875: step 8572, loss 0.00179909, acc 1
2016-09-05T18:18:08.407461: step 8573, loss 0.00199165, acc 1
2016-09-05T18:18:08.637652: step 8574, loss 0.00188993, acc 1
2016-09-05T18:18:08.866179: step 8575, loss 0.00188383, acc 1
2016-09-05T18:18:09.071324: step 8576, loss 0.00268751, acc 1
2016-09-05T18:18:09.288022: step 8577, loss 0.0025958, acc 1
2016-09-05T18:18:09.508509: step 8578, loss 0.00197371, acc 1
2016-09-05T18:18:09.733385: step 8579, loss 0.00298413, acc 1
2016-09-05T18:18:09.943566: step 8580, loss 0.00202207, acc 1
2016-09-05T18:18:10.162457: step 8581, loss 0.00205279, acc 1
2016-09-05T18:18:10.371172: step 8582, loss 0.00255657, acc 1
2016-09-05T18:18:10.576493: step 8583, loss 0.00190133, acc 1
2016-09-05T18:18:10.780771: step 8584, loss 0.0034306, acc 1
2016-09-05T18:18:11.006228: step 8585, loss 0.00216758, acc 1
2016-09-05T18:18:11.246182: step 8586, loss 0.00329115, acc 1
2016-09-05T18:18:11.435861: step 8587, loss 0.00228272, acc 1
2016-09-05T18:18:11.645312: step 8588, loss 0.00217121, acc 1
2016-09-05T18:18:11.885336: step 8589, loss 0.00208043, acc 1
2016-09-05T18:18:12.100562: step 8590, loss 0.00180416, acc 1
2016-09-05T18:18:12.301338: step 8591, loss 0.00220236, acc 1
2016-09-05T18:18:12.524872: step 8592, loss 0.00194798, acc 1
2016-09-05T18:18:12.739227: step 8593, loss 0.0030406, acc 1
2016-09-05T18:18:12.953897: step 8594, loss 0.00205456, acc 1
2016-09-05T18:18:13.178489: step 8595, loss 0.00232069, acc 1
2016-09-05T18:18:13.415279: step 8596, loss 0.00200616, acc 1
2016-09-05T18:18:13.638951: step 8597, loss 0.00308518, acc 1
2016-09-05T18:18:13.853020: step 8598, loss 0.00215186, acc 1
2016-09-05T18:18:14.080871: step 8599, loss 0.00207053, acc 1
2016-09-05T18:18:14.304986: step 8600, loss 0.00203368, acc 1

Evaluation:
2016-09-05T18:18:14.896788: step 8600, loss 1.28259, acc 0.733

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-8600

2016-09-05T18:18:15.595018: step 8601, loss 0.00218104, acc 1
2016-09-05T18:18:15.836317: step 8602, loss 0.00219985, acc 1
2016-09-05T18:18:16.041090: step 8603, loss 0.00197581, acc 1
2016-09-05T18:18:16.245151: step 8604, loss 0.00211687, acc 1
2016-09-05T18:18:16.466873: step 8605, loss 0.00277836, acc 1
2016-09-05T18:18:16.687210: step 8606, loss 0.00193187, acc 1
2016-09-05T18:18:16.931928: step 8607, loss 0.00189074, acc 1
2016-09-05T18:18:17.165904: step 8608, loss 0.00192175, acc 1
2016-09-05T18:18:17.388258: step 8609, loss 0.0021059, acc 1
2016-09-05T18:18:17.603533: step 8610, loss 0.00263005, acc 1
2016-09-05T18:18:17.821328: step 8611, loss 0.00193121, acc 1
2016-09-05T18:18:18.045495: step 8612, loss 0.00248958, acc 1
2016-09-05T18:18:18.264606: step 8613, loss 0.00216048, acc 1
2016-09-05T18:18:18.463880: step 8614, loss 0.00192233, acc 1
2016-09-05T18:18:18.669440: step 8615, loss 0.002208, acc 1
2016-09-05T18:18:18.862781: step 8616, loss 0.00208373, acc 1
2016-09-05T18:18:19.080949: step 8617, loss 0.00307429, acc 1
2016-09-05T18:18:19.302136: step 8618, loss 0.00204182, acc 1
2016-09-05T18:18:19.556227: step 8619, loss 0.00215724, acc 1
2016-09-05T18:18:19.775571: step 8620, loss 0.00198957, acc 1
2016-09-05T18:18:19.978275: step 8621, loss 0.00210891, acc 1
2016-09-05T18:18:20.187579: step 8622, loss 0.00213807, acc 1
2016-09-05T18:18:20.389254: step 8623, loss 0.00226469, acc 1
2016-09-05T18:18:20.600498: step 8624, loss 0.00194989, acc 1
2016-09-05T18:18:20.803622: step 8625, loss 0.00220886, acc 1
2016-09-05T18:18:21.013930: step 8626, loss 0.00172022, acc 1
2016-09-05T18:18:21.234106: step 8627, loss 0.00234193, acc 1
2016-09-05T18:18:21.477863: step 8628, loss 0.00287764, acc 1
2016-09-05T18:18:21.691893: step 8629, loss 0.0022797, acc 1
2016-09-05T18:18:21.923436: step 8630, loss 0.00240932, acc 1
2016-09-05T18:18:22.149219: step 8631, loss 0.00184814, acc 1
2016-09-05T18:18:22.359052: step 8632, loss 0.0023135, acc 1
2016-09-05T18:18:22.574619: step 8633, loss 0.00228502, acc 1
2016-09-05T18:18:22.798711: step 8634, loss 0.00179305, acc 1
2016-09-05T18:18:23.020697: step 8635, loss 0.00279887, acc 1
2016-09-05T18:18:23.225420: step 8636, loss 0.00211018, acc 1
2016-09-05T18:18:23.436122: step 8637, loss 0.00239648, acc 1
2016-09-05T18:18:23.643532: step 8638, loss 0.00211977, acc 1
2016-09-05T18:18:23.850920: step 8639, loss 0.00215805, acc 1
2016-09-05T18:18:24.069144: step 8640, loss 0.00203516, acc 1
2016-09-05T18:18:24.315639: step 8641, loss 0.00214582, acc 1
2016-09-05T18:18:24.531728: step 8642, loss 0.00215539, acc 1
2016-09-05T18:18:24.773319: step 8643, loss 0.00225866, acc 1
2016-09-05T18:18:24.967966: step 8644, loss 0.00196743, acc 1
2016-09-05T18:18:25.185347: step 8645, loss 0.00232688, acc 1
2016-09-05T18:18:25.410645: step 8646, loss 0.00205676, acc 1
2016-09-05T18:18:25.615912: step 8647, loss 0.00220186, acc 1
2016-09-05T18:18:25.828743: step 8648, loss 0.00275494, acc 1
2016-09-05T18:18:26.028352: step 8649, loss 0.00207925, acc 1
2016-09-05T18:18:26.250103: step 8650, loss 0.00206003, acc 1
2016-09-05T18:18:26.465801: step 8651, loss 0.00204384, acc 1
2016-09-05T18:18:26.688340: step 8652, loss 0.00275704, acc 1
2016-09-05T18:18:26.911571: step 8653, loss 0.00189298, acc 1
2016-09-05T18:18:27.153610: step 8654, loss 0.00224415, acc 1
2016-09-05T18:18:27.353940: step 8655, loss 0.00218903, acc 1
2016-09-05T18:18:27.557832: step 8656, loss 0.00213283, acc 1
2016-09-05T18:18:27.796464: step 8657, loss 0.00269465, acc 1
2016-09-05T18:18:28.053269: step 8658, loss 0.00229711, acc 1
2016-09-05T18:18:28.265586: step 8659, loss 0.00193102, acc 1
2016-09-05T18:18:28.474748: step 8660, loss 0.00220909, acc 1
2016-09-05T18:18:28.690833: step 8661, loss 0.0019341, acc 1
2016-09-05T18:18:28.897323: step 8662, loss 0.00212189, acc 1
2016-09-05T18:18:29.122540: step 8663, loss 0.00233407, acc 1
2016-09-05T18:18:29.336305: step 8664, loss 0.00215528, acc 1
2016-09-05T18:18:29.558420: step 8665, loss 0.00202899, acc 1
2016-09-05T18:18:29.774711: step 8666, loss 0.00221488, acc 1
2016-09-05T18:18:30.003872: step 8667, loss 0.00226738, acc 1
2016-09-05T18:18:30.229074: step 8668, loss 0.00240794, acc 1
2016-09-05T18:18:30.427570: step 8669, loss 0.00232735, acc 1
2016-09-05T18:18:30.645402: step 8670, loss 0.00210952, acc 1
2016-09-05T18:18:30.841102: step 8671, loss 0.0020878, acc 1
2016-09-05T18:18:31.080201: step 8672, loss 0.00242745, acc 1
2016-09-05T18:18:31.291064: step 8673, loss 0.00253664, acc 1
2016-09-05T18:18:31.519809: step 8674, loss 0.00180825, acc 1
2016-09-05T18:18:31.738533: step 8675, loss 0.00209491, acc 1
2016-09-05T18:18:31.947903: step 8676, loss 0.00272288, acc 1
2016-09-05T18:18:32.169473: step 8677, loss 0.00233241, acc 1
2016-09-05T18:18:32.390748: step 8678, loss 0.00217491, acc 1
2016-09-05T18:18:32.594048: step 8679, loss 0.00199193, acc 1
2016-09-05T18:18:32.837459: step 8680, loss 0.00214535, acc 1
2016-09-05T18:18:33.067751: step 8681, loss 0.00208448, acc 1
2016-09-05T18:18:33.294665: step 8682, loss 0.00193983, acc 1
2016-09-05T18:18:33.511087: step 8683, loss 0.00217286, acc 1
2016-09-05T18:18:33.764195: step 8684, loss 0.0022297, acc 1
2016-09-05T18:18:34.005069: step 8685, loss 0.00262116, acc 1
2016-09-05T18:18:34.208104: step 8686, loss 0.0021586, acc 1
2016-09-05T18:18:34.432948: step 8687, loss 0.00259452, acc 1
2016-09-05T18:18:34.649411: step 8688, loss 0.00192333, acc 1
2016-09-05T18:18:34.861230: step 8689, loss 0.00180517, acc 1
2016-09-05T18:18:35.080883: step 8690, loss 0.00209572, acc 1
2016-09-05T18:18:35.284658: step 8691, loss 0.00220127, acc 1
2016-09-05T18:18:35.522977: step 8692, loss 0.00260972, acc 1
2016-09-05T18:18:35.725834: step 8693, loss 0.00205509, acc 1
2016-09-05T18:18:35.929419: step 8694, loss 0.00175958, acc 1
2016-09-05T18:18:36.133908: step 8695, loss 0.00253005, acc 1
2016-09-05T18:18:36.343305: step 8696, loss 0.00211459, acc 1
2016-09-05T18:18:36.547483: step 8697, loss 0.00213476, acc 1
2016-09-05T18:18:36.751641: step 8698, loss 0.00251488, acc 1
2016-09-05T18:18:36.965800: step 8699, loss 0.00278972, acc 1
2016-09-05T18:18:37.192344: step 8700, loss 0.00221425, acc 1

Evaluation:
2016-09-05T18:18:37.790930: step 8700, loss 1.25723, acc 0.731

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-8700

2016-09-05T18:18:38.533448: step 8701, loss 0.00222201, acc 1
2016-09-05T18:18:38.763975: step 8702, loss 0.00192962, acc 1
2016-09-05T18:18:38.973791: step 8703, loss 0.00188448, acc 1
2016-09-05T18:18:39.192222: step 8704, loss 0.00408159, acc 1
2016-09-05T18:18:39.412815: step 8705, loss 0.00240293, acc 1
2016-09-05T18:18:39.637422: step 8706, loss 0.00267893, acc 1
2016-09-05T18:18:39.858868: step 8707, loss 0.00230908, acc 1
2016-09-05T18:18:40.084167: step 8708, loss 0.0019794, acc 1
2016-09-05T18:18:40.291864: step 8709, loss 0.00279782, acc 1
2016-09-05T18:18:40.506372: step 8710, loss 0.00206952, acc 1
2016-09-05T18:18:40.716905: step 8711, loss 0.00305538, acc 1
2016-09-05T18:18:40.919826: step 8712, loss 0.0021788, acc 1
2016-09-05T18:18:41.145896: step 8713, loss 0.00188507, acc 1
2016-09-05T18:18:41.363535: step 8714, loss 0.00225301, acc 1
2016-09-05T18:18:41.584630: step 8715, loss 0.0020353, acc 1
2016-09-05T18:18:41.776689: step 8716, loss 0.0020984, acc 1
2016-09-05T18:18:41.985947: step 8717, loss 0.0025694, acc 1
2016-09-05T18:18:42.202729: step 8718, loss 0.0019942, acc 1
2016-09-05T18:18:42.446619: step 8719, loss 0.00183851, acc 1
2016-09-05T18:18:42.697292: step 8720, loss 0.00214122, acc 1
2016-09-05T18:18:42.921746: step 8721, loss 0.00214066, acc 1
2016-09-05T18:18:43.139001: step 8722, loss 0.00201434, acc 1
2016-09-05T18:18:43.356884: step 8723, loss 0.00197588, acc 1
2016-09-05T18:18:43.600520: step 8724, loss 0.00209472, acc 1
2016-09-05T18:18:43.801570: step 8725, loss 0.00219726, acc 1
2016-09-05T18:18:44.020946: step 8726, loss 0.00198498, acc 1
2016-09-05T18:18:44.229626: step 8727, loss 0.00259575, acc 1
2016-09-05T18:18:44.434487: step 8728, loss 0.00220001, acc 1
2016-09-05T18:18:44.648562: step 8729, loss 0.00178279, acc 1
2016-09-05T18:18:44.812952: step 8730, loss 0.00222071, acc 1
2016-09-05T18:18:45.020519: step 8731, loss 0.00178139, acc 1
2016-09-05T18:18:45.245062: step 8732, loss 0.00173229, acc 1
2016-09-05T18:18:45.446290: step 8733, loss 0.00211773, acc 1
2016-09-05T18:18:45.667141: step 8734, loss 0.00202433, acc 1
2016-09-05T18:18:45.905604: step 8735, loss 0.00204712, acc 1
2016-09-05T18:18:46.119965: step 8736, loss 0.00193025, acc 1
2016-09-05T18:18:46.323791: step 8737, loss 0.00194842, acc 1
2016-09-05T18:18:46.544150: step 8738, loss 0.00188466, acc 1
2016-09-05T18:18:46.754483: step 8739, loss 0.00176291, acc 1
2016-09-05T18:18:46.970229: step 8740, loss 0.00192429, acc 1
2016-09-05T18:18:47.197640: step 8741, loss 0.00214571, acc 1
2016-09-05T18:18:47.436330: step 8742, loss 0.00189373, acc 1
2016-09-05T18:18:47.644083: step 8743, loss 0.00166885, acc 1
2016-09-05T18:18:47.864744: step 8744, loss 0.00197515, acc 1
2016-09-05T18:18:48.069589: step 8745, loss 0.00186598, acc 1
2016-09-05T18:18:48.274841: step 8746, loss 0.00256021, acc 1
2016-09-05T18:18:48.496074: step 8747, loss 0.00180746, acc 1
2016-09-05T18:18:48.707137: step 8748, loss 0.00198119, acc 1
2016-09-05T18:18:48.944041: step 8749, loss 0.00196824, acc 1
2016-09-05T18:18:49.148110: step 8750, loss 0.00168611, acc 1
2016-09-05T18:18:49.356854: step 8751, loss 0.00225512, acc 1
2016-09-05T18:18:49.579790: step 8752, loss 0.00200691, acc 1
2016-09-05T18:18:49.795087: step 8753, loss 0.00235748, acc 1
2016-09-05T18:18:50.000819: step 8754, loss 0.00181114, acc 1
2016-09-05T18:18:50.218682: step 8755, loss 0.0018413, acc 1
2016-09-05T18:18:50.422469: step 8756, loss 0.00245987, acc 1
2016-09-05T18:18:50.659720: step 8757, loss 0.00193243, acc 1
2016-09-05T18:18:50.862056: step 8758, loss 0.0021644, acc 1
2016-09-05T18:18:51.083368: step 8759, loss 0.00211593, acc 1
2016-09-05T18:18:51.287272: step 8760, loss 0.00188771, acc 1
2016-09-05T18:18:51.509010: step 8761, loss 0.00198745, acc 1
2016-09-05T18:18:51.723309: step 8762, loss 0.00176038, acc 1
2016-09-05T18:18:51.935891: step 8763, loss 0.00201324, acc 1
2016-09-05T18:18:52.141143: step 8764, loss 0.0028274, acc 1
2016-09-05T18:18:52.357396: step 8765, loss 0.0024277, acc 1
2016-09-05T18:18:52.577777: step 8766, loss 0.002176, acc 1
2016-09-05T18:18:52.791385: step 8767, loss 0.00185853, acc 1
2016-09-05T18:18:53.007803: step 8768, loss 0.0019115, acc 1
2016-09-05T18:18:53.229849: step 8769, loss 0.00181733, acc 1
2016-09-05T18:18:53.461464: step 8770, loss 0.002296, acc 1
2016-09-05T18:18:53.704916: step 8771, loss 0.00236499, acc 1
2016-09-05T18:18:53.921981: step 8772, loss 0.00224726, acc 1
2016-09-05T18:18:54.140795: step 8773, loss 0.00238452, acc 1
2016-09-05T18:18:54.377454: step 8774, loss 0.00200264, acc 1
2016-09-05T18:18:54.612709: step 8775, loss 0.00185122, acc 1
2016-09-05T18:18:54.827922: step 8776, loss 0.00204435, acc 1
2016-09-05T18:18:55.046832: step 8777, loss 0.0022363, acc 1
2016-09-05T18:18:55.262520: step 8778, loss 0.00186945, acc 1
2016-09-05T18:18:55.468732: step 8779, loss 0.00187034, acc 1
2016-09-05T18:18:55.718864: step 8780, loss 0.00226853, acc 1
2016-09-05T18:18:55.938492: step 8781, loss 0.00212275, acc 1
2016-09-05T18:18:56.148572: step 8782, loss 0.00188285, acc 1
2016-09-05T18:18:56.366926: step 8783, loss 0.00194813, acc 1
2016-09-05T18:18:56.607921: step 8784, loss 0.00180045, acc 1
2016-09-05T18:18:56.820580: step 8785, loss 0.00186399, acc 1
2016-09-05T18:18:57.035018: step 8786, loss 0.00225452, acc 1
2016-09-05T18:18:57.248971: step 8787, loss 0.00183269, acc 1
2016-09-05T18:18:57.491500: step 8788, loss 0.00174634, acc 1
2016-09-05T18:18:57.725743: step 8789, loss 0.00209731, acc 1
2016-09-05T18:18:57.936386: step 8790, loss 0.00176799, acc 1
2016-09-05T18:18:58.165688: step 8791, loss 0.0021923, acc 1
2016-09-05T18:18:58.396649: step 8792, loss 0.00301917, acc 1
2016-09-05T18:18:58.645331: step 8793, loss 0.00248917, acc 1
2016-09-05T18:18:58.847340: step 8794, loss 0.00164839, acc 1
2016-09-05T18:18:59.058856: step 8795, loss 0.00244725, acc 1
2016-09-05T18:18:59.266640: step 8796, loss 0.00286078, acc 1
2016-09-05T18:18:59.485621: step 8797, loss 0.00199418, acc 1
2016-09-05T18:18:59.691647: step 8798, loss 0.00176719, acc 1
2016-09-05T18:18:59.917481: step 8799, loss 0.00205374, acc 1
2016-09-05T18:19:00.124241: step 8800, loss 0.0020898, acc 1

Evaluation:
2016-09-05T18:19:00.751187: step 8800, loss 1.25061, acc 0.744

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-8800

2016-09-05T18:19:01.529515: step 8801, loss 0.00195498, acc 1
2016-09-05T18:19:01.792193: step 8802, loss 0.00219127, acc 1
2016-09-05T18:19:02.005312: step 8803, loss 0.0017826, acc 1
2016-09-05T18:19:02.232240: step 8804, loss 0.00214879, acc 1
2016-09-05T18:19:02.471780: step 8805, loss 0.00212963, acc 1
2016-09-05T18:19:02.665397: step 8806, loss 0.00220029, acc 1
2016-09-05T18:19:02.881815: step 8807, loss 0.00173573, acc 1
2016-09-05T18:19:03.087666: step 8808, loss 0.00224487, acc 1
2016-09-05T18:19:03.306314: step 8809, loss 0.00204566, acc 1
2016-09-05T18:19:03.522339: step 8810, loss 0.00181877, acc 1
2016-09-05T18:19:03.749583: step 8811, loss 0.00221104, acc 1
2016-09-05T18:19:03.962090: step 8812, loss 0.00203954, acc 1
2016-09-05T18:19:04.195713: step 8813, loss 0.0019955, acc 1
2016-09-05T18:19:04.409201: step 8814, loss 0.00188554, acc 1
2016-09-05T18:19:04.645063: step 8815, loss 0.00213125, acc 1
2016-09-05T18:19:04.862509: step 8816, loss 0.00282101, acc 1
2016-09-05T18:19:05.066983: step 8817, loss 0.00196559, acc 1
2016-09-05T18:19:05.271635: step 8818, loss 0.00220018, acc 1
2016-09-05T18:19:05.493468: step 8819, loss 0.00297048, acc 1
2016-09-05T18:19:05.722194: step 8820, loss 0.00217606, acc 1
2016-09-05T18:19:05.932573: step 8821, loss 0.00200975, acc 1
2016-09-05T18:19:06.134582: step 8822, loss 0.00195214, acc 1
2016-09-05T18:19:06.333690: step 8823, loss 0.00185726, acc 1
2016-09-05T18:19:06.551319: step 8824, loss 0.00194258, acc 1
2016-09-05T18:19:06.778991: step 8825, loss 0.00183105, acc 1
2016-09-05T18:19:07.031146: step 8826, loss 0.00190781, acc 1
2016-09-05T18:19:07.240992: step 8827, loss 0.00190193, acc 1
2016-09-05T18:19:07.468423: step 8828, loss 0.00192505, acc 1
2016-09-05T18:19:07.673963: step 8829, loss 0.00236316, acc 1
2016-09-05T18:19:07.887513: step 8830, loss 0.00233899, acc 1
2016-09-05T18:19:08.104157: step 8831, loss 0.00211964, acc 1
2016-09-05T18:19:08.304541: step 8832, loss 0.00208402, acc 1
2016-09-05T18:19:08.541448: step 8833, loss 0.00343936, acc 1
2016-09-05T18:19:08.750736: step 8834, loss 0.00232815, acc 1
2016-09-05T18:19:08.959177: step 8835, loss 0.0017502, acc 1
2016-09-05T18:19:09.198542: step 8836, loss 0.00221649, acc 1
2016-09-05T18:19:09.462099: step 8837, loss 0.0023051, acc 1
2016-09-05T18:19:09.672801: step 8838, loss 0.00209605, acc 1
2016-09-05T18:19:09.907832: step 8839, loss 0.00214541, acc 1
2016-09-05T18:19:10.130779: step 8840, loss 0.00269827, acc 1
2016-09-05T18:19:10.362856: step 8841, loss 0.00264819, acc 1
2016-09-05T18:19:10.579608: step 8842, loss 0.00272359, acc 1
2016-09-05T18:19:10.794190: step 8843, loss 0.00495149, acc 1
2016-09-05T18:19:11.020258: step 8844, loss 0.0022987, acc 1
2016-09-05T18:19:11.250913: step 8845, loss 0.00217898, acc 1
2016-09-05T18:19:11.480759: step 8846, loss 0.00256619, acc 1
2016-09-05T18:19:11.688036: step 8847, loss 0.00250919, acc 1
2016-09-05T18:19:11.909056: step 8848, loss 0.00494519, acc 1
2016-09-05T18:19:12.137426: step 8849, loss 0.00262396, acc 1
2016-09-05T18:19:12.379898: step 8850, loss 0.0023259, acc 1
2016-09-05T18:19:12.592913: step 8851, loss 0.00425122, acc 1
2016-09-05T18:19:12.794570: step 8852, loss 0.00259901, acc 1
2016-09-05T18:19:13.001531: step 8853, loss 0.00250582, acc 1
2016-09-05T18:19:13.199326: step 8854, loss 0.00246923, acc 1
2016-09-05T18:19:13.403738: step 8855, loss 0.00286477, acc 1
2016-09-05T18:19:13.606959: step 8856, loss 0.00263189, acc 1
2016-09-05T18:19:13.819610: step 8857, loss 0.00259837, acc 1
2016-09-05T18:19:14.024248: step 8858, loss 0.00261771, acc 1
2016-09-05T18:19:14.250183: step 8859, loss 0.00247736, acc 1
2016-09-05T18:19:14.453014: step 8860, loss 0.00309544, acc 1
2016-09-05T18:19:14.671054: step 8861, loss 0.00336445, acc 1
2016-09-05T18:19:14.876145: step 8862, loss 0.00322799, acc 1
2016-09-05T18:19:15.115559: step 8863, loss 0.00291998, acc 1
2016-09-05T18:19:15.325434: step 8864, loss 0.00263632, acc 1
2016-09-05T18:19:15.563986: step 8865, loss 0.00297489, acc 1
2016-09-05T18:19:15.822694: step 8866, loss 0.00255593, acc 1
2016-09-05T18:19:16.041573: step 8867, loss 0.00252901, acc 1
2016-09-05T18:19:16.255416: step 8868, loss 0.00259651, acc 1
2016-09-05T18:19:16.494589: step 8869, loss 0.00270117, acc 1
2016-09-05T18:19:16.733593: step 8870, loss 0.00236143, acc 1
2016-09-05T18:19:16.934818: step 8871, loss 0.00235335, acc 1
2016-09-05T18:19:17.145206: step 8872, loss 0.00264349, acc 1
2016-09-05T18:19:17.357415: step 8873, loss 0.00261395, acc 1
2016-09-05T18:19:17.572154: step 8874, loss 0.00264478, acc 1
2016-09-05T18:19:17.792014: step 8875, loss 0.00247101, acc 1
2016-09-05T18:19:18.028481: step 8876, loss 0.00256068, acc 1
2016-09-05T18:19:18.244951: step 8877, loss 0.00255622, acc 1
2016-09-05T18:19:18.442246: step 8878, loss 0.00234779, acc 1
2016-09-05T18:19:18.643597: step 8879, loss 0.00212422, acc 1
2016-09-05T18:19:18.854350: step 8880, loss 0.00211757, acc 1
2016-09-05T18:19:19.072591: step 8881, loss 0.0022143, acc 1
2016-09-05T18:19:19.295517: step 8882, loss 0.00201996, acc 1
2016-09-05T18:19:19.525434: step 8883, loss 0.00211798, acc 1
2016-09-05T18:19:19.764261: step 8884, loss 0.00213673, acc 1
2016-09-05T18:19:19.997051: step 8885, loss 0.00256707, acc 1
2016-09-05T18:19:20.243297: step 8886, loss 0.0020942, acc 1
2016-09-05T18:19:20.437456: step 8887, loss 0.00221506, acc 1
2016-09-05T18:19:20.667850: step 8888, loss 0.00218745, acc 1
2016-09-05T18:19:20.875556: step 8889, loss 0.00225626, acc 1
2016-09-05T18:19:21.073418: step 8890, loss 0.00187378, acc 1
2016-09-05T18:19:21.326255: step 8891, loss 0.00226042, acc 1
2016-09-05T18:19:21.561823: step 8892, loss 0.00202202, acc 1
2016-09-05T18:19:21.758921: step 8893, loss 0.00185776, acc 1
2016-09-05T18:19:21.978400: step 8894, loss 0.00203807, acc 1
2016-09-05T18:19:22.196515: step 8895, loss 0.00188189, acc 1
2016-09-05T18:19:22.413106: step 8896, loss 0.00179927, acc 1
2016-09-05T18:19:22.639815: step 8897, loss 0.00236477, acc 1
2016-09-05T18:19:22.841847: step 8898, loss 0.00205851, acc 1
2016-09-05T18:19:23.077150: step 8899, loss 0.0017721, acc 1
2016-09-05T18:19:23.302720: step 8900, loss 0.00240254, acc 1

Evaluation:
2016-09-05T18:19:23.899141: step 8900, loss 1.22272, acc 0.738

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-8900

2016-09-05T18:19:24.642403: step 8901, loss 0.00231784, acc 1
2016-09-05T18:19:24.899181: step 8902, loss 0.00181903, acc 1
2016-09-05T18:19:25.129824: step 8903, loss 0.00201396, acc 1
2016-09-05T18:19:25.349107: step 8904, loss 0.00167782, acc 1
2016-09-05T18:19:25.600373: step 8905, loss 0.00297492, acc 1
2016-09-05T18:19:25.796347: step 8906, loss 0.00171299, acc 1
2016-09-05T18:19:26.010469: step 8907, loss 0.00200794, acc 1
2016-09-05T18:19:26.219982: step 8908, loss 0.00342209, acc 1
2016-09-05T18:19:26.444725: step 8909, loss 0.00261664, acc 1
2016-09-05T18:19:26.665602: step 8910, loss 0.00210808, acc 1
2016-09-05T18:19:26.879649: step 8911, loss 0.00204289, acc 1
2016-09-05T18:19:27.104841: step 8912, loss 0.00198659, acc 1
2016-09-05T18:19:27.312680: step 8913, loss 0.00171856, acc 1
2016-09-05T18:19:27.525678: step 8914, loss 0.0193999, acc 0.98
2016-09-05T18:19:27.745556: step 8915, loss 0.00682984, acc 1
2016-09-05T18:19:27.972155: step 8916, loss 0.00503506, acc 1
2016-09-05T18:19:28.173758: step 8917, loss 0.0303731, acc 0.98
2016-09-05T18:19:28.385568: step 8918, loss 0.00287386, acc 1
2016-09-05T18:19:28.589952: step 8919, loss 0.00601083, acc 1
2016-09-05T18:19:28.834695: step 8920, loss 0.0184113, acc 1
2016-09-05T18:19:29.049077: step 8921, loss 0.0053011, acc 1
2016-09-05T18:19:29.285349: step 8922, loss 0.00595134, acc 1
2016-09-05T18:19:29.498042: step 8923, loss 0.00673543, acc 1
2016-09-05T18:19:29.645294: step 8924, loss 0.0068584, acc 1
2016-09-05T18:19:29.883210: step 8925, loss 0.00833371, acc 1
2016-09-05T18:19:30.094997: step 8926, loss 0.00834122, acc 1
2016-09-05T18:19:30.309899: step 8927, loss 0.00956139, acc 1
2016-09-05T18:19:30.534954: step 8928, loss 0.00927981, acc 1
2016-09-05T18:19:30.754133: step 8929, loss 0.0097564, acc 1
2016-09-05T18:19:30.984755: step 8930, loss 0.0101853, acc 1
2016-09-05T18:19:31.200125: step 8931, loss 0.0105409, acc 1
2016-09-05T18:19:31.405060: step 8932, loss 0.0108537, acc 1
2016-09-05T18:19:31.611370: step 8933, loss 0.0111165, acc 1
2016-09-05T18:19:31.831924: step 8934, loss 0.0113438, acc 1
2016-09-05T18:19:32.066274: step 8935, loss 0.0114712, acc 1
2016-09-05T18:19:32.275205: step 8936, loss 0.011608, acc 1
2016-09-05T18:19:32.494216: step 8937, loss 0.0116672, acc 1
2016-09-05T18:19:32.728065: step 8938, loss 0.0117814, acc 1
2016-09-05T18:19:32.928938: step 8939, loss 0.0117229, acc 1
2016-09-05T18:19:33.133536: step 8940, loss 0.0117037, acc 1
2016-09-05T18:19:33.379239: step 8941, loss 0.011667, acc 1
2016-09-05T18:19:33.587035: step 8942, loss 0.0115695, acc 1
2016-09-05T18:19:33.785929: step 8943, loss 0.0114489, acc 1
2016-09-05T18:19:33.985792: step 8944, loss 0.0113282, acc 1
2016-09-05T18:19:34.189400: step 8945, loss 0.0112965, acc 1
2016-09-05T18:19:34.388667: step 8946, loss 0.011192, acc 1
2016-09-05T18:19:34.600294: step 8947, loss 0.0187659, acc 1
2016-09-05T18:19:34.818770: step 8948, loss 0.0212646, acc 1
2016-09-05T18:19:35.027151: step 8949, loss 0.0109031, acc 1
2016-09-05T18:19:35.249991: step 8950, loss 0.0105291, acc 1
2016-09-05T18:19:35.462464: step 8951, loss 0.0104594, acc 1
2016-09-05T18:19:35.692915: step 8952, loss 0.0103871, acc 1
2016-09-05T18:19:35.910212: step 8953, loss 0.0103181, acc 1
2016-09-05T18:19:36.121877: step 8954, loss 0.0102689, acc 1
2016-09-05T18:19:36.330679: step 8955, loss 0.0101749, acc 1
2016-09-05T18:19:36.557267: step 8956, loss 0.010095, acc 1
2016-09-05T18:19:36.767772: step 8957, loss 0.00999801, acc 1
2016-09-05T18:19:37.005799: step 8958, loss 0.00989574, acc 1
2016-09-05T18:19:37.229749: step 8959, loss 0.00979273, acc 1
2016-09-05T18:19:37.431370: step 8960, loss 0.00970225, acc 1
2016-09-05T18:19:37.645135: step 8961, loss 0.00954481, acc 1
2016-09-05T18:19:37.854275: step 8962, loss 0.00941869, acc 1
2016-09-05T18:19:38.053726: step 8963, loss 0.00948638, acc 1
2016-09-05T18:19:38.258752: step 8964, loss 0.00913122, acc 1
2016-09-05T18:19:38.492510: step 8965, loss 0.00900037, acc 1
2016-09-05T18:19:38.722713: step 8966, loss 0.00883548, acc 1
2016-09-05T18:19:38.930213: step 8967, loss 0.0086718, acc 1
2016-09-05T18:19:39.134978: step 8968, loss 0.00853483, acc 1
2016-09-05T18:19:39.341746: step 8969, loss 0.00835949, acc 1
2016-09-05T18:19:39.565913: step 8970, loss 0.00821438, acc 1
2016-09-05T18:19:39.789341: step 8971, loss 0.00804568, acc 1
2016-09-05T18:19:40.029393: step 8972, loss 0.00788876, acc 1
2016-09-05T18:19:40.267372: step 8973, loss 0.00823594, acc 1
2016-09-05T18:19:40.501120: step 8974, loss 0.0075166, acc 1
2016-09-05T18:19:40.747618: step 8975, loss 0.00737285, acc 1
2016-09-05T18:19:40.949300: step 8976, loss 0.00732202, acc 1
2016-09-05T18:19:41.149739: step 8977, loss 0.00701686, acc 1
2016-09-05T18:19:41.367335: step 8978, loss 0.00691915, acc 1
2016-09-05T18:19:41.577988: step 8979, loss 0.00694664, acc 1
2016-09-05T18:19:41.787421: step 8980, loss 0.00656623, acc 1
2016-09-05T18:19:42.017385: step 8981, loss 0.00674275, acc 1
2016-09-05T18:19:42.272656: step 8982, loss 0.00650396, acc 1
2016-09-05T18:19:42.493965: step 8983, loss 0.00609851, acc 1
2016-09-05T18:19:42.707579: step 8984, loss 0.00596485, acc 1
2016-09-05T18:19:42.910448: step 8985, loss 0.00591009, acc 1
2016-09-05T18:19:43.139177: step 8986, loss 0.00585184, acc 1
2016-09-05T18:19:43.383919: step 8987, loss 0.00555813, acc 1
2016-09-05T18:19:43.587147: step 8988, loss 0.00581852, acc 1
2016-09-05T18:19:43.816165: step 8989, loss 0.00541865, acc 1
2016-09-05T18:19:44.032644: step 8990, loss 0.00535658, acc 1
2016-09-05T18:19:44.242664: step 8991, loss 0.00504579, acc 1
2016-09-05T18:19:44.472444: step 8992, loss 0.00574164, acc 1
2016-09-05T18:19:44.670586: step 8993, loss 0.00481634, acc 1
2016-09-05T18:19:44.877997: step 8994, loss 0.00498554, acc 1
2016-09-05T18:19:45.076879: step 8995, loss 0.00459271, acc 1
2016-09-05T18:19:45.286935: step 8996, loss 0.00470464, acc 1
2016-09-05T18:19:45.509123: step 8997, loss 0.00510343, acc 1
2016-09-05T18:19:45.737214: step 8998, loss 0.00447892, acc 1
2016-09-05T18:19:45.954348: step 8999, loss 0.00444278, acc 1
2016-09-05T18:19:46.196760: step 9000, loss 0.00497076, acc 1

Evaluation:
2016-09-05T18:19:46.783057: step 9000, loss 1.57175, acc 0.742

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-9000

2016-09-05T18:19:47.592764: step 9001, loss 0.00603252, acc 1
2016-09-05T18:19:47.823263: step 9002, loss 0.00396236, acc 1
2016-09-05T18:19:48.025835: step 9003, loss 0.00596522, acc 1
2016-09-05T18:19:48.244023: step 9004, loss 0.00401091, acc 1
2016-09-05T18:19:48.470190: step 9005, loss 0.00374637, acc 1
2016-09-05T18:19:48.688297: step 9006, loss 0.00395253, acc 1
2016-09-05T18:19:48.917005: step 9007, loss 0.00360225, acc 1
2016-09-05T18:19:49.152256: step 9008, loss 0.00406099, acc 1
2016-09-05T18:19:49.419649: step 9009, loss 0.00379537, acc 1
2016-09-05T18:19:49.631406: step 9010, loss 0.00346531, acc 1
2016-09-05T18:19:49.867617: step 9011, loss 0.00383581, acc 1
2016-09-05T18:19:50.074656: step 9012, loss 0.0042262, acc 1
2016-09-05T18:19:50.295785: step 9013, loss 0.00360791, acc 1
2016-09-05T18:19:50.548290: step 9014, loss 0.00334584, acc 1
2016-09-05T18:19:50.744248: step 9015, loss 0.00357667, acc 1
2016-09-05T18:19:50.955765: step 9016, loss 0.00339178, acc 1
2016-09-05T18:19:51.161249: step 9017, loss 0.00340207, acc 1
2016-09-05T18:19:51.362164: step 9018, loss 0.00305978, acc 1
2016-09-05T18:19:51.582245: step 9019, loss 0.0031173, acc 1
2016-09-05T18:19:51.802829: step 9020, loss 0.00379927, acc 1
2016-09-05T18:19:52.022234: step 9021, loss 0.00332312, acc 1
2016-09-05T18:19:52.246438: step 9022, loss 0.00289203, acc 1
2016-09-05T18:19:52.464161: step 9023, loss 0.00299909, acc 1
2016-09-05T18:19:52.682137: step 9024, loss 0.00473404, acc 1
2016-09-05T18:19:52.931700: step 9025, loss 0.00289652, acc 1
2016-09-05T18:19:53.147734: step 9026, loss 0.00291713, acc 1
2016-09-05T18:19:53.387432: step 9027, loss 0.00280535, acc 1
2016-09-05T18:19:53.601104: step 9028, loss 0.00294791, acc 1
2016-09-05T18:19:53.804209: step 9029, loss 0.00306096, acc 1
2016-09-05T18:19:54.037315: step 9030, loss 0.00276365, acc 1
2016-09-05T18:19:54.274518: step 9031, loss 0.0028098, acc 1
2016-09-05T18:19:54.480255: step 9032, loss 0.00270035, acc 1
2016-09-05T18:19:54.686265: step 9033, loss 0.00262722, acc 1
2016-09-05T18:19:54.897267: step 9034, loss 0.00278028, acc 1
2016-09-05T18:19:55.139908: step 9035, loss 0.00259675, acc 1
2016-09-05T18:19:55.371974: step 9036, loss 0.00273165, acc 1
2016-09-05T18:19:55.564425: step 9037, loss 0.00255103, acc 1
2016-09-05T18:19:55.791800: step 9038, loss 0.00263659, acc 1
2016-09-05T18:19:56.002586: step 9039, loss 0.00264169, acc 1
2016-09-05T18:19:56.215761: step 9040, loss 0.00270509, acc 1
2016-09-05T18:19:56.431576: step 9041, loss 0.00261443, acc 1
2016-09-05T18:19:56.660294: step 9042, loss 0.00248693, acc 1
2016-09-05T18:19:56.885051: step 9043, loss 0.00301458, acc 1
2016-09-05T18:19:57.106714: step 9044, loss 0.00349728, acc 1
2016-09-05T18:19:57.308044: step 9045, loss 0.0025934, acc 1
2016-09-05T18:19:57.521717: step 9046, loss 0.00337624, acc 1
2016-09-05T18:19:57.744862: step 9047, loss 0.00254123, acc 1
2016-09-05T18:19:57.972002: step 9048, loss 0.00224931, acc 1
2016-09-05T18:19:58.202902: step 9049, loss 0.00230325, acc 1
2016-09-05T18:19:58.405426: step 9050, loss 0.00271197, acc 1
2016-09-05T18:19:58.619021: step 9051, loss 0.0025545, acc 1
2016-09-05T18:19:58.821199: step 9052, loss 0.00247822, acc 1
2016-09-05T18:19:59.031009: step 9053, loss 0.00349249, acc 1
2016-09-05T18:19:59.228371: step 9054, loss 0.00326245, acc 1
2016-09-05T18:19:59.442386: step 9055, loss 0.00233026, acc 1
2016-09-05T18:19:59.650987: step 9056, loss 0.00310298, acc 1
2016-09-05T18:19:59.867919: step 9057, loss 0.00236539, acc 1
2016-09-05T18:20:00.076277: step 9058, loss 0.00358099, acc 1
2016-09-05T18:20:00.314669: step 9059, loss 0.00212869, acc 1
2016-09-05T18:20:00.544519: step 9060, loss 0.00226237, acc 1
2016-09-05T18:20:00.774809: step 9061, loss 0.00260754, acc 1
2016-09-05T18:20:00.994822: step 9062, loss 0.00210801, acc 1
2016-09-05T18:20:01.226528: step 9063, loss 0.00241964, acc 1
2016-09-05T18:20:01.444899: step 9064, loss 0.00208501, acc 1
2016-09-05T18:20:01.653048: step 9065, loss 0.00221866, acc 1
2016-09-05T18:20:01.903085: step 9066, loss 0.00218471, acc 1
2016-09-05T18:20:02.113260: step 9067, loss 0.00223566, acc 1
2016-09-05T18:20:02.339645: step 9068, loss 0.00253646, acc 1
2016-09-05T18:20:02.567082: step 9069, loss 0.00245339, acc 1
2016-09-05T18:20:02.822310: step 9070, loss 0.00298327, acc 1
2016-09-05T18:20:03.056884: step 9071, loss 0.0020453, acc 1
2016-09-05T18:20:03.259084: step 9072, loss 0.00229002, acc 1
2016-09-05T18:20:03.466285: step 9073, loss 0.00277667, acc 1
2016-09-05T18:20:03.687653: step 9074, loss 0.00278074, acc 1
2016-09-05T18:20:03.905142: step 9075, loss 0.00218445, acc 1
2016-09-05T18:20:04.128905: step 9076, loss 0.00291902, acc 1
2016-09-05T18:20:04.360112: step 9077, loss 0.0020417, acc 1
2016-09-05T18:20:04.573550: step 9078, loss 0.00276789, acc 1
2016-09-05T18:20:04.788146: step 9079, loss 0.00199415, acc 1
2016-09-05T18:20:04.998593: step 9080, loss 0.00187046, acc 1
2016-09-05T18:20:05.214727: step 9081, loss 0.00228053, acc 1
2016-09-05T18:20:05.434648: step 9082, loss 0.00240427, acc 1
2016-09-05T18:20:05.679959: step 9083, loss 0.00312132, acc 1
2016-09-05T18:20:05.888534: step 9084, loss 0.00234898, acc 1
2016-09-05T18:20:06.094750: step 9085, loss 0.00183979, acc 1
2016-09-05T18:20:06.323655: step 9086, loss 0.00192186, acc 1
2016-09-05T18:20:06.526962: step 9087, loss 0.00193457, acc 1
2016-09-05T18:20:06.757467: step 9088, loss 0.00201546, acc 1
2016-09-05T18:20:06.969062: step 9089, loss 0.00192071, acc 1
2016-09-05T18:20:07.188880: step 9090, loss 0.00233589, acc 1
2016-09-05T18:20:07.386393: step 9091, loss 0.00178773, acc 1
2016-09-05T18:20:07.603786: step 9092, loss 0.0019619, acc 1
2016-09-05T18:20:07.802337: step 9093, loss 0.00179425, acc 1
2016-09-05T18:20:08.027094: step 9094, loss 0.00188489, acc 1
2016-09-05T18:20:08.242105: step 9095, loss 0.00199121, acc 1
2016-09-05T18:20:08.463035: step 9096, loss 0.00392839, acc 1
2016-09-05T18:20:08.693300: step 9097, loss 0.00207682, acc 1
2016-09-05T18:20:08.892196: step 9098, loss 0.00177779, acc 1
2016-09-05T18:20:09.098293: step 9099, loss 0.00285438, acc 1
2016-09-05T18:20:09.288752: step 9100, loss 0.0020986, acc 1

Evaluation:
2016-09-05T18:20:09.881379: step 9100, loss 1.30905, acc 0.745

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-9100

2016-09-05T18:20:10.643564: step 9101, loss 0.00313384, acc 1
2016-09-05T18:20:10.863761: step 9102, loss 0.00173137, acc 1
2016-09-05T18:20:11.093656: step 9103, loss 0.00282707, acc 1
2016-09-05T18:20:11.313238: step 9104, loss 0.00228464, acc 1
2016-09-05T18:20:11.536910: step 9105, loss 0.00192259, acc 1
2016-09-05T18:20:11.746448: step 9106, loss 0.00283917, acc 1
2016-09-05T18:20:11.950034: step 9107, loss 0.00215609, acc 1
2016-09-05T18:20:12.154342: step 9108, loss 0.00194535, acc 1
2016-09-05T18:20:12.371974: step 9109, loss 0.00224792, acc 1
2016-09-05T18:20:12.595648: step 9110, loss 0.00193744, acc 1
2016-09-05T18:20:12.829689: step 9111, loss 0.00217105, acc 1
2016-09-05T18:20:13.033382: step 9112, loss 0.00215453, acc 1
2016-09-05T18:20:13.245803: step 9113, loss 0.00195317, acc 1
2016-09-05T18:20:13.453697: step 9114, loss 0.00251697, acc 1
2016-09-05T18:20:13.680023: step 9115, loss 0.0021249, acc 1
2016-09-05T18:20:13.897434: step 9116, loss 0.00222306, acc 1
2016-09-05T18:20:14.133433: step 9117, loss 0.00205212, acc 1
2016-09-05T18:20:14.270057: step 9118, loss 0.00287291, acc 1
2016-09-05T18:20:14.509882: step 9119, loss 0.00186048, acc 1
2016-09-05T18:20:14.743632: step 9120, loss 0.00193879, acc 1
2016-09-05T18:20:14.942627: step 9121, loss 0.00194552, acc 1
2016-09-05T18:20:15.157344: step 9122, loss 0.00195619, acc 1
2016-09-05T18:20:15.360185: step 9123, loss 0.00194213, acc 1
2016-09-05T18:20:15.578919: step 9124, loss 0.002083, acc 1
2016-09-05T18:20:15.783288: step 9125, loss 0.00182618, acc 1
2016-09-05T18:20:16.005077: step 9126, loss 0.00200329, acc 1
2016-09-05T18:20:16.208060: step 9127, loss 0.00226939, acc 1
2016-09-05T18:20:16.458197: step 9128, loss 0.00192015, acc 1
2016-09-05T18:20:16.664244: step 9129, loss 0.00172525, acc 1
2016-09-05T18:20:16.865149: step 9130, loss 0.00185634, acc 1
2016-09-05T18:20:17.067955: step 9131, loss 0.00232375, acc 1
2016-09-05T18:20:17.279602: step 9132, loss 0.00206242, acc 1
2016-09-05T18:20:17.481106: step 9133, loss 0.00183159, acc 1
2016-09-05T18:20:17.692981: step 9134, loss 0.00173086, acc 1
2016-09-05T18:20:17.899934: step 9135, loss 0.00265748, acc 1
2016-09-05T18:20:18.119402: step 9136, loss 0.00182171, acc 1
2016-09-05T18:20:18.359047: step 9137, loss 0.00191143, acc 1
2016-09-05T18:20:18.577445: step 9138, loss 0.00204767, acc 1
2016-09-05T18:20:18.799219: step 9139, loss 0.00195475, acc 1
2016-09-05T18:20:19.012285: step 9140, loss 0.00219358, acc 1
2016-09-05T18:20:19.232796: step 9141, loss 0.00189921, acc 1
2016-09-05T18:20:19.447542: step 9142, loss 0.00186984, acc 1
2016-09-05T18:20:19.667094: step 9143, loss 0.00222951, acc 1
2016-09-05T18:20:19.897643: step 9144, loss 0.00198503, acc 1
2016-09-05T18:20:20.121694: step 9145, loss 0.00199082, acc 1
2016-09-05T18:20:20.345071: step 9146, loss 0.00210839, acc 1
2016-09-05T18:20:20.559461: step 9147, loss 0.00204868, acc 1
2016-09-05T18:20:20.781507: step 9148, loss 0.00173165, acc 1
2016-09-05T18:20:21.008153: step 9149, loss 0.00253231, acc 1
2016-09-05T18:20:21.235713: step 9150, loss 0.00273054, acc 1
2016-09-05T18:20:21.443837: step 9151, loss 0.00197613, acc 1
2016-09-05T18:20:21.654941: step 9152, loss 0.0016941, acc 1
2016-09-05T18:20:21.876921: step 9153, loss 0.00176683, acc 1
2016-09-05T18:20:22.093119: step 9154, loss 0.00172337, acc 1
2016-09-05T18:20:22.300702: step 9155, loss 0.00163539, acc 1
2016-09-05T18:20:22.505916: step 9156, loss 0.00214529, acc 1
2016-09-05T18:20:22.735561: step 9157, loss 0.00157009, acc 1
2016-09-05T18:20:22.949583: step 9158, loss 0.00224299, acc 1
2016-09-05T18:20:23.187258: step 9159, loss 0.00192289, acc 1
2016-09-05T18:20:23.404361: step 9160, loss 0.00204444, acc 1
2016-09-05T18:20:23.638540: step 9161, loss 0.00184586, acc 1
2016-09-05T18:20:23.842967: step 9162, loss 0.00352059, acc 1
2016-09-05T18:20:24.054542: step 9163, loss 0.00189824, acc 1
2016-09-05T18:20:24.257309: step 9164, loss 0.00208822, acc 1
2016-09-05T18:20:24.469455: step 9165, loss 0.00183212, acc 1
2016-09-05T18:20:24.681024: step 9166, loss 0.00309966, acc 1
2016-09-05T18:20:24.906906: step 9167, loss 0.00211913, acc 1
2016-09-05T18:20:25.122575: step 9168, loss 0.00233933, acc 1
2016-09-05T18:20:25.358177: step 9169, loss 0.00178182, acc 1
2016-09-05T18:20:25.560367: step 9170, loss 0.00178304, acc 1
2016-09-05T18:20:25.776738: step 9171, loss 0.00186112, acc 1
2016-09-05T18:20:25.983392: step 9172, loss 0.00166972, acc 1
2016-09-05T18:20:26.210018: step 9173, loss 0.00170043, acc 1
2016-09-05T18:20:26.435853: step 9174, loss 0.00176579, acc 1
2016-09-05T18:20:26.685232: step 9175, loss 0.00173781, acc 1
2016-09-05T18:20:26.893859: step 9176, loss 0.00178002, acc 1
2016-09-05T18:20:27.103817: step 9177, loss 0.00335665, acc 1
2016-09-05T18:20:27.332832: step 9178, loss 0.0018412, acc 1
2016-09-05T18:20:27.548224: step 9179, loss 0.00175385, acc 1
2016-09-05T18:20:27.773915: step 9180, loss 0.00169499, acc 1
2016-09-05T18:20:27.992302: step 9181, loss 0.00182722, acc 1
2016-09-05T18:20:28.208102: step 9182, loss 0.00186894, acc 1
2016-09-05T18:20:28.458416: step 9183, loss 0.0017732, acc 1
2016-09-05T18:20:28.688988: step 9184, loss 0.00173543, acc 1
2016-09-05T18:20:28.899121: step 9185, loss 0.00176457, acc 1
2016-09-05T18:20:29.113281: step 9186, loss 0.0021158, acc 1
2016-09-05T18:20:29.327081: step 9187, loss 0.00199741, acc 1
2016-09-05T18:20:29.548095: step 9188, loss 0.00182385, acc 1
2016-09-05T18:20:29.772500: step 9189, loss 0.00208034, acc 1
2016-09-05T18:20:30.014304: step 9190, loss 0.00269538, acc 1
2016-09-05T18:20:30.235299: step 9191, loss 0.00192407, acc 1
2016-09-05T18:20:30.442528: step 9192, loss 0.00240766, acc 1
2016-09-05T18:20:30.664323: step 9193, loss 0.0018659, acc 1
2016-09-05T18:20:30.885187: step 9194, loss 0.00170812, acc 1
2016-09-05T18:20:31.097428: step 9195, loss 0.00180265, acc 1
2016-09-05T18:20:31.312443: step 9196, loss 0.00229957, acc 1
2016-09-05T18:20:31.530302: step 9197, loss 0.00182905, acc 1
2016-09-05T18:20:31.751455: step 9198, loss 0.00179148, acc 1
2016-09-05T18:20:31.951877: step 9199, loss 0.00210319, acc 1
2016-09-05T18:20:32.170616: step 9200, loss 0.00198307, acc 1

Evaluation:
2016-09-05T18:20:32.786128: step 9200, loss 1.30847, acc 0.735

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-9200

2016-09-05T18:20:33.561935: step 9201, loss 0.00304505, acc 1
2016-09-05T18:20:33.758858: step 9202, loss 0.00201054, acc 1
2016-09-05T18:20:33.976937: step 9203, loss 0.00189718, acc 1
2016-09-05T18:20:34.253100: step 9204, loss 0.00187003, acc 1
2016-09-05T18:20:34.468788: step 9205, loss 0.00169163, acc 1
2016-09-05T18:20:34.685875: step 9206, loss 0.00203584, acc 1
2016-09-05T18:20:34.900553: step 9207, loss 0.00206161, acc 1
2016-09-05T18:20:35.113519: step 9208, loss 0.00181174, acc 1
2016-09-05T18:20:35.349294: step 9209, loss 0.00194393, acc 1
2016-09-05T18:20:35.572198: step 9210, loss 0.00188434, acc 1
2016-09-05T18:20:35.780899: step 9211, loss 0.00184244, acc 1
2016-09-05T18:20:35.978108: step 9212, loss 0.00188894, acc 1
2016-09-05T18:20:36.182824: step 9213, loss 0.00305405, acc 1
2016-09-05T18:20:36.391807: step 9214, loss 0.00701279, acc 1
2016-09-05T18:20:36.630093: step 9215, loss 0.00183698, acc 1
2016-09-05T18:20:36.878928: step 9216, loss 0.00173756, acc 1
2016-09-05T18:20:37.097189: step 9217, loss 0.00193629, acc 1
2016-09-05T18:20:37.294392: step 9218, loss 0.00191189, acc 1
2016-09-05T18:20:37.495465: step 9219, loss 0.00436377, acc 1
2016-09-05T18:20:37.708151: step 9220, loss 0.00553241, acc 1
2016-09-05T18:20:37.934343: step 9221, loss 0.00391088, acc 1
2016-09-05T18:20:38.132461: step 9222, loss 0.00192835, acc 1
2016-09-05T18:20:38.359236: step 9223, loss 0.00223384, acc 1
2016-09-05T18:20:38.605224: step 9224, loss 0.00202365, acc 1
2016-09-05T18:20:38.814962: step 9225, loss 0.00217055, acc 1
2016-09-05T18:20:39.026929: step 9226, loss 0.0022742, acc 1
2016-09-05T18:20:39.222936: step 9227, loss 0.00223954, acc 1
2016-09-05T18:20:39.435225: step 9228, loss 0.00657113, acc 1
2016-09-05T18:20:39.661142: step 9229, loss 0.00423454, acc 1
2016-09-05T18:20:39.865311: step 9230, loss 0.00238482, acc 1
2016-09-05T18:20:40.076674: step 9231, loss 0.00256847, acc 1
2016-09-05T18:20:40.297392: step 9232, loss 0.00297584, acc 1
2016-09-05T18:20:40.513376: step 9233, loss 0.00241304, acc 1
2016-09-05T18:20:40.736977: step 9234, loss 0.00250915, acc 1
2016-09-05T18:20:40.940883: step 9235, loss 0.00321332, acc 1
2016-09-05T18:20:41.133629: step 9236, loss 0.00248157, acc 1
2016-09-05T18:20:41.342688: step 9237, loss 0.00283942, acc 1
2016-09-05T18:20:41.565469: step 9238, loss 0.00266393, acc 1
2016-09-05T18:20:41.772664: step 9239, loss 0.00309191, acc 1
2016-09-05T18:20:41.993823: step 9240, loss 0.00244652, acc 1
2016-09-05T18:20:42.223760: step 9241, loss 0.00298748, acc 1
2016-09-05T18:20:42.451728: step 9242, loss 0.00309497, acc 1
2016-09-05T18:20:42.655433: step 9243, loss 0.00250635, acc 1
2016-09-05T18:20:42.859216: step 9244, loss 0.00261629, acc 1
2016-09-05T18:20:43.088837: step 9245, loss 0.0051049, acc 1
2016-09-05T18:20:43.305393: step 9246, loss 0.0024038, acc 1
2016-09-05T18:20:43.537528: step 9247, loss 0.00244265, acc 1
2016-09-05T18:20:43.756128: step 9248, loss 0.00239761, acc 1
2016-09-05T18:20:43.971419: step 9249, loss 0.00261137, acc 1
2016-09-05T18:20:44.181509: step 9250, loss 0.00261537, acc 1
2016-09-05T18:20:44.403444: step 9251, loss 0.00243207, acc 1
2016-09-05T18:20:44.618493: step 9252, loss 0.0023707, acc 1
2016-09-05T18:20:44.861304: step 9253, loss 0.00236362, acc 1
2016-09-05T18:20:45.067736: step 9254, loss 0.00231438, acc 1
2016-09-05T18:20:45.267778: step 9255, loss 0.00219799, acc 1
2016-09-05T18:20:45.475128: step 9256, loss 0.00291649, acc 1
2016-09-05T18:20:45.679148: step 9257, loss 0.00246287, acc 1
2016-09-05T18:20:45.892868: step 9258, loss 0.00255429, acc 1
2016-09-05T18:20:46.118437: step 9259, loss 0.00220947, acc 1
2016-09-05T18:20:46.362336: step 9260, loss 0.00242511, acc 1
2016-09-05T18:20:46.566151: step 9261, loss 0.00215186, acc 1
2016-09-05T18:20:46.771790: step 9262, loss 0.00207927, acc 1
2016-09-05T18:20:46.971692: step 9263, loss 0.00199068, acc 1
2016-09-05T18:20:47.175496: step 9264, loss 0.00214254, acc 1
2016-09-05T18:20:47.394279: step 9265, loss 0.00194085, acc 1
2016-09-05T18:20:47.632509: step 9266, loss 0.00292394, acc 1
2016-09-05T18:20:47.898487: step 9267, loss 0.00213222, acc 1
2016-09-05T18:20:48.108766: step 9268, loss 0.00276634, acc 1
2016-09-05T18:20:48.309990: step 9269, loss 0.00194323, acc 1
2016-09-05T18:20:48.526977: step 9270, loss 0.0019428, acc 1
2016-09-05T18:20:48.762698: step 9271, loss 0.00233663, acc 1
2016-09-05T18:20:48.963926: step 9272, loss 0.00211921, acc 1
2016-09-05T18:20:49.185166: step 9273, loss 0.00248141, acc 1
2016-09-05T18:20:49.405510: step 9274, loss 0.00206738, acc 1
2016-09-05T18:20:49.610241: step 9275, loss 0.00182581, acc 1
2016-09-05T18:20:49.810177: step 9276, loss 0.00219218, acc 1
2016-09-05T18:20:50.038344: step 9277, loss 0.00335348, acc 1
2016-09-05T18:20:50.306933: step 9278, loss 0.00298885, acc 1
2016-09-05T18:20:50.503330: step 9279, loss 0.00260279, acc 1
2016-09-05T18:20:50.718268: step 9280, loss 0.00213388, acc 1
2016-09-05T18:20:50.943536: step 9281, loss 0.00411905, acc 1
2016-09-05T18:20:51.179358: step 9282, loss 0.00231868, acc 1
2016-09-05T18:20:51.384045: step 9283, loss 0.00191651, acc 1
2016-09-05T18:20:51.602100: step 9284, loss 0.00189977, acc 1
2016-09-05T18:20:51.809576: step 9285, loss 0.00196569, acc 1
2016-09-05T18:20:52.012404: step 9286, loss 0.00212135, acc 1
2016-09-05T18:20:52.217759: step 9287, loss 0.00533561, acc 1
2016-09-05T18:20:52.443590: step 9288, loss 0.0032687, acc 1
2016-09-05T18:20:52.665794: step 9289, loss 0.0022605, acc 1
2016-09-05T18:20:52.889602: step 9290, loss 0.00184347, acc 1
2016-09-05T18:20:53.106120: step 9291, loss 0.00287337, acc 1
2016-09-05T18:20:53.340596: step 9292, loss 0.00257834, acc 1
2016-09-05T18:20:53.552700: step 9293, loss 0.00212393, acc 1
2016-09-05T18:20:53.768872: step 9294, loss 0.00216598, acc 1
2016-09-05T18:20:53.992674: step 9295, loss 0.00320329, acc 1
2016-09-05T18:20:54.208161: step 9296, loss 0.00247718, acc 1
2016-09-05T18:20:54.446362: step 9297, loss 0.00220358, acc 1
2016-09-05T18:20:54.650151: step 9298, loss 0.00265252, acc 1
2016-09-05T18:20:54.907882: step 9299, loss 0.00210216, acc 1
2016-09-05T18:20:55.173396: step 9300, loss 0.00234126, acc 1

Evaluation:
2016-09-05T18:20:55.780274: step 9300, loss 1.42948, acc 0.738

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-9300

2016-09-05T18:20:56.500083: step 9301, loss 0.00225428, acc 1
2016-09-05T18:20:56.715879: step 9302, loss 0.00252135, acc 1
2016-09-05T18:20:56.968704: step 9303, loss 0.00228889, acc 1
2016-09-05T18:20:57.176098: step 9304, loss 0.00244141, acc 1
2016-09-05T18:20:57.395745: step 9305, loss 0.00216952, acc 1
2016-09-05T18:20:57.624498: step 9306, loss 0.00194983, acc 1
2016-09-05T18:20:57.841642: step 9307, loss 0.00212684, acc 1
2016-09-05T18:20:58.071829: step 9308, loss 0.00206706, acc 1
2016-09-05T18:20:58.309688: step 9309, loss 0.00235151, acc 1
2016-09-05T18:20:58.564389: step 9310, loss 0.00206446, acc 1
2016-09-05T18:20:58.798455: step 9311, loss 0.00231703, acc 1
2016-09-05T18:20:58.953449: step 9312, loss 0.00188829, acc 1
2016-09-05T18:20:59.174798: step 9313, loss 0.00207119, acc 1
2016-09-05T18:20:59.371239: step 9314, loss 0.00210309, acc 1
2016-09-05T18:20:59.576320: step 9315, loss 0.00194886, acc 1
2016-09-05T18:20:59.812583: step 9316, loss 0.00177623, acc 1
2016-09-05T18:21:00.032275: step 9317, loss 0.0023435, acc 1
2016-09-05T18:21:00.273211: step 9318, loss 0.00185648, acc 1
2016-09-05T18:21:00.482673: step 9319, loss 0.00196662, acc 1
2016-09-05T18:21:00.692643: step 9320, loss 0.00186773, acc 1
2016-09-05T18:21:00.901417: step 9321, loss 0.00250992, acc 1
2016-09-05T18:21:01.094647: step 9322, loss 0.00173092, acc 1
2016-09-05T18:21:01.303702: step 9323, loss 0.00206131, acc 1
2016-09-05T18:21:01.507425: step 9324, loss 0.00204471, acc 1
2016-09-05T18:21:01.764057: step 9325, loss 0.00179918, acc 1
2016-09-05T18:21:02.004459: step 9326, loss 0.00177215, acc 1
2016-09-05T18:21:02.231173: step 9327, loss 0.0017906, acc 1
2016-09-05T18:21:02.442309: step 9328, loss 0.00292474, acc 1
2016-09-05T18:21:02.683306: step 9329, loss 0.0019524, acc 1
2016-09-05T18:21:02.904799: step 9330, loss 0.00201409, acc 1
2016-09-05T18:21:03.116914: step 9331, loss 0.00214879, acc 1
2016-09-05T18:21:03.338986: step 9332, loss 0.00297913, acc 1
2016-09-05T18:21:03.578439: step 9333, loss 0.00180767, acc 1
2016-09-05T18:21:03.825422: step 9334, loss 0.00156581, acc 1
2016-09-05T18:21:04.026629: step 9335, loss 0.0017237, acc 1
2016-09-05T18:21:04.233931: step 9336, loss 0.00233895, acc 1
2016-09-05T18:21:04.437905: step 9337, loss 0.00192403, acc 1
2016-09-05T18:21:04.666097: step 9338, loss 0.00195788, acc 1
2016-09-05T18:21:04.877873: step 9339, loss 0.00191368, acc 1
2016-09-05T18:21:05.130755: step 9340, loss 0.00167574, acc 1
2016-09-05T18:21:05.337818: step 9341, loss 0.00271126, acc 1
2016-09-05T18:21:05.555873: step 9342, loss 0.0016908, acc 1
2016-09-05T18:21:05.781225: step 9343, loss 0.0050806, acc 1
2016-09-05T18:21:05.984117: step 9344, loss 0.00207536, acc 1
2016-09-05T18:21:06.208549: step 9345, loss 0.00273546, acc 1
2016-09-05T18:21:06.412349: step 9346, loss 0.00172948, acc 1
2016-09-05T18:21:06.649769: step 9347, loss 0.00174167, acc 1
2016-09-05T18:21:06.862359: step 9348, loss 0.00270763, acc 1
2016-09-05T18:21:07.085146: step 9349, loss 0.00324713, acc 1
2016-09-05T18:21:07.288386: step 9350, loss 0.00201744, acc 1
2016-09-05T18:21:07.512466: step 9351, loss 0.00279961, acc 1
2016-09-05T18:21:07.718230: step 9352, loss 0.00213949, acc 1
2016-09-05T18:21:07.924181: step 9353, loss 0.00190336, acc 1
2016-09-05T18:21:08.145393: step 9354, loss 0.0021146, acc 1
2016-09-05T18:21:08.379188: step 9355, loss 0.00186764, acc 1
2016-09-05T18:21:08.587346: step 9356, loss 0.00215397, acc 1
2016-09-05T18:21:08.828542: step 9357, loss 0.00207877, acc 1
2016-09-05T18:21:09.046135: step 9358, loss 0.00192323, acc 1
2016-09-05T18:21:09.273480: step 9359, loss 0.00188672, acc 1
2016-09-05T18:21:09.492253: step 9360, loss 0.00203689, acc 1
2016-09-05T18:21:09.703223: step 9361, loss 0.00234092, acc 1
2016-09-05T18:21:09.916258: step 9362, loss 0.0020624, acc 1
2016-09-05T18:21:10.123014: step 9363, loss 0.00228835, acc 1
2016-09-05T18:21:10.345111: step 9364, loss 0.00282565, acc 1
2016-09-05T18:21:10.577352: step 9365, loss 0.00197384, acc 1
2016-09-05T18:21:10.806450: step 9366, loss 0.00192762, acc 1
2016-09-05T18:21:11.019758: step 9367, loss 0.00225127, acc 1
2016-09-05T18:21:11.257890: step 9368, loss 0.00210459, acc 1
2016-09-05T18:21:11.464765: step 9369, loss 0.00179659, acc 1
2016-09-05T18:21:11.698620: step 9370, loss 0.00234844, acc 1
2016-09-05T18:21:11.913186: step 9371, loss 0.00177121, acc 1
2016-09-05T18:21:12.114656: step 9372, loss 0.00189721, acc 1
2016-09-05T18:21:12.335764: step 9373, loss 0.00216763, acc 1
2016-09-05T18:21:12.549127: step 9374, loss 0.00226289, acc 1
2016-09-05T18:21:12.798344: step 9375, loss 0.00205204, acc 1
2016-09-05T18:21:13.020369: step 9376, loss 0.00191946, acc 1
2016-09-05T18:21:13.270892: step 9377, loss 0.00219279, acc 1
2016-09-05T18:21:13.516806: step 9378, loss 0.00197728, acc 1
2016-09-05T18:21:13.719044: step 9379, loss 0.00171919, acc 1
2016-09-05T18:21:13.957661: step 9380, loss 0.00233066, acc 1
2016-09-05T18:21:14.187555: step 9381, loss 0.00178982, acc 1
2016-09-05T18:21:14.438696: step 9382, loss 0.00182019, acc 1
2016-09-05T18:21:14.660397: step 9383, loss 0.00175771, acc 1
2016-09-05T18:21:14.896112: step 9384, loss 0.00181888, acc 1
2016-09-05T18:21:15.113222: step 9385, loss 0.00186728, acc 1
2016-09-05T18:21:15.322354: step 9386, loss 0.00210672, acc 1
2016-09-05T18:21:15.534306: step 9387, loss 0.00219975, acc 1
2016-09-05T18:21:15.777785: step 9388, loss 0.00190277, acc 1
2016-09-05T18:21:15.995691: step 9389, loss 0.0016848, acc 1
2016-09-05T18:21:16.193771: step 9390, loss 0.00178948, acc 1
2016-09-05T18:21:16.422389: step 9391, loss 0.00164727, acc 1
2016-09-05T18:21:16.635457: step 9392, loss 0.00180374, acc 1
2016-09-05T18:21:16.851665: step 9393, loss 0.00190688, acc 1
2016-09-05T18:21:17.061762: step 9394, loss 0.00290913, acc 1
2016-09-05T18:21:17.270122: step 9395, loss 0.00301054, acc 1
2016-09-05T18:21:17.479604: step 9396, loss 0.00162194, acc 1
2016-09-05T18:21:17.701584: step 9397, loss 0.00247349, acc 1
2016-09-05T18:21:17.931601: step 9398, loss 0.00161228, acc 1
2016-09-05T18:21:18.157979: step 9399, loss 0.00223061, acc 1
2016-09-05T18:21:18.358514: step 9400, loss 0.00194803, acc 1

Evaluation:
2016-09-05T18:21:18.979384: step 9400, loss 1.31211, acc 0.734

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-9400

2016-09-05T18:21:19.734216: step 9401, loss 0.00191129, acc 1
2016-09-05T18:21:19.936299: step 9402, loss 0.00161007, acc 1
2016-09-05T18:21:20.157481: step 9403, loss 0.00156536, acc 1
2016-09-05T18:21:20.385940: step 9404, loss 0.00196095, acc 1
2016-09-05T18:21:20.610908: step 9405, loss 0.00188598, acc 1
2016-09-05T18:21:20.835611: step 9406, loss 0.00293134, acc 1
2016-09-05T18:21:21.060064: step 9407, loss 0.00174793, acc 1
2016-09-05T18:21:21.293665: step 9408, loss 0.00182739, acc 1
2016-09-05T18:21:21.508166: step 9409, loss 0.00201833, acc 1
2016-09-05T18:21:21.724595: step 9410, loss 0.00434354, acc 1
2016-09-05T18:21:21.943058: step 9411, loss 0.00217162, acc 1
2016-09-05T18:21:22.163935: step 9412, loss 0.00256703, acc 1
2016-09-05T18:21:22.373460: step 9413, loss 0.00181357, acc 1
2016-09-05T18:21:22.591433: step 9414, loss 0.00218111, acc 1
2016-09-05T18:21:22.800522: step 9415, loss 0.00183305, acc 1
2016-09-05T18:21:23.016153: step 9416, loss 0.00168574, acc 1
2016-09-05T18:21:23.233137: step 9417, loss 0.00272459, acc 1
2016-09-05T18:21:23.462167: step 9418, loss 0.00203818, acc 1
2016-09-05T18:21:23.724073: step 9419, loss 0.00270509, acc 1
2016-09-05T18:21:23.929671: step 9420, loss 0.00249742, acc 1
2016-09-05T18:21:24.158412: step 9421, loss 0.00256958, acc 1
2016-09-05T18:21:24.393478: step 9422, loss 0.00253372, acc 1
2016-09-05T18:21:24.626230: step 9423, loss 0.00197696, acc 1
2016-09-05T18:21:24.830125: step 9424, loss 0.00221118, acc 1
2016-09-05T18:21:25.037331: step 9425, loss 0.00215069, acc 1
2016-09-05T18:21:25.260444: step 9426, loss 0.00194783, acc 1
2016-09-05T18:21:25.497421: step 9427, loss 0.00243827, acc 1
2016-09-05T18:21:25.699494: step 9428, loss 0.00196723, acc 1
2016-09-05T18:21:25.937182: step 9429, loss 0.00190038, acc 1
2016-09-05T18:21:26.141569: step 9430, loss 0.00186279, acc 1
2016-09-05T18:21:26.349194: step 9431, loss 0.0019768, acc 1
2016-09-05T18:21:26.573285: step 9432, loss 0.00188928, acc 1
2016-09-05T18:21:26.795227: step 9433, loss 0.00190856, acc 1
2016-09-05T18:21:27.033085: step 9434, loss 0.0020653, acc 1
2016-09-05T18:21:27.222677: step 9435, loss 0.00175351, acc 1
2016-09-05T18:21:27.437346: step 9436, loss 0.00207678, acc 1
2016-09-05T18:21:27.644057: step 9437, loss 0.00200515, acc 1
2016-09-05T18:21:27.851176: step 9438, loss 0.00212348, acc 1
2016-09-05T18:21:28.056814: step 9439, loss 0.00210418, acc 1
2016-09-05T18:21:28.279470: step 9440, loss 0.00182594, acc 1
2016-09-05T18:21:28.498128: step 9441, loss 0.00184678, acc 1
2016-09-05T18:21:28.738183: step 9442, loss 0.00175059, acc 1
2016-09-05T18:21:28.956633: step 9443, loss 0.00170056, acc 1
2016-09-05T18:21:29.165288: step 9444, loss 0.00210781, acc 1
2016-09-05T18:21:29.412425: step 9445, loss 0.00179022, acc 1
2016-09-05T18:21:29.653383: step 9446, loss 0.00183009, acc 1
2016-09-05T18:21:29.871619: step 9447, loss 0.0016074, acc 1
2016-09-05T18:21:30.084093: step 9448, loss 0.00259917, acc 1
2016-09-05T18:21:30.306747: step 9449, loss 0.00219158, acc 1
2016-09-05T18:21:30.524963: step 9450, loss 0.00230463, acc 1
2016-09-05T18:21:30.744918: step 9451, loss 0.00224569, acc 1
2016-09-05T18:21:30.962584: step 9452, loss 0.00190414, acc 1
2016-09-05T18:21:31.162564: step 9453, loss 0.00207724, acc 1
2016-09-05T18:21:31.385830: step 9454, loss 0.00159849, acc 1
2016-09-05T18:21:31.597231: step 9455, loss 0.00192078, acc 1
2016-09-05T18:21:31.795615: step 9456, loss 0.00205704, acc 1
2016-09-05T18:21:32.027619: step 9457, loss 0.00158511, acc 1
2016-09-05T18:21:32.230819: step 9458, loss 0.0017074, acc 1
2016-09-05T18:21:32.450275: step 9459, loss 0.00196025, acc 1
2016-09-05T18:21:32.697520: step 9460, loss 0.00363717, acc 1
2016-09-05T18:21:32.898792: step 9461, loss 0.00172263, acc 1
2016-09-05T18:21:33.123664: step 9462, loss 0.00174101, acc 1
2016-09-05T18:21:33.332305: step 9463, loss 0.00163289, acc 1
2016-09-05T18:21:33.541606: step 9464, loss 0.00163068, acc 1
2016-09-05T18:21:33.761220: step 9465, loss 0.00197766, acc 1
2016-09-05T18:21:33.999453: step 9466, loss 0.0037192, acc 1
2016-09-05T18:21:34.215145: step 9467, loss 0.002561, acc 1
2016-09-05T18:21:34.443611: step 9468, loss 0.0017254, acc 1
2016-09-05T18:21:34.653473: step 9469, loss 0.00190275, acc 1
2016-09-05T18:21:34.873051: step 9470, loss 0.00181001, acc 1
2016-09-05T18:21:35.098399: step 9471, loss 0.00218488, acc 1
2016-09-05T18:21:35.312191: step 9472, loss 0.00193594, acc 1
2016-09-05T18:21:35.543604: step 9473, loss 0.0019401, acc 1
2016-09-05T18:21:35.745871: step 9474, loss 0.00210313, acc 1
2016-09-05T18:21:35.952945: step 9475, loss 0.00327002, acc 1
2016-09-05T18:21:36.174863: step 9476, loss 0.00201836, acc 1
2016-09-05T18:21:36.412071: step 9477, loss 0.00179006, acc 1
2016-09-05T18:21:36.630698: step 9478, loss 0.00204449, acc 1
2016-09-05T18:21:36.859754: step 9479, loss 0.00224153, acc 1
2016-09-05T18:21:37.068062: step 9480, loss 0.00288402, acc 1
2016-09-05T18:21:37.283414: step 9481, loss 0.00173469, acc 1
2016-09-05T18:21:37.499542: step 9482, loss 0.00171822, acc 1
2016-09-05T18:21:37.721429: step 9483, loss 0.00235063, acc 1
2016-09-05T18:21:37.947891: step 9484, loss 0.00173997, acc 1
2016-09-05T18:21:38.165662: step 9485, loss 0.00197846, acc 1
2016-09-05T18:21:38.375071: step 9486, loss 0.00192911, acc 1
2016-09-05T18:21:38.578464: step 9487, loss 0.00214924, acc 1
2016-09-05T18:21:38.785254: step 9488, loss 0.00180073, acc 1
2016-09-05T18:21:39.000100: step 9489, loss 0.00275534, acc 1
2016-09-05T18:21:39.237734: step 9490, loss 0.00227587, acc 1
2016-09-05T18:21:39.462879: step 9491, loss 0.00187336, acc 1
2016-09-05T18:21:39.685965: step 9492, loss 0.00197747, acc 1
2016-09-05T18:21:39.892834: step 9493, loss 0.00187654, acc 1
2016-09-05T18:21:40.124051: step 9494, loss 0.00181072, acc 1
2016-09-05T18:21:40.353986: step 9495, loss 0.00182281, acc 1
2016-09-05T18:21:40.558159: step 9496, loss 0.0020102, acc 1
2016-09-05T18:21:40.788661: step 9497, loss 0.00220805, acc 1
2016-09-05T18:21:40.994402: step 9498, loss 0.00395844, acc 1
2016-09-05T18:21:41.204965: step 9499, loss 0.00207419, acc 1
2016-09-05T18:21:41.405710: step 9500, loss 0.00198723, acc 1

Evaluation:
2016-09-05T18:21:42.013777: step 9500, loss 1.39402, acc 0.737

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-9500

2016-09-05T18:21:42.836318: step 9501, loss 0.00201742, acc 1
2016-09-05T18:21:43.038564: step 9502, loss 0.00200824, acc 1
2016-09-05T18:21:43.250910: step 9503, loss 0.00195368, acc 1
2016-09-05T18:21:43.465596: step 9504, loss 0.00180991, acc 1
2016-09-05T18:21:43.684760: step 9505, loss 0.00170967, acc 1
2016-09-05T18:21:43.825741: step 9506, loss 0.00164341, acc 1
2016-09-05T18:21:44.030495: step 9507, loss 0.00217871, acc 1
2016-09-05T18:21:44.229364: step 9508, loss 0.00200292, acc 1
2016-09-05T18:21:44.459524: step 9509, loss 0.00172993, acc 1
2016-09-05T18:21:44.674390: step 9510, loss 0.00197297, acc 1
2016-09-05T18:21:44.912301: step 9511, loss 0.00160408, acc 1
2016-09-05T18:21:45.131880: step 9512, loss 0.00224717, acc 1
2016-09-05T18:21:45.360359: step 9513, loss 0.00162363, acc 1
2016-09-05T18:21:45.569563: step 9514, loss 0.00340546, acc 1
2016-09-05T18:21:45.796327: step 9515, loss 0.00158791, acc 1
2016-09-05T18:21:46.050783: step 9516, loss 0.00172574, acc 1
2016-09-05T18:21:46.253220: step 9517, loss 0.00192678, acc 1
2016-09-05T18:21:46.472610: step 9518, loss 0.00198652, acc 1
2016-09-05T18:21:46.691961: step 9519, loss 0.00170712, acc 1
2016-09-05T18:21:46.918127: step 9520, loss 0.00214503, acc 1
2016-09-05T18:21:47.167541: step 9521, loss 0.00158025, acc 1
2016-09-05T18:21:47.375256: step 9522, loss 0.00208498, acc 1
2016-09-05T18:21:47.600055: step 9523, loss 0.00189687, acc 1
2016-09-05T18:21:47.812132: step 9524, loss 0.00161605, acc 1
2016-09-05T18:21:48.057762: step 9525, loss 0.00201763, acc 1
2016-09-05T18:21:48.261244: step 9526, loss 0.0018087, acc 1
2016-09-05T18:21:48.467207: step 9527, loss 0.0018783, acc 1
2016-09-05T18:21:48.679520: step 9528, loss 0.00156555, acc 1
2016-09-05T18:21:48.938204: step 9529, loss 0.00201655, acc 1
2016-09-05T18:21:49.167648: step 9530, loss 0.00197705, acc 1
2016-09-05T18:21:49.368673: step 9531, loss 0.0020676, acc 1
2016-09-05T18:21:49.570997: step 9532, loss 0.00171886, acc 1
2016-09-05T18:21:49.794344: step 9533, loss 0.00194482, acc 1
2016-09-05T18:21:49.998043: step 9534, loss 0.00227135, acc 1
2016-09-05T18:21:50.236963: step 9535, loss 0.0016245, acc 1
2016-09-05T18:21:50.465389: step 9536, loss 0.00181906, acc 1
2016-09-05T18:21:50.694711: step 9537, loss 0.0017371, acc 1
2016-09-05T18:21:50.926070: step 9538, loss 0.00148722, acc 1
2016-09-05T18:21:51.138949: step 9539, loss 0.00163293, acc 1
2016-09-05T18:21:51.347185: step 9540, loss 0.00238809, acc 1
2016-09-05T18:21:51.549713: step 9541, loss 0.00208778, acc 1
2016-09-05T18:21:51.787620: step 9542, loss 0.00216682, acc 1
2016-09-05T18:21:52.001716: step 9543, loss 0.00149789, acc 1
2016-09-05T18:21:52.232956: step 9544, loss 0.00162912, acc 1
2016-09-05T18:21:52.456234: step 9545, loss 0.00166935, acc 1
2016-09-05T18:21:52.658450: step 9546, loss 0.00220712, acc 1
2016-09-05T18:21:52.871902: step 9547, loss 0.00143259, acc 1
2016-09-05T18:21:53.089448: step 9548, loss 0.0016704, acc 1
2016-09-05T18:21:53.323548: step 9549, loss 0.0018619, acc 1
2016-09-05T18:21:53.530397: step 9550, loss 0.00180065, acc 1
2016-09-05T18:21:53.754228: step 9551, loss 0.0020227, acc 1
2016-09-05T18:21:53.953942: step 9552, loss 0.00162851, acc 1
2016-09-05T18:21:54.163410: step 9553, loss 0.00144149, acc 1
2016-09-05T18:21:54.393466: step 9554, loss 0.00191536, acc 1
2016-09-05T18:21:54.626616: step 9555, loss 0.00200757, acc 1
2016-09-05T18:21:54.822066: step 9556, loss 0.00180991, acc 1
2016-09-05T18:21:55.039095: step 9557, loss 0.00180715, acc 1
2016-09-05T18:21:55.244368: step 9558, loss 0.00178771, acc 1
2016-09-05T18:21:55.459001: step 9559, loss 0.00145779, acc 1
2016-09-05T18:21:55.666367: step 9560, loss 0.00202352, acc 1
2016-09-05T18:21:55.913335: step 9561, loss 0.00156526, acc 1
2016-09-05T18:21:56.141949: step 9562, loss 0.00198514, acc 1
2016-09-05T18:21:56.341446: step 9563, loss 0.00149209, acc 1
2016-09-05T18:21:56.568996: step 9564, loss 0.00184242, acc 1
2016-09-05T18:21:56.837211: step 9565, loss 0.00160292, acc 1
2016-09-05T18:21:57.080936: step 9566, loss 0.00135967, acc 1
2016-09-05T18:21:57.316435: step 9567, loss 0.00175165, acc 1
2016-09-05T18:21:57.543037: step 9568, loss 0.00171994, acc 1
2016-09-05T18:21:57.747743: step 9569, loss 0.00176778, acc 1
2016-09-05T18:21:57.957858: step 9570, loss 0.00202357, acc 1
2016-09-05T18:21:58.178168: step 9571, loss 0.00186442, acc 1
2016-09-05T18:21:58.396547: step 9572, loss 0.00173526, acc 1
2016-09-05T18:21:58.609378: step 9573, loss 0.00168237, acc 1
2016-09-05T18:21:58.824585: step 9574, loss 0.00167346, acc 1
2016-09-05T18:21:59.055123: step 9575, loss 0.00179077, acc 1
2016-09-05T18:21:59.264877: step 9576, loss 0.0014145, acc 1
2016-09-05T18:21:59.477886: step 9577, loss 0.00173754, acc 1
2016-09-05T18:21:59.685848: step 9578, loss 0.00170235, acc 1
2016-09-05T18:21:59.917635: step 9579, loss 0.00148271, acc 1
2016-09-05T18:22:00.139569: step 9580, loss 0.00173248, acc 1
2016-09-05T18:22:00.353424: step 9581, loss 0.00228818, acc 1
2016-09-05T18:22:00.575459: step 9582, loss 0.00159195, acc 1
2016-09-05T18:22:00.774226: step 9583, loss 0.00158183, acc 1
2016-09-05T18:22:00.992702: step 9584, loss 0.00194293, acc 1
2016-09-05T18:22:01.194043: step 9585, loss 0.0044954, acc 1
2016-09-05T18:22:01.402742: step 9586, loss 0.00171169, acc 1
2016-09-05T18:22:01.622345: step 9587, loss 0.00165475, acc 1
2016-09-05T18:22:01.853657: step 9588, loss 0.0020677, acc 1
2016-09-05T18:22:02.057107: step 9589, loss 0.00164227, acc 1
2016-09-05T18:22:02.290031: step 9590, loss 0.00233453, acc 1
2016-09-05T18:22:02.489642: step 9591, loss 0.0062114, acc 1
2016-09-05T18:22:02.697614: step 9592, loss 0.00204986, acc 1
2016-09-05T18:22:02.928358: step 9593, loss 0.00162481, acc 1
2016-09-05T18:22:03.162717: step 9594, loss 0.00182823, acc 1
2016-09-05T18:22:03.395463: step 9595, loss 0.00177732, acc 1
2016-09-05T18:22:03.597930: step 9596, loss 0.00230385, acc 1
2016-09-05T18:22:03.810887: step 9597, loss 0.00482128, acc 1
2016-09-05T18:22:04.013788: step 9598, loss 0.00258764, acc 1
2016-09-05T18:22:04.222548: step 9599, loss 0.00246267, acc 1
2016-09-05T18:22:04.427555: step 9600, loss 0.00243461, acc 1

Evaluation:
2016-09-05T18:22:05.039485: step 9600, loss 1.57716, acc 0.735

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-9600

2016-09-05T18:22:05.727175: step 9601, loss 0.00200398, acc 1
2016-09-05T18:22:05.942465: step 9602, loss 0.00235158, acc 1
2016-09-05T18:22:06.162064: step 9603, loss 0.00244088, acc 1
2016-09-05T18:22:06.378436: step 9604, loss 0.0021684, acc 1
2016-09-05T18:22:06.601390: step 9605, loss 0.00226243, acc 1
2016-09-05T18:22:06.827533: step 9606, loss 0.0022061, acc 1
2016-09-05T18:22:07.049119: step 9607, loss 0.00220291, acc 1
2016-09-05T18:22:07.253144: step 9608, loss 0.00252342, acc 1
2016-09-05T18:22:07.464412: step 9609, loss 0.00225884, acc 1
2016-09-05T18:22:07.686138: step 9610, loss 0.00216567, acc 1
2016-09-05T18:22:07.933143: step 9611, loss 0.00244563, acc 1
2016-09-05T18:22:08.144227: step 9612, loss 0.00217039, acc 1
2016-09-05T18:22:08.377874: step 9613, loss 0.00211548, acc 1
2016-09-05T18:22:08.594212: step 9614, loss 0.00244926, acc 1
2016-09-05T18:22:08.817011: step 9615, loss 0.00206584, acc 1
2016-09-05T18:22:09.066192: step 9616, loss 0.00203865, acc 1
2016-09-05T18:22:09.273859: step 9617, loss 0.00220326, acc 1
2016-09-05T18:22:09.484686: step 9618, loss 0.00211403, acc 1
2016-09-05T18:22:09.689698: step 9619, loss 0.00200312, acc 1
2016-09-05T18:22:09.903366: step 9620, loss 0.00189588, acc 1
2016-09-05T18:22:10.127827: step 9621, loss 0.0018983, acc 1
2016-09-05T18:22:10.375107: step 9622, loss 0.00186088, acc 1
2016-09-05T18:22:10.644908: step 9623, loss 0.00201182, acc 1
2016-09-05T18:22:10.865412: step 9624, loss 0.00199814, acc 1
2016-09-05T18:22:11.098470: step 9625, loss 0.00202266, acc 1
2016-09-05T18:22:11.343077: step 9626, loss 0.00188738, acc 1
2016-09-05T18:22:11.582049: step 9627, loss 0.00175687, acc 1
2016-09-05T18:22:11.799923: step 9628, loss 0.00203623, acc 1
2016-09-05T18:22:12.024573: step 9629, loss 0.00216014, acc 1
2016-09-05T18:22:12.249477: step 9630, loss 0.00240594, acc 1
2016-09-05T18:22:12.498819: step 9631, loss 0.00170407, acc 1
2016-09-05T18:22:12.707970: step 9632, loss 0.00204389, acc 1
2016-09-05T18:22:12.912557: step 9633, loss 0.00227549, acc 1
2016-09-05T18:22:13.124147: step 9634, loss 0.0015928, acc 1
2016-09-05T18:22:13.342396: step 9635, loss 0.00258629, acc 1
2016-09-05T18:22:13.557210: step 9636, loss 0.00213212, acc 1
2016-09-05T18:22:13.803499: step 9637, loss 0.00166687, acc 1
2016-09-05T18:22:14.025765: step 9638, loss 0.00165931, acc 1
2016-09-05T18:22:14.264286: step 9639, loss 0.00172807, acc 1
2016-09-05T18:22:14.494203: step 9640, loss 0.00187824, acc 1
2016-09-05T18:22:14.713476: step 9641, loss 0.00168425, acc 1
2016-09-05T18:22:14.920994: step 9642, loss 0.00214349, acc 1
2016-09-05T18:22:15.163329: step 9643, loss 0.00228328, acc 1
2016-09-05T18:22:15.394569: step 9644, loss 0.00155993, acc 1
2016-09-05T18:22:15.640900: step 9645, loss 0.00165083, acc 1
2016-09-05T18:22:15.845699: step 9646, loss 0.00197103, acc 1
2016-09-05T18:22:16.071577: step 9647, loss 0.00168787, acc 1
2016-09-05T18:22:16.319369: step 9648, loss 0.0018017, acc 1
2016-09-05T18:22:16.523731: step 9649, loss 0.00172396, acc 1
2016-09-05T18:22:16.747548: step 9650, loss 0.00185557, acc 1
2016-09-05T18:22:16.967712: step 9651, loss 0.00164986, acc 1
2016-09-05T18:22:17.183273: step 9652, loss 0.00274468, acc 1
2016-09-05T18:22:17.392721: step 9653, loss 0.00170685, acc 1
2016-09-05T18:22:17.631887: step 9654, loss 0.00179739, acc 1
2016-09-05T18:22:17.820677: step 9655, loss 0.0014834, acc 1
2016-09-05T18:22:18.045161: step 9656, loss 0.0022429, acc 1
2016-09-05T18:22:18.292945: step 9657, loss 0.00195156, acc 1
2016-09-05T18:22:18.532266: step 9658, loss 0.00225167, acc 1
2016-09-05T18:22:18.765948: step 9659, loss 0.00160514, acc 1
2016-09-05T18:22:18.970787: step 9660, loss 0.00154764, acc 1
2016-09-05T18:22:19.207717: step 9661, loss 0.00160643, acc 1
2016-09-05T18:22:19.427032: step 9662, loss 0.00196522, acc 1
2016-09-05T18:22:19.634282: step 9663, loss 0.00155974, acc 1
2016-09-05T18:22:19.869223: step 9664, loss 0.001918, acc 1
2016-09-05T18:22:20.094961: step 9665, loss 0.00213055, acc 1
2016-09-05T18:22:20.326217: step 9666, loss 0.00156651, acc 1
2016-09-05T18:22:20.527024: step 9667, loss 0.00159661, acc 1
2016-09-05T18:22:20.737601: step 9668, loss 0.00204267, acc 1
2016-09-05T18:22:20.937064: step 9669, loss 0.00159439, acc 1
2016-09-05T18:22:21.176970: step 9670, loss 0.00160338, acc 1
2016-09-05T18:22:21.381289: step 9671, loss 0.0019297, acc 1
2016-09-05T18:22:21.591230: step 9672, loss 0.00166137, acc 1
2016-09-05T18:22:21.790741: step 9673, loss 0.00173774, acc 1
2016-09-05T18:22:21.992716: step 9674, loss 0.00153334, acc 1
2016-09-05T18:22:22.204417: step 9675, loss 0.00199587, acc 1
2016-09-05T18:22:22.419186: step 9676, loss 0.00232193, acc 1
2016-09-05T18:22:22.631158: step 9677, loss 0.00193064, acc 1
2016-09-05T18:22:22.874389: step 9678, loss 0.0017253, acc 1
2016-09-05T18:22:23.085317: step 9679, loss 0.00178455, acc 1
2016-09-05T18:22:23.282964: step 9680, loss 0.00170393, acc 1
2016-09-05T18:22:23.489379: step 9681, loss 0.00194982, acc 1
2016-09-05T18:22:23.696283: step 9682, loss 0.00145749, acc 1
2016-09-05T18:22:23.892515: step 9683, loss 0.00173268, acc 1
2016-09-05T18:22:24.105566: step 9684, loss 0.00191863, acc 1
2016-09-05T18:22:24.319758: step 9685, loss 0.00164903, acc 1
2016-09-05T18:22:24.536657: step 9686, loss 0.00155067, acc 1
2016-09-05T18:22:24.766373: step 9687, loss 0.00219171, acc 1
2016-09-05T18:22:24.977400: step 9688, loss 0.00153613, acc 1
2016-09-05T18:22:25.190163: step 9689, loss 0.00157598, acc 1
2016-09-05T18:22:25.383368: step 9690, loss 0.00200033, acc 1
2016-09-05T18:22:25.592661: step 9691, loss 0.00159559, acc 1
2016-09-05T18:22:25.805698: step 9692, loss 0.00195824, acc 1
2016-09-05T18:22:26.007926: step 9693, loss 0.0014077, acc 1
2016-09-05T18:22:26.219175: step 9694, loss 0.00162255, acc 1
2016-09-05T18:22:26.431751: step 9695, loss 0.00173422, acc 1
2016-09-05T18:22:26.632694: step 9696, loss 0.00142985, acc 1
2016-09-05T18:22:26.843946: step 9697, loss 0.00169447, acc 1
2016-09-05T18:22:27.055485: step 9698, loss 0.00170429, acc 1
2016-09-05T18:22:27.279311: step 9699, loss 0.00153143, acc 1
2016-09-05T18:22:27.422085: step 9700, loss 0.00178853, acc 1

Evaluation:
2016-09-05T18:22:28.047292: step 9700, loss 1.30291, acc 0.736

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-9700

2016-09-05T18:22:28.758044: step 9701, loss 0.00146761, acc 1
2016-09-05T18:22:28.990141: step 9702, loss 0.00158207, acc 1
2016-09-05T18:22:29.239093: step 9703, loss 0.00138644, acc 1
2016-09-05T18:22:29.440429: step 9704, loss 0.00156384, acc 1
2016-09-05T18:22:29.652818: step 9705, loss 0.00165354, acc 1
2016-09-05T18:22:29.848299: step 9706, loss 0.00191151, acc 1
2016-09-05T18:22:30.067842: step 9707, loss 0.00145142, acc 1
2016-09-05T18:22:30.270514: step 9708, loss 0.00186552, acc 1
2016-09-05T18:22:30.479525: step 9709, loss 0.00174209, acc 1
2016-09-05T18:22:30.704491: step 9710, loss 0.00156337, acc 1
2016-09-05T18:22:30.963098: step 9711, loss 0.00150295, acc 1
2016-09-05T18:22:31.169006: step 9712, loss 0.00138824, acc 1
2016-09-05T18:22:31.387953: step 9713, loss 0.00160204, acc 1
2016-09-05T18:22:31.603008: step 9714, loss 0.00151071, acc 1
2016-09-05T18:22:31.827822: step 9715, loss 0.00142496, acc 1
2016-09-05T18:22:32.076178: step 9716, loss 0.0016237, acc 1
2016-09-05T18:22:32.284580: step 9717, loss 0.00161691, acc 1
2016-09-05T18:22:32.507540: step 9718, loss 0.00171812, acc 1
2016-09-05T18:22:32.729777: step 9719, loss 0.00136468, acc 1
2016-09-05T18:22:32.951053: step 9720, loss 0.00154573, acc 1
2016-09-05T18:22:33.165449: step 9721, loss 0.00142092, acc 1
2016-09-05T18:22:33.384644: step 9722, loss 0.00138505, acc 1
2016-09-05T18:22:33.615215: step 9723, loss 0.00241248, acc 1
2016-09-05T18:22:33.834698: step 9724, loss 0.00192388, acc 1
2016-09-05T18:22:34.075828: step 9725, loss 0.00159654, acc 1
2016-09-05T18:22:34.286212: step 9726, loss 0.00162208, acc 1
2016-09-05T18:22:34.503163: step 9727, loss 0.00143427, acc 1
2016-09-05T18:22:34.696558: step 9728, loss 0.00149771, acc 1
2016-09-05T18:22:34.909581: step 9729, loss 0.00143391, acc 1
2016-09-05T18:22:35.106888: step 9730, loss 0.00137773, acc 1
2016-09-05T18:22:35.312873: step 9731, loss 0.00139117, acc 1
2016-09-05T18:22:35.540802: step 9732, loss 0.00146619, acc 1
2016-09-05T18:22:35.747467: step 9733, loss 0.00163106, acc 1
2016-09-05T18:22:35.941353: step 9734, loss 0.00203994, acc 1
2016-09-05T18:22:36.158057: step 9735, loss 0.00148191, acc 1
2016-09-05T18:22:36.365775: step 9736, loss 0.00155278, acc 1
2016-09-05T18:22:36.595335: step 9737, loss 0.00181141, acc 1
2016-09-05T18:22:36.802241: step 9738, loss 0.0014158, acc 1
2016-09-05T18:22:37.014995: step 9739, loss 0.00140791, acc 1
2016-09-05T18:22:37.228330: step 9740, loss 0.00154191, acc 1
2016-09-05T18:22:37.449446: step 9741, loss 0.00178822, acc 1
2016-09-05T18:22:37.679697: step 9742, loss 0.00171246, acc 1
2016-09-05T18:22:37.917497: step 9743, loss 0.00187535, acc 1
2016-09-05T18:22:38.126871: step 9744, loss 0.0016331, acc 1
2016-09-05T18:22:38.349397: step 9745, loss 0.00167907, acc 1
2016-09-05T18:22:38.581461: step 9746, loss 0.0015141, acc 1
2016-09-05T18:22:38.813206: step 9747, loss 0.00165316, acc 1
2016-09-05T18:22:39.010183: step 9748, loss 0.00171124, acc 1
2016-09-05T18:22:39.214205: step 9749, loss 0.00159082, acc 1
2016-09-05T18:22:39.430068: step 9750, loss 0.00152996, acc 1
2016-09-05T18:22:39.632696: step 9751, loss 0.00149105, acc 1
2016-09-05T18:22:39.851588: step 9752, loss 0.00186843, acc 1
2016-09-05T18:22:40.058071: step 9753, loss 0.00143168, acc 1
2016-09-05T18:22:40.271709: step 9754, loss 0.00185991, acc 1
2016-09-05T18:22:40.489216: step 9755, loss 0.00163094, acc 1
2016-09-05T18:22:40.727856: step 9756, loss 0.00159595, acc 1
2016-09-05T18:22:40.929455: step 9757, loss 0.0016292, acc 1
2016-09-05T18:22:41.147572: step 9758, loss 0.00136869, acc 1
2016-09-05T18:22:41.353032: step 9759, loss 0.00133437, acc 1
2016-09-05T18:22:41.562618: step 9760, loss 0.00155291, acc 1
2016-09-05T18:22:41.777478: step 9761, loss 0.00134832, acc 1
2016-09-05T18:22:42.017440: step 9762, loss 0.00152165, acc 1
2016-09-05T18:22:42.258455: step 9763, loss 0.00274885, acc 1
2016-09-05T18:22:42.464862: step 9764, loss 0.00170136, acc 1
2016-09-05T18:22:42.658465: step 9765, loss 0.00157835, acc 1
2016-09-05T18:22:42.872306: step 9766, loss 0.00166296, acc 1
2016-09-05T18:22:43.089502: step 9767, loss 0.00217166, acc 1
2016-09-05T18:22:43.313244: step 9768, loss 0.00152629, acc 1
2016-09-05T18:22:43.540403: step 9769, loss 0.00187253, acc 1
2016-09-05T18:22:43.739488: step 9770, loss 0.00164548, acc 1
2016-09-05T18:22:43.952702: step 9771, loss 0.00167811, acc 1
2016-09-05T18:22:44.165794: step 9772, loss 0.00150522, acc 1
2016-09-05T18:22:44.433540: step 9773, loss 0.00151808, acc 1
2016-09-05T18:22:44.691856: step 9774, loss 0.00233953, acc 1
2016-09-05T18:22:44.905286: step 9775, loss 0.00148893, acc 1
2016-09-05T18:22:45.143405: step 9776, loss 0.0018109, acc 1
2016-09-05T18:22:45.373442: step 9777, loss 0.00148757, acc 1
2016-09-05T18:22:45.585890: step 9778, loss 0.00149069, acc 1
2016-09-05T18:22:45.793824: step 9779, loss 0.00196455, acc 1
2016-09-05T18:22:46.021054: step 9780, loss 0.00182126, acc 1
2016-09-05T18:22:46.242293: step 9781, loss 0.00170353, acc 1
2016-09-05T18:22:46.476775: step 9782, loss 0.00156979, acc 1
2016-09-05T18:22:46.695292: step 9783, loss 0.00177227, acc 1
2016-09-05T18:22:46.907661: step 9784, loss 0.00179072, acc 1
2016-09-05T18:22:47.121824: step 9785, loss 0.0017945, acc 1
2016-09-05T18:22:47.342608: step 9786, loss 0.00161603, acc 1
2016-09-05T18:22:47.568220: step 9787, loss 0.00175081, acc 1
2016-09-05T18:22:47.803241: step 9788, loss 0.00159425, acc 1
2016-09-05T18:22:48.040704: step 9789, loss 0.00144825, acc 1
2016-09-05T18:22:48.297088: step 9790, loss 0.00147792, acc 1
2016-09-05T18:22:48.504791: step 9791, loss 0.0014194, acc 1
2016-09-05T18:22:48.715937: step 9792, loss 0.00204314, acc 1
2016-09-05T18:22:48.948406: step 9793, loss 0.00168247, acc 1
2016-09-05T18:22:49.176862: step 9794, loss 0.00166109, acc 1
2016-09-05T18:22:49.403236: step 9795, loss 0.00365399, acc 1
2016-09-05T18:22:49.622896: step 9796, loss 0.00144766, acc 1
2016-09-05T18:22:49.837341: step 9797, loss 0.00195575, acc 1
2016-09-05T18:22:50.049735: step 9798, loss 0.00182248, acc 1
2016-09-05T18:22:50.276792: step 9799, loss 0.00235386, acc 1
2016-09-05T18:22:50.508674: step 9800, loss 0.00152597, acc 1

Evaluation:
2016-09-05T18:22:51.099842: step 9800, loss 1.34856, acc 0.739

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-9800

2016-09-05T18:22:51.807145: step 9801, loss 0.00173093, acc 1
2016-09-05T18:22:52.041190: step 9802, loss 0.00155236, acc 1
2016-09-05T18:22:52.243443: step 9803, loss 0.00190856, acc 1
2016-09-05T18:22:52.462412: step 9804, loss 0.00168093, acc 1
2016-09-05T18:22:52.661951: step 9805, loss 0.00225755, acc 1
2016-09-05T18:22:52.879899: step 9806, loss 0.00195087, acc 1
2016-09-05T18:22:53.097438: step 9807, loss 0.00165191, acc 1
2016-09-05T18:22:53.325411: step 9808, loss 0.00198157, acc 1
2016-09-05T18:22:53.530519: step 9809, loss 0.00189272, acc 1
2016-09-05T18:22:53.737304: step 9810, loss 0.00187574, acc 1
2016-09-05T18:22:53.945260: step 9811, loss 0.0017047, acc 1
2016-09-05T18:22:54.156709: step 9812, loss 0.0022408, acc 1
2016-09-05T18:22:54.356139: step 9813, loss 0.00259904, acc 1
2016-09-05T18:22:54.573009: step 9814, loss 0.00168161, acc 1
2016-09-05T18:22:54.791320: step 9815, loss 0.00193274, acc 1
2016-09-05T18:22:55.015137: step 9816, loss 0.00169367, acc 1
2016-09-05T18:22:55.262266: step 9817, loss 0.00200533, acc 1
2016-09-05T18:22:55.456538: step 9818, loss 0.00271198, acc 1
2016-09-05T18:22:55.673953: step 9819, loss 0.0016769, acc 1
2016-09-05T18:22:55.884185: step 9820, loss 0.00188365, acc 1
2016-09-05T18:22:56.098940: step 9821, loss 0.00172312, acc 1
2016-09-05T18:22:56.308443: step 9822, loss 0.00162212, acc 1
2016-09-05T18:22:56.527120: step 9823, loss 0.00186255, acc 1
2016-09-05T18:22:56.741855: step 9824, loss 0.00205141, acc 1
2016-09-05T18:22:56.965458: step 9825, loss 0.0018506, acc 1
2016-09-05T18:22:57.180688: step 9826, loss 0.0018761, acc 1
2016-09-05T18:22:57.379415: step 9827, loss 0.00196287, acc 1
2016-09-05T18:22:57.591237: step 9828, loss 0.00201519, acc 1
2016-09-05T18:22:57.813932: step 9829, loss 0.00177601, acc 1
2016-09-05T18:22:58.029222: step 9830, loss 0.00175276, acc 1
2016-09-05T18:22:58.262370: step 9831, loss 0.00157585, acc 1
2016-09-05T18:22:58.497085: step 9832, loss 0.00159447, acc 1
2016-09-05T18:22:58.712958: step 9833, loss 0.00190625, acc 1
2016-09-05T18:22:58.960494: step 9834, loss 0.00196508, acc 1
2016-09-05T18:22:59.209114: step 9835, loss 0.00221472, acc 1
2016-09-05T18:22:59.425192: step 9836, loss 0.00186815, acc 1
2016-09-05T18:22:59.647499: step 9837, loss 0.00166641, acc 1
2016-09-05T18:22:59.877412: step 9838, loss 0.00154718, acc 1
2016-09-05T18:23:00.123998: step 9839, loss 0.00174513, acc 1
2016-09-05T18:23:00.752281: step 9840, loss 0.00158364, acc 1
2016-09-05T18:23:00.966903: step 9841, loss 0.00150214, acc 1
2016-09-05T18:23:01.182395: step 9842, loss 0.00145828, acc 1
2016-09-05T18:23:01.416655: step 9843, loss 0.00268712, acc 1
2016-09-05T18:23:01.605388: step 9844, loss 0.00200465, acc 1
2016-09-05T18:23:01.829746: step 9845, loss 0.0014893, acc 1
2016-09-05T18:23:02.036212: step 9846, loss 0.00162127, acc 1
2016-09-05T18:23:02.235611: step 9847, loss 0.00149742, acc 1
2016-09-05T18:23:02.452637: step 9848, loss 0.00148128, acc 1
2016-09-05T18:23:02.683529: step 9849, loss 0.00183673, acc 1
2016-09-05T18:23:02.930278: step 9850, loss 0.00173118, acc 1
2016-09-05T18:23:03.155410: step 9851, loss 0.00199033, acc 1
2016-09-05T18:23:03.401256: step 9852, loss 0.00150413, acc 1
2016-09-05T18:23:03.644977: step 9853, loss 0.00139903, acc 1
2016-09-05T18:23:03.877159: step 9854, loss 0.00196752, acc 1
2016-09-05T18:23:04.085454: step 9855, loss 0.00182132, acc 1
2016-09-05T18:23:04.303613: step 9856, loss 0.00184223, acc 1
2016-09-05T18:23:04.551049: step 9857, loss 0.0019247, acc 1
2016-09-05T18:23:04.766589: step 9858, loss 0.00152998, acc 1
2016-09-05T18:23:04.976536: step 9859, loss 0.00171867, acc 1
2016-09-05T18:23:05.183742: step 9860, loss 0.0019804, acc 1
2016-09-05T18:23:05.427335: step 9861, loss 0.00162942, acc 1
2016-09-05T18:23:05.678462: step 9862, loss 0.00176163, acc 1
2016-09-05T18:23:05.909704: step 9863, loss 0.00165402, acc 1
2016-09-05T18:23:06.117194: step 9864, loss 0.00140683, acc 1
2016-09-05T18:23:06.338057: step 9865, loss 0.00141573, acc 1
2016-09-05T18:23:06.556092: step 9866, loss 0.00169264, acc 1
2016-09-05T18:23:06.786779: step 9867, loss 0.00146368, acc 1
2016-09-05T18:23:06.990352: step 9868, loss 0.0014384, acc 1
2016-09-05T18:23:07.211239: step 9869, loss 0.00143244, acc 1
2016-09-05T18:23:07.437637: step 9870, loss 0.0015112, acc 1
2016-09-05T18:23:07.679276: step 9871, loss 0.00196664, acc 1
2016-09-05T18:23:07.894542: step 9872, loss 0.00147451, acc 1
2016-09-05T18:23:08.101188: step 9873, loss 0.00147859, acc 1
2016-09-05T18:23:08.293515: step 9874, loss 0.00141665, acc 1
2016-09-05T18:23:08.495837: step 9875, loss 0.0015706, acc 1
2016-09-05T18:23:08.697055: step 9876, loss 0.00148126, acc 1
2016-09-05T18:23:08.890379: step 9877, loss 0.0017383, acc 1
2016-09-05T18:23:09.117099: step 9878, loss 0.00221387, acc 1
2016-09-05T18:23:09.325631: step 9879, loss 0.00158408, acc 1
2016-09-05T18:23:09.521481: step 9880, loss 0.00233072, acc 1
2016-09-05T18:23:09.728736: step 9881, loss 0.00147328, acc 1
2016-09-05T18:23:09.965824: step 9882, loss 0.00198695, acc 1
2016-09-05T18:23:10.194018: step 9883, loss 0.00292159, acc 1
2016-09-05T18:23:10.396561: step 9884, loss 0.00139073, acc 1
2016-09-05T18:23:10.612702: step 9885, loss 0.00145771, acc 1
2016-09-05T18:23:10.824809: step 9886, loss 0.00145773, acc 1
2016-09-05T18:23:11.068300: step 9887, loss 0.00155495, acc 1
2016-09-05T18:23:11.283265: step 9888, loss 0.00161543, acc 1
2016-09-05T18:23:11.534105: step 9889, loss 0.00179542, acc 1
2016-09-05T18:23:11.788706: step 9890, loss 0.00341005, acc 1
2016-09-05T18:23:12.024454: step 9891, loss 0.00172375, acc 1
2016-09-05T18:23:12.236774: step 9892, loss 0.0014398, acc 1
2016-09-05T18:23:12.454020: step 9893, loss 0.00157098, acc 1
2016-09-05T18:23:12.595326: step 9894, loss 0.00150358, acc 1
2016-09-05T18:23:12.823804: step 9895, loss 0.00162423, acc 1
2016-09-05T18:23:13.054631: step 9896, loss 0.001782, acc 1
2016-09-05T18:23:13.281437: step 9897, loss 0.00198046, acc 1
2016-09-05T18:23:13.499916: step 9898, loss 0.00289514, acc 1
2016-09-05T18:23:13.728990: step 9899, loss 0.00238178, acc 1
2016-09-05T18:23:13.937960: step 9900, loss 0.00258221, acc 1

Evaluation:
2016-09-05T18:23:14.554649: step 9900, loss 1.43308, acc 0.729

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-9900

2016-09-05T18:23:15.226140: step 9901, loss 0.00167759, acc 1
2016-09-05T18:23:15.453673: step 9902, loss 0.00176024, acc 1
2016-09-05T18:23:15.670273: step 9903, loss 0.00207364, acc 1
2016-09-05T18:23:15.900340: step 9904, loss 0.00177069, acc 1
2016-09-05T18:23:16.122338: step 9905, loss 0.00187015, acc 1
2016-09-05T18:23:16.368033: step 9906, loss 0.00349257, acc 1
2016-09-05T18:23:16.584943: step 9907, loss 0.0018642, acc 1
2016-09-05T18:23:16.806449: step 9908, loss 0.00186776, acc 1
2016-09-05T18:23:17.027319: step 9909, loss 0.00171105, acc 1
2016-09-05T18:23:17.254716: step 9910, loss 0.00217036, acc 1
2016-09-05T18:23:17.468426: step 9911, loss 0.00169101, acc 1
2016-09-05T18:23:17.689829: step 9912, loss 0.00190061, acc 1
2016-09-05T18:23:17.895143: step 9913, loss 0.00205712, acc 1
2016-09-05T18:23:18.106628: step 9914, loss 0.001892, acc 1
2016-09-05T18:23:18.341150: step 9915, loss 0.00177843, acc 1
2016-09-05T18:23:18.538470: step 9916, loss 0.00180675, acc 1
2016-09-05T18:23:18.744558: step 9917, loss 0.00228551, acc 1
2016-09-05T18:23:18.945573: step 9918, loss 0.00176176, acc 1
2016-09-05T18:23:19.154083: step 9919, loss 0.00167539, acc 1
2016-09-05T18:23:19.385323: step 9920, loss 0.00177798, acc 1
2016-09-05T18:23:19.608059: step 9921, loss 0.00173779, acc 1
2016-09-05T18:23:19.819669: step 9922, loss 0.00172936, acc 1
2016-09-05T18:23:20.075433: step 9923, loss 0.0017034, acc 1
2016-09-05T18:23:20.301288: step 9924, loss 0.00182468, acc 1
2016-09-05T18:23:20.542823: step 9925, loss 0.00165549, acc 1
2016-09-05T18:23:20.805680: step 9926, loss 0.00210516, acc 1
2016-09-05T18:23:21.018110: step 9927, loss 0.00249408, acc 1
2016-09-05T18:23:21.226747: step 9928, loss 0.0019693, acc 1
2016-09-05T18:23:21.423011: step 9929, loss 0.00168166, acc 1
2016-09-05T18:23:21.628058: step 9930, loss 0.00174998, acc 1
2016-09-05T18:23:21.841118: step 9931, loss 0.00167047, acc 1
2016-09-05T18:23:22.073796: step 9932, loss 0.00177942, acc 1
2016-09-05T18:23:22.305777: step 9933, loss 0.00167579, acc 1
2016-09-05T18:23:22.532782: step 9934, loss 0.00220852, acc 1
2016-09-05T18:23:22.737890: step 9935, loss 0.0019037, acc 1
2016-09-05T18:23:22.946704: step 9936, loss 0.00177493, acc 1
2016-09-05T18:23:23.162340: step 9937, loss 0.00160482, acc 1
2016-09-05T18:23:23.399976: step 9938, loss 0.00171377, acc 1
2016-09-05T18:23:23.636670: step 9939, loss 0.00197083, acc 1
2016-09-05T18:23:23.854034: step 9940, loss 0.0014819, acc 1
2016-09-05T18:23:24.057189: step 9941, loss 0.00153552, acc 1
2016-09-05T18:23:24.270179: step 9942, loss 0.00158657, acc 1
2016-09-05T18:23:24.481872: step 9943, loss 0.0014743, acc 1
2016-09-05T18:23:24.677468: step 9944, loss 0.00149562, acc 1
2016-09-05T18:23:24.883335: step 9945, loss 0.00141516, acc 1
2016-09-05T18:23:25.102443: step 9946, loss 0.00146005, acc 1
2016-09-05T18:23:25.300355: step 9947, loss 0.00167385, acc 1
2016-09-05T18:23:25.522421: step 9948, loss 0.00150961, acc 1
2016-09-05T18:23:25.759666: step 9949, loss 0.0013503, acc 1
2016-09-05T18:23:25.969135: step 9950, loss 0.0017034, acc 1
2016-09-05T18:23:26.185047: step 9951, loss 0.0014757, acc 1
2016-09-05T18:23:26.392169: step 9952, loss 0.00187519, acc 1
2016-09-05T18:23:26.653795: step 9953, loss 0.00137956, acc 1
2016-09-05T18:23:26.857383: step 9954, loss 0.00133081, acc 1
2016-09-05T18:23:27.048975: step 9955, loss 0.00233121, acc 1
2016-09-05T18:23:27.285449: step 9956, loss 0.00185496, acc 1
2016-09-05T18:23:27.492021: step 9957, loss 0.00166312, acc 1
2016-09-05T18:23:27.709520: step 9958, loss 0.00136235, acc 1
2016-09-05T18:23:27.923588: step 9959, loss 0.00140845, acc 1
2016-09-05T18:23:28.183990: step 9960, loss 0.00156905, acc 1
2016-09-05T18:23:28.409992: step 9961, loss 0.00140205, acc 1
2016-09-05T18:23:28.642022: step 9962, loss 0.00217835, acc 1
2016-09-05T18:23:28.855682: step 9963, loss 0.00143279, acc 1
2016-09-05T18:23:29.109299: step 9964, loss 0.00148274, acc 1
2016-09-05T18:23:29.333043: step 9965, loss 0.0016699, acc 1
2016-09-05T18:23:29.545008: step 9966, loss 0.00177128, acc 1
2016-09-05T18:23:29.773061: step 9967, loss 0.00172736, acc 1
2016-09-05T18:23:29.994020: step 9968, loss 0.00133728, acc 1
2016-09-05T18:23:30.201534: step 9969, loss 0.00138637, acc 1
2016-09-05T18:23:30.418016: step 9970, loss 0.00134731, acc 1
2016-09-05T18:23:30.621213: step 9971, loss 0.00149867, acc 1
2016-09-05T18:23:30.831052: step 9972, loss 0.00170423, acc 1
2016-09-05T18:23:31.070033: step 9973, loss 0.0015649, acc 1
2016-09-05T18:23:31.273579: step 9974, loss 0.00143087, acc 1
2016-09-05T18:23:31.509937: step 9975, loss 0.00141327, acc 1
2016-09-05T18:23:31.747061: step 9976, loss 0.0019789, acc 1
2016-09-05T18:23:31.950145: step 9977, loss 0.0013006, acc 1
2016-09-05T18:23:32.149685: step 9978, loss 0.00141915, acc 1
2016-09-05T18:23:32.345092: step 9979, loss 0.0012686, acc 1
2016-09-05T18:23:32.550635: step 9980, loss 0.00177489, acc 1
2016-09-05T18:23:32.764496: step 9981, loss 0.00153914, acc 1
2016-09-05T18:23:32.975843: step 9982, loss 0.00145046, acc 1
2016-09-05T18:23:33.175644: step 9983, loss 0.00147468, acc 1
2016-09-05T18:23:33.392501: step 9984, loss 0.0015339, acc 1
2016-09-05T18:23:33.590807: step 9985, loss 0.00169543, acc 1
2016-09-05T18:23:33.821421: step 9986, loss 0.00149997, acc 1
2016-09-05T18:23:34.025387: step 9987, loss 0.00163988, acc 1
2016-09-05T18:23:34.257163: step 9988, loss 0.00142969, acc 1
2016-09-05T18:23:34.468734: step 9989, loss 0.00176413, acc 1
2016-09-05T18:23:34.705358: step 9990, loss 0.00139173, acc 1
2016-09-05T18:23:34.913890: step 9991, loss 0.0013286, acc 1
2016-09-05T18:23:35.149307: step 9992, loss 0.00132988, acc 1
2016-09-05T18:23:35.362472: step 9993, loss 0.00323436, acc 1
2016-09-05T18:23:35.575297: step 9994, loss 0.00200154, acc 1
2016-09-05T18:23:35.790281: step 9995, loss 0.00131722, acc 1
2016-09-05T18:23:35.995727: step 9996, loss 0.00138345, acc 1
2016-09-05T18:23:36.217569: step 9997, loss 0.00138568, acc 1
2016-09-05T18:23:36.450075: step 9998, loss 0.00196378, acc 1
2016-09-05T18:23:36.689290: step 9999, loss 0.00232623, acc 1
2016-09-05T18:23:36.892810: step 10000, loss 0.0017463, acc 1

Evaluation:
2016-09-05T18:23:37.520791: step 10000, loss 1.34821, acc 0.741

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-10000

2016-09-05T18:23:38.248008: step 10001, loss 0.00215355, acc 1
2016-09-05T18:23:38.451291: step 10002, loss 0.00183751, acc 1
2016-09-05T18:23:38.702491: step 10003, loss 0.00168877, acc 1
2016-09-05T18:23:38.925634: step 10004, loss 0.00182923, acc 1
2016-09-05T18:23:39.197692: step 10005, loss 0.00185413, acc 1
2016-09-05T18:23:39.407707: step 10006, loss 0.00151635, acc 1
2016-09-05T18:23:39.632669: step 10007, loss 0.00159281, acc 1
2016-09-05T18:23:39.834847: step 10008, loss 0.00223993, acc 1
2016-09-05T18:23:40.058686: step 10009, loss 0.00165849, acc 1
2016-09-05T18:23:40.287687: step 10010, loss 0.00181197, acc 1
2016-09-05T18:23:40.520701: step 10011, loss 0.00157028, acc 1
2016-09-05T18:23:40.725372: step 10012, loss 0.00215646, acc 1
2016-09-05T18:23:40.936278: step 10013, loss 0.00154762, acc 1
2016-09-05T18:23:41.138370: step 10014, loss 0.00217488, acc 1
2016-09-05T18:23:41.354161: step 10015, loss 0.00165956, acc 1
2016-09-05T18:23:41.595423: step 10016, loss 0.002045, acc 1
2016-09-05T18:23:41.815640: step 10017, loss 0.00159615, acc 1
2016-09-05T18:23:42.031088: step 10018, loss 0.00177389, acc 1
2016-09-05T18:23:42.241561: step 10019, loss 0.00161342, acc 1
2016-09-05T18:23:42.462318: step 10020, loss 0.00168948, acc 1
2016-09-05T18:23:42.695203: step 10021, loss 0.00181316, acc 1
2016-09-05T18:23:42.913756: step 10022, loss 0.00155233, acc 1
2016-09-05T18:23:43.143963: step 10023, loss 0.00175925, acc 1
2016-09-05T18:23:43.359917: step 10024, loss 0.00165589, acc 1
2016-09-05T18:23:43.564260: step 10025, loss 0.00175462, acc 1
2016-09-05T18:23:43.801971: step 10026, loss 0.00149273, acc 1
2016-09-05T18:23:44.058890: step 10027, loss 0.00204625, acc 1
2016-09-05T18:23:44.261886: step 10028, loss 0.00149809, acc 1
2016-09-05T18:23:44.492027: step 10029, loss 0.00144411, acc 1
2016-09-05T18:23:44.714972: step 10030, loss 0.00158087, acc 1
2016-09-05T18:23:44.937396: step 10031, loss 0.00161585, acc 1
2016-09-05T18:23:45.161096: step 10032, loss 0.00148674, acc 1
2016-09-05T18:23:45.364979: step 10033, loss 0.00170475, acc 1
2016-09-05T18:23:45.582431: step 10034, loss 0.00143451, acc 1
2016-09-05T18:23:45.803566: step 10035, loss 0.00145865, acc 1
2016-09-05T18:23:46.006109: step 10036, loss 0.00166243, acc 1
2016-09-05T18:23:46.225436: step 10037, loss 0.0015379, acc 1
2016-09-05T18:23:46.452195: step 10038, loss 0.00163804, acc 1
2016-09-05T18:23:46.641987: step 10039, loss 0.00164589, acc 1
2016-09-05T18:23:46.865698: step 10040, loss 0.00157713, acc 1
2016-09-05T18:23:47.073929: step 10041, loss 0.00158244, acc 1
2016-09-05T18:23:47.280131: step 10042, loss 0.00142484, acc 1
2016-09-05T18:23:47.492682: step 10043, loss 0.00186939, acc 1
2016-09-05T18:23:47.707912: step 10044, loss 0.00153818, acc 1
2016-09-05T18:23:47.916505: step 10045, loss 0.0021053, acc 1
2016-09-05T18:23:48.132750: step 10046, loss 0.00173125, acc 1
2016-09-05T18:23:48.381302: step 10047, loss 0.00138215, acc 1
2016-09-05T18:23:48.593399: step 10048, loss 0.00162055, acc 1
2016-09-05T18:23:48.820584: step 10049, loss 0.00192754, acc 1
2016-09-05T18:23:49.026496: step 10050, loss 0.0012758, acc 1
2016-09-05T18:23:49.254671: step 10051, loss 0.00139767, acc 1
2016-09-05T18:23:49.455963: step 10052, loss 0.00176013, acc 1
2016-09-05T18:23:49.664096: step 10053, loss 0.00152078, acc 1
2016-09-05T18:23:49.881412: step 10054, loss 0.00233784, acc 1
2016-09-05T18:23:50.100985: step 10055, loss 0.00144367, acc 1
2016-09-05T18:23:50.308935: step 10056, loss 0.00129012, acc 1
2016-09-05T18:23:50.516208: step 10057, loss 0.00173985, acc 1
2016-09-05T18:23:50.728506: step 10058, loss 0.00221847, acc 1
2016-09-05T18:23:50.951653: step 10059, loss 0.001384, acc 1
2016-09-05T18:23:51.189847: step 10060, loss 0.0014319, acc 1
2016-09-05T18:23:51.417563: step 10061, loss 0.00156271, acc 1
2016-09-05T18:23:51.627688: step 10062, loss 0.00134414, acc 1
2016-09-05T18:23:51.841466: step 10063, loss 0.0016852, acc 1
2016-09-05T18:23:52.046643: step 10064, loss 0.00180899, acc 1
2016-09-05T18:23:52.244619: step 10065, loss 0.00156677, acc 1
2016-09-05T18:23:52.471219: step 10066, loss 0.00141759, acc 1
2016-09-05T18:23:52.695549: step 10067, loss 0.00146631, acc 1
2016-09-05T18:23:52.929496: step 10068, loss 0.00146698, acc 1
2016-09-05T18:23:53.137957: step 10069, loss 0.00132001, acc 1
2016-09-05T18:23:53.344398: step 10070, loss 0.0015902, acc 1
2016-09-05T18:23:53.565730: step 10071, loss 0.00142225, acc 1
2016-09-05T18:23:53.839613: step 10072, loss 0.00154143, acc 1
2016-09-05T18:23:54.065706: step 10073, loss 0.00133822, acc 1
2016-09-05T18:23:54.274073: step 10074, loss 0.00144733, acc 1
2016-09-05T18:23:54.498351: step 10075, loss 0.0015533, acc 1
2016-09-05T18:23:54.735593: step 10076, loss 0.00132955, acc 1
2016-09-05T18:23:54.947367: step 10077, loss 0.00142344, acc 1
2016-09-05T18:23:55.155328: step 10078, loss 0.00146111, acc 1
2016-09-05T18:23:55.381573: step 10079, loss 0.00212025, acc 1
2016-09-05T18:23:55.588500: step 10080, loss 0.00143487, acc 1
2016-09-05T18:23:55.796156: step 10081, loss 0.00154917, acc 1
2016-09-05T18:23:56.020609: step 10082, loss 0.00189212, acc 1
2016-09-05T18:23:56.215166: step 10083, loss 0.00163048, acc 1
2016-09-05T18:23:56.431232: step 10084, loss 0.00135607, acc 1
2016-09-05T18:23:56.652378: step 10085, loss 0.00148736, acc 1
2016-09-05T18:23:56.861655: step 10086, loss 0.00159323, acc 1
2016-09-05T18:23:57.084378: step 10087, loss 0.002097, acc 1
2016-09-05T18:23:57.255652: step 10088, loss 0.00226167, acc 1
2016-09-05T18:23:57.494273: step 10089, loss 0.00149879, acc 1
2016-09-05T18:23:57.698015: step 10090, loss 0.00131974, acc 1
2016-09-05T18:23:57.901929: step 10091, loss 0.00150796, acc 1
2016-09-05T18:23:58.113288: step 10092, loss 0.00166955, acc 1
2016-09-05T18:23:58.343534: step 10093, loss 0.00146294, acc 1
2016-09-05T18:23:58.576190: step 10094, loss 0.00142243, acc 1
2016-09-05T18:23:58.782449: step 10095, loss 0.00141656, acc 1
2016-09-05T18:23:59.008974: step 10096, loss 0.00139733, acc 1
2016-09-05T18:23:59.274442: step 10097, loss 0.00144311, acc 1
2016-09-05T18:23:59.511412: step 10098, loss 0.00146824, acc 1
2016-09-05T18:23:59.734876: step 10099, loss 0.0018399, acc 1
2016-09-05T18:23:59.937074: step 10100, loss 0.00143779, acc 1

Evaluation:
2016-09-05T18:24:00.531718: step 10100, loss 1.3346, acc 0.733

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-10100

2016-09-05T18:24:01.311157: step 10101, loss 0.00156085, acc 1
2016-09-05T18:24:01.512112: step 10102, loss 0.00146558, acc 1
2016-09-05T18:24:01.720806: step 10103, loss 0.00139775, acc 1
2016-09-05T18:24:01.915653: step 10104, loss 0.00131749, acc 1
2016-09-05T18:24:02.118792: step 10105, loss 0.00160771, acc 1
2016-09-05T18:24:02.346575: step 10106, loss 0.00156973, acc 1
2016-09-05T18:24:02.546218: step 10107, loss 0.00147677, acc 1
2016-09-05T18:24:02.744043: step 10108, loss 0.00158118, acc 1
2016-09-05T18:24:02.958857: step 10109, loss 0.00161572, acc 1
2016-09-05T18:24:03.161113: step 10110, loss 0.00125281, acc 1
2016-09-05T18:24:03.375511: step 10111, loss 0.00159725, acc 1
2016-09-05T18:24:03.581398: step 10112, loss 0.00131603, acc 1
2016-09-05T18:24:03.811627: step 10113, loss 0.00159092, acc 1
2016-09-05T18:24:04.031760: step 10114, loss 0.00155621, acc 1
2016-09-05T18:24:04.241005: step 10115, loss 0.00140089, acc 1
2016-09-05T18:24:04.454830: step 10116, loss 0.00139169, acc 1
2016-09-05T18:24:04.693443: step 10117, loss 0.00273159, acc 1
2016-09-05T18:24:04.909898: step 10118, loss 0.00143254, acc 1
2016-09-05T18:24:05.141186: step 10119, loss 0.0017288, acc 1
2016-09-05T18:24:05.343823: step 10120, loss 0.0014555, acc 1
2016-09-05T18:24:05.564011: step 10121, loss 0.00219316, acc 1
2016-09-05T18:24:05.778922: step 10122, loss 0.00136243, acc 1
2016-09-05T18:24:06.020889: step 10123, loss 0.00182668, acc 1
2016-09-05T18:24:06.261563: step 10124, loss 0.00152462, acc 1
2016-09-05T18:24:06.475384: step 10125, loss 0.00138589, acc 1
2016-09-05T18:24:06.678682: step 10126, loss 0.00176523, acc 1
2016-09-05T18:24:06.903591: step 10127, loss 0.00233519, acc 1
2016-09-05T18:24:07.116481: step 10128, loss 0.00140177, acc 1
2016-09-05T18:24:07.354448: step 10129, loss 0.0015548, acc 1
2016-09-05T18:24:07.585056: step 10130, loss 0.00161236, acc 1
2016-09-05T18:24:07.796266: step 10131, loss 0.00135256, acc 1
2016-09-05T18:24:08.015350: step 10132, loss 0.00155471, acc 1
2016-09-05T18:24:08.234762: step 10133, loss 0.00152648, acc 1
2016-09-05T18:24:08.447483: step 10134, loss 0.00167788, acc 1
2016-09-05T18:24:08.661380: step 10135, loss 0.00215742, acc 1
2016-09-05T18:24:08.871361: step 10136, loss 0.00264147, acc 1
2016-09-05T18:24:09.090569: step 10137, loss 0.00153451, acc 1
2016-09-05T18:24:09.312679: step 10138, loss 0.00141696, acc 1
2016-09-05T18:24:09.535485: step 10139, loss 0.0015736, acc 1
2016-09-05T18:24:09.774265: step 10140, loss 0.00162936, acc 1
2016-09-05T18:24:09.992399: step 10141, loss 0.00158789, acc 1
2016-09-05T18:24:10.196602: step 10142, loss 0.00155497, acc 1
2016-09-05T18:24:10.422139: step 10143, loss 0.00144148, acc 1
2016-09-05T18:24:10.657331: step 10144, loss 0.00177088, acc 1
2016-09-05T18:24:10.869399: step 10145, loss 0.00154771, acc 1
2016-09-05T18:24:11.104191: step 10146, loss 0.00146793, acc 1
2016-09-05T18:24:11.305863: step 10147, loss 0.00136938, acc 1
2016-09-05T18:24:11.521211: step 10148, loss 0.00196039, acc 1
2016-09-05T18:24:11.719672: step 10149, loss 0.00158645, acc 1
2016-09-05T18:24:11.937991: step 10150, loss 0.001594, acc 1
2016-09-05T18:24:12.173520: step 10151, loss 0.00157646, acc 1
2016-09-05T18:24:12.396731: step 10152, loss 0.00144944, acc 1
2016-09-05T18:24:12.600068: step 10153, loss 0.0015321, acc 1
2016-09-05T18:24:12.809575: step 10154, loss 0.00139244, acc 1
2016-09-05T18:24:13.018976: step 10155, loss 0.00154348, acc 1
2016-09-05T18:24:13.231512: step 10156, loss 0.00135414, acc 1
2016-09-05T18:24:13.457038: step 10157, loss 0.00133168, acc 1
2016-09-05T18:24:13.678465: step 10158, loss 0.00178665, acc 1
2016-09-05T18:24:13.888312: step 10159, loss 0.00136758, acc 1
2016-09-05T18:24:14.126711: step 10160, loss 0.00135963, acc 1
2016-09-05T18:24:14.346251: step 10161, loss 0.00128827, acc 1
2016-09-05T18:24:14.562412: step 10162, loss 0.00189419, acc 1
2016-09-05T18:24:14.821889: step 10163, loss 0.00161918, acc 1
2016-09-05T18:24:15.035762: step 10164, loss 0.00151248, acc 1
2016-09-05T18:24:15.256333: step 10165, loss 0.00168578, acc 1
2016-09-05T18:24:15.482382: step 10166, loss 0.00145778, acc 1
2016-09-05T18:24:15.683212: step 10167, loss 0.00149578, acc 1
2016-09-05T18:24:15.909795: step 10168, loss 0.00136671, acc 1
2016-09-05T18:24:16.128725: step 10169, loss 0.00126065, acc 1
2016-09-05T18:24:16.338965: step 10170, loss 0.00136966, acc 1
2016-09-05T18:24:16.551875: step 10171, loss 0.00133392, acc 1
2016-09-05T18:24:16.748753: step 10172, loss 0.00203398, acc 1
2016-09-05T18:24:16.945980: step 10173, loss 0.00140008, acc 1
2016-09-05T18:24:17.160804: step 10174, loss 0.00166033, acc 1
2016-09-05T18:24:17.367293: step 10175, loss 0.00134798, acc 1
2016-09-05T18:24:17.575908: step 10176, loss 0.00138636, acc 1
2016-09-05T18:24:17.779595: step 10177, loss 0.00182919, acc 1
2016-09-05T18:24:18.003466: step 10178, loss 0.00140231, acc 1
2016-09-05T18:24:18.226694: step 10179, loss 0.00143252, acc 1
2016-09-05T18:24:18.437381: step 10180, loss 0.00137767, acc 1
2016-09-05T18:24:18.653505: step 10181, loss 0.00148948, acc 1
2016-09-05T18:24:18.872925: step 10182, loss 0.00137431, acc 1
2016-09-05T18:24:19.094110: step 10183, loss 0.0017151, acc 1
2016-09-05T18:24:19.318250: step 10184, loss 0.00157409, acc 1
2016-09-05T18:24:19.561593: step 10185, loss 0.00131862, acc 1
2016-09-05T18:24:19.766627: step 10186, loss 0.00135673, acc 1
2016-09-05T18:24:19.974475: step 10187, loss 0.001343, acc 1
2016-09-05T18:24:20.173566: step 10188, loss 0.00144766, acc 1
2016-09-05T18:24:20.384135: step 10189, loss 0.00157716, acc 1
2016-09-05T18:24:20.601026: step 10190, loss 0.00141597, acc 1
2016-09-05T18:24:20.821476: step 10191, loss 0.00124368, acc 1
2016-09-05T18:24:21.042405: step 10192, loss 0.00185852, acc 1
2016-09-05T18:24:21.271577: step 10193, loss 0.00136462, acc 1
2016-09-05T18:24:21.477708: step 10194, loss 0.00137721, acc 1
2016-09-05T18:24:21.697806: step 10195, loss 0.00147248, acc 1
2016-09-05T18:24:21.904510: step 10196, loss 0.00160679, acc 1
2016-09-05T18:24:22.138613: step 10197, loss 0.00147184, acc 1
2016-09-05T18:24:22.348771: step 10198, loss 0.001281, acc 1
2016-09-05T18:24:22.582754: step 10199, loss 0.00125138, acc 1
2016-09-05T18:24:22.805790: step 10200, loss 0.00167799, acc 1

Evaluation:
2016-09-05T18:24:23.412558: step 10200, loss 1.30328, acc 0.733

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-10200

2016-09-05T18:24:24.166599: step 10201, loss 0.00136244, acc 1
2016-09-05T18:24:24.407507: step 10202, loss 0.00165275, acc 1
2016-09-05T18:24:24.640006: step 10203, loss 0.0012953, acc 1
2016-09-05T18:24:24.854125: step 10204, loss 0.0013743, acc 1
2016-09-05T18:24:25.063867: step 10205, loss 0.00174922, acc 1
2016-09-05T18:24:25.309893: step 10206, loss 0.00170643, acc 1
2016-09-05T18:24:25.529287: step 10207, loss 0.0012501, acc 1
2016-09-05T18:24:25.733232: step 10208, loss 0.00207979, acc 1
2016-09-05T18:24:25.943956: step 10209, loss 0.0012909, acc 1
2016-09-05T18:24:26.167792: step 10210, loss 0.00158496, acc 1
2016-09-05T18:24:26.390341: step 10211, loss 0.00155712, acc 1
2016-09-05T18:24:26.633014: step 10212, loss 0.00121224, acc 1
2016-09-05T18:24:26.834965: step 10213, loss 0.00152183, acc 1
2016-09-05T18:24:27.059055: step 10214, loss 0.00155926, acc 1
2016-09-05T18:24:27.270963: step 10215, loss 0.00147073, acc 1
2016-09-05T18:24:27.464209: step 10216, loss 0.00155551, acc 1
2016-09-05T18:24:27.668704: step 10217, loss 0.0025143, acc 1
2016-09-05T18:24:27.884958: step 10218, loss 0.00151709, acc 1
2016-09-05T18:24:28.091036: step 10219, loss 0.00154519, acc 1
2016-09-05T18:24:28.311477: step 10220, loss 0.00188885, acc 1
2016-09-05T18:24:28.529399: step 10221, loss 0.00149694, acc 1
2016-09-05T18:24:28.737830: step 10222, loss 0.00142079, acc 1
2016-09-05T18:24:28.941102: step 10223, loss 0.00139226, acc 1
2016-09-05T18:24:29.173820: step 10224, loss 0.00140688, acc 1
2016-09-05T18:24:29.384099: step 10225, loss 0.00190185, acc 1
2016-09-05T18:24:29.581848: step 10226, loss 0.00197161, acc 1
2016-09-05T18:24:29.796792: step 10227, loss 0.00152936, acc 1
2016-09-05T18:24:30.025190: step 10228, loss 0.00159371, acc 1
2016-09-05T18:24:30.279849: step 10229, loss 0.00126474, acc 1
2016-09-05T18:24:30.495710: step 10230, loss 0.00148079, acc 1
2016-09-05T18:24:30.715726: step 10231, loss 0.00216384, acc 1
2016-09-05T18:24:30.929809: step 10232, loss 0.00275707, acc 1
2016-09-05T18:24:31.178234: step 10233, loss 0.00158591, acc 1
2016-09-05T18:24:31.401581: step 10234, loss 0.00176305, acc 1
2016-09-05T18:24:31.621395: step 10235, loss 0.00151756, acc 1
2016-09-05T18:24:31.831844: step 10236, loss 0.00160652, acc 1
2016-09-05T18:24:32.041327: step 10237, loss 0.00149413, acc 1
2016-09-05T18:24:32.290407: step 10238, loss 0.00141094, acc 1
2016-09-05T18:24:32.507443: step 10239, loss 0.00151986, acc 1
2016-09-05T18:24:32.769128: step 10240, loss 0.00152375, acc 1
2016-09-05T18:24:33.022774: step 10241, loss 0.00161454, acc 1
2016-09-05T18:24:33.239570: step 10242, loss 0.00309016, acc 1
2016-09-05T18:24:33.469103: step 10243, loss 0.00209434, acc 1
2016-09-05T18:24:33.707299: step 10244, loss 0.00150942, acc 1
2016-09-05T18:24:33.932829: step 10245, loss 0.00167898, acc 1
2016-09-05T18:24:34.149439: step 10246, loss 0.00159262, acc 1
2016-09-05T18:24:34.414932: step 10247, loss 0.00168103, acc 1
2016-09-05T18:24:34.629028: step 10248, loss 0.00218816, acc 1
2016-09-05T18:24:34.846916: step 10249, loss 0.00194448, acc 1
2016-09-05T18:24:35.061262: step 10250, loss 0.00223521, acc 1
2016-09-05T18:24:35.286753: step 10251, loss 0.00262119, acc 1
2016-09-05T18:24:35.523061: step 10252, loss 0.00193078, acc 1
2016-09-05T18:24:35.734577: step 10253, loss 0.0029749, acc 1
2016-09-05T18:24:35.957329: step 10254, loss 0.00181969, acc 1
2016-09-05T18:24:36.176744: step 10255, loss 0.00191119, acc 1
2016-09-05T18:24:36.421978: step 10256, loss 0.00197798, acc 1
2016-09-05T18:24:36.644105: step 10257, loss 0.00193247, acc 1
2016-09-05T18:24:36.856594: step 10258, loss 0.00182282, acc 1
2016-09-05T18:24:37.064991: step 10259, loss 0.00234649, acc 1
2016-09-05T18:24:37.297909: step 10260, loss 0.00190896, acc 1
2016-09-05T18:24:37.555358: step 10261, loss 0.00297912, acc 1
2016-09-05T18:24:37.776001: step 10262, loss 0.00207636, acc 1
2016-09-05T18:24:37.991213: step 10263, loss 0.00199397, acc 1
2016-09-05T18:24:38.219946: step 10264, loss 0.00225189, acc 1
2016-09-05T18:24:38.449929: step 10265, loss 0.0018093, acc 1
2016-09-05T18:24:38.654274: step 10266, loss 0.00202066, acc 1
2016-09-05T18:24:38.863677: step 10267, loss 0.00215257, acc 1
2016-09-05T18:24:39.102455: step 10268, loss 0.00179705, acc 1
2016-09-05T18:24:39.318853: step 10269, loss 0.00185437, acc 1
2016-09-05T18:24:39.550885: step 10270, loss 0.00194397, acc 1
2016-09-05T18:24:39.761154: step 10271, loss 0.0020069, acc 1
2016-09-05T18:24:39.976057: step 10272, loss 0.00169151, acc 1
2016-09-05T18:24:40.188178: step 10273, loss 0.00192579, acc 1
2016-09-05T18:24:40.438144: step 10274, loss 0.00175985, acc 1
2016-09-05T18:24:40.639601: step 10275, loss 0.00179465, acc 1
2016-09-05T18:24:40.876893: step 10276, loss 0.00174862, acc 1
2016-09-05T18:24:41.100630: step 10277, loss 0.00164669, acc 1
2016-09-05T18:24:41.303695: step 10278, loss 0.00267358, acc 1
2016-09-05T18:24:41.546077: step 10279, loss 0.00163225, acc 1
2016-09-05T18:24:41.775284: step 10280, loss 0.0018088, acc 1
2016-09-05T18:24:41.981350: step 10281, loss 0.00157908, acc 1
2016-09-05T18:24:42.108476: step 10282, loss 0.00149931, acc 1
2016-09-05T18:24:42.331759: step 10283, loss 0.00210396, acc 1
2016-09-05T18:24:42.551868: step 10284, loss 0.00147967, acc 1
2016-09-05T18:24:42.771843: step 10285, loss 0.00152075, acc 1
2016-09-05T18:24:42.977060: step 10286, loss 0.00136629, acc 1
2016-09-05T18:24:43.199135: step 10287, loss 0.0014163, acc 1
2016-09-05T18:24:43.420123: step 10288, loss 0.00154611, acc 1
2016-09-05T18:24:43.686746: step 10289, loss 0.00192003, acc 1
2016-09-05T18:24:43.908626: step 10290, loss 0.00153275, acc 1
2016-09-05T18:24:44.169065: step 10291, loss 0.0016041, acc 1
2016-09-05T18:24:44.369731: step 10292, loss 0.00143357, acc 1
2016-09-05T18:24:44.612939: step 10293, loss 0.00153141, acc 1
2016-09-05T18:24:44.834188: step 10294, loss 0.00228299, acc 1
2016-09-05T18:24:45.042505: step 10295, loss 0.00136571, acc 1
2016-09-05T18:24:45.274910: step 10296, loss 0.0164661, acc 0.98
2016-09-05T18:24:45.500991: step 10297, loss 0.00319175, acc 1
2016-09-05T18:24:45.712581: step 10298, loss 0.00399952, acc 1
2016-09-05T18:24:45.916912: step 10299, loss 0.115507, acc 0.94
2016-09-05T18:24:46.137509: step 10300, loss 0.00300234, acc 1

Evaluation:
2016-09-05T18:24:46.741227: step 10300, loss 3.32343, acc 0.632

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-10300

2016-09-05T18:24:47.440464: step 10301, loss 0.232975, acc 0.94
2016-09-05T18:24:47.663168: step 10302, loss 0.0105053, acc 1
2016-09-05T18:24:47.870747: step 10303, loss 0.00434048, acc 1
2016-09-05T18:24:48.073294: step 10304, loss 0.00537948, acc 1
2016-09-05T18:24:48.286655: step 10305, loss 0.00644977, acc 1
2016-09-05T18:24:48.522416: step 10306, loss 0.00868393, acc 1
2016-09-05T18:24:48.728912: step 10307, loss 0.0113107, acc 1
2016-09-05T18:24:48.943358: step 10308, loss 0.196029, acc 0.94
2016-09-05T18:24:49.170094: step 10309, loss 0.0108208, acc 1
2016-09-05T18:24:49.398275: step 10310, loss 0.0118486, acc 1
2016-09-05T18:24:49.631474: step 10311, loss 0.0128884, acc 1
2016-09-05T18:24:49.860791: step 10312, loss 0.01391, acc 1
2016-09-05T18:24:50.085376: step 10313, loss 0.0148919, acc 1
2016-09-05T18:24:50.289862: step 10314, loss 0.015829, acc 1
2016-09-05T18:24:50.517090: step 10315, loss 0.0166976, acc 1
2016-09-05T18:24:50.730523: step 10316, loss 0.0175079, acc 1
2016-09-05T18:24:50.941254: step 10317, loss 0.0182525, acc 1
2016-09-05T18:24:51.154330: step 10318, loss 0.0189311, acc 1
2016-09-05T18:24:51.382698: step 10319, loss 0.0195443, acc 1
2016-09-05T18:24:51.596205: step 10320, loss 0.0200947, acc 1
2016-09-05T18:24:51.811033: step 10321, loss 0.0206199, acc 1
2016-09-05T18:24:52.037447: step 10322, loss 0.0210144, acc 1
2016-09-05T18:24:52.256796: step 10323, loss 0.0922998, acc 0.96
2016-09-05T18:24:52.475390: step 10324, loss 0.0232213, acc 1
2016-09-05T18:24:52.668235: step 10325, loss 0.0219108, acc 1
2016-09-05T18:24:52.889568: step 10326, loss 0.022127, acc 1
2016-09-05T18:24:53.141740: step 10327, loss 0.0223126, acc 1
2016-09-05T18:24:53.381206: step 10328, loss 0.0233139, acc 1
2016-09-05T18:24:53.581833: step 10329, loss 0.0225925, acc 1
2016-09-05T18:24:53.780161: step 10330, loss 0.0226927, acc 1
2016-09-05T18:24:53.978639: step 10331, loss 0.0264588, acc 1
2016-09-05T18:24:54.186627: step 10332, loss 0.0228235, acc 1
2016-09-05T18:24:54.394367: step 10333, loss 0.0228673, acc 1
2016-09-05T18:24:54.628153: step 10334, loss 0.022862, acc 1
2016-09-05T18:24:54.859580: step 10335, loss 0.0229012, acc 1
2016-09-05T18:24:55.061210: step 10336, loss 0.022829, acc 1
2016-09-05T18:24:55.290889: step 10337, loss 0.0227843, acc 1
2016-09-05T18:24:55.508286: step 10338, loss 0.0227274, acc 1
2016-09-05T18:24:55.720486: step 10339, loss 0.0226583, acc 1
2016-09-05T18:24:55.929543: step 10340, loss 0.0225779, acc 1
2016-09-05T18:24:56.136247: step 10341, loss 0.0224826, acc 1
2016-09-05T18:24:56.362946: step 10342, loss 0.0223802, acc 1
2016-09-05T18:24:56.592490: step 10343, loss 0.0222693, acc 1
2016-09-05T18:24:56.778949: step 10344, loss 0.0223546, acc 1
2016-09-05T18:24:57.009962: step 10345, loss 0.022081, acc 1
2016-09-05T18:24:57.225016: step 10346, loss 0.0218952, acc 1
2016-09-05T18:24:57.446520: step 10347, loss 0.0238721, acc 1
2016-09-05T18:24:57.650181: step 10348, loss 0.0216219, acc 1
2016-09-05T18:24:57.872419: step 10349, loss 0.0214793, acc 1
2016-09-05T18:24:58.111008: step 10350, loss 0.0236776, acc 1
2016-09-05T18:24:58.324943: step 10351, loss 0.0211828, acc 1
2016-09-05T18:24:58.541593: step 10352, loss 0.0210317, acc 1
2016-09-05T18:24:58.745342: step 10353, loss 0.0208784, acc 1
2016-09-05T18:24:58.959144: step 10354, loss 0.0207232, acc 1
2016-09-05T18:24:59.159060: step 10355, loss 0.0205658, acc 1
2016-09-05T18:24:59.380411: step 10356, loss 0.0204073, acc 1
2016-09-05T18:24:59.595129: step 10357, loss 0.0202492, acc 1
2016-09-05T18:24:59.830858: step 10358, loss 0.0200875, acc 1
2016-09-05T18:25:00.025417: step 10359, loss 0.019949, acc 1
2016-09-05T18:25:00.241401: step 10360, loss 0.0197654, acc 1
2016-09-05T18:25:00.466533: step 10361, loss 0.0196315, acc 1
2016-09-05T18:25:00.686459: step 10362, loss 0.0246638, acc 1
2016-09-05T18:25:00.910647: step 10363, loss 0.0192944, acc 1
2016-09-05T18:25:01.143915: step 10364, loss 0.0191259, acc 1
2016-09-05T18:25:01.375162: step 10365, loss 0.0189678, acc 1
2016-09-05T18:25:01.604956: step 10366, loss 0.0188101, acc 1
2016-09-05T18:25:01.821046: step 10367, loss 0.0186527, acc 1
2016-09-05T18:25:02.057391: step 10368, loss 0.018496, acc 1
2016-09-05T18:25:02.279318: step 10369, loss 0.01834, acc 1
2016-09-05T18:25:02.487921: step 10370, loss 0.0181858, acc 1
2016-09-05T18:25:02.700042: step 10371, loss 0.01805, acc 1
2016-09-05T18:25:02.946883: step 10372, loss 0.0178765, acc 1
2016-09-05T18:25:03.149036: step 10373, loss 0.0177233, acc 1
2016-09-05T18:25:03.361621: step 10374, loss 0.0209376, acc 1
2016-09-05T18:25:03.560830: step 10375, loss 0.0174262, acc 1
2016-09-05T18:25:03.769841: step 10376, loss 0.0172781, acc 1
2016-09-05T18:25:03.978940: step 10377, loss 0.0171377, acc 1
2016-09-05T18:25:04.191404: step 10378, loss 0.0169875, acc 1
2016-09-05T18:25:04.394579: step 10379, loss 0.0168491, acc 1
2016-09-05T18:25:04.612310: step 10380, loss 0.0167035, acc 1
2016-09-05T18:25:04.820183: step 10381, loss 0.0165628, acc 1
2016-09-05T18:25:05.049466: step 10382, loss 0.0164226, acc 1
2016-09-05T18:25:05.267043: step 10383, loss 0.0162797, acc 1
2016-09-05T18:25:05.483383: step 10384, loss 0.0161366, acc 1
2016-09-05T18:25:05.674318: step 10385, loss 0.0160524, acc 1
2016-09-05T18:25:05.882208: step 10386, loss 0.0158607, acc 1
2016-09-05T18:25:06.093852: step 10387, loss 0.0157247, acc 1
2016-09-05T18:25:06.312915: step 10388, loss 0.0155891, acc 1
2016-09-05T18:25:06.512996: step 10389, loss 0.0154556, acc 1
2016-09-05T18:25:06.735513: step 10390, loss 0.0153233, acc 1
2016-09-05T18:25:06.950976: step 10391, loss 0.0170519, acc 1
2016-09-05T18:25:07.144793: step 10392, loss 0.0150756, acc 1
2016-09-05T18:25:07.377411: step 10393, loss 0.0153394, acc 1
2016-09-05T18:25:07.602268: step 10394, loss 0.0148077, acc 1
2016-09-05T18:25:07.825192: step 10395, loss 0.0146824, acc 1
2016-09-05T18:25:08.039187: step 10396, loss 0.0145711, acc 1
2016-09-05T18:25:08.276754: step 10397, loss 0.0144345, acc 1
2016-09-05T18:25:08.500900: step 10398, loss 0.0143115, acc 1
2016-09-05T18:25:08.709946: step 10399, loss 0.0141896, acc 1
2016-09-05T18:25:08.913456: step 10400, loss 0.0140688, acc 1

Evaluation:
2016-09-05T18:25:09.531690: step 10400, loss 4.09451, acc 0.729

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-10400

2016-09-05T18:25:10.246659: step 10401, loss 0.0139486, acc 1
2016-09-05T18:25:10.474326: step 10402, loss 0.0138294, acc 1
2016-09-05T18:25:10.707134: step 10403, loss 0.0137114, acc 1
2016-09-05T18:25:10.920606: step 10404, loss 0.0135971, acc 1
2016-09-05T18:25:11.149632: step 10405, loss 0.0134776, acc 1
2016-09-05T18:25:11.354460: step 10406, loss 0.0133622, acc 1
2016-09-05T18:25:11.554967: step 10407, loss 0.0132478, acc 1
2016-09-05T18:25:11.746428: step 10408, loss 0.0131347, acc 1
2016-09-05T18:25:11.948939: step 10409, loss 0.0130221, acc 1
2016-09-05T18:25:12.146915: step 10410, loss 0.0129102, acc 1
2016-09-05T18:25:12.346855: step 10411, loss 0.0127997, acc 1
2016-09-05T18:25:12.547864: step 10412, loss 0.0127107, acc 1
2016-09-05T18:25:12.760343: step 10413, loss 0.0126046, acc 1
2016-09-05T18:25:12.956166: step 10414, loss 0.0125038, acc 1
2016-09-05T18:25:13.158573: step 10415, loss 0.0123671, acc 1
2016-09-05T18:25:13.358507: step 10416, loss 0.0140223, acc 1
2016-09-05T18:25:13.563106: step 10417, loss 0.0121626, acc 1
2016-09-05T18:25:13.761797: step 10418, loss 0.0120593, acc 1
2016-09-05T18:25:13.971172: step 10419, loss 0.0119673, acc 1
2016-09-05T18:25:14.167993: step 10420, loss 0.0171488, acc 1
2016-09-05T18:25:14.413086: step 10421, loss 0.0117566, acc 1
2016-09-05T18:25:14.664498: step 10422, loss 0.0116616, acc 1
2016-09-05T18:25:14.865854: step 10423, loss 0.0115644, acc 1
2016-09-05T18:25:15.066873: step 10424, loss 0.0115018, acc 1
2016-09-05T18:25:15.272796: step 10425, loss 0.0113743, acc 1
2016-09-05T18:25:15.461891: step 10426, loss 0.0112801, acc 1
2016-09-05T18:25:15.667622: step 10427, loss 0.0111972, acc 1
2016-09-05T18:25:15.872640: step 10428, loss 0.0110954, acc 1
2016-09-05T18:25:16.076597: step 10429, loss 0.0111754, acc 1
2016-09-05T18:25:16.280998: step 10430, loss 0.0109324, acc 1
2016-09-05T18:25:16.496592: step 10431, loss 0.0108347, acc 1
2016-09-05T18:25:16.719706: step 10432, loss 0.0109448, acc 1
2016-09-05T18:25:16.981390: step 10433, loss 0.0106411, acc 1
2016-09-05T18:25:17.179247: step 10434, loss 0.0105524, acc 1
2016-09-05T18:25:17.379822: step 10435, loss 0.0104648, acc 1
2016-09-05T18:25:17.582807: step 10436, loss 0.0105058, acc 1
2016-09-05T18:25:17.809088: step 10437, loss 0.0102926, acc 1
2016-09-05T18:25:18.023801: step 10438, loss 0.0102081, acc 1
2016-09-05T18:25:18.229809: step 10439, loss 0.0101256, acc 1
2016-09-05T18:25:18.452407: step 10440, loss 0.010043, acc 1
2016-09-05T18:25:18.685836: step 10441, loss 0.0100896, acc 1
2016-09-05T18:25:18.914986: step 10442, loss 0.0108335, acc 1
2016-09-05T18:25:19.119222: step 10443, loss 0.00978826, acc 1
2016-09-05T18:25:19.349559: step 10444, loss 0.00985984, acc 1
2016-09-05T18:25:19.573536: step 10445, loss 0.00963175, acc 1
2016-09-05T18:25:19.798815: step 10446, loss 0.0393878, acc 0.98
2016-09-05T18:25:20.013732: step 10447, loss 0.00947763, acc 1
2016-09-05T18:25:20.256814: step 10448, loss 0.00941993, acc 1
2016-09-05T18:25:20.498247: step 10449, loss 0.00934018, acc 1
2016-09-05T18:25:20.689432: step 10450, loss 0.00927387, acc 1
2016-09-05T18:25:20.910249: step 10451, loss 0.00956179, acc 1
2016-09-05T18:25:21.110794: step 10452, loss 0.00914584, acc 1
2016-09-05T18:25:21.322990: step 10453, loss 0.00911872, acc 1
2016-09-05T18:25:21.540254: step 10454, loss 0.00901564, acc 1
2016-09-05T18:25:21.764557: step 10455, loss 0.0089595, acc 1
2016-09-05T18:25:21.980450: step 10456, loss 0.00888638, acc 1
2016-09-05T18:25:22.196308: step 10457, loss 0.0088338, acc 1
2016-09-05T18:25:22.386236: step 10458, loss 0.00877411, acc 1
2016-09-05T18:25:22.609622: step 10459, loss 0.00870494, acc 1
2016-09-05T18:25:22.815776: step 10460, loss 0.00868386, acc 1
2016-09-05T18:25:23.031271: step 10461, loss 0.0570238, acc 0.98
2016-09-05T18:25:23.255503: step 10462, loss 0.00848745, acc 1
2016-09-05T18:25:23.476322: step 10463, loss 0.00860623, acc 1
2016-09-05T18:25:23.707437: step 10464, loss 0.00971755, acc 1
2016-09-05T18:25:23.915379: step 10465, loss 0.00886881, acc 1
2016-09-05T18:25:24.108352: step 10466, loss 0.00857197, acc 1
2016-09-05T18:25:24.308869: step 10467, loss 0.0081411, acc 1
2016-09-05T18:25:24.531096: step 10468, loss 0.00813449, acc 1
2016-09-05T18:25:24.742955: step 10469, loss 0.0253757, acc 0.98
2016-09-05T18:25:24.967042: step 10470, loss 0.00802187, acc 1
2016-09-05T18:25:25.180020: step 10471, loss 0.00885899, acc 1
2016-09-05T18:25:25.401575: step 10472, loss 0.00793825, acc 1
2016-09-05T18:25:25.618289: step 10473, loss 0.0120013, acc 1
2016-09-05T18:25:25.846787: step 10474, loss 0.00796521, acc 1
2016-09-05T18:25:26.064334: step 10475, loss 0.00971129, acc 1
2016-09-05T18:25:26.229209: step 10476, loss 0.00928222, acc 1
2016-09-05T18:25:26.462017: step 10477, loss 0.00930286, acc 1
2016-09-05T18:25:26.678060: step 10478, loss 0.00985416, acc 1
2016-09-05T18:25:26.883713: step 10479, loss 0.00785759, acc 1
2016-09-05T18:25:27.097158: step 10480, loss 0.00766616, acc 1
2016-09-05T18:25:27.321538: step 10481, loss 0.00765714, acc 1
2016-09-05T18:25:27.526684: step 10482, loss 0.0083747, acc 1
2016-09-05T18:25:27.774660: step 10483, loss 0.00768484, acc 1
2016-09-05T18:25:27.974455: step 10484, loss 0.0075526, acc 1
2016-09-05T18:25:28.170205: step 10485, loss 0.00772555, acc 1
2016-09-05T18:25:28.374480: step 10486, loss 0.00756472, acc 1
2016-09-05T18:25:28.581510: step 10487, loss 0.00738953, acc 1
2016-09-05T18:25:28.792190: step 10488, loss 0.0134946, acc 1
2016-09-05T18:25:29.008355: step 10489, loss 0.007821, acc 1
2016-09-05T18:25:29.216216: step 10490, loss 0.0182224, acc 1
2016-09-05T18:25:29.441127: step 10491, loss 0.00725208, acc 1
2016-09-05T18:25:29.680583: step 10492, loss 0.00724549, acc 1
2016-09-05T18:25:29.912920: step 10493, loss 0.00713896, acc 1
2016-09-05T18:25:30.106646: step 10494, loss 0.0070993, acc 1
2016-09-05T18:25:30.332403: step 10495, loss 0.00709988, acc 1
2016-09-05T18:25:30.538007: step 10496, loss 0.00727152, acc 1
2016-09-05T18:25:30.758071: step 10497, loss 0.00744534, acc 1
2016-09-05T18:25:31.005757: step 10498, loss 0.0069329, acc 1
2016-09-05T18:25:31.212927: step 10499, loss 0.00689111, acc 1
2016-09-05T18:25:31.440153: step 10500, loss 0.0070364, acc 1

Evaluation:
2016-09-05T18:25:32.061315: step 10500, loss 2.85483, acc 0.732

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-10500

2016-09-05T18:25:32.846870: step 10501, loss 0.00684815, acc 1
2016-09-05T18:25:33.049956: step 10502, loss 0.00679867, acc 1
2016-09-05T18:25:33.249695: step 10503, loss 0.00671688, acc 1
2016-09-05T18:25:33.453373: step 10504, loss 0.00669887, acc 1
2016-09-05T18:25:33.687768: step 10505, loss 0.0066434, acc 1
2016-09-05T18:25:33.915138: step 10506, loss 0.00658194, acc 1
2016-09-05T18:25:34.138040: step 10507, loss 0.00654209, acc 1
2016-09-05T18:25:34.369346: step 10508, loss 0.00648676, acc 1
2016-09-05T18:25:34.564534: step 10509, loss 0.00644075, acc 1
2016-09-05T18:25:34.795590: step 10510, loss 0.00640654, acc 1
2016-09-05T18:25:35.014273: step 10511, loss 0.00769772, acc 1
2016-09-05T18:25:35.251810: step 10512, loss 0.0109011, acc 1
2016-09-05T18:25:35.464488: step 10513, loss 0.00625659, acc 1
2016-09-05T18:25:35.682582: step 10514, loss 0.00622028, acc 1
2016-09-05T18:25:35.909481: step 10515, loss 0.00632901, acc 1
2016-09-05T18:25:36.113968: step 10516, loss 0.00612022, acc 1
2016-09-05T18:25:36.344869: step 10517, loss 0.0060788, acc 1
2016-09-05T18:25:36.536056: step 10518, loss 0.00602957, acc 1
2016-09-05T18:25:36.746232: step 10519, loss 0.00598507, acc 1
2016-09-05T18:25:36.949144: step 10520, loss 0.00598806, acc 1
2016-09-05T18:25:37.169526: step 10521, loss 0.00594245, acc 1
2016-09-05T18:25:37.367120: step 10522, loss 0.00589488, acc 1
2016-09-05T18:25:37.569644: step 10523, loss 0.00580572, acc 1
2016-09-05T18:25:37.766013: step 10524, loss 0.00579642, acc 1
2016-09-05T18:25:37.984599: step 10525, loss 0.00590009, acc 1
2016-09-05T18:25:38.201908: step 10526, loss 0.00605642, acc 1
2016-09-05T18:25:38.437925: step 10527, loss 0.00577998, acc 1
2016-09-05T18:25:38.628248: step 10528, loss 0.00559443, acc 1
2016-09-05T18:25:38.857435: step 10529, loss 0.00554493, acc 1
2016-09-05T18:25:39.076838: step 10530, loss 0.00550077, acc 1
2016-09-05T18:25:39.274770: step 10531, loss 0.00546287, acc 1
2016-09-05T18:25:39.485187: step 10532, loss 0.00542273, acc 1
2016-09-05T18:25:39.700680: step 10533, loss 0.00537422, acc 1
2016-09-05T18:25:39.906980: step 10534, loss 0.00533253, acc 1
2016-09-05T18:25:40.130569: step 10535, loss 0.00530763, acc 1
2016-09-05T18:25:40.350680: step 10536, loss 0.00528878, acc 1
2016-09-05T18:25:40.560181: step 10537, loss 0.00520535, acc 1
2016-09-05T18:25:40.789488: step 10538, loss 0.00517896, acc 1
2016-09-05T18:25:41.008058: step 10539, loss 0.00516545, acc 1
2016-09-05T18:25:41.217434: step 10540, loss 0.00517615, acc 1
2016-09-05T18:25:41.449251: step 10541, loss 0.00504201, acc 1
2016-09-05T18:25:41.679352: step 10542, loss 0.00500266, acc 1
2016-09-05T18:25:41.914080: step 10543, loss 0.00521014, acc 1
2016-09-05T18:25:42.125191: step 10544, loss 0.00492591, acc 1
2016-09-05T18:25:42.349222: step 10545, loss 0.00496037, acc 1
2016-09-05T18:25:42.564066: step 10546, loss 0.00487565, acc 1
2016-09-05T18:25:42.778024: step 10547, loss 0.00482041, acc 1
2016-09-05T18:25:42.985737: step 10548, loss 0.00479327, acc 1
2016-09-05T18:25:43.202631: step 10549, loss 0.00477455, acc 1
2016-09-05T18:25:43.432225: step 10550, loss 0.00497951, acc 1
2016-09-05T18:25:43.636195: step 10551, loss 0.00485185, acc 1
2016-09-05T18:25:43.856934: step 10552, loss 0.00464199, acc 1
2016-09-05T18:25:44.069885: step 10553, loss 0.00467608, acc 1
2016-09-05T18:25:44.273671: step 10554, loss 0.00463264, acc 1
2016-09-05T18:25:44.495056: step 10555, loss 0.00944904, acc 1
2016-09-05T18:25:44.699626: step 10556, loss 0.00450871, acc 1
2016-09-05T18:25:44.929473: step 10557, loss 0.00514717, acc 1
2016-09-05T18:25:45.129023: step 10558, loss 0.0045142, acc 1
2016-09-05T18:25:45.332287: step 10559, loss 0.0049396, acc 1
2016-09-05T18:25:45.526807: step 10560, loss 0.00435543, acc 1
2016-09-05T18:25:45.743086: step 10561, loss 0.00434479, acc 1
2016-09-05T18:25:45.936414: step 10562, loss 0.00597456, acc 1
2016-09-05T18:25:46.152373: step 10563, loss 0.0043526, acc 1
2016-09-05T18:25:46.352570: step 10564, loss 0.00447742, acc 1
2016-09-05T18:25:46.587199: step 10565, loss 0.00422279, acc 1
2016-09-05T18:25:46.814288: step 10566, loss 0.00426507, acc 1
2016-09-05T18:25:47.051630: step 10567, loss 0.00417689, acc 1
2016-09-05T18:25:47.259574: step 10568, loss 0.00415677, acc 1
2016-09-05T18:25:47.490229: step 10569, loss 0.00409239, acc 1
2016-09-05T18:25:47.715563: step 10570, loss 0.0058131, acc 1
2016-09-05T18:25:47.972826: step 10571, loss 0.00421876, acc 1
2016-09-05T18:25:48.189182: step 10572, loss 0.00435923, acc 1
2016-09-05T18:25:48.405020: step 10573, loss 0.00401511, acc 1
2016-09-05T18:25:48.622380: step 10574, loss 0.00404496, acc 1
2016-09-05T18:25:48.836833: step 10575, loss 0.0039884, acc 1
2016-09-05T18:25:49.062871: step 10576, loss 0.00415199, acc 1
2016-09-05T18:25:49.285911: step 10577, loss 0.00389381, acc 1
2016-09-05T18:25:49.534129: step 10578, loss 0.00450599, acc 1
2016-09-05T18:25:49.759540: step 10579, loss 0.00387624, acc 1
2016-09-05T18:25:49.963672: step 10580, loss 0.00478079, acc 1
2016-09-05T18:25:50.177161: step 10581, loss 0.00382506, acc 1
2016-09-05T18:25:50.381196: step 10582, loss 0.00387711, acc 1
2016-09-05T18:25:50.596515: step 10583, loss 0.00376077, acc 1
2016-09-05T18:25:50.814363: step 10584, loss 0.00439284, acc 1
2016-09-05T18:25:51.043443: step 10585, loss 0.0040523, acc 1
2016-09-05T18:25:51.260856: step 10586, loss 0.00395769, acc 1
2016-09-05T18:25:51.488072: step 10587, loss 0.00366551, acc 1
2016-09-05T18:25:51.690106: step 10588, loss 0.00365505, acc 1
2016-09-05T18:25:51.897854: step 10589, loss 0.00360249, acc 1
2016-09-05T18:25:52.092063: step 10590, loss 0.00359482, acc 1
2016-09-05T18:25:52.313891: step 10591, loss 0.00355375, acc 1
2016-09-05T18:25:52.545350: step 10592, loss 0.00400467, acc 1
2016-09-05T18:25:52.773272: step 10593, loss 0.00353561, acc 1
2016-09-05T18:25:52.975451: step 10594, loss 0.00430574, acc 1
2016-09-05T18:25:53.168474: step 10595, loss 0.00353167, acc 1
2016-09-05T18:25:53.377682: step 10596, loss 0.00343011, acc 1
2016-09-05T18:25:53.600792: step 10597, loss 0.00636561, acc 1
2016-09-05T18:25:53.824981: step 10598, loss 0.00340458, acc 1
2016-09-05T18:25:54.049830: step 10599, loss 0.00359343, acc 1
2016-09-05T18:25:54.276923: step 10600, loss 0.00338776, acc 1

Evaluation:
2016-09-05T18:25:54.895221: step 10600, loss 2.11605, acc 0.724

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-10600

2016-09-05T18:25:55.628909: step 10601, loss 0.00352615, acc 1
2016-09-05T18:25:55.854342: step 10602, loss 0.00337511, acc 1
2016-09-05T18:25:56.055923: step 10603, loss 0.00337537, acc 1
2016-09-05T18:25:56.266519: step 10604, loss 0.0033331, acc 1
2016-09-05T18:25:56.494299: step 10605, loss 0.00362641, acc 1
2016-09-05T18:25:56.732100: step 10606, loss 0.00431297, acc 1
2016-09-05T18:25:56.938204: step 10607, loss 0.00332369, acc 1
2016-09-05T18:25:57.164208: step 10608, loss 0.00376156, acc 1
2016-09-05T18:25:57.390403: step 10609, loss 0.00344945, acc 1
2016-09-05T18:25:57.614170: step 10610, loss 0.00337727, acc 1
2016-09-05T18:25:57.842504: step 10611, loss 0.00372391, acc 1
2016-09-05T18:25:58.052903: step 10612, loss 0.00320166, acc 1
2016-09-05T18:25:58.271369: step 10613, loss 0.0031619, acc 1
2016-09-05T18:25:58.483716: step 10614, loss 0.00313289, acc 1
2016-09-05T18:25:58.693679: step 10615, loss 0.00310911, acc 1
2016-09-05T18:25:58.923229: step 10616, loss 0.00323904, acc 1
2016-09-05T18:25:59.161932: step 10617, loss 0.00323019, acc 1
2016-09-05T18:25:59.361765: step 10618, loss 0.00673914, acc 1
2016-09-05T18:25:59.566905: step 10619, loss 0.00321964, acc 1
2016-09-05T18:25:59.769356: step 10620, loss 0.00303974, acc 1
2016-09-05T18:25:59.972097: step 10621, loss 0.00316112, acc 1
2016-09-05T18:26:00.174366: step 10622, loss 0.00299635, acc 1
2016-09-05T18:26:00.395357: step 10623, loss 0.00304175, acc 1
2016-09-05T18:26:00.611951: step 10624, loss 0.00296583, acc 1
2016-09-05T18:26:00.839401: step 10625, loss 0.00574999, acc 1
2016-09-05T18:26:01.077796: step 10626, loss 0.00363926, acc 1
2016-09-05T18:26:01.325340: step 10627, loss 0.00402338, acc 1
2016-09-05T18:26:01.578569: step 10628, loss 0.00301366, acc 1
2016-09-05T18:26:01.786538: step 10629, loss 0.00336415, acc 1
2016-09-05T18:26:02.014647: step 10630, loss 0.00330238, acc 1
2016-09-05T18:26:02.226606: step 10631, loss 0.00345014, acc 1
2016-09-05T18:26:02.451116: step 10632, loss 0.00289496, acc 1
2016-09-05T18:26:02.686662: step 10633, loss 0.00336714, acc 1
2016-09-05T18:26:02.903987: step 10634, loss 0.00570843, acc 1
2016-09-05T18:26:03.105356: step 10635, loss 0.00396909, acc 1
2016-09-05T18:26:03.333547: step 10636, loss 0.0034194, acc 1
2016-09-05T18:26:03.552612: step 10637, loss 0.0031596, acc 1
2016-09-05T18:26:03.798522: step 10638, loss 0.00280154, acc 1
2016-09-05T18:26:04.013543: step 10639, loss 0.00287474, acc 1
2016-09-05T18:26:04.207793: step 10640, loss 0.0028295, acc 1
2016-09-05T18:26:04.436537: step 10641, loss 0.00286125, acc 1
2016-09-05T18:26:04.686757: step 10642, loss 0.00309929, acc 1
2016-09-05T18:26:04.911724: step 10643, loss 0.00298596, acc 1
2016-09-05T18:26:05.120432: step 10644, loss 0.00286402, acc 1
2016-09-05T18:26:05.340550: step 10645, loss 0.00269653, acc 1
2016-09-05T18:26:05.551483: step 10646, loss 0.00267743, acc 1
2016-09-05T18:26:05.746045: step 10647, loss 0.00290619, acc 1
2016-09-05T18:26:05.956972: step 10648, loss 0.00297646, acc 1
2016-09-05T18:26:06.169024: step 10649, loss 0.00263718, acc 1
2016-09-05T18:26:06.389917: step 10650, loss 0.00261998, acc 1
2016-09-05T18:26:06.603652: step 10651, loss 0.0027056, acc 1
2016-09-05T18:26:06.844049: step 10652, loss 0.00260455, acc 1
2016-09-05T18:26:07.045670: step 10653, loss 0.00273327, acc 1
2016-09-05T18:26:07.246484: step 10654, loss 0.0401432, acc 0.98
2016-09-05T18:26:07.479841: step 10655, loss 0.00266879, acc 1
2016-09-05T18:26:07.706064: step 10656, loss 0.00318238, acc 1
2016-09-05T18:26:07.915395: step 10657, loss 0.00273613, acc 1
2016-09-05T18:26:08.149611: step 10658, loss 0.00338679, acc 1
2016-09-05T18:26:08.349287: step 10659, loss 0.00322249, acc 1
2016-09-05T18:26:08.583972: step 10660, loss 0.00290857, acc 1
2016-09-05T18:26:08.792309: step 10661, loss 0.0053797, acc 1
2016-09-05T18:26:09.032719: step 10662, loss 0.0425201, acc 0.98
2016-09-05T18:26:09.254956: step 10663, loss 0.0029957, acc 1
2016-09-05T18:26:09.480047: step 10664, loss 0.00310095, acc 1
2016-09-05T18:26:09.684197: step 10665, loss 0.00337429, acc 1
2016-09-05T18:26:09.897403: step 10666, loss 0.00346063, acc 1
2016-09-05T18:26:10.124308: step 10667, loss 0.00343778, acc 1
2016-09-05T18:26:10.330370: step 10668, loss 0.00331443, acc 1
2016-09-05T18:26:10.571361: step 10669, loss 0.00341821, acc 1
2016-09-05T18:26:10.708722: step 10670, loss 0.00370728, acc 1
2016-09-05T18:26:10.938570: step 10671, loss 0.00365693, acc 1
2016-09-05T18:26:11.174531: step 10672, loss 0.00451237, acc 1
2016-09-05T18:26:11.400332: step 10673, loss 0.00389048, acc 1
2016-09-05T18:26:11.612104: step 10674, loss 0.00492049, acc 1
2016-09-05T18:26:11.841089: step 10675, loss 0.00469707, acc 1
2016-09-05T18:26:12.053551: step 10676, loss 0.00473324, acc 1
2016-09-05T18:26:12.273228: step 10677, loss 0.0042716, acc 1
2016-09-05T18:26:12.512708: step 10678, loss 0.00498036, acc 1
2016-09-05T18:26:12.718808: step 10679, loss 0.00947413, acc 1
2016-09-05T18:26:12.935532: step 10680, loss 0.00423398, acc 1
2016-09-05T18:26:13.131329: step 10681, loss 0.00478003, acc 1
2016-09-05T18:26:13.344949: step 10682, loss 0.00504498, acc 1
2016-09-05T18:26:13.543763: step 10683, loss 0.00431752, acc 1
2016-09-05T18:26:13.771666: step 10684, loss 0.00474335, acc 1
2016-09-05T18:26:13.997506: step 10685, loss 0.00447267, acc 1
2016-09-05T18:26:14.226350: step 10686, loss 0.00469178, acc 1
2016-09-05T18:26:14.431836: step 10687, loss 0.00436665, acc 1
2016-09-05T18:26:14.635713: step 10688, loss 0.00452272, acc 1
2016-09-05T18:26:14.842884: step 10689, loss 0.00444297, acc 1
2016-09-05T18:26:15.060531: step 10690, loss 0.0045008, acc 1
2016-09-05T18:26:15.279646: step 10691, loss 0.00441839, acc 1
2016-09-05T18:26:15.504573: step 10692, loss 0.00445827, acc 1
2016-09-05T18:26:15.739339: step 10693, loss 0.00454586, acc 1
2016-09-05T18:26:15.949214: step 10694, loss 0.00439136, acc 1
2016-09-05T18:26:16.162704: step 10695, loss 0.00437494, acc 1
2016-09-05T18:26:16.368805: step 10696, loss 0.00439663, acc 1
2016-09-05T18:26:16.581673: step 10697, loss 0.00432125, acc 1
2016-09-05T18:26:16.790986: step 10698, loss 0.0043075, acc 1
2016-09-05T18:26:17.014814: step 10699, loss 0.00429019, acc 1
2016-09-05T18:26:17.257304: step 10700, loss 0.00431747, acc 1

Evaluation:
2016-09-05T18:26:17.855809: step 10700, loss 2.15809, acc 0.731

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-10700

2016-09-05T18:26:18.579882: step 10701, loss 0.00744687, acc 1
2016-09-05T18:26:18.782199: step 10702, loss 0.00441664, acc 1
2016-09-05T18:26:19.003690: step 10703, loss 0.0041948, acc 1
2016-09-05T18:26:19.220994: step 10704, loss 0.00419956, acc 1
2016-09-05T18:26:19.458696: step 10705, loss 0.00415673, acc 1
2016-09-05T18:26:19.675268: step 10706, loss 0.00416205, acc 1
2016-09-05T18:26:19.897709: step 10707, loss 0.00408706, acc 1
2016-09-05T18:26:20.097063: step 10708, loss 0.00407367, acc 1
2016-09-05T18:26:20.332910: step 10709, loss 0.00409731, acc 1
2016-09-05T18:26:20.549346: step 10710, loss 0.00399961, acc 1
2016-09-05T18:26:20.774949: step 10711, loss 0.00423939, acc 1
2016-09-05T18:26:20.989567: step 10712, loss 0.0039408, acc 1
2016-09-05T18:26:21.203221: step 10713, loss 0.00391943, acc 1
2016-09-05T18:26:21.423259: step 10714, loss 0.00387734, acc 1
2016-09-05T18:26:21.636289: step 10715, loss 0.0038582, acc 1
2016-09-05T18:26:21.847071: step 10716, loss 0.0039454, acc 1
2016-09-05T18:26:22.090483: step 10717, loss 0.00385857, acc 1
2016-09-05T18:26:22.316090: step 10718, loss 0.00428186, acc 1
2016-09-05T18:26:22.525615: step 10719, loss 0.00373808, acc 1
2016-09-05T18:26:22.751767: step 10720, loss 0.00382347, acc 1
2016-09-05T18:26:22.963631: step 10721, loss 0.00369866, acc 1
2016-09-05T18:26:23.204853: step 10722, loss 0.0036435, acc 1
2016-09-05T18:26:23.424005: step 10723, loss 0.00386007, acc 1
2016-09-05T18:26:23.632976: step 10724, loss 0.0035962, acc 1
2016-09-05T18:26:23.871381: step 10725, loss 0.00366789, acc 1
2016-09-05T18:26:24.116084: step 10726, loss 0.00350911, acc 1
2016-09-05T18:26:24.313656: step 10727, loss 0.00376217, acc 1
2016-09-05T18:26:24.529138: step 10728, loss 0.00587564, acc 1
2016-09-05T18:26:24.761505: step 10729, loss 0.00349842, acc 1
2016-09-05T18:26:24.999095: step 10730, loss 0.00351506, acc 1
2016-09-05T18:26:25.229466: step 10731, loss 0.0033972, acc 1
2016-09-05T18:26:25.441014: step 10732, loss 0.00341912, acc 1
2016-09-05T18:26:25.649626: step 10733, loss 0.0035031, acc 1
2016-09-05T18:26:25.871934: step 10734, loss 0.0033077, acc 1
2016-09-05T18:26:26.076474: step 10735, loss 0.00330026, acc 1
2016-09-05T18:26:26.276029: step 10736, loss 0.00325484, acc 1
2016-09-05T18:26:26.472893: step 10737, loss 0.00359049, acc 1
2016-09-05T18:26:26.698547: step 10738, loss 0.00330702, acc 1
2016-09-05T18:26:26.927524: step 10739, loss 0.00316989, acc 1
2016-09-05T18:26:27.169148: step 10740, loss 0.00319912, acc 1
2016-09-05T18:26:27.370479: step 10741, loss 0.00354513, acc 1
2016-09-05T18:26:27.584864: step 10742, loss 0.00318405, acc 1
2016-09-05T18:26:27.792125: step 10743, loss 0.00308326, acc 1
2016-09-05T18:26:28.006832: step 10744, loss 0.00313047, acc 1
2016-09-05T18:26:28.236815: step 10745, loss 0.00313104, acc 1
2016-09-05T18:26:28.478528: step 10746, loss 0.00312006, acc 1
2016-09-05T18:26:28.685347: step 10747, loss 0.00305339, acc 1
2016-09-05T18:26:28.896178: step 10748, loss 0.00348037, acc 1
2016-09-05T18:26:29.131067: step 10749, loss 0.00291303, acc 1
2016-09-05T18:26:29.331221: step 10750, loss 0.00293127, acc 1
2016-09-05T18:26:29.569764: step 10751, loss 0.00291414, acc 1
2016-09-05T18:26:29.787011: step 10752, loss 0.0029855, acc 1
2016-09-05T18:26:29.991713: step 10753, loss 0.00300053, acc 1
2016-09-05T18:26:30.191351: step 10754, loss 0.00312244, acc 1
2016-09-05T18:26:30.391826: step 10755, loss 0.00283468, acc 1
2016-09-05T18:26:30.602962: step 10756, loss 0.00325898, acc 1
2016-09-05T18:26:30.814864: step 10757, loss 0.00301584, acc 1
2016-09-05T18:26:31.018983: step 10758, loss 0.00314102, acc 1
2016-09-05T18:26:31.248691: step 10759, loss 0.00280426, acc 1
2016-09-05T18:26:31.457125: step 10760, loss 0.00275573, acc 1
2016-09-05T18:26:31.681423: step 10761, loss 0.00274455, acc 1
2016-09-05T18:26:31.896925: step 10762, loss 0.00278047, acc 1
2016-09-05T18:26:32.126723: step 10763, loss 0.00284873, acc 1
2016-09-05T18:26:32.373425: step 10764, loss 0.00278992, acc 1
2016-09-05T18:26:32.604571: step 10765, loss 0.0036016, acc 1
2016-09-05T18:26:32.810900: step 10766, loss 0.00268035, acc 1
2016-09-05T18:26:33.019756: step 10767, loss 0.00254976, acc 1
2016-09-05T18:26:33.217150: step 10768, loss 0.00300912, acc 1
2016-09-05T18:26:33.414982: step 10769, loss 0.00286509, acc 1
2016-09-05T18:26:33.629293: step 10770, loss 0.00282477, acc 1
2016-09-05T18:26:33.843744: step 10771, loss 0.0025452, acc 1
2016-09-05T18:26:34.053983: step 10772, loss 0.00264544, acc 1
2016-09-05T18:26:34.264009: step 10773, loss 0.00262593, acc 1
2016-09-05T18:26:34.486744: step 10774, loss 0.00246973, acc 1
2016-09-05T18:26:34.710852: step 10775, loss 0.00254201, acc 1
2016-09-05T18:26:34.930681: step 10776, loss 0.00253747, acc 1
2016-09-05T18:26:35.161893: step 10777, loss 0.00250806, acc 1
2016-09-05T18:26:35.375863: step 10778, loss 0.00241336, acc 1
2016-09-05T18:26:35.609386: step 10779, loss 0.0040204, acc 1
2016-09-05T18:26:35.811253: step 10780, loss 0.00251732, acc 1
2016-09-05T18:26:36.029929: step 10781, loss 0.0028404, acc 1
2016-09-05T18:26:36.239229: step 10782, loss 0.00275857, acc 1
2016-09-05T18:26:36.461534: step 10783, loss 0.00239279, acc 1
2016-09-05T18:26:36.670158: step 10784, loss 0.00533212, acc 1
2016-09-05T18:26:36.902483: step 10785, loss 0.00267134, acc 1
2016-09-05T18:26:37.143844: step 10786, loss 0.00243563, acc 1
2016-09-05T18:26:37.367305: step 10787, loss 0.00288402, acc 1
2016-09-05T18:26:37.605342: step 10788, loss 0.00279092, acc 1
2016-09-05T18:26:37.819497: step 10789, loss 0.00229745, acc 1
2016-09-05T18:26:38.057296: step 10790, loss 0.0034477, acc 1
2016-09-05T18:26:38.261563: step 10791, loss 0.0026568, acc 1
2016-09-05T18:26:38.491361: step 10792, loss 0.00229335, acc 1
2016-09-05T18:26:38.701864: step 10793, loss 0.00222377, acc 1
2016-09-05T18:26:38.910944: step 10794, loss 0.00223915, acc 1
2016-09-05T18:26:39.140315: step 10795, loss 0.00246881, acc 1
2016-09-05T18:26:39.360794: step 10796, loss 0.00224244, acc 1
2016-09-05T18:26:39.567972: step 10797, loss 0.0023836, acc 1
2016-09-05T18:26:39.780978: step 10798, loss 0.00239529, acc 1
2016-09-05T18:26:39.985300: step 10799, loss 0.00222888, acc 1
2016-09-05T18:26:40.205413: step 10800, loss 0.00235566, acc 1

Evaluation:
2016-09-05T18:26:40.833841: step 10800, loss 1.66481, acc 0.728

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-10800

2016-09-05T18:26:41.610735: step 10801, loss 0.00248045, acc 1
2016-09-05T18:26:41.852604: step 10802, loss 0.00327177, acc 1
2016-09-05T18:26:42.110742: step 10803, loss 0.00304466, acc 1
2016-09-05T18:26:42.331347: step 10804, loss 0.00406051, acc 1
2016-09-05T18:26:42.538868: step 10805, loss 0.00272343, acc 1
2016-09-05T18:26:42.743975: step 10806, loss 0.00236046, acc 1
2016-09-05T18:26:42.948726: step 10807, loss 0.00208223, acc 1
2016-09-05T18:26:43.171476: step 10808, loss 0.00285394, acc 1
2016-09-05T18:26:43.385206: step 10809, loss 0.00252082, acc 1
2016-09-05T18:26:43.601740: step 10810, loss 0.00248026, acc 1
2016-09-05T18:26:43.809039: step 10811, loss 0.00215084, acc 1
2016-09-05T18:26:44.019505: step 10812, loss 0.00217669, acc 1
2016-09-05T18:26:44.223661: step 10813, loss 0.00207472, acc 1
2016-09-05T18:26:44.425999: step 10814, loss 0.00253354, acc 1
2016-09-05T18:26:44.640787: step 10815, loss 0.00643581, acc 1
2016-09-05T18:26:44.842173: step 10816, loss 0.00241244, acc 1
2016-09-05T18:26:45.051610: step 10817, loss 0.00292085, acc 1
2016-09-05T18:26:45.248029: step 10818, loss 0.00215563, acc 1
2016-09-05T18:26:45.475209: step 10819, loss 0.00206276, acc 1
2016-09-05T18:26:45.697639: step 10820, loss 0.00208758, acc 1
2016-09-05T18:26:45.937558: step 10821, loss 0.00283019, acc 1
2016-09-05T18:26:46.139643: step 10822, loss 0.0045911, acc 1
2016-09-05T18:26:46.348064: step 10823, loss 0.00599577, acc 1
2016-09-05T18:26:46.550795: step 10824, loss 0.00199203, acc 1
2016-09-05T18:26:46.785935: step 10825, loss 0.00355313, acc 1
2016-09-05T18:26:47.012559: step 10826, loss 0.00278455, acc 1
2016-09-05T18:26:47.217957: step 10827, loss 0.00212084, acc 1
2016-09-05T18:26:47.461768: step 10828, loss 0.00352036, acc 1
2016-09-05T18:26:47.670510: step 10829, loss 0.00217259, acc 1
2016-09-05T18:26:47.905148: step 10830, loss 0.00219689, acc 1
2016-09-05T18:26:48.131269: step 10831, loss 0.00271985, acc 1
2016-09-05T18:26:48.352417: step 10832, loss 0.00248191, acc 1
2016-09-05T18:26:48.560814: step 10833, loss 0.00202505, acc 1
2016-09-05T18:26:48.771174: step 10834, loss 0.00273859, acc 1
2016-09-05T18:26:48.991368: step 10835, loss 0.00195914, acc 1
2016-09-05T18:26:49.215287: step 10836, loss 0.00217981, acc 1
2016-09-05T18:26:49.429735: step 10837, loss 0.00234137, acc 1
2016-09-05T18:26:49.656991: step 10838, loss 0.00555804, acc 1
2016-09-05T18:26:49.875502: step 10839, loss 0.00213947, acc 1
2016-09-05T18:26:50.109291: step 10840, loss 0.00211394, acc 1
2016-09-05T18:26:50.353385: step 10841, loss 0.00273915, acc 1
2016-09-05T18:26:50.589624: step 10842, loss 0.00491439, acc 1
2016-09-05T18:26:50.821780: step 10843, loss 0.00261687, acc 1
2016-09-05T18:26:51.046694: step 10844, loss 0.00212698, acc 1
2016-09-05T18:26:51.288750: step 10845, loss 0.00287125, acc 1
2016-09-05T18:26:51.515095: step 10846, loss 0.00212166, acc 1
2016-09-05T18:26:51.730538: step 10847, loss 0.00199058, acc 1
2016-09-05T18:26:51.958142: step 10848, loss 0.00279229, acc 1
2016-09-05T18:26:52.174462: step 10849, loss 0.0024107, acc 1
2016-09-05T18:26:52.409284: step 10850, loss 0.00195035, acc 1
2016-09-05T18:26:52.619883: step 10851, loss 0.00203101, acc 1
2016-09-05T18:26:52.845305: step 10852, loss 0.00463577, acc 1
2016-09-05T18:26:53.083720: step 10853, loss 0.00186166, acc 1
2016-09-05T18:26:53.308338: step 10854, loss 0.00236283, acc 1
2016-09-05T18:26:53.518543: step 10855, loss 0.00220346, acc 1
2016-09-05T18:26:53.735470: step 10856, loss 0.00204047, acc 1
2016-09-05T18:26:53.964870: step 10857, loss 0.00214195, acc 1
2016-09-05T18:26:54.172853: step 10858, loss 0.00280013, acc 1
2016-09-05T18:26:54.408516: step 10859, loss 0.00220312, acc 1
2016-09-05T18:26:54.607917: step 10860, loss 0.00237689, acc 1
2016-09-05T18:26:54.816535: step 10861, loss 0.00208421, acc 1
2016-09-05T18:26:55.014406: step 10862, loss 0.00228733, acc 1
2016-09-05T18:26:55.221261: step 10863, loss 0.00200467, acc 1
2016-09-05T18:26:55.340369: step 10864, loss 0.00182647, acc 1
2016-09-05T18:26:55.583801: step 10865, loss 0.00185049, acc 1
2016-09-05T18:26:55.806464: step 10866, loss 0.00187477, acc 1
2016-09-05T18:26:56.009124: step 10867, loss 0.00221003, acc 1
2016-09-05T18:26:56.213652: step 10868, loss 0.00194227, acc 1
2016-09-05T18:26:56.426682: step 10869, loss 0.00186174, acc 1
2016-09-05T18:26:56.619260: step 10870, loss 0.00251057, acc 1
2016-09-05T18:26:56.832572: step 10871, loss 0.00200809, acc 1
2016-09-05T18:26:57.043090: step 10872, loss 0.00203879, acc 1
2016-09-05T18:26:57.254030: step 10873, loss 0.00722975, acc 1
2016-09-05T18:26:57.477387: step 10874, loss 0.00192772, acc 1
2016-09-05T18:26:57.694469: step 10875, loss 0.00207049, acc 1
2016-09-05T18:26:57.937473: step 10876, loss 0.00181105, acc 1
2016-09-05T18:26:58.138023: step 10877, loss 0.00187541, acc 1
2016-09-05T18:26:58.346672: step 10878, loss 0.00359694, acc 1
2016-09-05T18:26:58.556879: step 10879, loss 0.00196113, acc 1
2016-09-05T18:26:58.767877: step 10880, loss 0.00226993, acc 1
2016-09-05T18:26:58.979866: step 10881, loss 0.00297397, acc 1
2016-09-05T18:26:59.193212: step 10882, loss 0.00417672, acc 1
2016-09-05T18:26:59.410540: step 10883, loss 0.00245217, acc 1
2016-09-05T18:26:59.666367: step 10884, loss 0.00259983, acc 1
2016-09-05T18:26:59.910686: step 10885, loss 0.0023741, acc 1
2016-09-05T18:27:00.116258: step 10886, loss 0.00222888, acc 1
2016-09-05T18:27:00.354821: step 10887, loss 0.00209036, acc 1
2016-09-05T18:27:00.555274: step 10888, loss 0.00202121, acc 1
2016-09-05T18:27:00.758718: step 10889, loss 0.00257646, acc 1
2016-09-05T18:27:00.970225: step 10890, loss 0.00472115, acc 1
2016-09-05T18:27:01.195403: step 10891, loss 0.0019931, acc 1
2016-09-05T18:27:01.427782: step 10892, loss 0.00270263, acc 1
2016-09-05T18:27:01.677401: step 10893, loss 0.00214168, acc 1
2016-09-05T18:27:01.881346: step 10894, loss 0.00196144, acc 1
2016-09-05T18:27:02.081776: step 10895, loss 0.00523244, acc 1
2016-09-05T18:27:02.313437: step 10896, loss 0.00216726, acc 1
2016-09-05T18:27:02.532212: step 10897, loss 0.0021939, acc 1
2016-09-05T18:27:02.749939: step 10898, loss 0.00206471, acc 1
2016-09-05T18:27:02.949027: step 10899, loss 0.00223534, acc 1
2016-09-05T18:27:03.161390: step 10900, loss 0.00215381, acc 1

Evaluation:
2016-09-05T18:27:03.764302: step 10900, loss 1.76461, acc 0.726

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-10900

2016-09-05T18:27:04.461228: step 10901, loss 0.00204109, acc 1
2016-09-05T18:27:04.689401: step 10902, loss 0.00227199, acc 1
2016-09-05T18:27:04.930957: step 10903, loss 0.0020718, acc 1
2016-09-05T18:27:05.177995: step 10904, loss 0.00204209, acc 1
2016-09-05T18:27:05.385043: step 10905, loss 0.00202294, acc 1
2016-09-05T18:27:05.606527: step 10906, loss 0.00241816, acc 1
2016-09-05T18:27:05.798288: step 10907, loss 0.00230144, acc 1
2016-09-05T18:27:06.030069: step 10908, loss 0.0021458, acc 1
2016-09-05T18:27:06.236079: step 10909, loss 0.0070456, acc 1
2016-09-05T18:27:06.461580: step 10910, loss 0.00253716, acc 1
2016-09-05T18:27:06.680099: step 10911, loss 0.00268593, acc 1
2016-09-05T18:27:06.929441: step 10912, loss 0.00208541, acc 1
2016-09-05T18:27:07.136964: step 10913, loss 0.00330985, acc 1
2016-09-05T18:27:07.351860: step 10914, loss 0.00264583, acc 1
2016-09-05T18:27:07.560225: step 10915, loss 0.00203119, acc 1
2016-09-05T18:27:07.786466: step 10916, loss 0.00194075, acc 1
2016-09-05T18:27:08.010359: step 10917, loss 0.00198403, acc 1
2016-09-05T18:27:08.247458: step 10918, loss 0.00204958, acc 1
2016-09-05T18:27:08.457096: step 10919, loss 0.00203507, acc 1
2016-09-05T18:27:08.708073: step 10920, loss 0.00214535, acc 1
2016-09-05T18:27:08.931341: step 10921, loss 0.00201502, acc 1
2016-09-05T18:27:09.149287: step 10922, loss 0.00211094, acc 1
2016-09-05T18:27:09.365840: step 10923, loss 0.00465889, acc 1
2016-09-05T18:27:09.580404: step 10924, loss 0.00197817, acc 1
2016-09-05T18:27:09.802078: step 10925, loss 0.00196978, acc 1
2016-09-05T18:27:10.002350: step 10926, loss 0.00215994, acc 1
2016-09-05T18:27:10.229117: step 10927, loss 0.0020075, acc 1
2016-09-05T18:27:10.445408: step 10928, loss 0.00193973, acc 1
2016-09-05T18:27:10.675504: step 10929, loss 0.00226109, acc 1
2016-09-05T18:27:10.885972: step 10930, loss 0.00203313, acc 1
2016-09-05T18:27:11.121082: step 10931, loss 0.0021917, acc 1
2016-09-05T18:27:11.343712: step 10932, loss 0.00232049, acc 1
2016-09-05T18:27:11.545697: step 10933, loss 0.00211566, acc 1
2016-09-05T18:27:11.767648: step 10934, loss 0.00212998, acc 1
2016-09-05T18:27:11.981541: step 10935, loss 0.00196787, acc 1
2016-09-05T18:27:12.206573: step 10936, loss 0.00193156, acc 1
2016-09-05T18:27:12.424372: step 10937, loss 0.00206815, acc 1
2016-09-05T18:27:12.648899: step 10938, loss 0.00209739, acc 1
2016-09-05T18:27:12.867760: step 10939, loss 0.00403901, acc 1
2016-09-05T18:27:13.116302: step 10940, loss 0.00235302, acc 1
2016-09-05T18:27:13.369272: step 10941, loss 0.00209812, acc 1
2016-09-05T18:27:13.590242: step 10942, loss 0.00197229, acc 1
2016-09-05T18:27:13.811615: step 10943, loss 0.00220328, acc 1
2016-09-05T18:27:14.023473: step 10944, loss 0.00187136, acc 1
2016-09-05T18:27:14.233379: step 10945, loss 0.00202557, acc 1
2016-09-05T18:27:14.444655: step 10946, loss 0.00207393, acc 1
2016-09-05T18:27:14.655938: step 10947, loss 0.00191748, acc 1
2016-09-05T18:27:14.873448: step 10948, loss 0.00189658, acc 1
2016-09-05T18:27:15.108696: step 10949, loss 0.00283564, acc 1
2016-09-05T18:27:15.313061: step 10950, loss 0.00233661, acc 1
2016-09-05T18:27:15.523865: step 10951, loss 0.00218974, acc 1
2016-09-05T18:27:15.740078: step 10952, loss 0.0018963, acc 1
2016-09-05T18:27:15.970654: step 10953, loss 0.00187464, acc 1
2016-09-05T18:27:16.178601: step 10954, loss 0.00429639, acc 1
2016-09-05T18:27:16.376130: step 10955, loss 0.00364215, acc 1
2016-09-05T18:27:16.600663: step 10956, loss 0.00185567, acc 1
2016-09-05T18:27:16.813565: step 10957, loss 0.00224031, acc 1
2016-09-05T18:27:17.040750: step 10958, loss 0.00191706, acc 1
2016-09-05T18:27:17.244689: step 10959, loss 0.0018314, acc 1
2016-09-05T18:27:17.468786: step 10960, loss 0.00185992, acc 1
2016-09-05T18:27:17.683949: step 10961, loss 0.00180815, acc 1
2016-09-05T18:27:17.917409: step 10962, loss 0.00180677, acc 1
2016-09-05T18:27:18.131697: step 10963, loss 0.00183753, acc 1
2016-09-05T18:27:18.358792: step 10964, loss 0.0021666, acc 1
2016-09-05T18:27:18.581703: step 10965, loss 0.00191669, acc 1
2016-09-05T18:27:18.793925: step 10966, loss 0.00212737, acc 1
2016-09-05T18:27:19.008868: step 10967, loss 0.0018939, acc 1
2016-09-05T18:27:19.258870: step 10968, loss 0.00219216, acc 1
2016-09-05T18:27:19.478191: step 10969, loss 0.001936, acc 1
2016-09-05T18:27:19.691868: step 10970, loss 0.00199095, acc 1
2016-09-05T18:27:19.922530: step 10971, loss 0.00175186, acc 1
2016-09-05T18:27:20.140875: step 10972, loss 0.00254398, acc 1
2016-09-05T18:27:20.349460: step 10973, loss 0.00193365, acc 1
2016-09-05T18:27:20.566636: step 10974, loss 0.00204062, acc 1
2016-09-05T18:27:20.789285: step 10975, loss 0.00232371, acc 1
2016-09-05T18:27:21.008583: step 10976, loss 0.0019818, acc 1
2016-09-05T18:27:21.226054: step 10977, loss 0.00185065, acc 1
2016-09-05T18:27:21.430202: step 10978, loss 0.00193526, acc 1
2016-09-05T18:27:21.659299: step 10979, loss 0.00167049, acc 1
2016-09-05T18:27:21.888597: step 10980, loss 0.00169024, acc 1
2016-09-05T18:27:22.096225: step 10981, loss 0.00268748, acc 1
2016-09-05T18:27:22.318509: step 10982, loss 0.00173523, acc 1
2016-09-05T18:27:22.526812: step 10983, loss 0.00174145, acc 1
2016-09-05T18:27:22.757559: step 10984, loss 0.00187478, acc 1
2016-09-05T18:27:22.988132: step 10985, loss 0.00189903, acc 1
2016-09-05T18:27:23.217164: step 10986, loss 0.0018806, acc 1
2016-09-05T18:27:23.443021: step 10987, loss 0.00205711, acc 1
2016-09-05T18:27:23.693955: step 10988, loss 0.00193098, acc 1
2016-09-05T18:27:23.902731: step 10989, loss 0.00184161, acc 1
2016-09-05T18:27:24.105783: step 10990, loss 0.00180594, acc 1
2016-09-05T18:27:24.323358: step 10991, loss 0.00169949, acc 1
2016-09-05T18:27:24.528872: step 10992, loss 0.00160727, acc 1
2016-09-05T18:27:24.747126: step 10993, loss 0.00174403, acc 1
2016-09-05T18:27:24.961150: step 10994, loss 0.00193763, acc 1
2016-09-05T18:27:25.208211: step 10995, loss 0.00230146, acc 1
2016-09-05T18:27:25.414028: step 10996, loss 0.00177184, acc 1
2016-09-05T18:27:25.627412: step 10997, loss 0.00165356, acc 1
2016-09-05T18:27:25.840483: step 10998, loss 0.00156878, acc 1
2016-09-05T18:27:26.077711: step 10999, loss 0.00177026, acc 1
2016-09-05T18:27:26.314490: step 11000, loss 0.00175081, acc 1

Evaluation:
2016-09-05T18:27:26.943750: step 11000, loss 1.53913, acc 0.727

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-11000

2016-09-05T18:27:27.686497: step 11001, loss 0.00344565, acc 1
2016-09-05T18:27:27.901957: step 11002, loss 0.00185519, acc 1
2016-09-05T18:27:28.125922: step 11003, loss 0.00166124, acc 1
2016-09-05T18:27:28.346549: step 11004, loss 0.00190609, acc 1
2016-09-05T18:27:28.544111: step 11005, loss 0.00170867, acc 1
2016-09-05T18:27:28.756276: step 11006, loss 0.00177001, acc 1
2016-09-05T18:27:28.968380: step 11007, loss 0.00171504, acc 1
2016-09-05T18:27:29.183399: step 11008, loss 0.00203057, acc 1
2016-09-05T18:27:29.384400: step 11009, loss 0.00217103, acc 1
2016-09-05T18:27:29.597690: step 11010, loss 0.00173267, acc 1
2016-09-05T18:27:29.802643: step 11011, loss 0.00204014, acc 1
2016-09-05T18:27:30.022238: step 11012, loss 0.00180621, acc 1
2016-09-05T18:27:30.261239: step 11013, loss 0.00195135, acc 1
2016-09-05T18:27:30.485596: step 11014, loss 0.00155225, acc 1
2016-09-05T18:27:30.686079: step 11015, loss 0.00204605, acc 1
2016-09-05T18:27:30.908773: step 11016, loss 0.00156179, acc 1
2016-09-05T18:27:31.117371: step 11017, loss 0.0017811, acc 1
2016-09-05T18:27:31.335388: step 11018, loss 0.00180195, acc 1
2016-09-05T18:27:31.568033: step 11019, loss 0.00159582, acc 1
2016-09-05T18:27:31.768644: step 11020, loss 0.00167028, acc 1
2016-09-05T18:27:31.974514: step 11021, loss 0.00240856, acc 1
2016-09-05T18:27:32.162401: step 11022, loss 0.00157968, acc 1
2016-09-05T18:27:32.379244: step 11023, loss 0.00159509, acc 1
2016-09-05T18:27:32.580398: step 11024, loss 0.00215659, acc 1
2016-09-05T18:27:32.790861: step 11025, loss 0.00178751, acc 1
2016-09-05T18:27:32.994106: step 11026, loss 0.00232193, acc 1
2016-09-05T18:27:33.213689: step 11027, loss 0.00162896, acc 1
2016-09-05T18:27:33.434398: step 11028, loss 0.00167594, acc 1
2016-09-05T18:27:33.669630: step 11029, loss 0.00253689, acc 1
2016-09-05T18:27:33.897162: step 11030, loss 0.00174692, acc 1
2016-09-05T18:27:34.117471: step 11031, loss 0.00213313, acc 1
2016-09-05T18:27:34.339439: step 11032, loss 0.00179162, acc 1
2016-09-05T18:27:34.568201: step 11033, loss 0.00303172, acc 1
2016-09-05T18:27:34.798327: step 11034, loss 0.00187319, acc 1
2016-09-05T18:27:35.000185: step 11035, loss 0.00193603, acc 1
2016-09-05T18:27:35.200757: step 11036, loss 0.00174084, acc 1
2016-09-05T18:27:35.404820: step 11037, loss 0.00162028, acc 1
2016-09-05T18:27:35.617286: step 11038, loss 0.00171255, acc 1
2016-09-05T18:27:35.825871: step 11039, loss 0.00161455, acc 1
2016-09-05T18:27:36.048125: step 11040, loss 0.0023416, acc 1
2016-09-05T18:27:36.252691: step 11041, loss 0.0016588, acc 1
2016-09-05T18:27:36.488406: step 11042, loss 0.00175592, acc 1
2016-09-05T18:27:36.712177: step 11043, loss 0.00170851, acc 1
2016-09-05T18:27:36.949465: step 11044, loss 0.00157434, acc 1
2016-09-05T18:27:37.170316: step 11045, loss 0.00163278, acc 1
2016-09-05T18:27:37.390357: step 11046, loss 0.0019903, acc 1
2016-09-05T18:27:37.634592: step 11047, loss 0.0016925, acc 1
2016-09-05T18:27:37.838878: step 11048, loss 0.00187807, acc 1
2016-09-05T18:27:38.066715: step 11049, loss 0.00165426, acc 1
2016-09-05T18:27:38.281802: step 11050, loss 0.00157475, acc 1
2016-09-05T18:27:38.514300: step 11051, loss 0.00178633, acc 1
2016-09-05T18:27:38.747346: step 11052, loss 0.00165478, acc 1
2016-09-05T18:27:38.963354: step 11053, loss 0.00172752, acc 1
2016-09-05T18:27:39.181111: step 11054, loss 0.00152535, acc 1
2016-09-05T18:27:39.415508: step 11055, loss 0.00145367, acc 1
2016-09-05T18:27:39.642460: step 11056, loss 0.00157726, acc 1
2016-09-05T18:27:39.852240: step 11057, loss 0.00322523, acc 1
2016-09-05T18:27:39.985519: step 11058, loss 0.0013885, acc 1
2016-09-05T18:27:40.235851: step 11059, loss 0.00199661, acc 1
2016-09-05T18:27:40.471743: step 11060, loss 0.00218273, acc 1
2016-09-05T18:27:40.675255: step 11061, loss 0.00170937, acc 1
2016-09-05T18:27:40.884153: step 11062, loss 0.00185459, acc 1
2016-09-05T18:27:41.091251: step 11063, loss 0.00145634, acc 1
2016-09-05T18:27:41.315751: step 11064, loss 0.00137223, acc 1
2016-09-05T18:27:41.537255: step 11065, loss 0.00158431, acc 1
2016-09-05T18:27:41.772894: step 11066, loss 0.00153773, acc 1
2016-09-05T18:27:41.964254: step 11067, loss 0.00182787, acc 1
2016-09-05T18:27:42.157400: step 11068, loss 0.00153284, acc 1
2016-09-05T18:27:42.379571: step 11069, loss 0.00205552, acc 1
2016-09-05T18:27:42.601847: step 11070, loss 0.00170726, acc 1
2016-09-05T18:27:42.806352: step 11071, loss 0.00144039, acc 1
2016-09-05T18:27:43.052829: step 11072, loss 0.00156343, acc 1
2016-09-05T18:27:43.277311: step 11073, loss 0.00165237, acc 1
2016-09-05T18:27:43.505397: step 11074, loss 0.00167081, acc 1
2016-09-05T18:27:43.737495: step 11075, loss 0.00214434, acc 1
2016-09-05T18:27:43.946400: step 11076, loss 0.0015921, acc 1
2016-09-05T18:27:44.187781: step 11077, loss 0.00136096, acc 1
2016-09-05T18:27:44.400215: step 11078, loss 0.00139761, acc 1
2016-09-05T18:27:44.607736: step 11079, loss 0.00147621, acc 1
2016-09-05T18:27:44.809197: step 11080, loss 0.0014892, acc 1
2016-09-05T18:27:45.030795: step 11081, loss 0.00133884, acc 1
2016-09-05T18:27:45.249234: step 11082, loss 0.00142235, acc 1
2016-09-05T18:27:45.485379: step 11083, loss 0.00174535, acc 1
2016-09-05T18:27:45.704078: step 11084, loss 0.0014745, acc 1
2016-09-05T18:27:45.910831: step 11085, loss 0.00251985, acc 1
2016-09-05T18:27:46.132090: step 11086, loss 0.00160773, acc 1
2016-09-05T18:27:46.349722: step 11087, loss 0.00157538, acc 1
2016-09-05T18:27:46.561890: step 11088, loss 0.00146068, acc 1
2016-09-05T18:27:46.750219: step 11089, loss 0.00437084, acc 1
2016-09-05T18:27:46.952368: step 11090, loss 0.00139921, acc 1
2016-09-05T18:27:47.155847: step 11091, loss 0.00167357, acc 1
2016-09-05T18:27:47.371696: step 11092, loss 0.00133537, acc 1
2016-09-05T18:27:47.604862: step 11093, loss 0.00154665, acc 1
2016-09-05T18:27:47.834886: step 11094, loss 0.00160363, acc 1
2016-09-05T18:27:48.059471: step 11095, loss 0.00241779, acc 1
2016-09-05T18:27:48.290706: step 11096, loss 0.00216303, acc 1
2016-09-05T18:27:48.522653: step 11097, loss 0.0017465, acc 1
2016-09-05T18:27:48.727672: step 11098, loss 0.0014077, acc 1
2016-09-05T18:27:48.944358: step 11099, loss 0.00131635, acc 1
2016-09-05T18:27:49.159160: step 11100, loss 0.00136479, acc 1

Evaluation:
2016-09-05T18:27:49.786038: step 11100, loss 1.47456, acc 0.725

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-11100

2016-09-05T18:27:50.499939: step 11101, loss 0.00161877, acc 1
2016-09-05T18:27:50.720518: step 11102, loss 0.00141985, acc 1
2016-09-05T18:27:50.921098: step 11103, loss 0.00214587, acc 1
2016-09-05T18:27:51.147962: step 11104, loss 0.00145407, acc 1
2016-09-05T18:27:51.342694: step 11105, loss 0.00142328, acc 1
2016-09-05T18:27:51.558854: step 11106, loss 0.00159027, acc 1
2016-09-05T18:27:51.761560: step 11107, loss 0.00140583, acc 1
2016-09-05T18:27:51.958980: step 11108, loss 0.00147375, acc 1
2016-09-05T18:27:52.162995: step 11109, loss 0.00140742, acc 1
2016-09-05T18:27:52.383630: step 11110, loss 0.00160199, acc 1
2016-09-05T18:27:52.605240: step 11111, loss 0.00138986, acc 1
2016-09-05T18:27:52.811602: step 11112, loss 0.00134153, acc 1
2016-09-05T18:27:53.037263: step 11113, loss 0.00177918, acc 1
2016-09-05T18:27:53.270921: step 11114, loss 0.00171528, acc 1
2016-09-05T18:27:53.498502: step 11115, loss 0.00129006, acc 1
2016-09-05T18:27:53.734845: step 11116, loss 0.0014475, acc 1
2016-09-05T18:27:53.957400: step 11117, loss 0.00131316, acc 1
2016-09-05T18:27:54.175085: step 11118, loss 0.00156902, acc 1
2016-09-05T18:27:54.385248: step 11119, loss 0.00167125, acc 1
2016-09-05T18:27:54.599704: step 11120, loss 0.00131729, acc 1
2016-09-05T18:27:54.813044: step 11121, loss 0.00136487, acc 1
2016-09-05T18:27:55.031695: step 11122, loss 0.0014513, acc 1
2016-09-05T18:27:55.243341: step 11123, loss 0.00150711, acc 1
2016-09-05T18:27:55.495493: step 11124, loss 0.00181184, acc 1
2016-09-05T18:27:55.688601: step 11125, loss 0.00212771, acc 1
2016-09-05T18:27:55.898860: step 11126, loss 0.00232441, acc 1
2016-09-05T18:27:56.115668: step 11127, loss 0.00152329, acc 1
2016-09-05T18:27:56.338731: step 11128, loss 0.00141801, acc 1
2016-09-05T18:27:56.555941: step 11129, loss 0.00140884, acc 1
2016-09-05T18:27:56.792197: step 11130, loss 0.00192656, acc 1
2016-09-05T18:27:56.997339: step 11131, loss 0.00165393, acc 1
2016-09-05T18:27:57.217242: step 11132, loss 0.0012816, acc 1
2016-09-05T18:27:57.445043: step 11133, loss 0.00135487, acc 1
2016-09-05T18:27:57.663907: step 11134, loss 0.00163843, acc 1
2016-09-05T18:27:57.880255: step 11135, loss 0.00166957, acc 1
2016-09-05T18:27:58.128071: step 11136, loss 0.00145235, acc 1
2016-09-05T18:27:58.346153: step 11137, loss 0.00153398, acc 1
2016-09-05T18:27:58.548059: step 11138, loss 0.00174026, acc 1
2016-09-05T18:27:58.782531: step 11139, loss 0.00168506, acc 1
2016-09-05T18:27:59.010086: step 11140, loss 0.00189284, acc 1
2016-09-05T18:27:59.205390: step 11141, loss 0.00182691, acc 1
2016-09-05T18:27:59.419132: step 11142, loss 0.00173649, acc 1
2016-09-05T18:27:59.633163: step 11143, loss 0.00280382, acc 1
2016-09-05T18:27:59.855372: step 11144, loss 0.00143495, acc 1
2016-09-05T18:28:00.093639: step 11145, loss 0.00137858, acc 1
2016-09-05T18:28:00.314213: step 11146, loss 0.00175628, acc 1
2016-09-05T18:28:00.521145: step 11147, loss 0.00171876, acc 1
2016-09-05T18:28:00.727125: step 11148, loss 0.00158306, acc 1
2016-09-05T18:28:00.933606: step 11149, loss 0.00140289, acc 1
2016-09-05T18:28:01.151637: step 11150, loss 0.00141838, acc 1
2016-09-05T18:28:01.365571: step 11151, loss 0.00135597, acc 1
2016-09-05T18:28:01.575029: step 11152, loss 0.00137001, acc 1
2016-09-05T18:28:01.776953: step 11153, loss 0.00185257, acc 1
2016-09-05T18:28:02.002852: step 11154, loss 0.00150729, acc 1
2016-09-05T18:28:02.229232: step 11155, loss 0.00177961, acc 1
2016-09-05T18:28:02.443566: step 11156, loss 0.001731, acc 1
2016-09-05T18:28:02.643197: step 11157, loss 0.0014096, acc 1
2016-09-05T18:28:02.853405: step 11158, loss 0.00134803, acc 1
2016-09-05T18:28:03.059598: step 11159, loss 0.00151543, acc 1
2016-09-05T18:28:03.278620: step 11160, loss 0.00130422, acc 1
2016-09-05T18:28:03.489483: step 11161, loss 0.00140338, acc 1
2016-09-05T18:28:03.709310: step 11162, loss 0.00144293, acc 1
2016-09-05T18:28:03.947827: step 11163, loss 0.00140814, acc 1
2016-09-05T18:28:04.167128: step 11164, loss 0.00142293, acc 1
2016-09-05T18:28:04.380359: step 11165, loss 0.00159095, acc 1
2016-09-05T18:28:04.591594: step 11166, loss 0.0015455, acc 1
2016-09-05T18:28:04.825092: step 11167, loss 0.0012917, acc 1
2016-09-05T18:28:05.030098: step 11168, loss 0.00137298, acc 1
2016-09-05T18:28:05.231347: step 11169, loss 0.00186969, acc 1
2016-09-05T18:28:05.444143: step 11170, loss 0.00181427, acc 1
2016-09-05T18:28:05.671291: step 11171, loss 0.0017325, acc 1
2016-09-05T18:28:05.870827: step 11172, loss 0.00162684, acc 1
2016-09-05T18:28:06.081137: step 11173, loss 0.00177742, acc 1
2016-09-05T18:28:06.288759: step 11174, loss 0.00169131, acc 1
2016-09-05T18:28:06.500008: step 11175, loss 0.00134367, acc 1
2016-09-05T18:28:06.711799: step 11176, loss 0.00149317, acc 1
2016-09-05T18:28:06.946069: step 11177, loss 0.0013356, acc 1
2016-09-05T18:28:07.201446: step 11178, loss 0.00124092, acc 1
2016-09-05T18:28:07.404424: step 11179, loss 0.00153611, acc 1
2016-09-05T18:28:07.630885: step 11180, loss 0.00179917, acc 1
2016-09-05T18:28:07.847288: step 11181, loss 0.0012966, acc 1
2016-09-05T18:28:08.075549: step 11182, loss 0.0018802, acc 1
2016-09-05T18:28:08.278101: step 11183, loss 0.00143602, acc 1
2016-09-05T18:28:08.504257: step 11184, loss 0.00152409, acc 1
2016-09-05T18:28:08.714360: step 11185, loss 0.001459, acc 1
2016-09-05T18:28:08.921334: step 11186, loss 0.00185223, acc 1
2016-09-05T18:28:09.120417: step 11187, loss 0.00194558, acc 1
2016-09-05T18:28:09.334478: step 11188, loss 0.00149792, acc 1
2016-09-05T18:28:09.544385: step 11189, loss 0.00148623, acc 1
2016-09-05T18:28:09.774441: step 11190, loss 0.00190269, acc 1
2016-09-05T18:28:10.018096: step 11191, loss 0.0018415, acc 1
2016-09-05T18:28:10.220649: step 11192, loss 0.00214751, acc 1
2016-09-05T18:28:10.436163: step 11193, loss 0.00148671, acc 1
2016-09-05T18:28:10.636877: step 11194, loss 0.00191958, acc 1
2016-09-05T18:28:10.832008: step 11195, loss 0.00145527, acc 1
2016-09-05T18:28:11.037914: step 11196, loss 0.00132282, acc 1
2016-09-05T18:28:11.275162: step 11197, loss 0.00147615, acc 1
2016-09-05T18:28:11.500443: step 11198, loss 0.00138718, acc 1
2016-09-05T18:28:11.735842: step 11199, loss 0.00344253, acc 1
2016-09-05T18:28:11.951221: step 11200, loss 0.00143651, acc 1

Evaluation:
2016-09-05T18:28:12.586971: step 11200, loss 1.46105, acc 0.729

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-11200

2016-09-05T18:28:13.341535: step 11201, loss 0.00137689, acc 1
2016-09-05T18:28:13.535336: step 11202, loss 0.00138484, acc 1
2016-09-05T18:28:13.747236: step 11203, loss 0.00139651, acc 1
2016-09-05T18:28:13.964377: step 11204, loss 0.0016963, acc 1
2016-09-05T18:28:14.174456: step 11205, loss 0.0013009, acc 1
2016-09-05T18:28:14.377209: step 11206, loss 0.00166795, acc 1
2016-09-05T18:28:14.588680: step 11207, loss 0.00134438, acc 1
2016-09-05T18:28:14.798112: step 11208, loss 0.00126532, acc 1
2016-09-05T18:28:15.014517: step 11209, loss 0.00214943, acc 1
2016-09-05T18:28:15.239616: step 11210, loss 0.00136858, acc 1
2016-09-05T18:28:15.461932: step 11211, loss 0.00143373, acc 1
2016-09-05T18:28:15.657319: step 11212, loss 0.0034474, acc 1
2016-09-05T18:28:15.890502: step 11213, loss 0.0017385, acc 1
2016-09-05T18:28:16.105243: step 11214, loss 0.00143592, acc 1
2016-09-05T18:28:16.366076: step 11215, loss 0.00186194, acc 1
2016-09-05T18:28:16.580119: step 11216, loss 0.00130234, acc 1
2016-09-05T18:28:16.786453: step 11217, loss 0.00138396, acc 1
2016-09-05T18:28:17.025909: step 11218, loss 0.00148392, acc 1
2016-09-05T18:28:17.225027: step 11219, loss 0.00197673, acc 1
2016-09-05T18:28:17.453127: step 11220, loss 0.00133453, acc 1
2016-09-05T18:28:17.685253: step 11221, loss 0.00200139, acc 1
2016-09-05T18:28:17.917855: step 11222, loss 0.0015071, acc 1
2016-09-05T18:28:18.147901: step 11223, loss 0.00131563, acc 1
2016-09-05T18:28:18.360323: step 11224, loss 0.00199573, acc 1
2016-09-05T18:28:18.595000: step 11225, loss 0.00204129, acc 1
2016-09-05T18:28:18.794422: step 11226, loss 0.00134008, acc 1
2016-09-05T18:28:19.004246: step 11227, loss 0.00134946, acc 1
2016-09-05T18:28:19.208274: step 11228, loss 0.00140777, acc 1
2016-09-05T18:28:19.430262: step 11229, loss 0.00141377, acc 1
2016-09-05T18:28:19.643160: step 11230, loss 0.00148309, acc 1
2016-09-05T18:28:19.847438: step 11231, loss 0.00234221, acc 1
2016-09-05T18:28:20.060696: step 11232, loss 0.00152705, acc 1
2016-09-05T18:28:20.280427: step 11233, loss 0.00149379, acc 1
2016-09-05T18:28:20.510424: step 11234, loss 0.00129191, acc 1
2016-09-05T18:28:20.728553: step 11235, loss 0.00146254, acc 1
2016-09-05T18:28:20.947336: step 11236, loss 0.00227867, acc 1
2016-09-05T18:28:21.148023: step 11237, loss 0.00260011, acc 1
2016-09-05T18:28:21.365528: step 11238, loss 0.00152765, acc 1
2016-09-05T18:28:21.569338: step 11239, loss 0.00159887, acc 1
2016-09-05T18:28:21.796255: step 11240, loss 0.00214676, acc 1
2016-09-05T18:28:21.991329: step 11241, loss 0.00147459, acc 1
2016-09-05T18:28:22.213389: step 11242, loss 0.00211203, acc 1
2016-09-05T18:28:22.419333: step 11243, loss 0.00132893, acc 1
2016-09-05T18:28:22.625059: step 11244, loss 0.00147258, acc 1
2016-09-05T18:28:22.835810: step 11245, loss 0.00130081, acc 1
2016-09-05T18:28:23.049426: step 11246, loss 0.00224166, acc 1
2016-09-05T18:28:23.252708: step 11247, loss 0.00142705, acc 1
2016-09-05T18:28:23.466058: step 11248, loss 0.00204546, acc 1
2016-09-05T18:28:23.674048: step 11249, loss 0.00132514, acc 1
2016-09-05T18:28:23.890282: step 11250, loss 0.00156, acc 1
2016-09-05T18:28:24.110617: step 11251, loss 0.00128299, acc 1
2016-09-05T18:28:24.276145: step 11252, loss 0.00126009, acc 1
2016-09-05T18:28:24.482265: step 11253, loss 0.00134597, acc 1
2016-09-05T18:28:24.695363: step 11254, loss 0.00162404, acc 1
2016-09-05T18:28:24.891702: step 11255, loss 0.00177155, acc 1
2016-09-05T18:28:25.112391: step 11256, loss 0.001467, acc 1
2016-09-05T18:28:25.349327: step 11257, loss 0.00163518, acc 1
2016-09-05T18:28:25.574912: step 11258, loss 0.00138308, acc 1
2016-09-05T18:28:25.796159: step 11259, loss 0.00128756, acc 1
2016-09-05T18:28:25.999232: step 11260, loss 0.0015232, acc 1
2016-09-05T18:28:26.225767: step 11261, loss 0.00176363, acc 1
2016-09-05T18:28:26.445958: step 11262, loss 0.00135064, acc 1
2016-09-05T18:28:26.655383: step 11263, loss 0.00184015, acc 1
2016-09-05T18:28:26.849551: step 11264, loss 0.00144759, acc 1
2016-09-05T18:28:27.067572: step 11265, loss 0.00146004, acc 1
2016-09-05T18:28:27.275857: step 11266, loss 0.00127358, acc 1
2016-09-05T18:28:27.490163: step 11267, loss 0.00153077, acc 1
2016-09-05T18:28:27.705144: step 11268, loss 0.00182449, acc 1
2016-09-05T18:28:27.923088: step 11269, loss 0.00127124, acc 1
2016-09-05T18:28:28.133897: step 11270, loss 0.00132972, acc 1
2016-09-05T18:28:28.380612: step 11271, loss 0.00128362, acc 1
2016-09-05T18:28:28.604010: step 11272, loss 0.00125419, acc 1
2016-09-05T18:28:28.835177: step 11273, loss 0.0012111, acc 1
2016-09-05T18:28:29.052610: step 11274, loss 0.00154378, acc 1
2016-09-05T18:28:29.247408: step 11275, loss 0.00140199, acc 1
2016-09-05T18:28:29.468053: step 11276, loss 0.00127079, acc 1
2016-09-05T18:28:29.681419: step 11277, loss 0.00158506, acc 1
2016-09-05T18:28:29.910160: step 11278, loss 0.00120381, acc 1
2016-09-05T18:28:30.115463: step 11279, loss 0.00118113, acc 1
2016-09-05T18:28:30.319706: step 11280, loss 0.00122152, acc 1
2016-09-05T18:28:30.526696: step 11281, loss 0.00415238, acc 1
2016-09-05T18:28:30.745100: step 11282, loss 0.0022083, acc 1
2016-09-05T18:28:30.967236: step 11283, loss 0.00144867, acc 1
2016-09-05T18:28:31.218980: step 11284, loss 0.0013449, acc 1
2016-09-05T18:28:31.464438: step 11285, loss 0.00129418, acc 1
2016-09-05T18:28:31.717128: step 11286, loss 0.00148707, acc 1
2016-09-05T18:28:31.949459: step 11287, loss 0.00136542, acc 1
2016-09-05T18:28:32.180456: step 11288, loss 0.00162689, acc 1
2016-09-05T18:28:32.414711: step 11289, loss 0.00141266, acc 1
2016-09-05T18:28:32.614022: step 11290, loss 0.00162247, acc 1
2016-09-05T18:28:32.838142: step 11291, loss 0.00283318, acc 1
2016-09-05T18:28:33.060307: step 11292, loss 0.00143941, acc 1
2016-09-05T18:28:33.308409: step 11293, loss 0.00138836, acc 1
2016-09-05T18:28:33.547179: step 11294, loss 0.00176876, acc 1
2016-09-05T18:28:33.772833: step 11295, loss 0.0014292, acc 1
2016-09-05T18:28:33.992411: step 11296, loss 0.00131728, acc 1
2016-09-05T18:28:34.211953: step 11297, loss 0.00154611, acc 1
2016-09-05T18:28:34.418248: step 11298, loss 0.00160962, acc 1
2016-09-05T18:28:34.648901: step 11299, loss 0.00174796, acc 1
2016-09-05T18:28:34.867373: step 11300, loss 0.00154702, acc 1

Evaluation:
2016-09-05T18:28:35.461323: step 11300, loss 1.47887, acc 0.723

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-11300

2016-09-05T18:28:36.153416: step 11301, loss 0.00136456, acc 1
2016-09-05T18:28:36.407262: step 11302, loss 0.001638, acc 1
2016-09-05T18:28:36.624160: step 11303, loss 0.00131678, acc 1
2016-09-05T18:28:36.850897: step 11304, loss 0.00134219, acc 1
2016-09-05T18:28:37.085780: step 11305, loss 0.00160767, acc 1
2016-09-05T18:28:37.302263: step 11306, loss 0.00180665, acc 1
2016-09-05T18:28:37.523616: step 11307, loss 0.00124661, acc 1
2016-09-05T18:28:37.724638: step 11308, loss 0.00134067, acc 1
2016-09-05T18:28:37.940964: step 11309, loss 0.00167451, acc 1
2016-09-05T18:28:38.149308: step 11310, loss 0.00131313, acc 1
2016-09-05T18:28:38.385396: step 11311, loss 0.00140782, acc 1
2016-09-05T18:28:38.589382: step 11312, loss 0.00174029, acc 1
2016-09-05T18:28:38.803010: step 11313, loss 0.00148335, acc 1
2016-09-05T18:28:38.999681: step 11314, loss 0.00153671, acc 1
2016-09-05T18:28:39.212603: step 11315, loss 0.00164773, acc 1
2016-09-05T18:28:39.422058: step 11316, loss 0.00155591, acc 1
2016-09-05T18:28:39.648125: step 11317, loss 0.00140875, acc 1
2016-09-05T18:28:39.867869: step 11318, loss 0.00185576, acc 1
2016-09-05T18:28:40.105416: step 11319, loss 0.00140454, acc 1
2016-09-05T18:28:40.320588: step 11320, loss 0.00126229, acc 1
2016-09-05T18:28:40.529515: step 11321, loss 0.00123855, acc 1
2016-09-05T18:28:40.751519: step 11322, loss 0.00134841, acc 1
2016-09-05T18:28:40.962932: step 11323, loss 0.0015176, acc 1
2016-09-05T18:28:41.156687: step 11324, loss 0.0017571, acc 1
2016-09-05T18:28:41.377971: step 11325, loss 0.00220895, acc 1
2016-09-05T18:28:41.596638: step 11326, loss 0.00160694, acc 1
2016-09-05T18:28:41.831090: step 11327, loss 0.00130835, acc 1
2016-09-05T18:28:42.051076: step 11328, loss 0.0013283, acc 1
2016-09-05T18:28:42.246361: step 11329, loss 0.00141556, acc 1
2016-09-05T18:28:42.498172: step 11330, loss 0.00132446, acc 1
2016-09-05T18:28:42.710458: step 11331, loss 0.00133318, acc 1
2016-09-05T18:28:42.933370: step 11332, loss 0.00137678, acc 1
2016-09-05T18:28:43.133457: step 11333, loss 0.00125791, acc 1
2016-09-05T18:28:43.360584: step 11334, loss 0.00155223, acc 1
2016-09-05T18:28:43.577264: step 11335, loss 0.00136236, acc 1
2016-09-05T18:28:43.817012: step 11336, loss 0.0013687, acc 1
2016-09-05T18:28:44.043555: step 11337, loss 0.00177107, acc 1
2016-09-05T18:28:44.258149: step 11338, loss 0.00127368, acc 1
2016-09-05T18:28:44.475201: step 11339, loss 0.00165861, acc 1
2016-09-05T18:28:44.695067: step 11340, loss 0.00142648, acc 1
2016-09-05T18:28:44.912294: step 11341, loss 0.00139259, acc 1
2016-09-05T18:28:45.139554: step 11342, loss 0.00165253, acc 1
2016-09-05T18:28:45.348329: step 11343, loss 0.00234018, acc 1
2016-09-05T18:28:45.557961: step 11344, loss 0.00160856, acc 1
2016-09-05T18:28:45.790215: step 11345, loss 0.0021621, acc 1
2016-09-05T18:28:46.015917: step 11346, loss 0.001519, acc 1
2016-09-05T18:28:46.214199: step 11347, loss 0.00294679, acc 1
2016-09-05T18:28:46.422967: step 11348, loss 0.00138818, acc 1
2016-09-05T18:28:46.640274: step 11349, loss 0.00136081, acc 1
2016-09-05T18:28:46.880006: step 11350, loss 0.00155714, acc 1
2016-09-05T18:28:47.094548: step 11351, loss 0.00160854, acc 1
2016-09-05T18:28:47.326104: step 11352, loss 0.0013161, acc 1
2016-09-05T18:28:47.543550: step 11353, loss 0.00143132, acc 1
2016-09-05T18:28:47.791378: step 11354, loss 0.00166139, acc 1
2016-09-05T18:28:47.993489: step 11355, loss 0.00126518, acc 1
2016-09-05T18:28:48.223604: step 11356, loss 0.00225491, acc 1
2016-09-05T18:28:48.461961: step 11357, loss 0.00137474, acc 1
2016-09-05T18:28:48.688781: step 11358, loss 0.00143075, acc 1
2016-09-05T18:28:48.925839: step 11359, loss 0.00124397, acc 1
2016-09-05T18:28:49.179883: step 11360, loss 0.0020246, acc 1
2016-09-05T18:28:49.432831: step 11361, loss 0.00128337, acc 1
2016-09-05T18:28:49.639493: step 11362, loss 0.00149084, acc 1
2016-09-05T18:28:49.856653: step 11363, loss 0.00134211, acc 1
2016-09-05T18:28:50.096411: step 11364, loss 0.00158964, acc 1
2016-09-05T18:28:50.303903: step 11365, loss 0.0016257, acc 1
2016-09-05T18:28:50.515546: step 11366, loss 0.00130117, acc 1
2016-09-05T18:28:50.707295: step 11367, loss 0.00125719, acc 1
2016-09-05T18:28:50.918948: step 11368, loss 0.00132234, acc 1
2016-09-05T18:28:51.127480: step 11369, loss 0.00165143, acc 1
2016-09-05T18:28:51.397690: step 11370, loss 0.00139026, acc 1
2016-09-05T18:28:51.601481: step 11371, loss 0.00123163, acc 1
2016-09-05T18:28:51.834827: step 11372, loss 0.00126192, acc 1
2016-09-05T18:28:52.043678: step 11373, loss 0.00159795, acc 1
2016-09-05T18:28:52.269080: step 11374, loss 0.00127167, acc 1
2016-09-05T18:28:52.475799: step 11375, loss 0.0013192, acc 1
2016-09-05T18:28:52.685309: step 11376, loss 0.00162862, acc 1
2016-09-05T18:28:52.921446: step 11377, loss 0.00198778, acc 1
2016-09-05T18:28:53.148773: step 11378, loss 0.00141245, acc 1
2016-09-05T18:28:53.369683: step 11379, loss 0.00125788, acc 1
2016-09-05T18:28:53.574607: step 11380, loss 0.00121572, acc 1
2016-09-05T18:28:53.791901: step 11381, loss 0.00134043, acc 1
2016-09-05T18:28:54.031541: step 11382, loss 0.00122422, acc 1
2016-09-05T18:28:54.243960: step 11383, loss 0.00207651, acc 1
2016-09-05T18:28:54.456638: step 11384, loss 0.00122832, acc 1
2016-09-05T18:28:54.695459: step 11385, loss 0.0015226, acc 1
2016-09-05T18:28:54.945297: step 11386, loss 0.00123342, acc 1
2016-09-05T18:28:55.157721: step 11387, loss 0.00125769, acc 1
2016-09-05T18:28:55.380746: step 11388, loss 0.0015334, acc 1
2016-09-05T18:28:55.609797: step 11389, loss 0.00130983, acc 1
2016-09-05T18:28:55.848511: step 11390, loss 0.00146554, acc 1
2016-09-05T18:28:56.054187: step 11391, loss 0.00235771, acc 1
2016-09-05T18:28:56.260113: step 11392, loss 0.00117804, acc 1
2016-09-05T18:28:56.465002: step 11393, loss 0.00130648, acc 1
2016-09-05T18:28:56.682560: step 11394, loss 0.00129308, acc 1
2016-09-05T18:28:56.901449: step 11395, loss 0.00115867, acc 1
2016-09-05T18:28:57.133393: step 11396, loss 0.00127917, acc 1
2016-09-05T18:28:57.372797: step 11397, loss 0.00122445, acc 1
2016-09-05T18:28:57.573607: step 11398, loss 0.00124182, acc 1
2016-09-05T18:28:57.783017: step 11399, loss 0.00219329, acc 1
2016-09-05T18:28:57.983762: step 11400, loss 0.00141746, acc 1

Evaluation:
2016-09-05T18:28:58.586309: step 11400, loss 1.42261, acc 0.731

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-11400

2016-09-05T18:28:59.373481: step 11401, loss 0.00272032, acc 1
2016-09-05T18:28:59.601364: step 11402, loss 0.00179885, acc 1
2016-09-05T18:28:59.831566: step 11403, loss 0.00117374, acc 1
2016-09-05T18:29:00.039317: step 11404, loss 0.00132446, acc 1
2016-09-05T18:29:00.277642: step 11405, loss 0.0013132, acc 1
2016-09-05T18:29:00.480306: step 11406, loss 0.00119685, acc 1
2016-09-05T18:29:00.706740: step 11407, loss 0.00321791, acc 1
2016-09-05T18:29:00.919837: step 11408, loss 0.00183275, acc 1
2016-09-05T18:29:01.128152: step 11409, loss 0.00120676, acc 1
2016-09-05T18:29:01.333244: step 11410, loss 0.00131423, acc 1
2016-09-05T18:29:01.563393: step 11411, loss 0.00143446, acc 1
2016-09-05T18:29:01.776727: step 11412, loss 0.00152056, acc 1
2016-09-05T18:29:01.973336: step 11413, loss 0.00128875, acc 1
2016-09-05T18:29:02.180700: step 11414, loss 0.00126385, acc 1
2016-09-05T18:29:02.379451: step 11415, loss 0.00124212, acc 1
2016-09-05T18:29:02.623559: step 11416, loss 0.00120829, acc 1
2016-09-05T18:29:02.824029: step 11417, loss 0.00128175, acc 1
2016-09-05T18:29:03.047058: step 11418, loss 0.00119608, acc 1
2016-09-05T18:29:03.266746: step 11419, loss 0.00159814, acc 1
2016-09-05T18:29:03.481881: step 11420, loss 0.0013826, acc 1
2016-09-05T18:29:03.693204: step 11421, loss 0.00165019, acc 1
2016-09-05T18:29:03.937124: step 11422, loss 0.00138038, acc 1
2016-09-05T18:29:04.144399: step 11423, loss 0.00121021, acc 1
2016-09-05T18:29:04.373610: step 11424, loss 0.00291552, acc 1
2016-09-05T18:29:04.594556: step 11425, loss 0.00145457, acc 1
2016-09-05T18:29:04.808131: step 11426, loss 0.00126561, acc 1
2016-09-05T18:29:05.048164: step 11427, loss 0.00130027, acc 1
2016-09-05T18:29:05.249152: step 11428, loss 0.00167888, acc 1
2016-09-05T18:29:05.468148: step 11429, loss 0.00152539, acc 1
2016-09-05T18:29:05.664807: step 11430, loss 0.00128176, acc 1
2016-09-05T18:29:05.860118: step 11431, loss 0.00165615, acc 1
2016-09-05T18:29:06.068215: step 11432, loss 0.00127011, acc 1
2016-09-05T18:29:06.283757: step 11433, loss 0.00138667, acc 1
2016-09-05T18:29:06.506372: step 11434, loss 0.00175558, acc 1
2016-09-05T18:29:06.731569: step 11435, loss 0.00131671, acc 1
2016-09-05T18:29:06.939502: step 11436, loss 0.0017176, acc 1
2016-09-05T18:29:07.173033: step 11437, loss 0.00148305, acc 1
2016-09-05T18:29:07.379742: step 11438, loss 0.00149383, acc 1
2016-09-05T18:29:07.611531: step 11439, loss 0.00142828, acc 1
2016-09-05T18:29:07.865952: step 11440, loss 0.00126454, acc 1
2016-09-05T18:29:08.062209: step 11441, loss 0.0012879, acc 1
2016-09-05T18:29:08.261898: step 11442, loss 0.00121467, acc 1
2016-09-05T18:29:08.489969: step 11443, loss 0.00133571, acc 1
2016-09-05T18:29:08.729694: step 11444, loss 0.00138985, acc 1
2016-09-05T18:29:08.937062: step 11445, loss 0.00175843, acc 1
2016-09-05T18:29:09.073586: step 11446, loss 0.00144922, acc 1
2016-09-05T18:29:09.280567: step 11447, loss 0.00126574, acc 1
2016-09-05T18:29:09.489883: step 11448, loss 0.00122257, acc 1
2016-09-05T18:29:09.701763: step 11449, loss 0.00129629, acc 1
2016-09-05T18:29:09.914731: step 11450, loss 0.00134306, acc 1
2016-09-05T18:29:10.124151: step 11451, loss 0.00119932, acc 1
2016-09-05T18:29:10.344191: step 11452, loss 0.00124661, acc 1
2016-09-05T18:29:10.555239: step 11453, loss 0.00121612, acc 1
2016-09-05T18:29:10.779990: step 11454, loss 0.00130064, acc 1
2016-09-05T18:29:11.001820: step 11455, loss 0.00142796, acc 1
2016-09-05T18:29:11.228661: step 11456, loss 0.00213939, acc 1
2016-09-05T18:29:11.433814: step 11457, loss 0.00117703, acc 1
2016-09-05T18:29:11.654135: step 11458, loss 0.00136755, acc 1
2016-09-05T18:29:11.860850: step 11459, loss 0.0017171, acc 1
2016-09-05T18:29:12.100988: step 11460, loss 0.00140158, acc 1
2016-09-05T18:29:12.330877: step 11461, loss 0.00138941, acc 1
2016-09-05T18:29:12.542835: step 11462, loss 0.00137412, acc 1
2016-09-05T18:29:12.782514: step 11463, loss 0.0013047, acc 1
2016-09-05T18:29:12.992571: step 11464, loss 0.00122787, acc 1
2016-09-05T18:29:13.188443: step 11465, loss 0.00135322, acc 1
2016-09-05T18:29:13.421065: step 11466, loss 0.00135044, acc 1
2016-09-05T18:29:13.642016: step 11467, loss 0.00129616, acc 1
2016-09-05T18:29:13.845259: step 11468, loss 0.00156394, acc 1
2016-09-05T18:29:14.080919: step 11469, loss 0.00149552, acc 1
2016-09-05T18:29:14.316228: step 11470, loss 0.00128226, acc 1
2016-09-05T18:29:14.528000: step 11471, loss 0.00134052, acc 1
2016-09-05T18:29:14.732860: step 11472, loss 0.00120543, acc 1
2016-09-05T18:29:14.940808: step 11473, loss 0.00122612, acc 1
2016-09-05T18:29:15.170214: step 11474, loss 0.0014567, acc 1
2016-09-05T18:29:15.380686: step 11475, loss 0.00130362, acc 1
2016-09-05T18:29:15.597901: step 11476, loss 0.00218468, acc 1
2016-09-05T18:29:15.852942: step 11477, loss 0.00138036, acc 1
2016-09-05T18:29:16.071412: step 11478, loss 0.00137864, acc 1
2016-09-05T18:29:16.284676: step 11479, loss 0.00118896, acc 1
2016-09-05T18:29:16.518925: step 11480, loss 0.00127195, acc 1
2016-09-05T18:29:16.721608: step 11481, loss 0.00119526, acc 1
2016-09-05T18:29:16.933447: step 11482, loss 0.00120432, acc 1
2016-09-05T18:29:17.153748: step 11483, loss 0.00119801, acc 1
2016-09-05T18:29:17.363975: step 11484, loss 0.00134414, acc 1
2016-09-05T18:29:17.574894: step 11485, loss 0.00114225, acc 1
2016-09-05T18:29:17.781391: step 11486, loss 0.00115927, acc 1
2016-09-05T18:29:18.008708: step 11487, loss 0.00119787, acc 1
2016-09-05T18:29:18.255899: step 11488, loss 0.00112177, acc 1
2016-09-05T18:29:18.484405: step 11489, loss 0.00131648, acc 1
2016-09-05T18:29:18.700520: step 11490, loss 0.00133403, acc 1
2016-09-05T18:29:18.934858: step 11491, loss 0.0011772, acc 1
2016-09-05T18:29:19.143893: step 11492, loss 0.00124932, acc 1
2016-09-05T18:29:19.372074: step 11493, loss 0.00122068, acc 1
2016-09-05T18:29:19.584072: step 11494, loss 0.00112052, acc 1
2016-09-05T18:29:19.782540: step 11495, loss 0.00138703, acc 1
2016-09-05T18:29:19.997590: step 11496, loss 0.0011511, acc 1
2016-09-05T18:29:20.194627: step 11497, loss 0.00137397, acc 1
2016-09-05T18:29:20.407923: step 11498, loss 0.00154879, acc 1
2016-09-05T18:29:20.615545: step 11499, loss 0.00110089, acc 1
2016-09-05T18:29:20.830200: step 11500, loss 0.00120748, acc 1

Evaluation:
2016-09-05T18:29:21.436145: step 11500, loss 1.38888, acc 0.729

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-11500

2016-09-05T18:29:22.150891: step 11501, loss 0.00132698, acc 1
2016-09-05T18:29:22.343674: step 11502, loss 0.00115478, acc 1
2016-09-05T18:29:22.577710: step 11503, loss 0.00136168, acc 1
2016-09-05T18:29:22.807105: step 11504, loss 0.00129519, acc 1
2016-09-05T18:29:23.004184: step 11505, loss 0.00120463, acc 1
2016-09-05T18:29:23.213828: step 11506, loss 0.00134425, acc 1
2016-09-05T18:29:23.414840: step 11507, loss 0.00227424, acc 1
2016-09-05T18:29:23.636885: step 11508, loss 0.00122905, acc 1
2016-09-05T18:29:23.838373: step 11509, loss 0.00118022, acc 1
2016-09-05T18:29:24.050594: step 11510, loss 0.0013214, acc 1
2016-09-05T18:29:24.275545: step 11511, loss 0.00231345, acc 1
2016-09-05T18:29:24.522105: step 11512, loss 0.00125677, acc 1
2016-09-05T18:29:24.730426: step 11513, loss 0.00138722, acc 1
2016-09-05T18:29:24.939538: step 11514, loss 0.00119178, acc 1
2016-09-05T18:29:25.139368: step 11515, loss 0.00139252, acc 1
2016-09-05T18:29:25.388031: step 11516, loss 0.00123666, acc 1
2016-09-05T18:29:25.603584: step 11517, loss 0.00129247, acc 1
2016-09-05T18:29:25.830262: step 11518, loss 0.00135107, acc 1
2016-09-05T18:29:26.055440: step 11519, loss 0.00122201, acc 1
2016-09-05T18:29:26.271769: step 11520, loss 0.00131234, acc 1
2016-09-05T18:29:26.485542: step 11521, loss 0.00135621, acc 1
2016-09-05T18:29:26.701138: step 11522, loss 0.00121772, acc 1
2016-09-05T18:29:26.945350: step 11523, loss 0.00125194, acc 1
2016-09-05T18:29:27.137384: step 11524, loss 0.00172079, acc 1
2016-09-05T18:29:27.371411: step 11525, loss 0.00117171, acc 1
2016-09-05T18:29:27.575116: step 11526, loss 0.00151693, acc 1
2016-09-05T18:29:27.790200: step 11527, loss 0.00116856, acc 1
2016-09-05T18:29:28.020424: step 11528, loss 0.0011304, acc 1
2016-09-05T18:29:28.226534: step 11529, loss 0.00114714, acc 1
2016-09-05T18:29:28.452209: step 11530, loss 0.00112716, acc 1
2016-09-05T18:29:28.649118: step 11531, loss 0.00158251, acc 1
2016-09-05T18:29:28.864634: step 11532, loss 0.00147628, acc 1
2016-09-05T18:29:29.083644: step 11533, loss 0.00108731, acc 1
2016-09-05T18:29:29.324884: step 11534, loss 0.00118033, acc 1
2016-09-05T18:29:29.536618: step 11535, loss 0.00124166, acc 1
2016-09-05T18:29:29.779255: step 11536, loss 0.00192689, acc 1
2016-09-05T18:29:29.986490: step 11537, loss 0.00112407, acc 1
2016-09-05T18:29:30.202997: step 11538, loss 0.00128192, acc 1
2016-09-05T18:29:30.419154: step 11539, loss 0.00145491, acc 1
2016-09-05T18:29:30.647118: step 11540, loss 0.00118417, acc 1
2016-09-05T18:29:30.881362: step 11541, loss 0.001895, acc 1
2016-09-05T18:29:31.073694: step 11542, loss 0.00133099, acc 1
2016-09-05T18:29:31.292868: step 11543, loss 0.00126234, acc 1
2016-09-05T18:29:31.500252: step 11544, loss 0.00146111, acc 1
2016-09-05T18:29:31.722997: step 11545, loss 0.00137587, acc 1
2016-09-05T18:29:31.926087: step 11546, loss 0.00171664, acc 1
2016-09-05T18:29:32.158259: step 11547, loss 0.00124015, acc 1
2016-09-05T18:29:32.382639: step 11548, loss 0.00161065, acc 1
2016-09-05T18:29:32.608290: step 11549, loss 0.00128485, acc 1
2016-09-05T18:29:32.816036: step 11550, loss 0.00134508, acc 1
2016-09-05T18:29:33.046074: step 11551, loss 0.00123435, acc 1
2016-09-05T18:29:33.252580: step 11552, loss 0.00115321, acc 1
2016-09-05T18:29:33.481841: step 11553, loss 0.00120561, acc 1
2016-09-05T18:29:33.705387: step 11554, loss 0.00204024, acc 1
2016-09-05T18:29:33.928668: step 11555, loss 0.00179163, acc 1
2016-09-05T18:29:34.143830: step 11556, loss 0.00116793, acc 1
2016-09-05T18:29:34.379648: step 11557, loss 0.00124307, acc 1
2016-09-05T18:29:34.617498: step 11558, loss 0.00123344, acc 1
2016-09-05T18:29:34.835297: step 11559, loss 0.0015586, acc 1
2016-09-05T18:29:35.063375: step 11560, loss 0.00136773, acc 1
2016-09-05T18:29:35.290892: step 11561, loss 0.00109933, acc 1
2016-09-05T18:29:35.544674: step 11562, loss 0.0014214, acc 1
2016-09-05T18:29:35.755048: step 11563, loss 0.00140925, acc 1
2016-09-05T18:29:35.986884: step 11564, loss 0.00151672, acc 1
2016-09-05T18:29:36.202724: step 11565, loss 0.00132081, acc 1
2016-09-05T18:29:36.432341: step 11566, loss 0.00128301, acc 1
2016-09-05T18:29:36.654863: step 11567, loss 0.00162508, acc 1
2016-09-05T18:29:36.863595: step 11568, loss 0.00114892, acc 1
2016-09-05T18:29:37.078700: step 11569, loss 0.0014073, acc 1
2016-09-05T18:29:37.289732: step 11570, loss 0.00126011, acc 1
2016-09-05T18:29:37.509693: step 11571, loss 0.00133296, acc 1
2016-09-05T18:29:37.749633: step 11572, loss 0.00118835, acc 1
2016-09-05T18:29:37.974419: step 11573, loss 0.00135104, acc 1
2016-09-05T18:29:38.181586: step 11574, loss 0.00145554, acc 1
2016-09-05T18:29:38.425310: step 11575, loss 0.00144582, acc 1
2016-09-05T18:29:38.659121: step 11576, loss 0.00110152, acc 1
2016-09-05T18:29:38.880219: step 11577, loss 0.00171652, acc 1
2016-09-05T18:29:39.095369: step 11578, loss 0.00144727, acc 1
2016-09-05T18:29:39.299299: step 11579, loss 0.00106896, acc 1
2016-09-05T18:29:39.516410: step 11580, loss 0.00114862, acc 1
2016-09-05T18:29:39.722753: step 11581, loss 0.00173648, acc 1
2016-09-05T18:29:39.950758: step 11582, loss 0.00203886, acc 1
2016-09-05T18:29:40.188497: step 11583, loss 0.00143411, acc 1
2016-09-05T18:29:40.411866: step 11584, loss 0.00126944, acc 1
2016-09-05T18:29:40.625379: step 11585, loss 0.00140131, acc 1
2016-09-05T18:29:40.827871: step 11586, loss 0.00129783, acc 1
2016-09-05T18:29:41.044700: step 11587, loss 0.00119868, acc 1
2016-09-05T18:29:41.299824: step 11588, loss 0.00156078, acc 1
2016-09-05T18:29:41.519705: step 11589, loss 0.00129694, acc 1
2016-09-05T18:29:41.730987: step 11590, loss 0.0011163, acc 1
2016-09-05T18:29:41.949731: step 11591, loss 0.00127029, acc 1
2016-09-05T18:29:42.162069: step 11592, loss 0.00112985, acc 1
2016-09-05T18:29:42.400180: step 11593, loss 0.00130949, acc 1
2016-09-05T18:29:42.620085: step 11594, loss 0.00118394, acc 1
2016-09-05T18:29:42.839505: step 11595, loss 0.00107699, acc 1
2016-09-05T18:29:43.053626: step 11596, loss 0.00110346, acc 1
2016-09-05T18:29:43.288007: step 11597, loss 0.001585, acc 1
2016-09-05T18:29:43.506269: step 11598, loss 0.00132139, acc 1
2016-09-05T18:29:43.727903: step 11599, loss 0.00144606, acc 1
2016-09-05T18:29:43.947557: step 11600, loss 0.00124643, acc 1

Evaluation:
2016-09-05T18:29:44.528561: step 11600, loss 1.4034, acc 0.729

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-11600

2016-09-05T18:29:45.329063: step 11601, loss 0.00136714, acc 1
2016-09-05T18:29:45.574028: step 11602, loss 0.00132302, acc 1
2016-09-05T18:29:45.785543: step 11603, loss 0.00140829, acc 1
2016-09-05T18:29:46.012989: step 11604, loss 0.00116167, acc 1
2016-09-05T18:29:46.257493: step 11605, loss 0.00134023, acc 1
2016-09-05T18:29:46.497764: step 11606, loss 0.00146779, acc 1
2016-09-05T18:29:46.721659: step 11607, loss 0.00114744, acc 1
2016-09-05T18:29:46.930253: step 11608, loss 0.00136691, acc 1
2016-09-05T18:29:47.170052: step 11609, loss 0.00108675, acc 1
2016-09-05T18:29:47.378404: step 11610, loss 0.00211705, acc 1
2016-09-05T18:29:47.616170: step 11611, loss 0.00111275, acc 1
2016-09-05T18:29:47.867271: step 11612, loss 0.0012938, acc 1
2016-09-05T18:29:48.078066: step 11613, loss 0.0010761, acc 1
2016-09-05T18:29:48.280351: step 11614, loss 0.00135468, acc 1
2016-09-05T18:29:48.491352: step 11615, loss 0.00134997, acc 1
2016-09-05T18:29:48.743865: step 11616, loss 0.00127169, acc 1
2016-09-05T18:29:48.957119: step 11617, loss 0.00165442, acc 1
2016-09-05T18:29:49.155375: step 11618, loss 0.00119437, acc 1
2016-09-05T18:29:49.372162: step 11619, loss 0.00165198, acc 1
2016-09-05T18:29:49.587113: step 11620, loss 0.00243672, acc 1
2016-09-05T18:29:49.801940: step 11621, loss 0.00131019, acc 1
2016-09-05T18:29:50.016789: step 11622, loss 0.00122246, acc 1
2016-09-05T18:29:50.259149: step 11623, loss 0.00116328, acc 1
2016-09-05T18:29:50.487877: step 11624, loss 0.00123723, acc 1
2016-09-05T18:29:50.690667: step 11625, loss 0.00112741, acc 1
2016-09-05T18:29:50.908004: step 11626, loss 0.00159093, acc 1
2016-09-05T18:29:51.121465: step 11627, loss 0.00159234, acc 1
2016-09-05T18:29:51.366013: step 11628, loss 0.00130082, acc 1
2016-09-05T18:29:51.592204: step 11629, loss 0.00123475, acc 1
2016-09-05T18:29:51.789442: step 11630, loss 0.00143214, acc 1
2016-09-05T18:29:52.007409: step 11631, loss 0.00145779, acc 1
2016-09-05T18:29:52.214204: step 11632, loss 0.00134104, acc 1
2016-09-05T18:29:52.428753: step 11633, loss 0.00119559, acc 1
2016-09-05T18:29:52.641834: step 11634, loss 0.00145239, acc 1
2016-09-05T18:29:52.872060: step 11635, loss 0.00122471, acc 1
2016-09-05T18:29:53.087070: step 11636, loss 0.00123467, acc 1
2016-09-05T18:29:53.325611: step 11637, loss 0.00137561, acc 1
2016-09-05T18:29:53.530813: step 11638, loss 0.00165854, acc 1
2016-09-05T18:29:53.748905: step 11639, loss 0.00216297, acc 1
2016-09-05T18:29:53.891153: step 11640, loss 0.00119572, acc 1
2016-09-05T18:29:54.131597: step 11641, loss 0.00129028, acc 1
2016-09-05T18:29:54.339381: step 11642, loss 0.00115742, acc 1
2016-09-05T18:29:54.543310: step 11643, loss 0.00121644, acc 1
2016-09-05T18:29:54.767851: step 11644, loss 0.00119374, acc 1
2016-09-05T18:29:55.010665: step 11645, loss 0.00144588, acc 1
2016-09-05T18:29:55.269846: step 11646, loss 0.00132568, acc 1
2016-09-05T18:29:55.490654: step 11647, loss 0.00114017, acc 1
2016-09-05T18:29:55.716317: step 11648, loss 0.00120085, acc 1
2016-09-05T18:29:55.937439: step 11649, loss 0.00112618, acc 1
2016-09-05T18:29:56.188876: step 11650, loss 0.00153047, acc 1
2016-09-05T18:29:56.776484: step 11651, loss 0.00141789, acc 1
2016-09-05T18:29:56.980219: step 11652, loss 0.00220701, acc 1
2016-09-05T18:29:57.193862: step 11653, loss 0.00128975, acc 1
2016-09-05T18:29:57.473416: step 11654, loss 0.00122865, acc 1
2016-09-05T18:29:57.700260: step 11655, loss 0.00133712, acc 1
2016-09-05T18:29:57.915275: step 11656, loss 0.00133888, acc 1
2016-09-05T18:29:58.130569: step 11657, loss 0.00121085, acc 1
2016-09-05T18:29:58.326174: step 11658, loss 0.00117519, acc 1
2016-09-05T18:29:58.544557: step 11659, loss 0.00118171, acc 1
2016-09-05T18:29:58.779674: step 11660, loss 0.0011087, acc 1
2016-09-05T18:29:59.003853: step 11661, loss 0.00144791, acc 1
2016-09-05T18:29:59.211092: step 11662, loss 0.00137152, acc 1
2016-09-05T18:29:59.421561: step 11663, loss 0.00124621, acc 1
2016-09-05T18:29:59.627881: step 11664, loss 0.00202249, acc 1
2016-09-05T18:29:59.855129: step 11665, loss 0.00143185, acc 1
2016-09-05T18:30:00.080868: step 11666, loss 0.00166832, acc 1
2016-09-05T18:30:00.303947: step 11667, loss 0.00114351, acc 1
2016-09-05T18:30:00.508190: step 11668, loss 0.00123931, acc 1
2016-09-05T18:30:00.720267: step 11669, loss 0.00114522, acc 1
2016-09-05T18:30:00.950837: step 11670, loss 0.00118786, acc 1
2016-09-05T18:30:01.163734: step 11671, loss 0.00147973, acc 1
2016-09-05T18:30:01.407243: step 11672, loss 0.00119684, acc 1
2016-09-05T18:30:01.621357: step 11673, loss 0.00111365, acc 1
2016-09-05T18:30:01.844870: step 11674, loss 0.00116008, acc 1
2016-09-05T18:30:02.065311: step 11675, loss 0.00117232, acc 1
2016-09-05T18:30:02.307130: step 11676, loss 0.00126101, acc 1
2016-09-05T18:30:02.550619: step 11677, loss 0.00117152, acc 1
2016-09-05T18:30:02.750727: step 11678, loss 0.00109359, acc 1
2016-09-05T18:30:02.972438: step 11679, loss 0.00109702, acc 1
2016-09-05T18:30:03.185548: step 11680, loss 0.00190928, acc 1
2016-09-05T18:30:03.425698: step 11681, loss 0.00109629, acc 1
2016-09-05T18:30:03.625834: step 11682, loss 0.00102357, acc 1
2016-09-05T18:30:03.840834: step 11683, loss 0.00115885, acc 1
2016-09-05T18:30:04.053164: step 11684, loss 0.00114682, acc 1
2016-09-05T18:30:04.308896: step 11685, loss 0.00113518, acc 1
2016-09-05T18:30:04.545272: step 11686, loss 0.00109631, acc 1
2016-09-05T18:30:04.742828: step 11687, loss 0.00117885, acc 1
2016-09-05T18:30:04.953608: step 11688, loss 0.00126753, acc 1
2016-09-05T18:30:05.150505: step 11689, loss 0.00104451, acc 1
2016-09-05T18:30:05.353322: step 11690, loss 0.00126966, acc 1
2016-09-05T18:30:05.556626: step 11691, loss 0.00116107, acc 1
2016-09-05T18:30:05.774294: step 11692, loss 0.00104777, acc 1
2016-09-05T18:30:05.979299: step 11693, loss 0.00108256, acc 1
2016-09-05T18:30:06.205039: step 11694, loss 0.0010835, acc 1
2016-09-05T18:30:06.423395: step 11695, loss 0.00130827, acc 1
2016-09-05T18:30:06.647128: step 11696, loss 0.00114555, acc 1
2016-09-05T18:30:06.860059: step 11697, loss 0.00144778, acc 1
2016-09-05T18:30:07.096752: step 11698, loss 0.00105097, acc 1
2016-09-05T18:30:07.315958: step 11699, loss 0.00105345, acc 1
2016-09-05T18:30:07.533114: step 11700, loss 0.00123583, acc 1

Evaluation:
2016-09-05T18:30:08.143976: step 11700, loss 1.35622, acc 0.728

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-11700

2016-09-05T18:30:08.899483: step 11701, loss 0.00160354, acc 1
2016-09-05T18:30:09.111441: step 11702, loss 0.0020339, acc 1
2016-09-05T18:30:09.351799: step 11703, loss 0.00124586, acc 1
2016-09-05T18:30:09.597819: step 11704, loss 0.00114602, acc 1
2016-09-05T18:30:09.800012: step 11705, loss 0.00131099, acc 1
2016-09-05T18:30:10.012713: step 11706, loss 0.00109056, acc 1
2016-09-05T18:30:10.230120: step 11707, loss 0.00204304, acc 1
2016-09-05T18:30:10.438924: step 11708, loss 0.00129202, acc 1
2016-09-05T18:30:10.651684: step 11709, loss 0.00132224, acc 1
2016-09-05T18:30:10.845238: step 11710, loss 0.00167153, acc 1
2016-09-05T18:30:11.081686: step 11711, loss 0.00123445, acc 1
2016-09-05T18:30:11.270572: step 11712, loss 0.00146269, acc 1
2016-09-05T18:30:11.497420: step 11713, loss 0.00123954, acc 1
2016-09-05T18:30:11.711267: step 11714, loss 0.00139041, acc 1
2016-09-05T18:30:11.925237: step 11715, loss 0.0011642, acc 1
2016-09-05T18:30:12.155836: step 11716, loss 0.00117462, acc 1
2016-09-05T18:30:12.387567: step 11717, loss 0.00149751, acc 1
2016-09-05T18:30:12.607443: step 11718, loss 0.00124231, acc 1
2016-09-05T18:30:12.810868: step 11719, loss 0.00119429, acc 1
2016-09-05T18:30:13.017901: step 11720, loss 0.0010907, acc 1
2016-09-05T18:30:13.240819: step 11721, loss 0.00154372, acc 1
2016-09-05T18:30:13.483567: step 11722, loss 0.00185132, acc 1
2016-09-05T18:30:13.709401: step 11723, loss 0.00301602, acc 1
2016-09-05T18:30:13.932371: step 11724, loss 0.00103821, acc 1
2016-09-05T18:30:14.152240: step 11725, loss 0.00123215, acc 1
2016-09-05T18:30:14.371065: step 11726, loss 0.00107342, acc 1
2016-09-05T18:30:14.588493: step 11727, loss 0.00123818, acc 1
2016-09-05T18:30:14.836611: step 11728, loss 0.00127388, acc 1
2016-09-05T18:30:15.038443: step 11729, loss 0.00207503, acc 1
2016-09-05T18:30:15.243162: step 11730, loss 0.00147768, acc 1
2016-09-05T18:30:15.448238: step 11731, loss 0.00165434, acc 1
2016-09-05T18:30:15.671620: step 11732, loss 0.00131942, acc 1
2016-09-05T18:30:15.876778: step 11733, loss 0.00127793, acc 1
2016-09-05T18:30:16.086728: step 11734, loss 0.00112335, acc 1
2016-09-05T18:30:16.303136: step 11735, loss 0.00116494, acc 1
2016-09-05T18:30:16.520830: step 11736, loss 0.00163718, acc 1
2016-09-05T18:30:16.742419: step 11737, loss 0.00107725, acc 1
2016-09-05T18:30:16.953261: step 11738, loss 0.00113652, acc 1
2016-09-05T18:30:17.172195: step 11739, loss 0.00108113, acc 1
2016-09-05T18:30:17.372215: step 11740, loss 0.00120729, acc 1
2016-09-05T18:30:17.580865: step 11741, loss 0.00131207, acc 1
2016-09-05T18:30:17.774315: step 11742, loss 0.00110319, acc 1
2016-09-05T18:30:17.988446: step 11743, loss 0.00170993, acc 1
2016-09-05T18:30:18.187830: step 11744, loss 0.00149547, acc 1
2016-09-05T18:30:18.407860: step 11745, loss 0.0011255, acc 1
2016-09-05T18:30:18.616093: step 11746, loss 0.00115172, acc 1
2016-09-05T18:30:18.829014: step 11747, loss 0.00155341, acc 1
2016-09-05T18:30:19.052762: step 11748, loss 0.00114327, acc 1
2016-09-05T18:30:19.291968: step 11749, loss 0.00119103, acc 1
2016-09-05T18:30:19.487639: step 11750, loss 0.00113825, acc 1
2016-09-05T18:30:19.707260: step 11751, loss 0.00122529, acc 1
2016-09-05T18:30:19.934408: step 11752, loss 0.00122862, acc 1
2016-09-05T18:30:20.185710: step 11753, loss 0.00118745, acc 1
2016-09-05T18:30:20.389320: step 11754, loss 0.00107842, acc 1
2016-09-05T18:30:20.592431: step 11755, loss 0.00116851, acc 1
2016-09-05T18:30:20.796102: step 11756, loss 0.00122857, acc 1
2016-09-05T18:30:20.998142: step 11757, loss 0.00149979, acc 1
2016-09-05T18:30:21.203603: step 11758, loss 0.00193179, acc 1
2016-09-05T18:30:21.403909: step 11759, loss 0.0016366, acc 1
2016-09-05T18:30:21.608557: step 11760, loss 0.0011237, acc 1
2016-09-05T18:30:21.812033: step 11761, loss 0.00112585, acc 1
2016-09-05T18:30:22.021561: step 11762, loss 0.00129834, acc 1
2016-09-05T18:30:22.219170: step 11763, loss 0.00109654, acc 1
2016-09-05T18:30:22.419016: step 11764, loss 0.00136641, acc 1
2016-09-05T18:30:22.642334: step 11765, loss 0.00134131, acc 1
2016-09-05T18:30:22.872767: step 11766, loss 0.00123083, acc 1
2016-09-05T18:30:23.095488: step 11767, loss 0.00122128, acc 1
2016-09-05T18:30:23.318619: step 11768, loss 0.00110194, acc 1
2016-09-05T18:30:23.518599: step 11769, loss 0.00121864, acc 1
2016-09-05T18:30:23.727832: step 11770, loss 0.00109646, acc 1
2016-09-05T18:30:23.936479: step 11771, loss 0.00129055, acc 1
2016-09-05T18:30:24.166850: step 11772, loss 0.0011765, acc 1
2016-09-05T18:30:24.399935: step 11773, loss 0.00144107, acc 1
2016-09-05T18:30:24.623980: step 11774, loss 0.00117938, acc 1
2016-09-05T18:30:24.834034: step 11775, loss 0.0012043, acc 1
2016-09-05T18:30:25.032617: step 11776, loss 0.00131946, acc 1
2016-09-05T18:30:25.235813: step 11777, loss 0.00134529, acc 1
2016-09-05T18:30:25.442467: step 11778, loss 0.00112796, acc 1
2016-09-05T18:30:25.648531: step 11779, loss 0.00135467, acc 1
2016-09-05T18:30:25.848065: step 11780, loss 0.0012074, acc 1
2016-09-05T18:30:26.055573: step 11781, loss 0.00116714, acc 1
2016-09-05T18:30:26.279617: step 11782, loss 0.0010171, acc 1
2016-09-05T18:30:26.503260: step 11783, loss 0.00110374, acc 1
2016-09-05T18:30:26.741310: step 11784, loss 0.00143396, acc 1
2016-09-05T18:30:26.966218: step 11785, loss 0.00194566, acc 1
2016-09-05T18:30:27.173639: step 11786, loss 0.00133477, acc 1
2016-09-05T18:30:27.397626: step 11787, loss 0.00108425, acc 1
2016-09-05T18:30:27.621917: step 11788, loss 0.00128739, acc 1
2016-09-05T18:30:27.831621: step 11789, loss 0.00145577, acc 1
2016-09-05T18:30:28.059066: step 11790, loss 0.00124134, acc 1
2016-09-05T18:30:28.256440: step 11791, loss 0.00113247, acc 1
2016-09-05T18:30:28.457448: step 11792, loss 0.0012438, acc 1
2016-09-05T18:30:28.670952: step 11793, loss 0.0012407, acc 1
2016-09-05T18:30:28.885465: step 11794, loss 0.00112099, acc 1
2016-09-05T18:30:29.099454: step 11795, loss 0.00120567, acc 1
2016-09-05T18:30:29.311855: step 11796, loss 0.00173665, acc 1
2016-09-05T18:30:29.519466: step 11797, loss 0.00116745, acc 1
2016-09-05T18:30:29.743734: step 11798, loss 0.00125261, acc 1
2016-09-05T18:30:29.982910: step 11799, loss 0.00123215, acc 1
2016-09-05T18:30:30.193353: step 11800, loss 0.00122586, acc 1

Evaluation:
2016-09-05T18:30:30.811381: step 11800, loss 1.42464, acc 0.73

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-11800

2016-09-05T18:30:31.631036: step 11801, loss 0.00119028, acc 1
2016-09-05T18:30:31.838136: step 11802, loss 0.00108858, acc 1
2016-09-05T18:30:32.062316: step 11803, loss 0.00107579, acc 1
2016-09-05T18:30:32.285592: step 11804, loss 0.0014108, acc 1
2016-09-05T18:30:32.512027: step 11805, loss 0.00185838, acc 1
2016-09-05T18:30:32.733251: step 11806, loss 0.00123293, acc 1
2016-09-05T18:30:32.942642: step 11807, loss 0.00119784, acc 1
2016-09-05T18:30:33.167114: step 11808, loss 0.00114397, acc 1
2016-09-05T18:30:33.370127: step 11809, loss 0.00146037, acc 1
2016-09-05T18:30:33.600828: step 11810, loss 0.00112654, acc 1
2016-09-05T18:30:33.830298: step 11811, loss 0.00123167, acc 1
2016-09-05T18:30:34.046684: step 11812, loss 0.00104766, acc 1
2016-09-05T18:30:34.244474: step 11813, loss 0.00111823, acc 1
2016-09-05T18:30:34.470933: step 11814, loss 0.00185109, acc 1
2016-09-05T18:30:34.683600: step 11815, loss 0.00146593, acc 1
2016-09-05T18:30:34.897567: step 11816, loss 0.00124523, acc 1
2016-09-05T18:30:35.136821: step 11817, loss 0.00146737, acc 1
2016-09-05T18:30:35.338660: step 11818, loss 0.00123264, acc 1
2016-09-05T18:30:35.554402: step 11819, loss 0.00154129, acc 1
2016-09-05T18:30:35.770757: step 11820, loss 0.00120811, acc 1
2016-09-05T18:30:35.995025: step 11821, loss 0.00117775, acc 1
2016-09-05T18:30:36.209611: step 11822, loss 0.0012413, acc 1
2016-09-05T18:30:36.441765: step 11823, loss 0.00134738, acc 1
2016-09-05T18:30:36.653880: step 11824, loss 0.00124105, acc 1
2016-09-05T18:30:36.880951: step 11825, loss 0.00117883, acc 1
2016-09-05T18:30:37.105997: step 11826, loss 0.00139168, acc 1
2016-09-05T18:30:37.323742: step 11827, loss 0.0012901, acc 1
2016-09-05T18:30:37.567727: step 11828, loss 0.00121627, acc 1
2016-09-05T18:30:37.783469: step 11829, loss 0.00114304, acc 1
2016-09-05T18:30:37.996140: step 11830, loss 0.0011584, acc 1
2016-09-05T18:30:38.187436: step 11831, loss 0.0010589, acc 1
2016-09-05T18:30:38.400059: step 11832, loss 0.00196708, acc 1
2016-09-05T18:30:38.609724: step 11833, loss 0.00125656, acc 1
2016-09-05T18:30:38.769376: step 11834, loss 0.00109193, acc 1
2016-09-05T18:30:38.989331: step 11835, loss 0.00105282, acc 1
2016-09-05T18:30:39.196220: step 11836, loss 0.00122482, acc 1
2016-09-05T18:30:39.385636: step 11837, loss 0.00112277, acc 1
2016-09-05T18:30:39.592790: step 11838, loss 0.00141565, acc 1
2016-09-05T18:30:39.811459: step 11839, loss 0.00114946, acc 1
2016-09-05T18:30:40.038815: step 11840, loss 0.00103862, acc 1
2016-09-05T18:30:40.248410: step 11841, loss 0.00186462, acc 1
2016-09-05T18:30:40.483602: step 11842, loss 0.00103089, acc 1
2016-09-05T18:30:40.684960: step 11843, loss 0.0010457, acc 1
2016-09-05T18:30:40.885268: step 11844, loss 0.00101685, acc 1
2016-09-05T18:30:41.088582: step 11845, loss 0.00107318, acc 1
2016-09-05T18:30:41.297563: step 11846, loss 0.00117447, acc 1
2016-09-05T18:30:41.505852: step 11847, loss 0.00115436, acc 1
2016-09-05T18:30:41.716646: step 11848, loss 0.00123718, acc 1
2016-09-05T18:30:41.928332: step 11849, loss 0.00110751, acc 1
2016-09-05T18:30:42.180813: step 11850, loss 0.00100396, acc 1
2016-09-05T18:30:42.402883: step 11851, loss 0.00103721, acc 1
2016-09-05T18:30:42.604026: step 11852, loss 0.00107872, acc 1
2016-09-05T18:30:42.816020: step 11853, loss 0.000982559, acc 1
2016-09-05T18:30:43.033860: step 11854, loss 0.00145321, acc 1
2016-09-05T18:30:43.241185: step 11855, loss 0.0010665, acc 1
2016-09-05T18:30:43.472864: step 11856, loss 0.00245126, acc 1
2016-09-05T18:30:43.713958: step 11857, loss 0.00113307, acc 1
2016-09-05T18:30:43.909416: step 11858, loss 0.00101513, acc 1
2016-09-05T18:30:44.108004: step 11859, loss 0.00121647, acc 1
2016-09-05T18:30:44.327875: step 11860, loss 0.00141975, acc 1
2016-09-05T18:30:44.569349: step 11861, loss 0.00109355, acc 1
2016-09-05T18:30:44.810429: step 11862, loss 0.00113606, acc 1
2016-09-05T18:30:45.013404: step 11863, loss 0.00103729, acc 1
2016-09-05T18:30:45.248993: step 11864, loss 0.00119636, acc 1
2016-09-05T18:30:45.449399: step 11865, loss 0.00124969, acc 1
2016-09-05T18:30:45.667146: step 11866, loss 0.00105636, acc 1
2016-09-05T18:30:45.876888: step 11867, loss 0.00112372, acc 1
2016-09-05T18:30:46.117459: step 11868, loss 0.00129637, acc 1
2016-09-05T18:30:46.333670: step 11869, loss 0.00109475, acc 1
2016-09-05T18:30:46.554823: step 11870, loss 0.00120033, acc 1
2016-09-05T18:30:46.775073: step 11871, loss 0.00137069, acc 1
2016-09-05T18:30:47.000877: step 11872, loss 0.00107997, acc 1
2016-09-05T18:30:47.253423: step 11873, loss 0.00107279, acc 1
2016-09-05T18:30:47.467942: step 11874, loss 0.00109855, acc 1
2016-09-05T18:30:47.685699: step 11875, loss 0.00199617, acc 1
2016-09-05T18:30:47.881212: step 11876, loss 0.0012481, acc 1
2016-09-05T18:30:48.085014: step 11877, loss 0.00110009, acc 1
2016-09-05T18:30:48.318897: step 11878, loss 0.00157423, acc 1
2016-09-05T18:30:48.522544: step 11879, loss 0.00128896, acc 1
2016-09-05T18:30:48.751220: step 11880, loss 0.000981097, acc 1
2016-09-05T18:30:48.960031: step 11881, loss 0.00157672, acc 1
2016-09-05T18:30:49.166300: step 11882, loss 0.00125804, acc 1
2016-09-05T18:30:49.383662: step 11883, loss 0.00138776, acc 1
2016-09-05T18:30:49.609598: step 11884, loss 0.00096784, acc 1
2016-09-05T18:30:49.818086: step 11885, loss 0.0012552, acc 1
2016-09-05T18:30:50.044986: step 11886, loss 0.00115271, acc 1
2016-09-05T18:30:50.242676: step 11887, loss 0.00106591, acc 1
2016-09-05T18:30:50.470044: step 11888, loss 0.00161108, acc 1
2016-09-05T18:30:50.683123: step 11889, loss 0.000993437, acc 1
2016-09-05T18:30:50.901819: step 11890, loss 0.00152948, acc 1
2016-09-05T18:30:51.102973: step 11891, loss 0.00105765, acc 1
2016-09-05T18:30:51.333837: step 11892, loss 0.000999642, acc 1
2016-09-05T18:30:51.546263: step 11893, loss 0.00108516, acc 1
2016-09-05T18:30:51.788576: step 11894, loss 0.00105911, acc 1
2016-09-05T18:30:52.016404: step 11895, loss 0.00106357, acc 1
2016-09-05T18:30:52.255069: step 11896, loss 0.00108936, acc 1
2016-09-05T18:30:52.477393: step 11897, loss 0.0010258, acc 1
2016-09-05T18:30:52.687087: step 11898, loss 0.00109029, acc 1
2016-09-05T18:30:52.912821: step 11899, loss 0.0012594, acc 1
2016-09-05T18:30:53.122141: step 11900, loss 0.00116151, acc 1

Evaluation:
2016-09-05T18:30:53.714402: step 11900, loss 1.41996, acc 0.728

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-11900

2016-09-05T18:30:54.520100: step 11901, loss 0.00140582, acc 1
2016-09-05T18:30:54.746938: step 11902, loss 0.00119754, acc 1
2016-09-05T18:30:54.961208: step 11903, loss 0.00117189, acc 1
2016-09-05T18:30:55.173899: step 11904, loss 0.00112076, acc 1
2016-09-05T18:30:55.389713: step 11905, loss 0.00127569, acc 1
2016-09-05T18:30:55.627393: step 11906, loss 0.00130438, acc 1
2016-09-05T18:30:55.864620: step 11907, loss 0.00111214, acc 1
2016-09-05T18:30:56.097181: step 11908, loss 0.00113676, acc 1
2016-09-05T18:30:56.313270: step 11909, loss 0.00106794, acc 1
2016-09-05T18:30:56.539008: step 11910, loss 0.00148154, acc 1
2016-09-05T18:30:56.768440: step 11911, loss 0.00186518, acc 1
2016-09-05T18:30:56.987296: step 11912, loss 0.0011044, acc 1
2016-09-05T18:30:57.196724: step 11913, loss 0.00112004, acc 1
2016-09-05T18:30:57.441319: step 11914, loss 0.001241, acc 1
2016-09-05T18:30:57.662300: step 11915, loss 0.00161365, acc 1
2016-09-05T18:30:57.875032: step 11916, loss 0.00121867, acc 1
2016-09-05T18:30:58.099626: step 11917, loss 0.00112069, acc 1
2016-09-05T18:30:58.349415: step 11918, loss 0.00101709, acc 1
2016-09-05T18:30:58.580470: step 11919, loss 0.00103409, acc 1
2016-09-05T18:30:58.793954: step 11920, loss 0.0022354, acc 1
2016-09-05T18:30:59.022879: step 11921, loss 0.00118942, acc 1
2016-09-05T18:30:59.269555: step 11922, loss 0.00109802, acc 1
2016-09-05T18:30:59.505840: step 11923, loss 0.00100502, acc 1
2016-09-05T18:30:59.733313: step 11924, loss 0.00113305, acc 1
2016-09-05T18:30:59.979615: step 11925, loss 0.00100794, acc 1
2016-09-05T18:31:00.214436: step 11926, loss 0.00110013, acc 1
2016-09-05T18:31:00.421930: step 11927, loss 0.0010437, acc 1
2016-09-05T18:31:00.632944: step 11928, loss 0.00187348, acc 1
2016-09-05T18:31:00.835144: step 11929, loss 0.00104815, acc 1
2016-09-05T18:31:01.056681: step 11930, loss 0.00110434, acc 1
2016-09-05T18:31:01.266882: step 11931, loss 0.00112161, acc 1
2016-09-05T18:31:01.474489: step 11932, loss 0.00108602, acc 1
2016-09-05T18:31:01.688606: step 11933, loss 0.00126771, acc 1
2016-09-05T18:31:01.910629: step 11934, loss 0.00113042, acc 1
2016-09-05T18:31:02.121501: step 11935, loss 0.0015896, acc 1
2016-09-05T18:31:02.337939: step 11936, loss 0.00123051, acc 1
2016-09-05T18:31:02.542071: step 11937, loss 0.00119708, acc 1
2016-09-05T18:31:02.745016: step 11938, loss 0.00133457, acc 1
2016-09-05T18:31:02.966096: step 11939, loss 0.00103459, acc 1
2016-09-05T18:31:03.191745: step 11940, loss 0.00105818, acc 1
2016-09-05T18:31:03.435264: step 11941, loss 0.00120587, acc 1
2016-09-05T18:31:03.637298: step 11942, loss 0.00126373, acc 1
2016-09-05T18:31:03.837925: step 11943, loss 0.00120833, acc 1
2016-09-05T18:31:04.049965: step 11944, loss 0.00102435, acc 1
2016-09-05T18:31:04.264789: step 11945, loss 0.0011058, acc 1
2016-09-05T18:31:04.468934: step 11946, loss 0.00117952, acc 1
2016-09-05T18:31:04.709459: step 11947, loss 0.00131258, acc 1
2016-09-05T18:31:04.921652: step 11948, loss 0.0011213, acc 1
2016-09-05T18:31:05.134525: step 11949, loss 0.00106466, acc 1
2016-09-05T18:31:05.340476: step 11950, loss 0.00115367, acc 1
2016-09-05T18:31:05.553502: step 11951, loss 0.00117756, acc 1
2016-09-05T18:31:05.770447: step 11952, loss 0.00106536, acc 1
2016-09-05T18:31:06.008871: step 11953, loss 0.00104399, acc 1
2016-09-05T18:31:06.240146: step 11954, loss 0.00195759, acc 1
2016-09-05T18:31:06.448283: step 11955, loss 0.00102475, acc 1
2016-09-05T18:31:06.655029: step 11956, loss 0.00118118, acc 1
2016-09-05T18:31:06.863205: step 11957, loss 0.00110048, acc 1
2016-09-05T18:31:07.105209: step 11958, loss 0.00116868, acc 1
2016-09-05T18:31:07.312034: step 11959, loss 0.00108937, acc 1
2016-09-05T18:31:07.553960: step 11960, loss 0.00137947, acc 1
2016-09-05T18:31:07.757883: step 11961, loss 0.00121747, acc 1
2016-09-05T18:31:07.967064: step 11962, loss 0.00103116, acc 1
2016-09-05T18:31:08.180888: step 11963, loss 0.00126416, acc 1
2016-09-05T18:31:08.403770: step 11964, loss 0.00117432, acc 1
2016-09-05T18:31:08.630933: step 11965, loss 0.00120548, acc 1
2016-09-05T18:31:08.860622: step 11966, loss 0.00126139, acc 1
2016-09-05T18:31:09.064783: step 11967, loss 0.00143029, acc 1
2016-09-05T18:31:09.268215: step 11968, loss 0.00112842, acc 1
2016-09-05T18:31:09.477626: step 11969, loss 0.00119577, acc 1
2016-09-05T18:31:09.679768: step 11970, loss 0.00142904, acc 1
2016-09-05T18:31:09.880673: step 11971, loss 0.00140474, acc 1
2016-09-05T18:31:10.089574: step 11972, loss 0.00105359, acc 1
2016-09-05T18:31:10.318563: step 11973, loss 0.001305, acc 1
2016-09-05T18:31:10.521716: step 11974, loss 0.00103758, acc 1
2016-09-05T18:31:10.737082: step 11975, loss 0.00124494, acc 1
2016-09-05T18:31:10.950961: step 11976, loss 0.00113372, acc 1
2016-09-05T18:31:11.171141: step 11977, loss 0.00106641, acc 1
2016-09-05T18:31:11.373377: step 11978, loss 0.00116277, acc 1
2016-09-05T18:31:11.598459: step 11979, loss 0.00112987, acc 1
2016-09-05T18:31:11.819216: step 11980, loss 0.0012487, acc 1
2016-09-05T18:31:12.068269: step 11981, loss 0.00136748, acc 1
2016-09-05T18:31:12.297410: step 11982, loss 0.00103713, acc 1
2016-09-05T18:31:12.511779: step 11983, loss 0.00128664, acc 1
2016-09-05T18:31:12.719402: step 11984, loss 0.00102357, acc 1
2016-09-05T18:31:12.930653: step 11985, loss 0.00108251, acc 1
2016-09-05T18:31:13.153018: step 11986, loss 0.000971048, acc 1
2016-09-05T18:31:13.387812: step 11987, loss 0.00113016, acc 1
2016-09-05T18:31:13.610614: step 11988, loss 0.00114556, acc 1
2016-09-05T18:31:13.818182: step 11989, loss 0.00113818, acc 1
2016-09-05T18:31:14.056412: step 11990, loss 0.00118792, acc 1
2016-09-05T18:31:14.299782: step 11991, loss 0.00166444, acc 1
2016-09-05T18:31:14.505045: step 11992, loss 0.00109112, acc 1
2016-09-05T18:31:14.717758: step 11993, loss 0.0014995, acc 1
2016-09-05T18:31:14.927400: step 11994, loss 0.00158602, acc 1
2016-09-05T18:31:15.151551: step 11995, loss 0.00147279, acc 1
2016-09-05T18:31:15.380593: step 11996, loss 0.00126538, acc 1
2016-09-05T18:31:15.620986: step 11997, loss 0.00137303, acc 1
2016-09-05T18:31:15.826864: step 11998, loss 0.00100978, acc 1
2016-09-05T18:31:16.028314: step 11999, loss 0.00121649, acc 1
2016-09-05T18:31:16.237016: step 12000, loss 0.00119995, acc 1

Evaluation:
2016-09-05T18:31:16.873492: step 12000, loss 1.42483, acc 0.73

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-12000

2016-09-05T18:31:17.535094: step 12001, loss 0.00106591, acc 1
2016-09-05T18:31:17.741118: step 12002, loss 0.00133032, acc 1
2016-09-05T18:31:17.945272: step 12003, loss 0.00137476, acc 1
2016-09-05T18:31:18.143116: step 12004, loss 0.00104683, acc 1
2016-09-05T18:31:18.353755: step 12005, loss 0.0033706, acc 1
2016-09-05T18:31:18.558017: step 12006, loss 0.00144275, acc 1
2016-09-05T18:31:18.781881: step 12007, loss 0.00122368, acc 1
2016-09-05T18:31:18.995908: step 12008, loss 0.00114286, acc 1
2016-09-05T18:31:19.219689: step 12009, loss 0.00116715, acc 1
2016-09-05T18:31:19.455945: step 12010, loss 0.00106132, acc 1
2016-09-05T18:31:19.662209: step 12011, loss 0.00133343, acc 1
2016-09-05T18:31:19.894107: step 12012, loss 0.00169111, acc 1
2016-09-05T18:31:20.159354: step 12013, loss 0.00134922, acc 1
2016-09-05T18:31:20.390023: step 12014, loss 0.00140472, acc 1
2016-09-05T18:31:20.605015: step 12015, loss 0.00231207, acc 1
2016-09-05T18:31:20.824386: step 12016, loss 0.00119627, acc 1
2016-09-05T18:31:21.033436: step 12017, loss 0.00141422, acc 1
2016-09-05T18:31:21.269007: step 12018, loss 0.00110927, acc 1
2016-09-05T18:31:21.478653: step 12019, loss 0.00126228, acc 1
2016-09-05T18:31:21.701539: step 12020, loss 0.00108959, acc 1
2016-09-05T18:31:21.918717: step 12021, loss 0.00128359, acc 1
2016-09-05T18:31:22.138761: step 12022, loss 0.00113433, acc 1
2016-09-05T18:31:22.368646: step 12023, loss 0.00126062, acc 1
2016-09-05T18:31:22.571362: step 12024, loss 0.00128407, acc 1
2016-09-05T18:31:22.791490: step 12025, loss 0.00138797, acc 1
2016-09-05T18:31:23.000259: step 12026, loss 0.00170901, acc 1
2016-09-05T18:31:23.205296: step 12027, loss 0.00118744, acc 1
2016-09-05T18:31:23.347841: step 12028, loss 0.001284, acc 1
2016-09-05T18:31:23.590546: step 12029, loss 0.00108958, acc 1
2016-09-05T18:31:23.785434: step 12030, loss 0.00113056, acc 1
2016-09-05T18:31:24.001039: step 12031, loss 0.00121645, acc 1
2016-09-05T18:31:24.215860: step 12032, loss 0.00137563, acc 1
2016-09-05T18:31:24.451538: step 12033, loss 0.00107015, acc 1
2016-09-05T18:31:24.692760: step 12034, loss 0.00148881, acc 1
2016-09-05T18:31:24.918680: step 12035, loss 0.00127657, acc 1
2016-09-05T18:31:25.141440: step 12036, loss 0.00107068, acc 1
2016-09-05T18:31:25.362734: step 12037, loss 0.00103132, acc 1
2016-09-05T18:31:25.581857: step 12038, loss 0.00115246, acc 1
2016-09-05T18:31:25.818777: step 12039, loss 0.00113695, acc 1
2016-09-05T18:31:26.030894: step 12040, loss 0.00110633, acc 1
2016-09-05T18:31:26.243678: step 12041, loss 0.00111795, acc 1
2016-09-05T18:31:26.472290: step 12042, loss 0.00103652, acc 1
2016-09-05T18:31:26.716189: step 12043, loss 0.0011329, acc 1
2016-09-05T18:31:26.919404: step 12044, loss 0.00112646, acc 1
2016-09-05T18:31:27.145587: step 12045, loss 0.00108784, acc 1
2016-09-05T18:31:27.372335: step 12046, loss 0.00134027, acc 1
2016-09-05T18:31:27.596117: step 12047, loss 0.00112585, acc 1
2016-09-05T18:31:27.806355: step 12048, loss 0.00121307, acc 1
2016-09-05T18:31:28.023052: step 12049, loss 0.00102199, acc 1
2016-09-05T18:31:28.235900: step 12050, loss 0.00110283, acc 1
2016-09-05T18:31:28.445513: step 12051, loss 0.00107843, acc 1
2016-09-05T18:31:28.653930: step 12052, loss 0.000986442, acc 1
2016-09-05T18:31:28.879875: step 12053, loss 0.00126544, acc 1
2016-09-05T18:31:29.112876: step 12054, loss 0.000988393, acc 1
2016-09-05T18:31:29.337707: step 12055, loss 0.00122554, acc 1
2016-09-05T18:31:29.540675: step 12056, loss 0.00112867, acc 1
2016-09-05T18:31:29.756005: step 12057, loss 0.00202563, acc 1
2016-09-05T18:31:29.960147: step 12058, loss 0.00125606, acc 1
2016-09-05T18:31:30.199908: step 12059, loss 0.00133291, acc 1
2016-09-05T18:31:30.434150: step 12060, loss 0.00109791, acc 1
2016-09-05T18:31:30.652709: step 12061, loss 0.00104578, acc 1
2016-09-05T18:31:30.874298: step 12062, loss 0.00153042, acc 1
2016-09-05T18:31:31.105051: step 12063, loss 0.00158703, acc 1
2016-09-05T18:31:31.332152: step 12064, loss 0.00116993, acc 1
2016-09-05T18:31:31.533339: step 12065, loss 0.00108544, acc 1
2016-09-05T18:31:31.756173: step 12066, loss 0.00126883, acc 1
2016-09-05T18:31:31.968955: step 12067, loss 0.00107392, acc 1
2016-09-05T18:31:32.183313: step 12068, loss 0.0010348, acc 1
2016-09-05T18:31:32.395389: step 12069, loss 0.00104222, acc 1
2016-09-05T18:31:32.623048: step 12070, loss 0.00110552, acc 1
2016-09-05T18:31:32.855826: step 12071, loss 0.00112067, acc 1
2016-09-05T18:31:33.083133: step 12072, loss 0.0012288, acc 1
2016-09-05T18:31:33.296688: step 12073, loss 0.000962957, acc 1
2016-09-05T18:31:33.536986: step 12074, loss 0.00102062, acc 1
2016-09-05T18:31:33.767668: step 12075, loss 0.00120221, acc 1
2016-09-05T18:31:33.975359: step 12076, loss 0.000953531, acc 1
2016-09-05T18:31:34.196487: step 12077, loss 0.00100095, acc 1
2016-09-05T18:31:34.401977: step 12078, loss 0.00168632, acc 1
2016-09-05T18:31:34.610232: step 12079, loss 0.000976686, acc 1
2016-09-05T18:31:34.808713: step 12080, loss 0.000990547, acc 1
2016-09-05T18:31:35.021653: step 12081, loss 0.000980586, acc 1
2016-09-05T18:31:35.235839: step 12082, loss 0.00108941, acc 1
2016-09-05T18:31:35.459125: step 12083, loss 0.00139187, acc 1
2016-09-05T18:31:35.675657: step 12084, loss 0.000993009, acc 1
2016-09-05T18:31:35.919943: step 12085, loss 0.00109257, acc 1
2016-09-05T18:31:36.136843: step 12086, loss 0.00115766, acc 1
2016-09-05T18:31:36.362636: step 12087, loss 0.000990076, acc 1
2016-09-05T18:31:36.574448: step 12088, loss 0.00144781, acc 1
2016-09-05T18:31:36.778968: step 12089, loss 0.00123637, acc 1
2016-09-05T18:31:36.999010: step 12090, loss 0.00103123, acc 1
2016-09-05T18:31:37.217304: step 12091, loss 0.000952997, acc 1
2016-09-05T18:31:37.426833: step 12092, loss 0.00101897, acc 1
2016-09-05T18:31:37.633048: step 12093, loss 0.00163937, acc 1
2016-09-05T18:31:37.832498: step 12094, loss 0.00109624, acc 1
2016-09-05T18:31:38.044936: step 12095, loss 0.00112124, acc 1
2016-09-05T18:31:38.270452: step 12096, loss 0.000994325, acc 1
2016-09-05T18:31:38.474795: step 12097, loss 0.00124123, acc 1
2016-09-05T18:31:38.705875: step 12098, loss 0.00106408, acc 1
2016-09-05T18:31:38.942327: step 12099, loss 0.00113273, acc 1
2016-09-05T18:31:39.142091: step 12100, loss 0.00111693, acc 1

Evaluation:
2016-09-05T18:31:39.751702: step 12100, loss 1.39513, acc 0.729

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-12100

2016-09-05T18:31:40.452677: step 12101, loss 0.00101771, acc 1
2016-09-05T18:31:40.649374: step 12102, loss 0.0011194, acc 1
2016-09-05T18:31:40.845445: step 12103, loss 0.000998701, acc 1
2016-09-05T18:31:41.080317: step 12104, loss 0.00155166, acc 1
2016-09-05T18:31:41.297121: step 12105, loss 0.0010673, acc 1
2016-09-05T18:31:41.505313: step 12106, loss 0.00103629, acc 1
2016-09-05T18:31:41.736709: step 12107, loss 0.00100786, acc 1
2016-09-05T18:31:41.943412: step 12108, loss 0.00101738, acc 1
2016-09-05T18:31:42.171230: step 12109, loss 0.000990504, acc 1
2016-09-05T18:31:42.390752: step 12110, loss 0.00095842, acc 1
2016-09-05T18:31:42.619250: step 12111, loss 0.0011879, acc 1
2016-09-05T18:31:42.865481: step 12112, loss 0.00125844, acc 1
2016-09-05T18:31:43.088194: step 12113, loss 0.0010679, acc 1
2016-09-05T18:31:43.278523: step 12114, loss 0.00104195, acc 1
2016-09-05T18:31:43.506612: step 12115, loss 0.00120284, acc 1
2016-09-05T18:31:43.718273: step 12116, loss 0.00104413, acc 1
2016-09-05T18:31:43.931911: step 12117, loss 0.0010729, acc 1
2016-09-05T18:31:44.147478: step 12118, loss 0.00093468, acc 1
2016-09-05T18:31:44.374506: step 12119, loss 0.00116511, acc 1
2016-09-05T18:31:44.579570: step 12120, loss 0.0009109, acc 1
2016-09-05T18:31:44.791686: step 12121, loss 0.00112548, acc 1
2016-09-05T18:31:45.000070: step 12122, loss 0.000977986, acc 1
2016-09-05T18:31:45.198789: step 12123, loss 0.00100619, acc 1
2016-09-05T18:31:45.398810: step 12124, loss 0.00166262, acc 1
2016-09-05T18:31:45.615665: step 12125, loss 0.001272, acc 1
2016-09-05T18:31:45.837297: step 12126, loss 0.00160166, acc 1
2016-09-05T18:31:46.066064: step 12127, loss 0.00123411, acc 1
2016-09-05T18:31:46.289798: step 12128, loss 0.0010724, acc 1
2016-09-05T18:31:46.507439: step 12129, loss 0.00109598, acc 1
2016-09-05T18:31:46.731592: step 12130, loss 0.00132876, acc 1
2016-09-05T18:31:46.952282: step 12131, loss 0.000959648, acc 1
2016-09-05T18:31:47.172682: step 12132, loss 0.00109979, acc 1
2016-09-05T18:31:47.384281: step 12133, loss 0.00102984, acc 1
2016-09-05T18:31:47.610757: step 12134, loss 0.00118489, acc 1
2016-09-05T18:31:47.827269: step 12135, loss 0.00102197, acc 1
2016-09-05T18:31:48.058825: step 12136, loss 0.00114486, acc 1
2016-09-05T18:31:48.292469: step 12137, loss 0.00109221, acc 1
2016-09-05T18:31:48.505064: step 12138, loss 0.00103441, acc 1
2016-09-05T18:31:48.731539: step 12139, loss 0.000965854, acc 1
2016-09-05T18:31:48.939420: step 12140, loss 0.00122604, acc 1
2016-09-05T18:31:49.156506: step 12141, loss 0.00104921, acc 1
2016-09-05T18:31:49.371026: step 12142, loss 0.00136228, acc 1
2016-09-05T18:31:49.589550: step 12143, loss 0.00157792, acc 1
2016-09-05T18:31:49.807498: step 12144, loss 0.00103895, acc 1
2016-09-05T18:31:50.039775: step 12145, loss 0.00110463, acc 1
2016-09-05T18:31:50.252003: step 12146, loss 0.00110184, acc 1
2016-09-05T18:31:50.498967: step 12147, loss 0.00110344, acc 1
2016-09-05T18:31:50.757981: step 12148, loss 0.00106222, acc 1
2016-09-05T18:31:50.959490: step 12149, loss 0.00158022, acc 1
2016-09-05T18:31:51.174741: step 12150, loss 0.00122796, acc 1
2016-09-05T18:31:51.378897: step 12151, loss 0.0010959, acc 1
2016-09-05T18:31:51.610299: step 12152, loss 0.000984276, acc 1
2016-09-05T18:31:51.842174: step 12153, loss 0.00103512, acc 1
2016-09-05T18:31:52.078721: step 12154, loss 0.00111168, acc 1
2016-09-05T18:31:52.309554: step 12155, loss 0.00204512, acc 1
2016-09-05T18:31:52.566862: step 12156, loss 0.0016695, acc 1
2016-09-05T18:31:52.795744: step 12157, loss 0.00100171, acc 1
2016-09-05T18:31:53.017566: step 12158, loss 0.00110015, acc 1
2016-09-05T18:31:53.255944: step 12159, loss 0.000976812, acc 1
2016-09-05T18:31:53.475443: step 12160, loss 0.00097364, acc 1
2016-09-05T18:31:53.679864: step 12161, loss 0.00105979, acc 1
2016-09-05T18:31:53.879183: step 12162, loss 0.00110801, acc 1
2016-09-05T18:31:54.084495: step 12163, loss 0.00100292, acc 1
2016-09-05T18:31:54.288669: step 12164, loss 0.00100718, acc 1
2016-09-05T18:31:54.519782: step 12165, loss 0.00107695, acc 1
2016-09-05T18:31:54.751074: step 12166, loss 0.00101444, acc 1
2016-09-05T18:31:54.989382: step 12167, loss 0.00102111, acc 1
2016-09-05T18:31:55.202154: step 12168, loss 0.00131643, acc 1
2016-09-05T18:31:55.419026: step 12169, loss 0.00133096, acc 1
2016-09-05T18:31:55.644817: step 12170, loss 0.000978105, acc 1
2016-09-05T18:31:55.868298: step 12171, loss 0.000933591, acc 1
2016-09-05T18:31:56.120793: step 12172, loss 0.00123364, acc 1
2016-09-05T18:31:56.353688: step 12173, loss 0.00125245, acc 1
2016-09-05T18:31:56.580738: step 12174, loss 0.00110885, acc 1
2016-09-05T18:31:56.823757: step 12175, loss 0.00100787, acc 1
2016-09-05T18:31:57.045131: step 12176, loss 0.00102057, acc 1
2016-09-05T18:31:57.259402: step 12177, loss 0.00108292, acc 1
2016-09-05T18:31:57.503757: step 12178, loss 0.00109758, acc 1
2016-09-05T18:31:57.725016: step 12179, loss 0.0011143, acc 1
2016-09-05T18:31:57.951234: step 12180, loss 0.000960694, acc 1
2016-09-05T18:31:58.157366: step 12181, loss 0.00113124, acc 1
2016-09-05T18:31:58.403408: step 12182, loss 0.00139997, acc 1
2016-09-05T18:31:58.636000: step 12183, loss 0.000970408, acc 1
2016-09-05T18:31:58.872000: step 12184, loss 0.00127942, acc 1
2016-09-05T18:31:59.100334: step 12185, loss 0.00112644, acc 1
2016-09-05T18:31:59.334877: step 12186, loss 0.0012355, acc 1
2016-09-05T18:31:59.537335: step 12187, loss 0.00107883, acc 1
2016-09-05T18:31:59.741808: step 12188, loss 0.00129682, acc 1
2016-09-05T18:31:59.940008: step 12189, loss 0.00115262, acc 1
2016-09-05T18:32:00.157221: step 12190, loss 0.00143673, acc 1
2016-09-05T18:32:00.372718: step 12191, loss 0.00107906, acc 1
2016-09-05T18:32:00.570879: step 12192, loss 0.00112933, acc 1
2016-09-05T18:32:00.782534: step 12193, loss 0.00144648, acc 1
2016-09-05T18:32:01.009160: step 12194, loss 0.0010667, acc 1
2016-09-05T18:32:01.219865: step 12195, loss 0.000947076, acc 1
2016-09-05T18:32:01.433139: step 12196, loss 0.00163571, acc 1
2016-09-05T18:32:01.661066: step 12197, loss 0.000972355, acc 1
2016-09-05T18:32:01.867212: step 12198, loss 0.0011007, acc 1
2016-09-05T18:32:02.103856: step 12199, loss 0.00102477, acc 1
2016-09-05T18:32:02.331541: step 12200, loss 0.00111264, acc 1

Evaluation:
2016-09-05T18:32:02.949529: step 12200, loss 1.43327, acc 0.726

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-12200

2016-09-05T18:32:03.688350: step 12201, loss 0.00101807, acc 1
2016-09-05T18:32:03.893942: step 12202, loss 0.00115178, acc 1
2016-09-05T18:32:04.148555: step 12203, loss 0.00110409, acc 1
2016-09-05T18:32:04.366702: step 12204, loss 0.00106895, acc 1
2016-09-05T18:32:04.583867: step 12205, loss 0.00104086, acc 1
2016-09-05T18:32:04.787563: step 12206, loss 0.00105654, acc 1
2016-09-05T18:32:04.994790: step 12207, loss 0.00106035, acc 1
2016-09-05T18:32:05.208414: step 12208, loss 0.00109002, acc 1
2016-09-05T18:32:05.444290: step 12209, loss 0.00103853, acc 1
2016-09-05T18:32:05.670401: step 12210, loss 0.00106856, acc 1
2016-09-05T18:32:05.894016: step 12211, loss 0.00113707, acc 1
2016-09-05T18:32:06.109659: step 12212, loss 0.00103046, acc 1
2016-09-05T18:32:06.326393: step 12213, loss 0.000964188, acc 1
2016-09-05T18:32:06.555062: step 12214, loss 0.00114041, acc 1
2016-09-05T18:32:06.790490: step 12215, loss 0.00095364, acc 1
2016-09-05T18:32:07.007640: step 12216, loss 0.00217573, acc 1
2016-09-05T18:32:07.225344: step 12217, loss 0.00154526, acc 1
2016-09-05T18:32:07.475413: step 12218, loss 0.00100821, acc 1
2016-09-05T18:32:07.712103: step 12219, loss 0.000961776, acc 1
2016-09-05T18:32:07.922868: step 12220, loss 0.00207566, acc 1
2016-09-05T18:32:08.125993: step 12221, loss 0.0010813, acc 1
2016-09-05T18:32:08.301783: step 12222, loss 0.000921969, acc 1
2016-09-05T18:32:08.519107: step 12223, loss 0.001014, acc 1
2016-09-05T18:32:08.727816: step 12224, loss 0.00105277, acc 1
2016-09-05T18:32:08.940889: step 12225, loss 0.00145828, acc 1
2016-09-05T18:32:09.152701: step 12226, loss 0.00094924, acc 1
2016-09-05T18:32:09.372763: step 12227, loss 0.00103109, acc 1
2016-09-05T18:32:09.598013: step 12228, loss 0.00120293, acc 1
2016-09-05T18:32:09.829390: step 12229, loss 0.000962982, acc 1
2016-09-05T18:32:10.040903: step 12230, loss 0.00115473, acc 1
2016-09-05T18:32:10.269982: step 12231, loss 0.00110654, acc 1
2016-09-05T18:32:10.490091: step 12232, loss 0.0012979, acc 1
2016-09-05T18:32:10.721772: step 12233, loss 0.00144907, acc 1
2016-09-05T18:32:10.943649: step 12234, loss 0.00113426, acc 1
2016-09-05T18:32:11.144307: step 12235, loss 0.001887, acc 1
2016-09-05T18:32:11.373745: step 12236, loss 0.00104847, acc 1
2016-09-05T18:32:11.583898: step 12237, loss 0.00104335, acc 1
2016-09-05T18:32:11.815280: step 12238, loss 0.0011347, acc 1
2016-09-05T18:32:12.054194: step 12239, loss 0.00120188, acc 1
2016-09-05T18:32:12.279864: step 12240, loss 0.00104282, acc 1
2016-09-05T18:32:12.500202: step 12241, loss 0.000968151, acc 1
2016-09-05T18:32:12.722860: step 12242, loss 0.00121645, acc 1
2016-09-05T18:32:12.968722: step 12243, loss 0.000965128, acc 1
2016-09-05T18:32:13.184148: step 12244, loss 0.00100836, acc 1
2016-09-05T18:32:13.382837: step 12245, loss 0.00102517, acc 1
2016-09-05T18:32:13.582972: step 12246, loss 0.000987981, acc 1
2016-09-05T18:32:13.806832: step 12247, loss 0.00111199, acc 1
2016-09-05T18:32:14.029013: step 12248, loss 0.00114356, acc 1
2016-09-05T18:32:14.238284: step 12249, loss 0.00136461, acc 1
2016-09-05T18:32:14.459358: step 12250, loss 0.00114556, acc 1
2016-09-05T18:32:14.675866: step 12251, loss 0.00110014, acc 1
2016-09-05T18:32:14.871753: step 12252, loss 0.000997971, acc 1
2016-09-05T18:32:15.083037: step 12253, loss 0.0010244, acc 1
2016-09-05T18:32:15.289009: step 12254, loss 0.00124073, acc 1
2016-09-05T18:32:15.502073: step 12255, loss 0.000947207, acc 1
2016-09-05T18:32:15.707882: step 12256, loss 0.00107654, acc 1
2016-09-05T18:32:15.946212: step 12257, loss 0.00102704, acc 1
2016-09-05T18:32:16.179591: step 12258, loss 0.00157791, acc 1
2016-09-05T18:32:16.379098: step 12259, loss 0.000975527, acc 1
2016-09-05T18:32:16.607110: step 12260, loss 0.00094028, acc 1
2016-09-05T18:32:16.844159: step 12261, loss 0.000971012, acc 1
2016-09-05T18:32:17.082670: step 12262, loss 0.00103162, acc 1
2016-09-05T18:32:17.295370: step 12263, loss 0.000983076, acc 1
2016-09-05T18:32:17.508530: step 12264, loss 0.00105581, acc 1
2016-09-05T18:32:17.712135: step 12265, loss 0.00092401, acc 1
2016-09-05T18:32:17.928203: step 12266, loss 0.00104723, acc 1
2016-09-05T18:32:18.128929: step 12267, loss 0.00156351, acc 1
2016-09-05T18:32:18.361741: step 12268, loss 0.00116694, acc 1
2016-09-05T18:32:18.571831: step 12269, loss 0.0012245, acc 1
2016-09-05T18:32:18.774590: step 12270, loss 0.00113616, acc 1
2016-09-05T18:32:18.999247: step 12271, loss 0.000962052, acc 1
2016-09-05T18:32:19.225064: step 12272, loss 0.000977654, acc 1
2016-09-05T18:32:19.445077: step 12273, loss 0.000984862, acc 1
2016-09-05T18:32:19.658010: step 12274, loss 0.00138577, acc 1
2016-09-05T18:32:19.859933: step 12275, loss 0.000998013, acc 1
2016-09-05T18:32:20.064913: step 12276, loss 0.00119717, acc 1
2016-09-05T18:32:20.285841: step 12277, loss 0.00105954, acc 1
2016-09-05T18:32:20.509657: step 12278, loss 0.00162079, acc 1
2016-09-05T18:32:20.726786: step 12279, loss 0.00109892, acc 1
2016-09-05T18:32:20.941363: step 12280, loss 0.00103436, acc 1
2016-09-05T18:32:21.150102: step 12281, loss 0.00116193, acc 1
2016-09-05T18:32:21.360082: step 12282, loss 0.0011128, acc 1
2016-09-05T18:32:21.580510: step 12283, loss 0.000954583, acc 1
2016-09-05T18:32:21.806894: step 12284, loss 0.000951631, acc 1
2016-09-05T18:32:22.001931: step 12285, loss 0.000991724, acc 1
2016-09-05T18:32:22.241383: step 12286, loss 0.00138994, acc 1
2016-09-05T18:32:22.459259: step 12287, loss 0.000907651, acc 1
2016-09-05T18:32:22.670538: step 12288, loss 0.00111286, acc 1
2016-09-05T18:32:22.891635: step 12289, loss 0.000912465, acc 1
2016-09-05T18:32:23.115777: step 12290, loss 0.000966315, acc 1
2016-09-05T18:32:23.350718: step 12291, loss 0.000971294, acc 1
2016-09-05T18:32:23.581289: step 12292, loss 0.000936655, acc 1
2016-09-05T18:32:23.855426: step 12293, loss 0.00121396, acc 1
2016-09-05T18:32:24.065616: step 12294, loss 0.0010087, acc 1
2016-09-05T18:32:24.273289: step 12295, loss 0.000938218, acc 1
2016-09-05T18:32:24.482153: step 12296, loss 0.000989659, acc 1
2016-09-05T18:32:24.701824: step 12297, loss 0.00103709, acc 1
2016-09-05T18:32:24.912384: step 12298, loss 0.000966331, acc 1
2016-09-05T18:32:25.140671: step 12299, loss 0.000938722, acc 1
2016-09-05T18:32:25.361341: step 12300, loss 0.00103555, acc 1

Evaluation:
2016-09-05T18:32:25.973250: step 12300, loss 1.38656, acc 0.728

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-12300

2016-09-05T18:32:26.657711: step 12301, loss 0.00105219, acc 1
2016-09-05T18:32:26.894035: step 12302, loss 0.00111599, acc 1
2016-09-05T18:32:27.093976: step 12303, loss 0.000960234, acc 1
2016-09-05T18:32:27.314311: step 12304, loss 0.0010782, acc 1
2016-09-05T18:32:27.521155: step 12305, loss 0.00121437, acc 1
2016-09-05T18:32:27.730126: step 12306, loss 0.000878681, acc 1
2016-09-05T18:32:27.949581: step 12307, loss 0.00109522, acc 1
2016-09-05T18:32:28.184594: step 12308, loss 0.00135967, acc 1
2016-09-05T18:32:28.395855: step 12309, loss 0.000928277, acc 1
2016-09-05T18:32:28.606121: step 12310, loss 0.00108938, acc 1
2016-09-05T18:32:28.809480: step 12311, loss 0.00121617, acc 1
2016-09-05T18:32:29.004669: step 12312, loss 0.000948421, acc 1
2016-09-05T18:32:29.211458: step 12313, loss 0.0010061, acc 1
2016-09-05T18:32:29.439549: step 12314, loss 0.000865306, acc 1
2016-09-05T18:32:29.631319: step 12315, loss 0.00105501, acc 1
2016-09-05T18:32:29.859026: step 12316, loss 0.00104755, acc 1
2016-09-05T18:32:30.079699: step 12317, loss 0.00107924, acc 1
2016-09-05T18:32:30.314773: step 12318, loss 0.0010743, acc 1
2016-09-05T18:32:30.523628: step 12319, loss 0.00157806, acc 1
2016-09-05T18:32:30.718205: step 12320, loss 0.00112383, acc 1
2016-09-05T18:32:30.933839: step 12321, loss 0.00297378, acc 1
2016-09-05T18:32:31.129726: step 12322, loss 0.00101658, acc 1
2016-09-05T18:32:31.330462: step 12323, loss 0.00113103, acc 1
2016-09-05T18:32:31.528073: step 12324, loss 0.00156361, acc 1
2016-09-05T18:32:31.737677: step 12325, loss 0.0011771, acc 1
2016-09-05T18:32:31.939689: step 12326, loss 0.00163904, acc 1
2016-09-05T18:32:32.144458: step 12327, loss 0.00193907, acc 1
2016-09-05T18:32:32.344270: step 12328, loss 0.00134219, acc 1
2016-09-05T18:32:32.543381: step 12329, loss 0.00150779, acc 1
2016-09-05T18:32:32.747723: step 12330, loss 0.00132067, acc 1
2016-09-05T18:32:32.995261: step 12331, loss 0.00161559, acc 1
2016-09-05T18:32:33.208668: step 12332, loss 0.00119961, acc 1
2016-09-05T18:32:33.445579: step 12333, loss 0.00116663, acc 1
2016-09-05T18:32:33.663561: step 12334, loss 0.00119655, acc 1
2016-09-05T18:32:33.919624: step 12335, loss 0.00114914, acc 1
2016-09-05T18:32:34.156155: step 12336, loss 0.00123413, acc 1
2016-09-05T18:32:34.352964: step 12337, loss 0.00117379, acc 1
2016-09-05T18:32:34.566235: step 12338, loss 0.00116254, acc 1
2016-09-05T18:32:34.762510: step 12339, loss 0.00123398, acc 1
2016-09-05T18:32:34.969213: step 12340, loss 0.00114623, acc 1
2016-09-05T18:32:35.182987: step 12341, loss 0.00147483, acc 1
2016-09-05T18:32:35.401008: step 12342, loss 0.00115145, acc 1
2016-09-05T18:32:35.612736: step 12343, loss 0.00121814, acc 1
2016-09-05T18:32:35.852006: step 12344, loss 0.00119181, acc 1
2016-09-05T18:32:36.056910: step 12345, loss 0.00137362, acc 1
2016-09-05T18:32:36.279625: step 12346, loss 0.00117211, acc 1
2016-09-05T18:32:36.478469: step 12347, loss 0.00114473, acc 1
2016-09-05T18:32:36.698812: step 12348, loss 0.00113418, acc 1
2016-09-05T18:32:36.908054: step 12349, loss 0.00126714, acc 1
2016-09-05T18:32:37.147245: step 12350, loss 0.00135566, acc 1
2016-09-05T18:32:37.365814: step 12351, loss 0.00115615, acc 1
2016-09-05T18:32:37.577449: step 12352, loss 0.00117212, acc 1
2016-09-05T18:32:37.780390: step 12353, loss 0.00136885, acc 1
2016-09-05T18:32:37.973570: step 12354, loss 0.00109514, acc 1
2016-09-05T18:32:38.184262: step 12355, loss 0.00122206, acc 1
2016-09-05T18:32:38.385690: step 12356, loss 0.00116686, acc 1
2016-09-05T18:32:38.597190: step 12357, loss 0.00119803, acc 1
2016-09-05T18:32:38.837519: step 12358, loss 0.00105812, acc 1
2016-09-05T18:32:39.059883: step 12359, loss 0.00106887, acc 1
2016-09-05T18:32:39.267452: step 12360, loss 0.00114813, acc 1
2016-09-05T18:32:39.497726: step 12361, loss 0.0015561, acc 1
2016-09-05T18:32:39.709464: step 12362, loss 0.00149689, acc 1
2016-09-05T18:32:39.916362: step 12363, loss 0.00106943, acc 1
2016-09-05T18:32:40.132712: step 12364, loss 0.00111148, acc 1
2016-09-05T18:32:40.354352: step 12365, loss 0.000961417, acc 1
2016-09-05T18:32:40.577440: step 12366, loss 0.00106, acc 1
2016-09-05T18:32:40.789421: step 12367, loss 0.00103145, acc 1
2016-09-05T18:32:41.015469: step 12368, loss 0.00108022, acc 1
2016-09-05T18:32:41.250435: step 12369, loss 0.00132015, acc 1
2016-09-05T18:32:41.481406: step 12370, loss 0.0010058, acc 1
2016-09-05T18:32:41.680611: step 12371, loss 0.00134839, acc 1
2016-09-05T18:32:41.915762: step 12372, loss 0.00113764, acc 1
2016-09-05T18:32:42.112352: step 12373, loss 0.00150617, acc 1
2016-09-05T18:32:42.318010: step 12374, loss 0.00112883, acc 1
2016-09-05T18:32:42.517422: step 12375, loss 0.0017108, acc 1
2016-09-05T18:32:42.723587: step 12376, loss 0.000972703, acc 1
2016-09-05T18:32:42.911904: step 12377, loss 0.00144687, acc 1
2016-09-05T18:32:43.129134: step 12378, loss 0.000960625, acc 1
2016-09-05T18:32:43.355999: step 12379, loss 0.00101508, acc 1
2016-09-05T18:32:43.607904: step 12380, loss 0.000959631, acc 1
2016-09-05T18:32:43.839438: step 12381, loss 0.00105051, acc 1
2016-09-05T18:32:44.033561: step 12382, loss 0.00118088, acc 1
2016-09-05T18:32:44.245815: step 12383, loss 0.00102178, acc 1
2016-09-05T18:32:44.458829: step 12384, loss 0.00100712, acc 1
2016-09-05T18:32:44.674688: step 12385, loss 0.000984991, acc 1
2016-09-05T18:32:44.901629: step 12386, loss 0.000935181, acc 1
2016-09-05T18:32:45.137849: step 12387, loss 0.00113208, acc 1
2016-09-05T18:32:45.353551: step 12388, loss 0.001094, acc 1
2016-09-05T18:32:45.610049: step 12389, loss 0.00119704, acc 1
2016-09-05T18:32:45.849976: step 12390, loss 0.00130863, acc 1
2016-09-05T18:32:46.058170: step 12391, loss 0.00105743, acc 1
2016-09-05T18:32:46.338333: step 12392, loss 0.00116847, acc 1
2016-09-05T18:32:46.563082: step 12393, loss 0.00115656, acc 1
2016-09-05T18:32:46.768986: step 12394, loss 0.0011665, acc 1
2016-09-05T18:32:46.978643: step 12395, loss 0.0010815, acc 1
2016-09-05T18:32:47.181201: step 12396, loss 0.00132797, acc 1
2016-09-05T18:32:47.393565: step 12397, loss 0.0011908, acc 1
2016-09-05T18:32:47.628223: step 12398, loss 0.00126001, acc 1
2016-09-05T18:32:47.858050: step 12399, loss 0.000990598, acc 1
2016-09-05T18:32:48.057181: step 12400, loss 0.00120401, acc 1

Evaluation:
2016-09-05T18:32:48.652875: step 12400, loss 1.41532, acc 0.727

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-12400

2016-09-05T18:32:49.393676: step 12401, loss 0.00130125, acc 1
2016-09-05T18:32:49.602958: step 12402, loss 0.00103821, acc 1
2016-09-05T18:32:49.813915: step 12403, loss 0.00118739, acc 1
2016-09-05T18:32:50.058513: step 12404, loss 0.00180827, acc 1
2016-09-05T18:32:50.279552: step 12405, loss 0.00120352, acc 1
2016-09-05T18:32:50.474366: step 12406, loss 0.0011864, acc 1
2016-09-05T18:32:50.678621: step 12407, loss 0.00120239, acc 1
2016-09-05T18:32:50.893882: step 12408, loss 0.00134688, acc 1
2016-09-05T18:32:51.130407: step 12409, loss 0.000926633, acc 1
2016-09-05T18:32:51.364601: step 12410, loss 0.00135507, acc 1
2016-09-05T18:32:51.593625: step 12411, loss 0.0025768, acc 1
2016-09-05T18:32:51.810358: step 12412, loss 0.00148709, acc 1
2016-09-05T18:32:52.033808: step 12413, loss 0.00101715, acc 1
2016-09-05T18:32:52.281153: step 12414, loss 0.00141156, acc 1
2016-09-05T18:32:52.484120: step 12415, loss 0.0011305, acc 1
2016-09-05T18:32:52.636752: step 12416, loss 0.0010247, acc 1
2016-09-05T18:32:52.865479: step 12417, loss 0.00104521, acc 1
2016-09-05T18:32:53.101411: step 12418, loss 0.00125182, acc 1
2016-09-05T18:32:53.317285: step 12419, loss 0.00105109, acc 1
2016-09-05T18:32:53.535759: step 12420, loss 0.00107043, acc 1
2016-09-05T18:32:53.746148: step 12421, loss 0.00106867, acc 1
2016-09-05T18:32:53.974951: step 12422, loss 0.00109981, acc 1
2016-09-05T18:32:54.205529: step 12423, loss 0.00103938, acc 1
2016-09-05T18:32:54.412137: step 12424, loss 0.00120718, acc 1
2016-09-05T18:32:54.619637: step 12425, loss 0.00112212, acc 1
2016-09-05T18:32:54.828947: step 12426, loss 0.0010252, acc 1
2016-09-05T18:32:55.040124: step 12427, loss 0.00107613, acc 1
2016-09-05T18:32:55.250030: step 12428, loss 0.00105858, acc 1
2016-09-05T18:32:55.479228: step 12429, loss 0.00113261, acc 1
2016-09-05T18:32:55.711484: step 12430, loss 0.00107092, acc 1
2016-09-05T18:32:55.921199: step 12431, loss 0.00109526, acc 1
2016-09-05T18:32:56.152367: step 12432, loss 0.00141683, acc 1
2016-09-05T18:32:56.366454: step 12433, loss 0.00106053, acc 1
2016-09-05T18:32:56.588715: step 12434, loss 0.00132746, acc 1
2016-09-05T18:32:56.792239: step 12435, loss 0.00100452, acc 1
2016-09-05T18:32:57.023586: step 12436, loss 0.00096187, acc 1
2016-09-05T18:32:57.240546: step 12437, loss 0.00105435, acc 1
2016-09-05T18:32:57.458192: step 12438, loss 0.0010189, acc 1
2016-09-05T18:32:57.682401: step 12439, loss 0.00109979, acc 1
2016-09-05T18:32:57.903192: step 12440, loss 0.00108892, acc 1
2016-09-05T18:32:58.147188: step 12441, loss 0.00117376, acc 1
2016-09-05T18:32:58.358962: step 12442, loss 0.00111605, acc 1
2016-09-05T18:32:58.562949: step 12443, loss 0.00089375, acc 1
2016-09-05T18:32:58.787263: step 12444, loss 0.000981374, acc 1
2016-09-05T18:32:59.013753: step 12445, loss 0.000963517, acc 1
2016-09-05T18:32:59.233716: step 12446, loss 0.00103085, acc 1
2016-09-05T18:32:59.450604: step 12447, loss 0.00126799, acc 1
2016-09-05T18:32:59.662004: step 12448, loss 0.00105685, acc 1
2016-09-05T18:32:59.875942: step 12449, loss 0.000966949, acc 1
2016-09-05T18:33:00.104143: step 12450, loss 0.000953896, acc 1
2016-09-05T18:33:00.342014: step 12451, loss 0.00101399, acc 1
2016-09-05T18:33:00.544947: step 12452, loss 0.00128375, acc 1
2016-09-05T18:33:00.758510: step 12453, loss 0.00102728, acc 1
2016-09-05T18:33:00.953733: step 12454, loss 0.00104666, acc 1
2016-09-05T18:33:01.163217: step 12455, loss 0.00103582, acc 1
2016-09-05T18:33:01.362206: step 12456, loss 0.00089125, acc 1
2016-09-05T18:33:01.570780: step 12457, loss 0.00112695, acc 1
2016-09-05T18:33:01.780558: step 12458, loss 0.00106111, acc 1
2016-09-05T18:33:02.009405: step 12459, loss 0.00109879, acc 1
2016-09-05T18:33:02.217388: step 12460, loss 0.000932764, acc 1
2016-09-05T18:33:02.436951: step 12461, loss 0.000918102, acc 1
2016-09-05T18:33:02.639352: step 12462, loss 0.000921243, acc 1
2016-09-05T18:33:02.846077: step 12463, loss 0.00107322, acc 1
2016-09-05T18:33:03.049493: step 12464, loss 0.000939962, acc 1
2016-09-05T18:33:03.270759: step 12465, loss 0.00105479, acc 1
2016-09-05T18:33:03.480136: step 12466, loss 0.00104393, acc 1
2016-09-05T18:33:03.706545: step 12467, loss 0.000897473, acc 1
2016-09-05T18:33:03.912232: step 12468, loss 0.00149297, acc 1
2016-09-05T18:33:04.134526: step 12469, loss 0.00087005, acc 1
2016-09-05T18:33:04.355145: step 12470, loss 0.000957391, acc 1
2016-09-05T18:33:04.554035: step 12471, loss 0.000937962, acc 1
2016-09-05T18:33:04.780839: step 12472, loss 0.00105909, acc 1
2016-09-05T18:33:04.994178: step 12473, loss 0.000900347, acc 1
2016-09-05T18:33:05.209113: step 12474, loss 0.00109283, acc 1
2016-09-05T18:33:05.419270: step 12475, loss 0.00106742, acc 1
2016-09-05T18:33:05.658040: step 12476, loss 0.00107518, acc 1
2016-09-05T18:33:05.882629: step 12477, loss 0.00105885, acc 1
2016-09-05T18:33:06.107015: step 12478, loss 0.0011027, acc 1
2016-09-05T18:33:06.315234: step 12479, loss 0.00108654, acc 1
2016-09-05T18:33:06.535391: step 12480, loss 0.00108505, acc 1
2016-09-05T18:33:06.744607: step 12481, loss 0.00129754, acc 1
2016-09-05T18:33:06.958843: step 12482, loss 0.000935194, acc 1
2016-09-05T18:33:07.181353: step 12483, loss 0.00103593, acc 1
2016-09-05T18:33:07.407081: step 12484, loss 0.000966336, acc 1
2016-09-05T18:33:07.618590: step 12485, loss 0.00100281, acc 1
2016-09-05T18:33:07.830450: step 12486, loss 0.0010332, acc 1
2016-09-05T18:33:08.058949: step 12487, loss 0.000946569, acc 1
2016-09-05T18:33:08.285433: step 12488, loss 0.000969207, acc 1
2016-09-05T18:33:08.514265: step 12489, loss 0.000926446, acc 1
2016-09-05T18:33:08.705774: step 12490, loss 0.000945211, acc 1
2016-09-05T18:33:08.929421: step 12491, loss 0.000910126, acc 1
2016-09-05T18:33:09.149681: step 12492, loss 0.000965755, acc 1
2016-09-05T18:33:09.388488: step 12493, loss 0.00117228, acc 1
2016-09-05T18:33:09.619659: step 12494, loss 0.00130848, acc 1
2016-09-05T18:33:09.806506: step 12495, loss 0.000870075, acc 1
2016-09-05T18:33:10.044393: step 12496, loss 0.00114895, acc 1
2016-09-05T18:33:10.248729: step 12497, loss 0.000974045, acc 1
2016-09-05T18:33:10.466076: step 12498, loss 0.000969639, acc 1
2016-09-05T18:33:10.684608: step 12499, loss 0.0011137, acc 1
2016-09-05T18:33:10.925297: step 12500, loss 0.000844422, acc 1

Evaluation:
2016-09-05T18:33:11.505421: step 12500, loss 1.4104, acc 0.728

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-12500

2016-09-05T18:33:12.218750: step 12501, loss 0.000968385, acc 1
2016-09-05T18:33:12.445412: step 12502, loss 0.00122533, acc 1
2016-09-05T18:33:12.670342: step 12503, loss 0.000978454, acc 1
2016-09-05T18:33:12.912721: step 12504, loss 0.000957764, acc 1
2016-09-05T18:33:13.123144: step 12505, loss 0.00110335, acc 1
2016-09-05T18:33:13.379323: step 12506, loss 0.000969634, acc 1
2016-09-05T18:33:13.582615: step 12507, loss 0.000943761, acc 1
2016-09-05T18:33:13.792215: step 12508, loss 0.00106255, acc 1
2016-09-05T18:33:14.000262: step 12509, loss 0.00089962, acc 1
2016-09-05T18:33:14.220285: step 12510, loss 0.00091896, acc 1
2016-09-05T18:33:14.447417: step 12511, loss 0.000959654, acc 1
2016-09-05T18:33:14.699708: step 12512, loss 0.00100697, acc 1
2016-09-05T18:33:14.911883: step 12513, loss 0.000824969, acc 1
2016-09-05T18:33:15.131876: step 12514, loss 0.0013912, acc 1
2016-09-05T18:33:15.378061: step 12515, loss 0.00177194, acc 1
2016-09-05T18:33:15.564014: step 12516, loss 0.00093551, acc 1
2016-09-05T18:33:15.807941: step 12517, loss 0.00107319, acc 1
2016-09-05T18:33:16.033965: step 12518, loss 0.00104525, acc 1
2016-09-05T18:33:16.250947: step 12519, loss 0.000870087, acc 1
2016-09-05T18:33:16.466668: step 12520, loss 0.000915025, acc 1
2016-09-05T18:33:16.691154: step 12521, loss 0.00124879, acc 1
2016-09-05T18:33:16.896615: step 12522, loss 0.00106762, acc 1
2016-09-05T18:33:17.123789: step 12523, loss 0.00103502, acc 1
2016-09-05T18:33:17.313471: step 12524, loss 0.000896883, acc 1
2016-09-05T18:33:17.518956: step 12525, loss 0.00135632, acc 1
2016-09-05T18:33:17.751263: step 12526, loss 0.00109601, acc 1
2016-09-05T18:33:17.953841: step 12527, loss 0.000881072, acc 1
2016-09-05T18:33:18.181391: step 12528, loss 0.00105198, acc 1
2016-09-05T18:33:18.409535: step 12529, loss 0.00124184, acc 1
2016-09-05T18:33:18.626897: step 12530, loss 0.00090733, acc 1
2016-09-05T18:33:18.830817: step 12531, loss 0.000921977, acc 1
2016-09-05T18:33:19.035844: step 12532, loss 0.000965487, acc 1
2016-09-05T18:33:19.246328: step 12533, loss 0.00122917, acc 1
2016-09-05T18:33:19.452012: step 12534, loss 0.00105594, acc 1
2016-09-05T18:33:19.663092: step 12535, loss 0.000904344, acc 1
2016-09-05T18:33:19.885272: step 12536, loss 0.0011263, acc 1
2016-09-05T18:33:20.118008: step 12537, loss 0.0009782, acc 1
2016-09-05T18:33:20.344500: step 12538, loss 0.00110526, acc 1
2016-09-05T18:33:20.567694: step 12539, loss 0.00125707, acc 1
2016-09-05T18:33:20.817414: step 12540, loss 0.00097131, acc 1
2016-09-05T18:33:21.014691: step 12541, loss 0.00140612, acc 1
2016-09-05T18:33:21.238189: step 12542, loss 0.000870968, acc 1
2016-09-05T18:33:21.461155: step 12543, loss 0.00108055, acc 1
2016-09-05T18:33:21.667391: step 12544, loss 0.0013068, acc 1
2016-09-05T18:33:21.885574: step 12545, loss 0.00126464, acc 1
2016-09-05T18:33:22.106210: step 12546, loss 0.000932827, acc 1
2016-09-05T18:33:22.343962: step 12547, loss 0.000986169, acc 1
2016-09-05T18:33:22.551524: step 12548, loss 0.000951631, acc 1
2016-09-05T18:33:22.773711: step 12549, loss 0.000993963, acc 1
2016-09-05T18:33:22.989430: step 12550, loss 0.00104363, acc 1
2016-09-05T18:33:23.211181: step 12551, loss 0.000965957, acc 1
2016-09-05T18:33:23.426291: step 12552, loss 0.000980464, acc 1
2016-09-05T18:33:23.661067: step 12553, loss 0.000909021, acc 1
2016-09-05T18:33:23.883292: step 12554, loss 0.000945908, acc 1
2016-09-05T18:33:24.089974: step 12555, loss 0.000941567, acc 1
2016-09-05T18:33:24.306308: step 12556, loss 0.00104606, acc 1
2016-09-05T18:33:24.525941: step 12557, loss 0.0010502, acc 1
2016-09-05T18:33:24.751451: step 12558, loss 0.000889104, acc 1
2016-09-05T18:33:24.949497: step 12559, loss 0.00124278, acc 1
2016-09-05T18:33:25.177514: step 12560, loss 0.0010007, acc 1
2016-09-05T18:33:25.401564: step 12561, loss 0.000976346, acc 1
2016-09-05T18:33:25.634797: step 12562, loss 0.000845806, acc 1
2016-09-05T18:33:25.856879: step 12563, loss 0.00107972, acc 1
2016-09-05T18:33:26.075616: step 12564, loss 0.000910065, acc 1
2016-09-05T18:33:26.278316: step 12565, loss 0.000970725, acc 1
2016-09-05T18:33:26.503447: step 12566, loss 0.00104042, acc 1
2016-09-05T18:33:26.708904: step 12567, loss 0.00139176, acc 1
2016-09-05T18:33:26.952443: step 12568, loss 0.00111804, acc 1
2016-09-05T18:33:27.180529: step 12569, loss 0.000998669, acc 1
2016-09-05T18:33:27.389071: step 12570, loss 0.00106133, acc 1
2016-09-05T18:33:27.603530: step 12571, loss 0.00122295, acc 1
2016-09-05T18:33:27.821196: step 12572, loss 0.00112022, acc 1
2016-09-05T18:33:28.037165: step 12573, loss 0.0010406, acc 1
2016-09-05T18:33:28.274875: step 12574, loss 0.001063, acc 1
2016-09-05T18:33:28.491329: step 12575, loss 0.000848333, acc 1
2016-09-05T18:33:28.702870: step 12576, loss 0.000918059, acc 1
2016-09-05T18:33:28.919882: step 12577, loss 0.00096569, acc 1
2016-09-05T18:33:29.141423: step 12578, loss 0.000979886, acc 1
2016-09-05T18:33:29.353242: step 12579, loss 0.00093864, acc 1
2016-09-05T18:33:29.572510: step 12580, loss 0.00123199, acc 1
2016-09-05T18:33:29.804616: step 12581, loss 0.000936437, acc 1
2016-09-05T18:33:30.021903: step 12582, loss 0.00089849, acc 1
2016-09-05T18:33:30.229625: step 12583, loss 0.00108985, acc 1
2016-09-05T18:33:30.474761: step 12584, loss 0.00093076, acc 1
2016-09-05T18:33:30.720758: step 12585, loss 0.000884127, acc 1
2016-09-05T18:33:30.948196: step 12586, loss 0.00125266, acc 1
2016-09-05T18:33:31.175763: step 12587, loss 0.000951443, acc 1
2016-09-05T18:33:31.412406: step 12588, loss 0.000863451, acc 1
2016-09-05T18:33:31.630194: step 12589, loss 0.00104802, acc 1
2016-09-05T18:33:31.834823: step 12590, loss 0.00105715, acc 1
2016-09-05T18:33:32.057837: step 12591, loss 0.00116012, acc 1
2016-09-05T18:33:32.281273: step 12592, loss 0.00130321, acc 1
2016-09-05T18:33:32.517928: step 12593, loss 0.00213013, acc 1
2016-09-05T18:33:32.721501: step 12594, loss 0.000881222, acc 1
2016-09-05T18:33:32.935079: step 12595, loss 0.00104367, acc 1
2016-09-05T18:33:33.146588: step 12596, loss 0.000998836, acc 1
2016-09-05T18:33:33.371051: step 12597, loss 0.000936685, acc 1
2016-09-05T18:33:33.617406: step 12598, loss 0.00101689, acc 1
2016-09-05T18:33:33.855978: step 12599, loss 0.00131422, acc 1
2016-09-05T18:33:34.066448: step 12600, loss 0.00107058, acc 1

Evaluation:
2016-09-05T18:33:34.677242: step 12600, loss 1.42707, acc 0.734

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-12600

2016-09-05T18:33:35.497013: step 12601, loss 0.00112246, acc 1
2016-09-05T18:33:35.765639: step 12602, loss 0.00102399, acc 1
2016-09-05T18:33:35.962258: step 12603, loss 0.000993358, acc 1
2016-09-05T18:33:36.166702: step 12604, loss 0.00136192, acc 1
2016-09-05T18:33:36.367082: step 12605, loss 0.00114945, acc 1
2016-09-05T18:33:36.579664: step 12606, loss 0.00102571, acc 1
2016-09-05T18:33:36.783934: step 12607, loss 0.00106227, acc 1
2016-09-05T18:33:36.985087: step 12608, loss 0.00189909, acc 1
2016-09-05T18:33:37.194462: step 12609, loss 0.000947961, acc 1
2016-09-05T18:33:37.385713: step 12610, loss 0.00122459, acc 1
2016-09-05T18:33:37.597745: step 12611, loss 0.00117355, acc 1
2016-09-05T18:33:37.803959: step 12612, loss 0.00101176, acc 1
2016-09-05T18:33:37.999708: step 12613, loss 0.00135826, acc 1
2016-09-05T18:33:38.208118: step 12614, loss 0.000975858, acc 1
2016-09-05T18:33:38.430371: step 12615, loss 0.001032, acc 1
2016-09-05T18:33:38.656093: step 12616, loss 0.000965617, acc 1
2016-09-05T18:33:38.877416: step 12617, loss 0.00121289, acc 1
2016-09-05T18:33:39.115236: step 12618, loss 0.00118648, acc 1
2016-09-05T18:33:39.336609: step 12619, loss 0.000952486, acc 1
2016-09-05T18:33:39.587902: step 12620, loss 0.00109344, acc 1
2016-09-05T18:33:39.803803: step 12621, loss 0.00105541, acc 1
2016-09-05T18:33:40.014570: step 12622, loss 0.00107247, acc 1
2016-09-05T18:33:40.233898: step 12623, loss 0.00110604, acc 1
2016-09-05T18:33:40.431868: step 12624, loss 0.00101197, acc 1
2016-09-05T18:33:40.631918: step 12625, loss 0.00117184, acc 1
2016-09-05T18:33:40.837128: step 12626, loss 0.00119274, acc 1
2016-09-05T18:33:41.061234: step 12627, loss 0.000994818, acc 1
2016-09-05T18:33:41.312031: step 12628, loss 0.00116231, acc 1
2016-09-05T18:33:41.512498: step 12629, loss 0.00116626, acc 1
2016-09-05T18:33:41.721643: step 12630, loss 0.000931291, acc 1
2016-09-05T18:33:41.930452: step 12631, loss 0.000904234, acc 1
2016-09-05T18:33:42.161376: step 12632, loss 0.00118925, acc 1
2016-09-05T18:33:42.392323: step 12633, loss 0.00101724, acc 1
2016-09-05T18:33:42.605500: step 12634, loss 0.000922223, acc 1
2016-09-05T18:33:42.821510: step 12635, loss 0.00101137, acc 1
2016-09-05T18:33:43.026940: step 12636, loss 0.000851769, acc 1
2016-09-05T18:33:43.237744: step 12637, loss 0.00110232, acc 1
2016-09-05T18:33:43.473202: step 12638, loss 0.00132478, acc 1
2016-09-05T18:33:43.686409: step 12639, loss 0.000876616, acc 1
2016-09-05T18:33:43.900738: step 12640, loss 0.000966883, acc 1
2016-09-05T18:33:44.129457: step 12641, loss 0.000939764, acc 1
2016-09-05T18:33:44.342546: step 12642, loss 0.000906689, acc 1
2016-09-05T18:33:44.564980: step 12643, loss 0.000966517, acc 1
2016-09-05T18:33:44.778906: step 12644, loss 0.00133937, acc 1
2016-09-05T18:33:45.007950: step 12645, loss 0.000975077, acc 1
2016-09-05T18:33:45.215302: step 12646, loss 0.000990362, acc 1
2016-09-05T18:33:45.459704: step 12647, loss 0.0013627, acc 1
2016-09-05T18:33:45.664908: step 12648, loss 0.000994347, acc 1
2016-09-05T18:33:45.888061: step 12649, loss 0.00110458, acc 1
2016-09-05T18:33:46.092794: step 12650, loss 0.000925832, acc 1
2016-09-05T18:33:46.316752: step 12651, loss 0.00089229, acc 1
2016-09-05T18:33:46.537573: step 12652, loss 0.000989423, acc 1
2016-09-05T18:33:46.773988: step 12653, loss 0.00134598, acc 1
2016-09-05T18:33:47.006579: step 12654, loss 0.000994382, acc 1
2016-09-05T18:33:47.202679: step 12655, loss 0.000853645, acc 1
2016-09-05T18:33:47.431908: step 12656, loss 0.00101334, acc 1
2016-09-05T18:33:47.647132: step 12657, loss 0.000883589, acc 1
2016-09-05T18:33:47.866690: step 12658, loss 0.000942603, acc 1
2016-09-05T18:33:48.079855: step 12659, loss 0.00111672, acc 1
2016-09-05T18:33:48.294321: step 12660, loss 0.00246839, acc 1
2016-09-05T18:33:48.514368: step 12661, loss 0.000848604, acc 1
2016-09-05T18:33:48.737450: step 12662, loss 0.00123589, acc 1
2016-09-05T18:33:48.949363: step 12663, loss 0.000995535, acc 1
2016-09-05T18:33:49.156267: step 12664, loss 0.00111046, acc 1
2016-09-05T18:33:49.397201: step 12665, loss 0.000923023, acc 1
2016-09-05T18:33:49.584683: step 12666, loss 0.00101162, acc 1
2016-09-05T18:33:49.807956: step 12667, loss 0.00185724, acc 1
2016-09-05T18:33:50.017854: step 12668, loss 0.00152192, acc 1
2016-09-05T18:33:50.227504: step 12669, loss 0.000977556, acc 1
2016-09-05T18:33:50.449467: step 12670, loss 0.00107206, acc 1
2016-09-05T18:33:50.698384: step 12671, loss 0.00110118, acc 1
2016-09-05T18:33:50.908757: step 12672, loss 0.00108755, acc 1
2016-09-05T18:33:51.135053: step 12673, loss 0.0013055, acc 1
2016-09-05T18:33:51.362229: step 12674, loss 0.00100903, acc 1
2016-09-05T18:33:51.589785: step 12675, loss 0.00116268, acc 1
2016-09-05T18:33:51.811771: step 12676, loss 0.00111128, acc 1
2016-09-05T18:33:52.019101: step 12677, loss 0.00102913, acc 1
2016-09-05T18:33:52.225921: step 12678, loss 0.000998494, acc 1
2016-09-05T18:33:52.426149: step 12679, loss 0.00099185, acc 1
2016-09-05T18:33:52.634334: step 12680, loss 0.00104262, acc 1
2016-09-05T18:33:52.860252: step 12681, loss 0.000992522, acc 1
2016-09-05T18:33:53.091016: step 12682, loss 0.000997008, acc 1
2016-09-05T18:33:53.319841: step 12683, loss 0.000970886, acc 1
2016-09-05T18:33:53.552592: step 12684, loss 0.00102614, acc 1
2016-09-05T18:33:53.773844: step 12685, loss 0.000936505, acc 1
2016-09-05T18:33:54.002912: step 12686, loss 0.00188814, acc 1
2016-09-05T18:33:54.237180: step 12687, loss 0.00102976, acc 1
2016-09-05T18:33:54.447214: step 12688, loss 0.00101647, acc 1
2016-09-05T18:33:54.653987: step 12689, loss 0.00113122, acc 1
2016-09-05T18:33:54.848174: step 12690, loss 0.00115471, acc 1
2016-09-05T18:33:55.058655: step 12691, loss 0.00155486, acc 1
2016-09-05T18:33:55.265925: step 12692, loss 0.0010863, acc 1
2016-09-05T18:33:55.496342: step 12693, loss 0.00105834, acc 1
2016-09-05T18:33:55.708504: step 12694, loss 0.00108011, acc 1
2016-09-05T18:33:55.926931: step 12695, loss 0.00123702, acc 1
2016-09-05T18:33:56.173411: step 12696, loss 0.00124925, acc 1
2016-09-05T18:33:56.380209: step 12697, loss 0.00120638, acc 1
2016-09-05T18:33:56.623690: step 12698, loss 0.00122167, acc 1
2016-09-05T18:33:56.829486: step 12699, loss 0.00100604, acc 1
2016-09-05T18:33:57.061396: step 12700, loss 0.00114941, acc 1

Evaluation:
2016-09-05T18:33:57.661922: step 12700, loss 1.506, acc 0.718

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-12700

2016-09-05T18:33:58.408649: step 12701, loss 0.00112176, acc 1
2016-09-05T18:33:58.612343: step 12702, loss 0.000907417, acc 1
2016-09-05T18:33:58.850672: step 12703, loss 0.00108195, acc 1
2016-09-05T18:33:59.109288: step 12704, loss 0.00101683, acc 1
2016-09-05T18:33:59.313903: step 12705, loss 0.0010211, acc 1
2016-09-05T18:33:59.529996: step 12706, loss 0.000980037, acc 1
2016-09-05T18:33:59.735772: step 12707, loss 0.00107631, acc 1
2016-09-05T18:33:59.944616: step 12708, loss 0.000998072, acc 1
2016-09-05T18:34:00.152823: step 12709, loss 0.000953499, acc 1
2016-09-05T18:34:00.370047: step 12710, loss 0.000983413, acc 1
2016-09-05T18:34:00.582659: step 12711, loss 0.00102624, acc 1
2016-09-05T18:34:00.820514: step 12712, loss 0.000927758, acc 1
2016-09-05T18:34:01.023971: step 12713, loss 0.00111128, acc 1
2016-09-05T18:34:01.234771: step 12714, loss 0.00125826, acc 1
2016-09-05T18:34:01.442364: step 12715, loss 0.00125788, acc 1
2016-09-05T18:34:01.697407: step 12716, loss 0.000940664, acc 1
2016-09-05T18:34:01.925427: step 12717, loss 0.000944012, acc 1
2016-09-05T18:34:02.134308: step 12718, loss 0.000858949, acc 1
2016-09-05T18:34:02.334402: step 12719, loss 0.00104595, acc 1
2016-09-05T18:34:02.541563: step 12720, loss 0.000915695, acc 1
2016-09-05T18:34:02.748772: step 12721, loss 0.000923385, acc 1
2016-09-05T18:34:02.964317: step 12722, loss 0.000975885, acc 1
2016-09-05T18:34:03.181426: step 12723, loss 0.00104703, acc 1
2016-09-05T18:34:03.411959: step 12724, loss 0.00154636, acc 1
2016-09-05T18:34:03.642672: step 12725, loss 0.000934104, acc 1
2016-09-05T18:34:03.853502: step 12726, loss 0.000869331, acc 1
2016-09-05T18:34:04.066710: step 12727, loss 0.00101496, acc 1
2016-09-05T18:34:04.278814: step 12728, loss 0.00102669, acc 1
2016-09-05T18:34:04.499585: step 12729, loss 0.00101713, acc 1
2016-09-05T18:34:04.708013: step 12730, loss 0.000904021, acc 1
2016-09-05T18:34:04.941621: step 12731, loss 0.00100657, acc 1
2016-09-05T18:34:05.180477: step 12732, loss 0.000820634, acc 1
2016-09-05T18:34:05.419444: step 12733, loss 0.00120367, acc 1
2016-09-05T18:34:05.653915: step 12734, loss 0.000896235, acc 1
2016-09-05T18:34:05.869072: step 12735, loss 0.000875225, acc 1
2016-09-05T18:34:06.069143: step 12736, loss 0.00147954, acc 1
2016-09-05T18:34:06.297938: step 12737, loss 0.00101031, acc 1
2016-09-05T18:34:06.510037: step 12738, loss 0.000922788, acc 1
2016-09-05T18:34:06.740385: step 12739, loss 0.000951812, acc 1
2016-09-05T18:34:06.969047: step 12740, loss 0.00087374, acc 1
2016-09-05T18:34:07.152849: step 12741, loss 0.000976056, acc 1
2016-09-05T18:34:07.388573: step 12742, loss 0.00147266, acc 1
2016-09-05T18:34:07.634779: step 12743, loss 0.000948244, acc 1
2016-09-05T18:34:07.851620: step 12744, loss 0.00129222, acc 1
2016-09-05T18:34:08.099199: step 12745, loss 0.00117577, acc 1
2016-09-05T18:34:08.323812: step 12746, loss 0.000880431, acc 1
2016-09-05T18:34:08.543333: step 12747, loss 0.000879907, acc 1
2016-09-05T18:34:08.765814: step 12748, loss 0.000900147, acc 1
2016-09-05T18:34:09.000917: step 12749, loss 0.00125942, acc 1
2016-09-05T18:34:09.210530: step 12750, loss 0.00259316, acc 1
2016-09-05T18:34:09.431211: step 12751, loss 0.00108459, acc 1
2016-09-05T18:34:09.637922: step 12752, loss 0.00100984, acc 1
2016-09-05T18:34:09.860275: step 12753, loss 0.00104859, acc 1
2016-09-05T18:34:10.067844: step 12754, loss 0.00103837, acc 1
2016-09-05T18:34:10.279460: step 12755, loss 0.000969961, acc 1
2016-09-05T18:34:10.507340: step 12756, loss 0.000960007, acc 1
2016-09-05T18:34:10.722467: step 12757, loss 0.0009368, acc 1
2016-09-05T18:34:10.923380: step 12758, loss 0.00109913, acc 1
2016-09-05T18:34:11.136130: step 12759, loss 0.00118605, acc 1
2016-09-05T18:34:11.347300: step 12760, loss 0.00137841, acc 1
2016-09-05T18:34:11.577431: step 12761, loss 0.00127964, acc 1
2016-09-05T18:34:11.792415: step 12762, loss 0.000944697, acc 1
2016-09-05T18:34:11.997073: step 12763, loss 0.000945972, acc 1
2016-09-05T18:34:12.230563: step 12764, loss 0.00104664, acc 1
2016-09-05T18:34:12.446592: step 12765, loss 0.00103871, acc 1
2016-09-05T18:34:12.660076: step 12766, loss 0.00146752, acc 1
2016-09-05T18:34:12.882287: step 12767, loss 0.000934152, acc 1
2016-09-05T18:34:13.125723: step 12768, loss 0.000949086, acc 1
2016-09-05T18:34:13.332518: step 12769, loss 0.00109572, acc 1
2016-09-05T18:34:13.548314: step 12770, loss 0.000935338, acc 1
2016-09-05T18:34:13.758032: step 12771, loss 0.000947894, acc 1
2016-09-05T18:34:13.984773: step 12772, loss 0.00109987, acc 1
2016-09-05T18:34:14.208879: step 12773, loss 0.00105459, acc 1
2016-09-05T18:34:14.452953: step 12774, loss 0.000973572, acc 1
2016-09-05T18:34:14.658576: step 12775, loss 0.00115426, acc 1
2016-09-05T18:34:14.880867: step 12776, loss 0.00097519, acc 1
2016-09-05T18:34:15.115993: step 12777, loss 0.00108553, acc 1
2016-09-05T18:34:15.342538: step 12778, loss 0.00093484, acc 1
2016-09-05T18:34:15.574105: step 12779, loss 0.00106307, acc 1
2016-09-05T18:34:15.779711: step 12780, loss 0.000866227, acc 1
2016-09-05T18:34:15.985310: step 12781, loss 0.000957782, acc 1
2016-09-05T18:34:16.242627: step 12782, loss 0.0013626, acc 1
2016-09-05T18:34:16.479168: step 12783, loss 0.00095425, acc 1
2016-09-05T18:34:16.698212: step 12784, loss 0.00102776, acc 1
2016-09-05T18:34:16.899452: step 12785, loss 0.00121851, acc 1
2016-09-05T18:34:17.111770: step 12786, loss 0.001394, acc 1
2016-09-05T18:34:17.314689: step 12787, loss 0.00105609, acc 1
2016-09-05T18:34:17.555681: step 12788, loss 0.00115077, acc 1
2016-09-05T18:34:17.779484: step 12789, loss 0.00102895, acc 1
2016-09-05T18:34:18.003165: step 12790, loss 0.00114941, acc 1
2016-09-05T18:34:18.206985: step 12791, loss 0.000953008, acc 1
2016-09-05T18:34:18.410860: step 12792, loss 0.00092865, acc 1
2016-09-05T18:34:18.627308: step 12793, loss 0.00102508, acc 1
2016-09-05T18:34:18.844443: step 12794, loss 0.000891569, acc 1
2016-09-05T18:34:19.061415: step 12795, loss 0.000999273, acc 1
2016-09-05T18:34:19.263152: step 12796, loss 0.000861029, acc 1
2016-09-05T18:34:19.463653: step 12797, loss 0.00126045, acc 1
2016-09-05T18:34:19.697413: step 12798, loss 0.00135792, acc 1
2016-09-05T18:34:19.917902: step 12799, loss 0.00121875, acc 1
2016-09-05T18:34:20.124084: step 12800, loss 0.00112092, acc 1

Evaluation:
2016-09-05T18:34:20.749570: step 12800, loss 1.46003, acc 0.726

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-12800

2016-09-05T18:34:21.544224: step 12801, loss 0.00110492, acc 1
2016-09-05T18:34:21.742715: step 12802, loss 0.000943096, acc 1
2016-09-05T18:34:21.951170: step 12803, loss 0.00106431, acc 1
2016-09-05T18:34:22.075597: step 12804, loss 0.000963678, acc 1
2016-09-05T18:34:22.295483: step 12805, loss 0.00091881, acc 1
2016-09-05T18:34:22.559602: step 12806, loss 0.00107357, acc 1
2016-09-05T18:34:22.806943: step 12807, loss 0.000910689, acc 1
2016-09-05T18:34:23.050775: step 12808, loss 0.00111421, acc 1
2016-09-05T18:34:23.269376: step 12809, loss 0.000901813, acc 1
2016-09-05T18:34:23.477470: step 12810, loss 0.000937715, acc 1
2016-09-05T18:34:23.698509: step 12811, loss 0.000918406, acc 1
2016-09-05T18:34:23.908719: step 12812, loss 0.000873067, acc 1
2016-09-05T18:34:24.129377: step 12813, loss 0.00112871, acc 1
2016-09-05T18:34:24.353897: step 12814, loss 0.00102244, acc 1
2016-09-05T18:34:24.573794: step 12815, loss 0.001051, acc 1
2016-09-05T18:34:24.814447: step 12816, loss 0.000920191, acc 1
2016-09-05T18:34:25.034270: step 12817, loss 0.000869109, acc 1
2016-09-05T18:34:25.258604: step 12818, loss 0.000936507, acc 1
2016-09-05T18:34:25.452591: step 12819, loss 0.00126882, acc 1
2016-09-05T18:34:25.682628: step 12820, loss 0.000879268, acc 1
2016-09-05T18:34:25.906055: step 12821, loss 0.000986819, acc 1
2016-09-05T18:34:26.155677: step 12822, loss 0.000895154, acc 1
2016-09-05T18:34:26.389916: step 12823, loss 0.000946166, acc 1
2016-09-05T18:34:26.607225: step 12824, loss 0.000955622, acc 1
2016-09-05T18:34:26.815803: step 12825, loss 0.000883975, acc 1
2016-09-05T18:34:27.017875: step 12826, loss 0.000852281, acc 1
2016-09-05T18:34:27.232886: step 12827, loss 0.000841485, acc 1
2016-09-05T18:34:27.489905: step 12828, loss 0.000905776, acc 1
2016-09-05T18:34:27.711502: step 12829, loss 0.000932254, acc 1
2016-09-05T18:34:27.906598: step 12830, loss 0.000848977, acc 1
2016-09-05T18:34:28.111556: step 12831, loss 0.000886018, acc 1
2016-09-05T18:34:28.330501: step 12832, loss 0.000847809, acc 1
2016-09-05T18:34:28.544039: step 12833, loss 0.00101239, acc 1
2016-09-05T18:34:28.741793: step 12834, loss 0.000835192, acc 1
2016-09-05T18:34:28.956075: step 12835, loss 0.000836727, acc 1
2016-09-05T18:34:29.167934: step 12836, loss 0.000776795, acc 1
2016-09-05T18:34:29.400322: step 12837, loss 0.00081984, acc 1
2016-09-05T18:34:29.608986: step 12838, loss 0.00113943, acc 1
2016-09-05T18:34:29.834096: step 12839, loss 0.000937105, acc 1
2016-09-05T18:34:30.035924: step 12840, loss 0.00101732, acc 1
2016-09-05T18:34:30.264645: step 12841, loss 0.0011265, acc 1
2016-09-05T18:34:30.460985: step 12842, loss 0.000907939, acc 1
2016-09-05T18:34:30.686364: step 12843, loss 0.000848637, acc 1
2016-09-05T18:34:30.934364: step 12844, loss 0.00107667, acc 1
2016-09-05T18:34:31.153759: step 12845, loss 0.000985614, acc 1
2016-09-05T18:34:31.360924: step 12846, loss 0.00083948, acc 1
2016-09-05T18:34:31.569030: step 12847, loss 0.00089387, acc 1
2016-09-05T18:34:31.788898: step 12848, loss 0.000990798, acc 1
2016-09-05T18:34:32.038124: step 12849, loss 0.000796763, acc 1
2016-09-05T18:34:32.254416: step 12850, loss 0.00094941, acc 1
2016-09-05T18:34:32.465986: step 12851, loss 0.000815722, acc 1
2016-09-05T18:34:32.692497: step 12852, loss 0.00100854, acc 1
2016-09-05T18:34:32.928742: step 12853, loss 0.000939577, acc 1
2016-09-05T18:34:33.146425: step 12854, loss 0.00102242, acc 1
2016-09-05T18:34:33.373288: step 12855, loss 0.000855595, acc 1
2016-09-05T18:34:33.586681: step 12856, loss 0.000796295, acc 1
2016-09-05T18:34:33.834973: step 12857, loss 0.000846084, acc 1
2016-09-05T18:34:34.058076: step 12858, loss 0.000813027, acc 1
2016-09-05T18:34:34.278051: step 12859, loss 0.000786613, acc 1
2016-09-05T18:34:34.501725: step 12860, loss 0.000879472, acc 1
2016-09-05T18:34:34.728811: step 12861, loss 0.00100628, acc 1
2016-09-05T18:34:34.969040: step 12862, loss 0.0013452, acc 1
2016-09-05T18:34:35.183974: step 12863, loss 0.000813992, acc 1
2016-09-05T18:34:35.407580: step 12864, loss 0.000876251, acc 1
2016-09-05T18:34:35.642717: step 12865, loss 0.000848954, acc 1
2016-09-05T18:34:35.893398: step 12866, loss 0.0008889, acc 1
2016-09-05T18:34:36.143014: step 12867, loss 0.00089318, acc 1
2016-09-05T18:34:36.356849: step 12868, loss 0.000955358, acc 1
2016-09-05T18:34:36.572579: step 12869, loss 0.0012207, acc 1
2016-09-05T18:34:36.782985: step 12870, loss 0.000780452, acc 1
2016-09-05T18:34:37.003795: step 12871, loss 0.00113992, acc 1
2016-09-05T18:34:37.219455: step 12872, loss 0.00110614, acc 1
2016-09-05T18:34:37.460940: step 12873, loss 0.000787001, acc 1
2016-09-05T18:34:37.685750: step 12874, loss 0.00100709, acc 1
2016-09-05T18:34:37.899583: step 12875, loss 0.000883997, acc 1
2016-09-05T18:34:38.112348: step 12876, loss 0.00115128, acc 1
2016-09-05T18:34:38.343742: step 12877, loss 0.000957083, acc 1
2016-09-05T18:34:38.551171: step 12878, loss 0.00085559, acc 1
2016-09-05T18:34:38.791911: step 12879, loss 0.000778804, acc 1
2016-09-05T18:34:38.998312: step 12880, loss 0.000927269, acc 1
2016-09-05T18:34:39.249232: step 12881, loss 0.000886507, acc 1
2016-09-05T18:34:39.480900: step 12882, loss 0.00092592, acc 1
2016-09-05T18:34:39.668576: step 12883, loss 0.000876739, acc 1
2016-09-05T18:34:39.895808: step 12884, loss 0.000974199, acc 1
2016-09-05T18:34:40.097828: step 12885, loss 0.00101527, acc 1
2016-09-05T18:34:40.306473: step 12886, loss 0.00099223, acc 1
2016-09-05T18:34:40.541572: step 12887, loss 0.000850985, acc 1
2016-09-05T18:34:40.779521: step 12888, loss 0.00141143, acc 1
2016-09-05T18:34:41.006574: step 12889, loss 0.000853553, acc 1
2016-09-05T18:34:41.221651: step 12890, loss 0.000852526, acc 1
2016-09-05T18:34:41.434964: step 12891, loss 0.00102885, acc 1
2016-09-05T18:34:41.665795: step 12892, loss 0.000952507, acc 1
2016-09-05T18:34:41.873923: step 12893, loss 0.000999783, acc 1
2016-09-05T18:34:42.116599: step 12894, loss 0.00089408, acc 1
2016-09-05T18:34:42.320092: step 12895, loss 0.00103472, acc 1
2016-09-05T18:34:42.541975: step 12896, loss 0.00091561, acc 1
2016-09-05T18:34:42.745535: step 12897, loss 0.000909286, acc 1
2016-09-05T18:34:42.960867: step 12898, loss 0.000845292, acc 1
2016-09-05T18:34:43.167422: step 12899, loss 0.000891463, acc 1
2016-09-05T18:34:43.403532: step 12900, loss 0.0008507, acc 1

Evaluation:
2016-09-05T18:34:44.000616: step 12900, loss 1.4375, acc 0.725

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-12900

2016-09-05T18:34:44.737363: step 12901, loss 0.000858603, acc 1
2016-09-05T18:34:44.959587: step 12902, loss 0.000873198, acc 1
2016-09-05T18:34:45.161832: step 12903, loss 0.00136733, acc 1
2016-09-05T18:34:45.379129: step 12904, loss 0.000817195, acc 1
2016-09-05T18:34:45.587037: step 12905, loss 0.00182687, acc 1
2016-09-05T18:34:45.841436: step 12906, loss 0.00131561, acc 1
2016-09-05T18:34:46.057941: step 12907, loss 0.000837533, acc 1
2016-09-05T18:34:46.266994: step 12908, loss 0.00139109, acc 1
2016-09-05T18:34:46.465132: step 12909, loss 0.00140741, acc 1
2016-09-05T18:34:46.668673: step 12910, loss 0.000836655, acc 1
2016-09-05T18:34:46.874459: step 12911, loss 0.000876823, acc 1
2016-09-05T18:34:47.091171: step 12912, loss 0.0010883, acc 1
2016-09-05T18:34:47.329539: step 12913, loss 0.000920984, acc 1
2016-09-05T18:34:47.564835: step 12914, loss 0.00100783, acc 1
2016-09-05T18:34:47.777394: step 12915, loss 0.000983754, acc 1
2016-09-05T18:34:48.007451: step 12916, loss 0.00162459, acc 1
2016-09-05T18:34:48.258365: step 12917, loss 0.000908115, acc 1
2016-09-05T18:34:48.467729: step 12918, loss 0.00154784, acc 1
2016-09-05T18:34:48.670946: step 12919, loss 0.00112292, acc 1
2016-09-05T18:34:48.870405: step 12920, loss 0.000936455, acc 1
2016-09-05T18:34:49.070219: step 12921, loss 0.00092067, acc 1
2016-09-05T18:34:49.286956: step 12922, loss 0.00107744, acc 1
2016-09-05T18:34:49.491209: step 12923, loss 0.000974742, acc 1
2016-09-05T18:34:49.699137: step 12924, loss 0.00105403, acc 1
2016-09-05T18:34:49.907006: step 12925, loss 0.00089186, acc 1
2016-09-05T18:34:50.119189: step 12926, loss 0.00105257, acc 1
2016-09-05T18:34:50.335523: step 12927, loss 0.00127347, acc 1
2016-09-05T18:34:50.573650: step 12928, loss 0.000902312, acc 1
2016-09-05T18:34:50.771010: step 12929, loss 0.000887743, acc 1
2016-09-05T18:34:50.982808: step 12930, loss 0.000991332, acc 1
2016-09-05T18:34:51.192036: step 12931, loss 0.000967047, acc 1
2016-09-05T18:34:51.396762: step 12932, loss 0.000914114, acc 1
2016-09-05T18:34:51.609770: step 12933, loss 0.00273356, acc 1
2016-09-05T18:34:51.851219: step 12934, loss 0.00113856, acc 1
2016-09-05T18:34:52.091925: step 12935, loss 0.00109876, acc 1
2016-09-05T18:34:52.287404: step 12936, loss 0.000997603, acc 1
2016-09-05T18:34:52.503210: step 12937, loss 0.000989628, acc 1
2016-09-05T18:34:52.701750: step 12938, loss 0.00124287, acc 1
2016-09-05T18:34:52.901091: step 12939, loss 0.00185414, acc 1
2016-09-05T18:34:53.106160: step 12940, loss 0.00155012, acc 1
2016-09-05T18:34:53.338395: step 12941, loss 0.00133094, acc 1
2016-09-05T18:34:53.541554: step 12942, loss 0.00143956, acc 1
2016-09-05T18:34:53.762844: step 12943, loss 0.00121746, acc 1
2016-09-05T18:34:53.995018: step 12944, loss 0.0010439, acc 1
2016-09-05T18:34:54.201900: step 12945, loss 0.00108918, acc 1
2016-09-05T18:34:54.394877: step 12946, loss 0.00177077, acc 1
2016-09-05T18:34:54.617208: step 12947, loss 0.00112558, acc 1
2016-09-05T18:34:54.826975: step 12948, loss 0.00160631, acc 1
2016-09-05T18:34:55.038171: step 12949, loss 0.00117008, acc 1
2016-09-05T18:34:55.238345: step 12950, loss 0.00111018, acc 1
2016-09-05T18:34:55.458223: step 12951, loss 0.0011218, acc 1
2016-09-05T18:34:55.672436: step 12952, loss 0.00118279, acc 1
2016-09-05T18:34:55.888103: step 12953, loss 0.00163787, acc 1
2016-09-05T18:34:56.115871: step 12954, loss 0.00122853, acc 1
2016-09-05T18:34:56.325308: step 12955, loss 0.00416212, acc 1
2016-09-05T18:34:56.568318: step 12956, loss 0.0014794, acc 1
2016-09-05T18:34:56.818460: step 12957, loss 0.00138854, acc 1
2016-09-05T18:34:57.039248: step 12958, loss 0.00128916, acc 1
2016-09-05T18:34:57.244434: step 12959, loss 0.00122974, acc 1
2016-09-05T18:34:57.470758: step 12960, loss 0.00144323, acc 1
2016-09-05T18:34:57.701634: step 12961, loss 0.00160402, acc 1
2016-09-05T18:34:57.931965: step 12962, loss 0.0027267, acc 1
2016-09-05T18:34:58.156729: step 12963, loss 0.00168027, acc 1
2016-09-05T18:34:58.366988: step 12964, loss 0.00195544, acc 1
2016-09-05T18:34:58.582062: step 12965, loss 0.00141742, acc 1
2016-09-05T18:34:58.793583: step 12966, loss 0.00133659, acc 1
2016-09-05T18:34:59.029424: step 12967, loss 0.00147272, acc 1
2016-09-05T18:34:59.251940: step 12968, loss 0.00142601, acc 1
2016-09-05T18:34:59.466755: step 12969, loss 0.0013888, acc 1
2016-09-05T18:34:59.671215: step 12970, loss 0.0013923, acc 1
2016-09-05T18:34:59.882012: step 12971, loss 0.00153989, acc 1
2016-09-05T18:35:00.098204: step 12972, loss 0.00142817, acc 1
2016-09-05T18:35:00.324599: step 12973, loss 0.00383003, acc 1
2016-09-05T18:35:00.570733: step 12974, loss 0.00140839, acc 1
2016-09-05T18:35:00.775247: step 12975, loss 0.00142197, acc 1
2016-09-05T18:35:00.973123: step 12976, loss 0.00147611, acc 1
2016-09-05T18:35:01.180625: step 12977, loss 0.00143785, acc 1
2016-09-05T18:35:01.398849: step 12978, loss 0.00141911, acc 1
2016-09-05T18:35:01.617979: step 12979, loss 0.00149527, acc 1
2016-09-05T18:35:01.834346: step 12980, loss 0.0014308, acc 1
2016-09-05T18:35:02.064262: step 12981, loss 0.00142083, acc 1
2016-09-05T18:35:02.280158: step 12982, loss 0.00142221, acc 1
2016-09-05T18:35:02.498490: step 12983, loss 0.00142195, acc 1
2016-09-05T18:35:02.714746: step 12984, loss 0.00141337, acc 1
2016-09-05T18:35:02.911968: step 12985, loss 0.00154372, acc 1
2016-09-05T18:35:03.135714: step 12986, loss 0.00137808, acc 1
2016-09-05T18:35:03.349902: step 12987, loss 0.00155091, acc 1
2016-09-05T18:35:03.590181: step 12988, loss 0.00188913, acc 1
2016-09-05T18:35:03.801337: step 12989, loss 0.00131014, acc 1
2016-09-05T18:35:04.021736: step 12990, loss 0.00131946, acc 1
2016-09-05T18:35:04.245646: step 12991, loss 0.00126589, acc 1
2016-09-05T18:35:04.456649: step 12992, loss 0.00131897, acc 1
2016-09-05T18:35:04.670387: step 12993, loss 0.00248502, acc 1
2016-09-05T18:35:04.898395: step 12994, loss 0.0012626, acc 1
2016-09-05T18:35:05.125799: step 12995, loss 0.00128034, acc 1
2016-09-05T18:35:05.339791: step 12996, loss 0.00129098, acc 1
2016-09-05T18:35:05.560811: step 12997, loss 0.00120303, acc 1
2016-09-05T18:35:05.717942: step 12998, loss 0.00117536, acc 1
2016-09-05T18:35:05.924634: step 12999, loss 0.00125476, acc 1
2016-09-05T18:35:06.154715: step 13000, loss 0.00113252, acc 1

Evaluation:
2016-09-05T18:35:06.753378: step 13000, loss 1.5995, acc 0.721

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-13000

2016-09-05T18:35:07.474452: step 13001, loss 0.00111331, acc 1
2016-09-05T18:35:07.683717: step 13002, loss 0.00109908, acc 1
2016-09-05T18:35:07.936209: step 13003, loss 0.00120779, acc 1
2016-09-05T18:35:08.162925: step 13004, loss 0.00105171, acc 1
2016-09-05T18:35:08.371706: step 13005, loss 0.00115918, acc 1
2016-09-05T18:35:08.585432: step 13006, loss 0.00109739, acc 1
2016-09-05T18:35:08.816366: step 13007, loss 0.00109802, acc 1
2016-09-05T18:35:09.052862: step 13008, loss 0.00114456, acc 1
2016-09-05T18:35:09.234279: step 13009, loss 0.00106273, acc 1
2016-09-05T18:35:09.457470: step 13010, loss 0.00111075, acc 1
2016-09-05T18:35:09.674647: step 13011, loss 0.00134581, acc 1
2016-09-05T18:35:09.897750: step 13012, loss 0.00116187, acc 1
2016-09-05T18:35:10.114373: step 13013, loss 0.00101986, acc 1
2016-09-05T18:35:10.352860: step 13014, loss 0.000970159, acc 1
2016-09-05T18:35:10.557963: step 13015, loss 0.0010084, acc 1
2016-09-05T18:35:10.773668: step 13016, loss 0.00108356, acc 1
2016-09-05T18:35:10.980654: step 13017, loss 0.00126653, acc 1
2016-09-05T18:35:11.212516: step 13018, loss 0.00103711, acc 1
2016-09-05T18:35:11.447931: step 13019, loss 0.00107938, acc 1
2016-09-05T18:35:11.648293: step 13020, loss 0.00090754, acc 1
2016-09-05T18:35:11.877761: step 13021, loss 0.00115333, acc 1
2016-09-05T18:35:12.084772: step 13022, loss 0.000857715, acc 1
2016-09-05T18:35:12.296617: step 13023, loss 0.000867329, acc 1
2016-09-05T18:35:12.495251: step 13024, loss 0.00127476, acc 1
2016-09-05T18:35:12.728274: step 13025, loss 0.00112397, acc 1
2016-09-05T18:35:12.951389: step 13026, loss 0.00100653, acc 1
2016-09-05T18:35:13.178803: step 13027, loss 0.000881592, acc 1
2016-09-05T18:35:13.393960: step 13028, loss 0.000897731, acc 1
2016-09-05T18:35:13.608815: step 13029, loss 0.0015141, acc 1
2016-09-05T18:35:13.813025: step 13030, loss 0.00102232, acc 1
2016-09-05T18:35:14.030576: step 13031, loss 0.00133452, acc 1
2016-09-05T18:35:14.246535: step 13032, loss 0.00127507, acc 1
2016-09-05T18:35:14.464052: step 13033, loss 0.00104518, acc 1
2016-09-05T18:35:14.687138: step 13034, loss 0.000957167, acc 1
2016-09-05T18:35:14.895727: step 13035, loss 0.00143052, acc 1
2016-09-05T18:35:15.124802: step 13036, loss 0.000976761, acc 1
2016-09-05T18:35:15.343597: step 13037, loss 0.00105111, acc 1
2016-09-05T18:35:15.562644: step 13038, loss 0.00087343, acc 1
2016-09-05T18:35:15.803762: step 13039, loss 0.000995463, acc 1
2016-09-05T18:35:16.014782: step 13040, loss 0.000868656, acc 1
2016-09-05T18:35:16.207064: step 13041, loss 0.00102887, acc 1
2016-09-05T18:35:16.443431: step 13042, loss 0.000913356, acc 1
2016-09-05T18:35:16.671332: step 13043, loss 0.000962385, acc 1
2016-09-05T18:35:16.928131: step 13044, loss 0.000893588, acc 1
2016-09-05T18:35:17.147621: step 13045, loss 0.000952408, acc 1
2016-09-05T18:35:17.360009: step 13046, loss 0.000904531, acc 1
2016-09-05T18:35:17.597381: step 13047, loss 0.000957463, acc 1
2016-09-05T18:35:17.810059: step 13048, loss 0.000921561, acc 1
2016-09-05T18:35:18.035817: step 13049, loss 0.000913925, acc 1
2016-09-05T18:35:18.250733: step 13050, loss 0.00112878, acc 1
2016-09-05T18:35:18.481438: step 13051, loss 0.000809755, acc 1
2016-09-05T18:35:18.717045: step 13052, loss 0.00098048, acc 1
2016-09-05T18:35:18.917745: step 13053, loss 0.00113914, acc 1
2016-09-05T18:35:19.130441: step 13054, loss 0.00101571, acc 1
2016-09-05T18:35:19.335670: step 13055, loss 0.00123053, acc 1
2016-09-05T18:35:19.550395: step 13056, loss 0.000843586, acc 1
2016-09-05T18:35:19.763514: step 13057, loss 0.000848077, acc 1
2016-09-05T18:35:19.980941: step 13058, loss 0.00102373, acc 1
2016-09-05T18:35:20.203060: step 13059, loss 0.000875698, acc 1
2016-09-05T18:35:20.427435: step 13060, loss 0.000840328, acc 1
2016-09-05T18:35:20.658137: step 13061, loss 0.000892001, acc 1
2016-09-05T18:35:20.891889: step 13062, loss 0.000931463, acc 1
2016-09-05T18:35:21.117535: step 13063, loss 0.00112147, acc 1
2016-09-05T18:35:21.380092: step 13064, loss 0.000847771, acc 1
2016-09-05T18:35:21.590409: step 13065, loss 0.000814002, acc 1
2016-09-05T18:35:21.818894: step 13066, loss 0.00143504, acc 1
2016-09-05T18:35:22.079537: step 13067, loss 0.00105125, acc 1
2016-09-05T18:35:22.304572: step 13068, loss 0.000851824, acc 1
2016-09-05T18:35:22.520800: step 13069, loss 0.000890161, acc 1
2016-09-05T18:35:22.748727: step 13070, loss 0.000911396, acc 1
2016-09-05T18:35:22.943079: step 13071, loss 0.00101456, acc 1
2016-09-05T18:35:23.172505: step 13072, loss 0.00098263, acc 1
2016-09-05T18:35:23.390516: step 13073, loss 0.000934152, acc 1
2016-09-05T18:35:23.595419: step 13074, loss 0.000792642, acc 1
2016-09-05T18:35:23.827001: step 13075, loss 0.000903255, acc 1
2016-09-05T18:35:24.042468: step 13076, loss 0.00101927, acc 1
2016-09-05T18:35:24.246437: step 13077, loss 0.000874146, acc 1
2016-09-05T18:35:24.474600: step 13078, loss 0.000951018, acc 1
2016-09-05T18:35:24.678897: step 13079, loss 0.00117492, acc 1
2016-09-05T18:35:24.898222: step 13080, loss 0.00235168, acc 1
2016-09-05T18:35:25.117305: step 13081, loss 0.00114252, acc 1
2016-09-05T18:35:25.357724: step 13082, loss 0.00094141, acc 1
2016-09-05T18:35:25.584531: step 13083, loss 0.00151235, acc 1
2016-09-05T18:35:25.814259: step 13084, loss 0.000982062, acc 1
2016-09-05T18:35:26.032404: step 13085, loss 0.000979985, acc 1
2016-09-05T18:35:26.265357: step 13086, loss 0.000878186, acc 1
2016-09-05T18:35:26.488411: step 13087, loss 0.000841102, acc 1
2016-09-05T18:35:26.702166: step 13088, loss 0.000926658, acc 1
2016-09-05T18:35:26.914565: step 13089, loss 0.000954082, acc 1
2016-09-05T18:35:27.124782: step 13090, loss 0.00115909, acc 1
2016-09-05T18:35:27.356232: step 13091, loss 0.00110464, acc 1
2016-09-05T18:35:27.570773: step 13092, loss 0.000969284, acc 1
2016-09-05T18:35:27.801533: step 13093, loss 0.000952491, acc 1
2016-09-05T18:35:28.028764: step 13094, loss 0.000930764, acc 1
2016-09-05T18:35:28.260352: step 13095, loss 0.00118608, acc 1
2016-09-05T18:35:28.479678: step 13096, loss 0.000963402, acc 1
2016-09-05T18:35:28.695902: step 13097, loss 0.000895752, acc 1
2016-09-05T18:35:28.922769: step 13098, loss 0.00151149, acc 1
2016-09-05T18:35:29.121517: step 13099, loss 0.0010229, acc 1
2016-09-05T18:35:29.341698: step 13100, loss 0.00099089, acc 1

Evaluation:
2016-09-05T18:35:29.966157: step 13100, loss 1.57649, acc 0.721

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-13100

2016-09-05T18:35:30.688144: step 13101, loss 0.000989192, acc 1
2016-09-05T18:35:30.912266: step 13102, loss 0.000940584, acc 1
2016-09-05T18:35:31.152799: step 13103, loss 0.00108372, acc 1
2016-09-05T18:35:31.364832: step 13104, loss 0.000926129, acc 1
2016-09-05T18:35:31.573971: step 13105, loss 0.00117913, acc 1
2016-09-05T18:35:31.780144: step 13106, loss 0.0029975, acc 1
2016-09-05T18:35:31.988378: step 13107, loss 0.000923232, acc 1
2016-09-05T18:35:32.230728: step 13108, loss 0.00104583, acc 1
2016-09-05T18:35:32.445391: step 13109, loss 0.000976905, acc 1
2016-09-05T18:35:32.669179: step 13110, loss 0.00113311, acc 1
2016-09-05T18:35:32.874442: step 13111, loss 0.00121641, acc 1
2016-09-05T18:35:33.085320: step 13112, loss 0.00180193, acc 1
2016-09-05T18:35:33.285259: step 13113, loss 0.00139044, acc 1
2016-09-05T18:35:33.512368: step 13114, loss 0.00142269, acc 1
2016-09-05T18:35:33.743020: step 13115, loss 0.00264874, acc 1
2016-09-05T18:35:33.973931: step 13116, loss 0.00185989, acc 1
2016-09-05T18:35:34.200328: step 13117, loss 0.00157412, acc 1
2016-09-05T18:35:34.414871: step 13118, loss 0.00138246, acc 1
2016-09-05T18:35:34.630696: step 13119, loss 0.00133445, acc 1
2016-09-05T18:35:34.842680: step 13120, loss 0.00136552, acc 1
2016-09-05T18:35:35.083341: step 13121, loss 0.00132168, acc 1
2016-09-05T18:35:35.292710: step 13122, loss 0.00137712, acc 1
2016-09-05T18:35:35.516132: step 13123, loss 0.00137279, acc 1
2016-09-05T18:35:35.779895: step 13124, loss 0.00140737, acc 1
2016-09-05T18:35:35.985217: step 13125, loss 0.00186702, acc 1
2016-09-05T18:35:36.195086: step 13126, loss 0.00142229, acc 1
2016-09-05T18:35:36.408405: step 13127, loss 0.001786, acc 1
2016-09-05T18:35:36.622284: step 13128, loss 0.00162728, acc 1
2016-09-05T18:35:36.835739: step 13129, loss 0.00146529, acc 1
2016-09-05T18:35:37.048988: step 13130, loss 0.00141489, acc 1
2016-09-05T18:35:37.260418: step 13131, loss 0.00145777, acc 1
2016-09-05T18:35:37.489957: step 13132, loss 0.00142028, acc 1
2016-09-05T18:35:37.724278: step 13133, loss 0.00136442, acc 1
2016-09-05T18:35:37.947005: step 13134, loss 0.00142415, acc 1
2016-09-05T18:35:38.173641: step 13135, loss 0.0013133, acc 1
2016-09-05T18:35:38.404987: step 13136, loss 0.00129413, acc 1
2016-09-05T18:35:38.609291: step 13137, loss 0.00130558, acc 1
2016-09-05T18:35:38.827867: step 13138, loss 0.00129058, acc 1
2016-09-05T18:35:39.048317: step 13139, loss 0.00143649, acc 1
2016-09-05T18:35:39.257948: step 13140, loss 0.00149117, acc 1
2016-09-05T18:35:39.476456: step 13141, loss 0.00134451, acc 1
2016-09-05T18:35:39.688405: step 13142, loss 0.00131271, acc 1
2016-09-05T18:35:39.909398: step 13143, loss 0.00118681, acc 1
2016-09-05T18:35:40.101684: step 13144, loss 0.00127622, acc 1
2016-09-05T18:35:40.317875: step 13145, loss 0.0012013, acc 1
2016-09-05T18:35:40.529444: step 13146, loss 0.00114118, acc 1
2016-09-05T18:35:40.750866: step 13147, loss 0.00121918, acc 1
2016-09-05T18:35:40.960016: step 13148, loss 0.00114216, acc 1
2016-09-05T18:35:41.163025: step 13149, loss 0.00109934, acc 1
2016-09-05T18:35:41.376817: step 13150, loss 0.00118701, acc 1
2016-09-05T18:35:41.594820: step 13151, loss 0.00120116, acc 1
2016-09-05T18:35:41.825709: step 13152, loss 0.00113903, acc 1
2016-09-05T18:35:42.062287: step 13153, loss 0.00144046, acc 1
2016-09-05T18:35:42.281262: step 13154, loss 0.00105887, acc 1
2016-09-05T18:35:42.488517: step 13155, loss 0.00112018, acc 1
2016-09-05T18:35:42.713889: step 13156, loss 0.00118408, acc 1
2016-09-05T18:35:42.929046: step 13157, loss 0.00139394, acc 1
2016-09-05T18:35:43.181632: step 13158, loss 0.00104758, acc 1
2016-09-05T18:35:43.381952: step 13159, loss 0.000994833, acc 1
2016-09-05T18:35:43.587114: step 13160, loss 0.00119332, acc 1
2016-09-05T18:35:43.800070: step 13161, loss 0.00106034, acc 1
2016-09-05T18:35:44.012492: step 13162, loss 0.00101906, acc 1
2016-09-05T18:35:44.232364: step 13163, loss 0.00112842, acc 1
2016-09-05T18:35:44.438543: step 13164, loss 0.00119512, acc 1
2016-09-05T18:35:44.651696: step 13165, loss 0.00176814, acc 1
2016-09-05T18:35:44.869446: step 13166, loss 0.00119259, acc 1
2016-09-05T18:35:45.098065: step 13167, loss 0.000966564, acc 1
2016-09-05T18:35:45.315977: step 13168, loss 0.00106709, acc 1
2016-09-05T18:35:45.536090: step 13169, loss 0.000930629, acc 1
2016-09-05T18:35:45.747854: step 13170, loss 0.00124719, acc 1
2016-09-05T18:35:45.971714: step 13171, loss 0.000920599, acc 1
2016-09-05T18:35:46.214386: step 13172, loss 0.00151493, acc 1
2016-09-05T18:35:46.419931: step 13173, loss 0.000903136, acc 1
2016-09-05T18:35:46.620748: step 13174, loss 0.000919895, acc 1
2016-09-05T18:35:46.867975: step 13175, loss 0.00134879, acc 1
2016-09-05T18:35:47.066826: step 13176, loss 0.000907748, acc 1
2016-09-05T18:35:47.274304: step 13177, loss 0.000928573, acc 1
2016-09-05T18:35:47.517844: step 13178, loss 0.00117244, acc 1
2016-09-05T18:35:47.718449: step 13179, loss 0.000885527, acc 1
2016-09-05T18:35:47.928227: step 13180, loss 0.00110367, acc 1
2016-09-05T18:35:48.139365: step 13181, loss 0.000867783, acc 1
2016-09-05T18:35:48.350843: step 13182, loss 0.000974531, acc 1
2016-09-05T18:35:48.579787: step 13183, loss 0.00125771, acc 1
2016-09-05T18:35:48.811061: step 13184, loss 0.000975427, acc 1
2016-09-05T18:35:49.030266: step 13185, loss 0.00089294, acc 1
2016-09-05T18:35:49.245644: step 13186, loss 0.00111445, acc 1
2016-09-05T18:35:49.446925: step 13187, loss 0.00103167, acc 1
2016-09-05T18:35:49.663435: step 13188, loss 0.000938832, acc 1
2016-09-05T18:35:49.892742: step 13189, loss 0.00122429, acc 1
2016-09-05T18:35:50.095625: step 13190, loss 0.000845316, acc 1
2016-09-05T18:35:50.325034: step 13191, loss 0.000950909, acc 1
2016-09-05T18:35:50.445499: step 13192, loss 0.000936945, acc 1
2016-09-05T18:35:50.648688: step 13193, loss 0.000951182, acc 1
2016-09-05T18:35:50.851188: step 13194, loss 0.00107099, acc 1
2016-09-05T18:35:51.084367: step 13195, loss 0.000875715, acc 1
2016-09-05T18:35:51.280019: step 13196, loss 0.00087917, acc 1
2016-09-05T18:35:51.504431: step 13197, loss 0.000893575, acc 1
2016-09-05T18:35:51.737515: step 13198, loss 0.000809404, acc 1
2016-09-05T18:35:51.968909: step 13199, loss 0.00093014, acc 1
2016-09-05T18:35:52.198379: step 13200, loss 0.00111041, acc 1

Evaluation:
2016-09-05T18:35:52.796867: step 13200, loss 1.467, acc 0.727

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-13200

2016-09-05T18:35:53.583601: step 13201, loss 0.000853171, acc 1
2016-09-05T18:35:53.803479: step 13202, loss 0.000973177, acc 1
2016-09-05T18:35:54.019218: step 13203, loss 0.000901045, acc 1
2016-09-05T18:35:54.228989: step 13204, loss 0.00101363, acc 1
2016-09-05T18:35:54.437303: step 13205, loss 0.000852652, acc 1
2016-09-05T18:35:54.649391: step 13206, loss 0.000783076, acc 1
2016-09-05T18:35:54.887162: step 13207, loss 0.00100411, acc 1
2016-09-05T18:35:55.082877: step 13208, loss 0.000843583, acc 1
2016-09-05T18:35:55.298395: step 13209, loss 0.000771472, acc 1
2016-09-05T18:35:55.497329: step 13210, loss 0.000805798, acc 1
2016-09-05T18:35:55.707692: step 13211, loss 0.00104649, acc 1
2016-09-05T18:35:55.926010: step 13212, loss 0.000902929, acc 1
2016-09-05T18:35:56.197090: step 13213, loss 0.000808807, acc 1
2016-09-05T18:35:56.397263: step 13214, loss 0.000809647, acc 1
2016-09-05T18:35:56.598348: step 13215, loss 0.000854661, acc 1
2016-09-05T18:35:56.812462: step 13216, loss 0.000756744, acc 1
2016-09-05T18:35:57.024833: step 13217, loss 0.00144118, acc 1
2016-09-05T18:35:57.270165: step 13218, loss 0.000806345, acc 1
2016-09-05T18:35:57.519286: step 13219, loss 0.000823883, acc 1
2016-09-05T18:35:57.741867: step 13220, loss 0.00082672, acc 1
2016-09-05T18:35:57.953353: step 13221, loss 0.00102649, acc 1
2016-09-05T18:35:58.189359: step 13222, loss 0.00095846, acc 1
2016-09-05T18:35:58.429913: step 13223, loss 0.0008463, acc 1
2016-09-05T18:35:58.630121: step 13224, loss 0.00155675, acc 1
2016-09-05T18:35:58.866577: step 13225, loss 0.000994615, acc 1
2016-09-05T18:35:59.121756: step 13226, loss 0.000954305, acc 1
2016-09-05T18:35:59.329292: step 13227, loss 0.000803303, acc 1
2016-09-05T18:35:59.533042: step 13228, loss 0.000766129, acc 1
2016-09-05T18:35:59.756767: step 13229, loss 0.000827032, acc 1
2016-09-05T18:35:59.960127: step 13230, loss 0.000776788, acc 1
2016-09-05T18:36:00.188699: step 13231, loss 0.000890283, acc 1
2016-09-05T18:36:00.433398: step 13232, loss 0.00100167, acc 1
2016-09-05T18:36:00.633007: step 13233, loss 0.000783572, acc 1
2016-09-05T18:36:00.847295: step 13234, loss 0.0008651, acc 1
2016-09-05T18:36:01.051488: step 13235, loss 0.000799262, acc 1
2016-09-05T18:36:01.266860: step 13236, loss 0.000981085, acc 1
2016-09-05T18:36:01.476263: step 13237, loss 0.00093873, acc 1
2016-09-05T18:36:01.671780: step 13238, loss 0.00114937, acc 1
2016-09-05T18:36:01.871653: step 13239, loss 0.00075744, acc 1
2016-09-05T18:36:02.091903: step 13240, loss 0.000891596, acc 1
2016-09-05T18:36:02.321945: step 13241, loss 0.00110561, acc 1
2016-09-05T18:36:02.520629: step 13242, loss 0.00132124, acc 1
2016-09-05T18:36:02.749662: step 13243, loss 0.00117379, acc 1
2016-09-05T18:36:02.955226: step 13244, loss 0.000964579, acc 1
2016-09-05T18:36:03.168028: step 13245, loss 0.000801802, acc 1
2016-09-05T18:36:03.417709: step 13246, loss 0.00105651, acc 1
2016-09-05T18:36:03.644942: step 13247, loss 0.00101214, acc 1
2016-09-05T18:36:03.827553: step 13248, loss 0.000807974, acc 1
2016-09-05T18:36:04.051309: step 13249, loss 0.000845769, acc 1
2016-09-05T18:36:04.292693: step 13250, loss 0.000790883, acc 1
2016-09-05T18:36:04.503679: step 13251, loss 0.00108926, acc 1
2016-09-05T18:36:04.714845: step 13252, loss 0.000856338, acc 1
2016-09-05T18:36:04.942404: step 13253, loss 0.000981131, acc 1
2016-09-05T18:36:05.167400: step 13254, loss 0.000871767, acc 1
2016-09-05T18:36:05.381349: step 13255, loss 0.000832266, acc 1
2016-09-05T18:36:05.601523: step 13256, loss 0.000919816, acc 1
2016-09-05T18:36:05.837386: step 13257, loss 0.000795481, acc 1
2016-09-05T18:36:06.075828: step 13258, loss 0.000776287, acc 1
2016-09-05T18:36:06.278953: step 13259, loss 0.00091443, acc 1
2016-09-05T18:36:06.488907: step 13260, loss 0.00124356, acc 1
2016-09-05T18:36:06.699712: step 13261, loss 0.00081936, acc 1
2016-09-05T18:36:06.922840: step 13262, loss 0.000803078, acc 1
2016-09-05T18:36:07.148981: step 13263, loss 0.000836244, acc 1
2016-09-05T18:36:07.396262: step 13264, loss 0.00101414, acc 1
2016-09-05T18:36:07.588989: step 13265, loss 0.000973513, acc 1
2016-09-05T18:36:07.807181: step 13266, loss 0.00102244, acc 1
2016-09-05T18:36:08.015386: step 13267, loss 0.000880651, acc 1
2016-09-05T18:36:08.262085: step 13268, loss 0.000829205, acc 1
2016-09-05T18:36:08.485481: step 13269, loss 0.000951587, acc 1
2016-09-05T18:36:08.699960: step 13270, loss 0.000853881, acc 1
2016-09-05T18:36:08.903441: step 13271, loss 0.00134051, acc 1
2016-09-05T18:36:09.111369: step 13272, loss 0.00104177, acc 1
2016-09-05T18:36:09.334170: step 13273, loss 0.000762147, acc 1
2016-09-05T18:36:09.549347: step 13274, loss 0.000763377, acc 1
2016-09-05T18:36:09.783010: step 13275, loss 0.000791537, acc 1
2016-09-05T18:36:09.987319: step 13276, loss 0.000835717, acc 1
2016-09-05T18:36:10.213202: step 13277, loss 0.000743979, acc 1
2016-09-05T18:36:10.430700: step 13278, loss 0.000893524, acc 1
2016-09-05T18:36:10.651780: step 13279, loss 0.000754675, acc 1
2016-09-05T18:36:10.859794: step 13280, loss 0.000873063, acc 1
2016-09-05T18:36:11.089884: step 13281, loss 0.00100508, acc 1
2016-09-05T18:36:11.298086: step 13282, loss 0.000936101, acc 1
2016-09-05T18:36:11.498668: step 13283, loss 0.000893823, acc 1
2016-09-05T18:36:11.722099: step 13284, loss 0.000781846, acc 1
2016-09-05T18:36:11.930458: step 13285, loss 0.000816028, acc 1
2016-09-05T18:36:12.153415: step 13286, loss 0.000931773, acc 1
2016-09-05T18:36:12.361810: step 13287, loss 0.000837858, acc 1
2016-09-05T18:36:12.571426: step 13288, loss 0.000953719, acc 1
2016-09-05T18:36:12.794902: step 13289, loss 0.001029, acc 1
2016-09-05T18:36:13.037202: step 13290, loss 0.000734144, acc 1
2016-09-05T18:36:13.257351: step 13291, loss 0.000759011, acc 1
2016-09-05T18:36:13.500675: step 13292, loss 0.000761244, acc 1
2016-09-05T18:36:13.741363: step 13293, loss 0.0009021, acc 1
2016-09-05T18:36:13.953416: step 13294, loss 0.00104309, acc 1
2016-09-05T18:36:14.168139: step 13295, loss 0.000934206, acc 1
2016-09-05T18:36:14.376455: step 13296, loss 0.000896099, acc 1
2016-09-05T18:36:14.598505: step 13297, loss 0.000817061, acc 1
2016-09-05T18:36:14.827807: step 13298, loss 0.000921136, acc 1
2016-09-05T18:36:15.059867: step 13299, loss 0.000829883, acc 1
2016-09-05T18:36:15.275989: step 13300, loss 0.000902221, acc 1

Evaluation:
2016-09-05T18:36:15.901929: step 13300, loss 1.46242, acc 0.724

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-13300

2016-09-05T18:36:16.679769: step 13301, loss 0.00131014, acc 1
2016-09-05T18:36:16.882252: step 13302, loss 0.00106831, acc 1
2016-09-05T18:36:17.093667: step 13303, loss 0.000969009, acc 1
2016-09-05T18:36:17.303467: step 13304, loss 0.000815528, acc 1
2016-09-05T18:36:17.508116: step 13305, loss 0.000772749, acc 1
2016-09-05T18:36:17.722677: step 13306, loss 0.000941315, acc 1
2016-09-05T18:36:17.961454: step 13307, loss 0.000922555, acc 1
2016-09-05T18:36:18.173496: step 13308, loss 0.000856354, acc 1
2016-09-05T18:36:18.395229: step 13309, loss 0.000848779, acc 1
2016-09-05T18:36:18.594742: step 13310, loss 0.000797897, acc 1
2016-09-05T18:36:18.796927: step 13311, loss 0.000816334, acc 1
2016-09-05T18:36:19.053525: step 13312, loss 0.000823923, acc 1
2016-09-05T18:36:19.300461: step 13313, loss 0.000882738, acc 1
2016-09-05T18:36:19.527071: step 13314, loss 0.000811235, acc 1
2016-09-05T18:36:19.735397: step 13315, loss 0.000815142, acc 1
2016-09-05T18:36:19.949594: step 13316, loss 0.00102933, acc 1
2016-09-05T18:36:20.166651: step 13317, loss 0.000982601, acc 1
2016-09-05T18:36:20.404381: step 13318, loss 0.000876235, acc 1
2016-09-05T18:36:20.610652: step 13319, loss 0.000923364, acc 1
2016-09-05T18:36:20.834267: step 13320, loss 0.00104664, acc 1
2016-09-05T18:36:21.053492: step 13321, loss 0.000758012, acc 1
2016-09-05T18:36:21.264750: step 13322, loss 0.000911384, acc 1
2016-09-05T18:36:21.514718: step 13323, loss 0.000800418, acc 1
2016-09-05T18:36:21.711943: step 13324, loss 0.000826814, acc 1
2016-09-05T18:36:21.934036: step 13325, loss 0.000818682, acc 1
2016-09-05T18:36:22.147638: step 13326, loss 0.000842143, acc 1
2016-09-05T18:36:22.367784: step 13327, loss 0.000868901, acc 1
2016-09-05T18:36:22.584111: step 13328, loss 0.000757944, acc 1
2016-09-05T18:36:22.825114: step 13329, loss 0.00167711, acc 1
2016-09-05T18:36:23.038436: step 13330, loss 0.000917376, acc 1
2016-09-05T18:36:23.242739: step 13331, loss 0.000926246, acc 1
2016-09-05T18:36:23.455338: step 13332, loss 0.000832947, acc 1
2016-09-05T18:36:23.670786: step 13333, loss 0.00077631, acc 1
2016-09-05T18:36:23.885434: step 13334, loss 0.00088559, acc 1
2016-09-05T18:36:24.128315: step 13335, loss 0.000927385, acc 1
2016-09-05T18:36:24.342517: step 13336, loss 0.000742556, acc 1
2016-09-05T18:36:24.539144: step 13337, loss 0.000954715, acc 1
2016-09-05T18:36:24.730300: step 13338, loss 0.000833516, acc 1
2016-09-05T18:36:24.945199: step 13339, loss 0.000773874, acc 1
2016-09-05T18:36:25.161804: step 13340, loss 0.00110723, acc 1
2016-09-05T18:36:25.380549: step 13341, loss 0.000836098, acc 1
2016-09-05T18:36:25.617135: step 13342, loss 0.000874647, acc 1
2016-09-05T18:36:25.847931: step 13343, loss 0.000803582, acc 1
2016-09-05T18:36:26.057362: step 13344, loss 0.000948799, acc 1
2016-09-05T18:36:26.292659: step 13345, loss 0.000979271, acc 1
2016-09-05T18:36:26.524894: step 13346, loss 0.000870347, acc 1
2016-09-05T18:36:26.756790: step 13347, loss 0.0009413, acc 1
2016-09-05T18:36:26.946077: step 13348, loss 0.000914301, acc 1
2016-09-05T18:36:27.171760: step 13349, loss 0.00107219, acc 1
2016-09-05T18:36:27.386999: step 13350, loss 0.000772527, acc 1
2016-09-05T18:36:27.620043: step 13351, loss 0.00076638, acc 1
2016-09-05T18:36:27.832679: step 13352, loss 0.000797513, acc 1
2016-09-05T18:36:28.075574: step 13353, loss 0.0007976, acc 1
2016-09-05T18:36:28.292553: step 13354, loss 0.000784819, acc 1
2016-09-05T18:36:28.507537: step 13355, loss 0.000767976, acc 1
2016-09-05T18:36:28.718451: step 13356, loss 0.000822486, acc 1
2016-09-05T18:36:28.939840: step 13357, loss 0.000848487, acc 1
2016-09-05T18:36:29.177389: step 13358, loss 0.00102001, acc 1
2016-09-05T18:36:29.382517: step 13359, loss 0.00107888, acc 1
2016-09-05T18:36:29.597244: step 13360, loss 0.000884933, acc 1
2016-09-05T18:36:29.803823: step 13361, loss 0.000728371, acc 1
2016-09-05T18:36:30.020570: step 13362, loss 0.000692593, acc 1
2016-09-05T18:36:30.230010: step 13363, loss 0.000833475, acc 1
2016-09-05T18:36:30.458349: step 13364, loss 0.000875819, acc 1
2016-09-05T18:36:30.682032: step 13365, loss 0.000821072, acc 1
2016-09-05T18:36:30.936938: step 13366, loss 0.00123057, acc 1
2016-09-05T18:36:31.145051: step 13367, loss 0.000723972, acc 1
2016-09-05T18:36:31.361354: step 13368, loss 0.000779522, acc 1
2016-09-05T18:36:31.558147: step 13369, loss 0.000947987, acc 1
2016-09-05T18:36:31.757832: step 13370, loss 0.000939772, acc 1
2016-09-05T18:36:31.972788: step 13371, loss 0.000753471, acc 1
2016-09-05T18:36:32.186264: step 13372, loss 0.00104912, acc 1
2016-09-05T18:36:32.413457: step 13373, loss 0.000815996, acc 1
2016-09-05T18:36:32.607360: step 13374, loss 0.000955802, acc 1
2016-09-05T18:36:32.847987: step 13375, loss 0.00104681, acc 1
2016-09-05T18:36:33.063391: step 13376, loss 0.0012851, acc 1
2016-09-05T18:36:33.281303: step 13377, loss 0.000896057, acc 1
2016-09-05T18:36:33.499072: step 13378, loss 0.000889499, acc 1
2016-09-05T18:36:33.712218: step 13379, loss 0.000865271, acc 1
2016-09-05T18:36:33.900812: step 13380, loss 0.000882405, acc 1
2016-09-05T18:36:34.142079: step 13381, loss 0.000888504, acc 1
2016-09-05T18:36:34.352780: step 13382, loss 0.000774391, acc 1
2016-09-05T18:36:34.567995: step 13383, loss 0.00104427, acc 1
2016-09-05T18:36:34.771381: step 13384, loss 0.000911751, acc 1
2016-09-05T18:36:35.002838: step 13385, loss 0.000938079, acc 1
2016-09-05T18:36:35.127118: step 13386, loss 0.000758875, acc 1
2016-09-05T18:36:35.375557: step 13387, loss 0.00122004, acc 1
2016-09-05T18:36:35.588395: step 13388, loss 0.000794964, acc 1
2016-09-05T18:36:35.793825: step 13389, loss 0.000778667, acc 1
2016-09-05T18:36:36.000952: step 13390, loss 0.000793559, acc 1
2016-09-05T18:36:36.228902: step 13391, loss 0.00097969, acc 1
2016-09-05T18:36:36.449377: step 13392, loss 0.000804636, acc 1
2016-09-05T18:36:36.664819: step 13393, loss 0.00108463, acc 1
2016-09-05T18:36:36.860564: step 13394, loss 0.000838953, acc 1
2016-09-05T18:36:37.063892: step 13395, loss 0.000807697, acc 1
2016-09-05T18:36:37.276960: step 13396, loss 0.000825993, acc 1
2016-09-05T18:36:37.484065: step 13397, loss 0.000815855, acc 1
2016-09-05T18:36:37.711003: step 13398, loss 0.000821506, acc 1
2016-09-05T18:36:37.918757: step 13399, loss 0.000819318, acc 1
2016-09-05T18:36:38.128989: step 13400, loss 0.00077035, acc 1

Evaluation:
2016-09-05T18:36:38.744062: step 13400, loss 1.47463, acc 0.728

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-13400

2016-09-05T18:36:39.509462: step 13401, loss 0.000781935, acc 1
2016-09-05T18:36:39.749643: step 13402, loss 0.000815039, acc 1
2016-09-05T18:36:39.978903: step 13403, loss 0.000767132, acc 1
2016-09-05T18:36:40.203181: step 13404, loss 0.00107924, acc 1
2016-09-05T18:36:40.410846: step 13405, loss 0.00093874, acc 1
2016-09-05T18:36:40.619278: step 13406, loss 0.000933143, acc 1
2016-09-05T18:36:40.843192: step 13407, loss 0.000785238, acc 1
2016-09-05T18:36:41.081675: step 13408, loss 0.000722113, acc 1
2016-09-05T18:36:41.281318: step 13409, loss 0.000905149, acc 1
2016-09-05T18:36:41.476698: step 13410, loss 0.000897586, acc 1
2016-09-05T18:36:41.701393: step 13411, loss 0.000831064, acc 1
2016-09-05T18:36:41.918055: step 13412, loss 0.000699267, acc 1
2016-09-05T18:36:42.144100: step 13413, loss 0.0008513, acc 1
2016-09-05T18:36:42.354021: step 13414, loss 0.000761646, acc 1
2016-09-05T18:36:42.577664: step 13415, loss 0.000706121, acc 1
2016-09-05T18:36:42.803806: step 13416, loss 0.000703266, acc 1
2016-09-05T18:36:43.030186: step 13417, loss 0.000987767, acc 1
2016-09-05T18:36:43.238145: step 13418, loss 0.00146091, acc 1
2016-09-05T18:36:43.480512: step 13419, loss 0.000896393, acc 1
2016-09-05T18:36:43.701343: step 13420, loss 0.000888295, acc 1
2016-09-05T18:36:43.905452: step 13421, loss 0.000820329, acc 1
2016-09-05T18:36:44.142275: step 13422, loss 0.000822284, acc 1
2016-09-05T18:36:44.353680: step 13423, loss 0.00160928, acc 1
2016-09-05T18:36:44.594220: step 13424, loss 0.00105336, acc 1
2016-09-05T18:36:44.825392: step 13425, loss 0.000796418, acc 1
2016-09-05T18:36:45.067681: step 13426, loss 0.000892275, acc 1
2016-09-05T18:36:45.275303: step 13427, loss 0.000952684, acc 1
2016-09-05T18:36:45.483378: step 13428, loss 0.000993049, acc 1
2016-09-05T18:36:45.708990: step 13429, loss 0.000804502, acc 1
2016-09-05T18:36:45.924840: step 13430, loss 0.000773838, acc 1
2016-09-05T18:36:46.164671: step 13431, loss 0.000907302, acc 1
2016-09-05T18:36:46.368158: step 13432, loss 0.000939076, acc 1
2016-09-05T18:36:46.575016: step 13433, loss 0.000891585, acc 1
2016-09-05T18:36:46.807003: step 13434, loss 0.000796601, acc 1
2016-09-05T18:36:47.037441: step 13435, loss 0.000770461, acc 1
2016-09-05T18:36:47.259463: step 13436, loss 0.000825974, acc 1
2016-09-05T18:36:47.484425: step 13437, loss 0.000962509, acc 1
2016-09-05T18:36:47.688356: step 13438, loss 0.000775673, acc 1
2016-09-05T18:36:47.906745: step 13439, loss 0.00182288, acc 1
2016-09-05T18:36:48.144603: step 13440, loss 0.000873166, acc 1
2016-09-05T18:36:48.382967: step 13441, loss 0.000884878, acc 1
2016-09-05T18:36:48.657275: step 13442, loss 0.00094904, acc 1
2016-09-05T18:36:48.866302: step 13443, loss 0.000863325, acc 1
2016-09-05T18:36:49.082189: step 13444, loss 0.000957761, acc 1
2016-09-05T18:36:49.302947: step 13445, loss 0.000991557, acc 1
2016-09-05T18:36:49.536489: step 13446, loss 0.00122563, acc 1
2016-09-05T18:36:49.751249: step 13447, loss 0.000868285, acc 1
2016-09-05T18:36:49.991230: step 13448, loss 0.000899196, acc 1
2016-09-05T18:36:50.197846: step 13449, loss 0.00115037, acc 1
2016-09-05T18:36:50.427213: step 13450, loss 0.000840377, acc 1
2016-09-05T18:36:50.670456: step 13451, loss 0.000828034, acc 1
2016-09-05T18:36:50.914458: step 13452, loss 0.000854197, acc 1
2016-09-05T18:36:51.144673: step 13453, loss 0.00085872, acc 1
2016-09-05T18:36:51.370889: step 13454, loss 0.000827677, acc 1
2016-09-05T18:36:51.585241: step 13455, loss 0.000847278, acc 1
2016-09-05T18:36:51.805075: step 13456, loss 0.000863567, acc 1
2016-09-05T18:36:52.018780: step 13457, loss 0.000903109, acc 1
2016-09-05T18:36:52.224822: step 13458, loss 0.000776216, acc 1
2016-09-05T18:36:52.469559: step 13459, loss 0.000987968, acc 1
2016-09-05T18:36:52.680278: step 13460, loss 0.000845403, acc 1
2016-09-05T18:36:52.916538: step 13461, loss 0.00107738, acc 1
2016-09-05T18:36:53.130842: step 13462, loss 0.000795565, acc 1
2016-09-05T18:36:53.333166: step 13463, loss 0.000776268, acc 1
2016-09-05T18:36:53.536357: step 13464, loss 0.000789465, acc 1
2016-09-05T18:36:53.743165: step 13465, loss 0.000809898, acc 1
2016-09-05T18:36:53.960487: step 13466, loss 0.000955027, acc 1
2016-09-05T18:36:54.179271: step 13467, loss 0.000979246, acc 1
2016-09-05T18:36:54.425224: step 13468, loss 0.000735337, acc 1
2016-09-05T18:36:54.636980: step 13469, loss 0.000760287, acc 1
2016-09-05T18:36:54.861531: step 13470, loss 0.000768435, acc 1
2016-09-05T18:36:55.060530: step 13471, loss 0.000855736, acc 1
2016-09-05T18:36:55.278210: step 13472, loss 0.0008764, acc 1
2016-09-05T18:36:55.522672: step 13473, loss 0.000987719, acc 1
2016-09-05T18:36:55.728165: step 13474, loss 0.00102715, acc 1
2016-09-05T18:36:55.939237: step 13475, loss 0.00112743, acc 1
2016-09-05T18:36:56.136470: step 13476, loss 0.000694405, acc 1
2016-09-05T18:36:56.345960: step 13477, loss 0.000801986, acc 1
2016-09-05T18:36:56.549872: step 13478, loss 0.00087723, acc 1
2016-09-05T18:36:56.789618: step 13479, loss 0.000816161, acc 1
2016-09-05T18:36:56.998699: step 13480, loss 0.000816768, acc 1
2016-09-05T18:36:57.249788: step 13481, loss 0.000885887, acc 1
2016-09-05T18:36:57.457015: step 13482, loss 0.000718106, acc 1
2016-09-05T18:36:57.661562: step 13483, loss 0.000830836, acc 1
2016-09-05T18:36:57.876066: step 13484, loss 0.000826314, acc 1
2016-09-05T18:36:58.100507: step 13485, loss 0.00124574, acc 1
2016-09-05T18:36:58.330456: step 13486, loss 0.000797786, acc 1
2016-09-05T18:36:58.553763: step 13487, loss 0.000726032, acc 1
2016-09-05T18:36:58.753390: step 13488, loss 0.000888993, acc 1
2016-09-05T18:36:58.966098: step 13489, loss 0.000910707, acc 1
2016-09-05T18:36:59.196445: step 13490, loss 0.00106306, acc 1
2016-09-05T18:36:59.418933: step 13491, loss 0.000794122, acc 1
2016-09-05T18:36:59.661497: step 13492, loss 0.000770944, acc 1
2016-09-05T18:36:59.879528: step 13493, loss 0.0010656, acc 1
2016-09-05T18:37:00.109377: step 13494, loss 0.000737632, acc 1
2016-09-05T18:37:00.357866: step 13495, loss 0.000793013, acc 1
2016-09-05T18:37:00.549418: step 13496, loss 0.000968048, acc 1
2016-09-05T18:37:00.756098: step 13497, loss 0.00148991, acc 1
2016-09-05T18:37:00.963370: step 13498, loss 0.000829518, acc 1
2016-09-05T18:37:01.189270: step 13499, loss 0.0011634, acc 1
2016-09-05T18:37:01.400060: step 13500, loss 0.000784332, acc 1

Evaluation:
2016-09-05T18:37:02.028346: step 13500, loss 1.49596, acc 0.724

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-13500

2016-09-05T18:37:02.737968: step 13501, loss 0.000741635, acc 1
2016-09-05T18:37:02.967889: step 13502, loss 0.000940017, acc 1
2016-09-05T18:37:03.178643: step 13503, loss 0.000884255, acc 1
2016-09-05T18:37:03.442450: step 13504, loss 0.000831981, acc 1
2016-09-05T18:37:03.662807: step 13505, loss 0.00077673, acc 1
2016-09-05T18:37:03.902324: step 13506, loss 0.000961251, acc 1
2016-09-05T18:37:04.142303: step 13507, loss 0.000836091, acc 1
2016-09-05T18:37:04.340546: step 13508, loss 0.000756012, acc 1
2016-09-05T18:37:04.556805: step 13509, loss 0.000782061, acc 1
2016-09-05T18:37:04.766581: step 13510, loss 0.000817502, acc 1
2016-09-05T18:37:04.974313: step 13511, loss 0.000785048, acc 1
2016-09-05T18:37:05.177721: step 13512, loss 0.000783876, acc 1
2016-09-05T18:37:05.430853: step 13513, loss 0.000767038, acc 1
2016-09-05T18:37:05.632066: step 13514, loss 0.000839905, acc 1
2016-09-05T18:37:05.856444: step 13515, loss 0.000844074, acc 1
2016-09-05T18:37:06.064286: step 13516, loss 0.000963675, acc 1
2016-09-05T18:37:06.279472: step 13517, loss 0.00108079, acc 1
2016-09-05T18:37:06.535530: step 13518, loss 0.00100367, acc 1
2016-09-05T18:37:06.751517: step 13519, loss 0.00102446, acc 1
2016-09-05T18:37:06.959827: step 13520, loss 0.000793112, acc 1
2016-09-05T18:37:07.160984: step 13521, loss 0.000963075, acc 1
2016-09-05T18:37:07.372924: step 13522, loss 0.000762227, acc 1
2016-09-05T18:37:07.586508: step 13523, loss 0.000865489, acc 1
2016-09-05T18:37:07.801567: step 13524, loss 0.000886565, acc 1
2016-09-05T18:37:08.018361: step 13525, loss 0.000743421, acc 1
2016-09-05T18:37:08.255132: step 13526, loss 0.000951654, acc 1
2016-09-05T18:37:08.459698: step 13527, loss 0.000909696, acc 1
2016-09-05T18:37:08.664818: step 13528, loss 0.000914373, acc 1
2016-09-05T18:37:08.876917: step 13529, loss 0.000821635, acc 1
2016-09-05T18:37:09.102579: step 13530, loss 0.000902077, acc 1
2016-09-05T18:37:09.330596: step 13531, loss 0.00085909, acc 1
2016-09-05T18:37:09.545460: step 13532, loss 0.000724451, acc 1
2016-09-05T18:37:09.772509: step 13533, loss 0.000947015, acc 1
2016-09-05T18:37:09.985848: step 13534, loss 0.000968388, acc 1
2016-09-05T18:37:10.227913: step 13535, loss 0.000870944, acc 1
2016-09-05T18:37:10.441052: step 13536, loss 0.000768262, acc 1
2016-09-05T18:37:10.678397: step 13537, loss 0.000834846, acc 1
2016-09-05T18:37:10.887797: step 13538, loss 0.000989092, acc 1
2016-09-05T18:37:11.096004: step 13539, loss 0.000885338, acc 1
2016-09-05T18:37:11.299261: step 13540, loss 0.000755338, acc 1
2016-09-05T18:37:11.510466: step 13541, loss 0.000882489, acc 1
2016-09-05T18:37:11.735127: step 13542, loss 0.00125206, acc 1
2016-09-05T18:37:11.934244: step 13543, loss 0.000741131, acc 1
2016-09-05T18:37:12.145163: step 13544, loss 0.000757176, acc 1
2016-09-05T18:37:12.367629: step 13545, loss 0.00112626, acc 1
2016-09-05T18:37:12.617972: step 13546, loss 0.000735623, acc 1
2016-09-05T18:37:12.832621: step 13547, loss 0.00086719, acc 1
2016-09-05T18:37:13.073443: step 13548, loss 0.000805462, acc 1
2016-09-05T18:37:13.296260: step 13549, loss 0.000974032, acc 1
2016-09-05T18:37:13.496509: step 13550, loss 0.000749647, acc 1
2016-09-05T18:37:13.697768: step 13551, loss 0.000806546, acc 1
2016-09-05T18:37:13.934804: step 13552, loss 0.000958656, acc 1
2016-09-05T18:37:14.174330: step 13553, loss 0.000858589, acc 1
2016-09-05T18:37:14.423333: step 13554, loss 0.000733731, acc 1
2016-09-05T18:37:14.646674: step 13555, loss 0.000710374, acc 1
2016-09-05T18:37:14.886584: step 13556, loss 0.00155973, acc 1
2016-09-05T18:37:15.123624: step 13557, loss 0.00071432, acc 1
2016-09-05T18:37:15.338082: step 13558, loss 0.000883606, acc 1
2016-09-05T18:37:15.586525: step 13559, loss 0.00108089, acc 1
2016-09-05T18:37:15.830647: step 13560, loss 0.000871061, acc 1
2016-09-05T18:37:16.045898: step 13561, loss 0.000828173, acc 1
2016-09-05T18:37:16.261305: step 13562, loss 0.00103003, acc 1
2016-09-05T18:37:16.482504: step 13563, loss 0.00073778, acc 1
2016-09-05T18:37:16.715631: step 13564, loss 0.00078669, acc 1
2016-09-05T18:37:16.938140: step 13565, loss 0.00111104, acc 1
2016-09-05T18:37:17.152214: step 13566, loss 0.000859351, acc 1
2016-09-05T18:37:17.362661: step 13567, loss 0.000823179, acc 1
2016-09-05T18:37:17.600253: step 13568, loss 0.000847946, acc 1
2016-09-05T18:37:17.845264: step 13569, loss 0.0008035, acc 1
2016-09-05T18:37:18.053283: step 13570, loss 0.000948914, acc 1
2016-09-05T18:37:18.264432: step 13571, loss 0.000845655, acc 1
2016-09-05T18:37:18.466435: step 13572, loss 0.0011209, acc 1
2016-09-05T18:37:18.674330: step 13573, loss 0.000957509, acc 1
2016-09-05T18:37:18.889968: step 13574, loss 0.000766574, acc 1
2016-09-05T18:37:19.108506: step 13575, loss 0.000765509, acc 1
2016-09-05T18:37:19.333933: step 13576, loss 0.000865704, acc 1
2016-09-05T18:37:19.557643: step 13577, loss 0.000803961, acc 1
2016-09-05T18:37:19.763867: step 13578, loss 0.000835404, acc 1
2016-09-05T18:37:19.983853: step 13579, loss 0.000790088, acc 1
2016-09-05T18:37:20.121128: step 13580, loss 0.000699728, acc 1
2016-09-05T18:37:20.362397: step 13581, loss 0.000833584, acc 1
2016-09-05T18:37:20.581945: step 13582, loss 0.000759882, acc 1
2016-09-05T18:37:20.806363: step 13583, loss 0.000870731, acc 1
2016-09-05T18:37:21.043942: step 13584, loss 0.00080287, acc 1
2016-09-05T18:37:21.266404: step 13585, loss 0.000868721, acc 1
2016-09-05T18:37:21.486146: step 13586, loss 0.000815899, acc 1
2016-09-05T18:37:21.682449: step 13587, loss 0.000795042, acc 1
2016-09-05T18:37:21.898922: step 13588, loss 0.00093165, acc 1
2016-09-05T18:37:22.120397: step 13589, loss 0.000732507, acc 1
2016-09-05T18:37:22.365401: step 13590, loss 0.000940914, acc 1
2016-09-05T18:37:22.577463: step 13591, loss 0.000763245, acc 1
2016-09-05T18:37:22.817053: step 13592, loss 0.00081303, acc 1
2016-09-05T18:37:23.022972: step 13593, loss 0.000705705, acc 1
2016-09-05T18:37:23.232214: step 13594, loss 0.000803389, acc 1
2016-09-05T18:37:23.463175: step 13595, loss 0.000798698, acc 1
2016-09-05T18:37:23.692629: step 13596, loss 0.0008481, acc 1
2016-09-05T18:37:23.928766: step 13597, loss 0.000882319, acc 1
2016-09-05T18:37:24.147326: step 13598, loss 0.000878064, acc 1
2016-09-05T18:37:24.359786: step 13599, loss 0.000691277, acc 1
2016-09-05T18:37:24.576867: step 13600, loss 0.000714086, acc 1

Evaluation:
2016-09-05T18:37:25.196610: step 13600, loss 1.44094, acc 0.725

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-13600

2016-09-05T18:37:25.963405: step 13601, loss 0.000694919, acc 1
2016-09-05T18:37:26.181871: step 13602, loss 0.000673385, acc 1
2016-09-05T18:37:26.424705: step 13603, loss 0.00090772, acc 1
2016-09-05T18:37:26.645797: step 13604, loss 0.000792412, acc 1
2016-09-05T18:37:26.849270: step 13605, loss 0.00093309, acc 1
2016-09-05T18:37:27.061651: step 13606, loss 0.000786825, acc 1
2016-09-05T18:37:27.285387: step 13607, loss 0.000757312, acc 1
2016-09-05T18:37:27.500048: step 13608, loss 0.000826959, acc 1
2016-09-05T18:37:27.737520: step 13609, loss 0.000679234, acc 1
2016-09-05T18:37:27.952012: step 13610, loss 0.000693567, acc 1
2016-09-05T18:37:28.163157: step 13611, loss 0.00108164, acc 1
2016-09-05T18:37:28.367554: step 13612, loss 0.00077991, acc 1
2016-09-05T18:37:28.571818: step 13613, loss 0.000773428, acc 1
2016-09-05T18:37:28.781608: step 13614, loss 0.00074768, acc 1
2016-09-05T18:37:28.998546: step 13615, loss 0.000733961, acc 1
2016-09-05T18:37:29.204837: step 13616, loss 0.001244, acc 1
2016-09-05T18:37:29.413650: step 13617, loss 0.000902636, acc 1
2016-09-05T18:37:29.652832: step 13618, loss 0.000688752, acc 1
2016-09-05T18:37:29.860623: step 13619, loss 0.00070716, acc 1
2016-09-05T18:37:30.070400: step 13620, loss 0.000761434, acc 1
2016-09-05T18:37:30.265104: step 13621, loss 0.00102942, acc 1
2016-09-05T18:37:30.475224: step 13622, loss 0.000768256, acc 1
2016-09-05T18:37:30.691361: step 13623, loss 0.000768485, acc 1
2016-09-05T18:37:30.936966: step 13624, loss 0.000806369, acc 1
2016-09-05T18:37:31.155729: step 13625, loss 0.000758677, acc 1
2016-09-05T18:37:31.391792: step 13626, loss 0.00124863, acc 1
2016-09-05T18:37:31.588077: step 13627, loss 0.000780087, acc 1
2016-09-05T18:37:31.806469: step 13628, loss 0.000758514, acc 1
2016-09-05T18:37:32.017505: step 13629, loss 0.000872349, acc 1
2016-09-05T18:37:32.260180: step 13630, loss 0.000800976, acc 1
2016-09-05T18:37:32.509446: step 13631, loss 0.000875042, acc 1
2016-09-05T18:37:32.725297: step 13632, loss 0.000793393, acc 1
2016-09-05T18:37:32.933221: step 13633, loss 0.000735232, acc 1
2016-09-05T18:37:33.139857: step 13634, loss 0.000722946, acc 1
2016-09-05T18:37:33.364185: step 13635, loss 0.000926882, acc 1
2016-09-05T18:37:33.579825: step 13636, loss 0.00101617, acc 1
2016-09-05T18:37:33.805429: step 13637, loss 0.000750924, acc 1
2016-09-05T18:37:34.021433: step 13638, loss 0.000849981, acc 1
2016-09-05T18:37:34.244177: step 13639, loss 0.000715638, acc 1
2016-09-05T18:37:34.447701: step 13640, loss 0.00172737, acc 1
2016-09-05T18:37:34.682015: step 13641, loss 0.000778114, acc 1
2016-09-05T18:37:34.896376: step 13642, loss 0.00105877, acc 1
2016-09-05T18:37:35.108693: step 13643, loss 0.000907424, acc 1
2016-09-05T18:37:35.328957: step 13644, loss 0.00081879, acc 1
2016-09-05T18:37:35.541130: step 13645, loss 0.000939524, acc 1
2016-09-05T18:37:35.758261: step 13646, loss 0.000817105, acc 1
2016-09-05T18:37:35.979440: step 13647, loss 0.000743395, acc 1
2016-09-05T18:37:36.198583: step 13648, loss 0.000868559, acc 1
2016-09-05T18:37:36.410589: step 13649, loss 0.000821271, acc 1
2016-09-05T18:37:36.660464: step 13650, loss 0.000876369, acc 1
2016-09-05T18:37:36.873143: step 13651, loss 0.000861511, acc 1
2016-09-05T18:37:37.086852: step 13652, loss 0.000903862, acc 1
2016-09-05T18:37:37.315937: step 13653, loss 0.000777006, acc 1
2016-09-05T18:37:37.552725: step 13654, loss 0.000876644, acc 1
2016-09-05T18:37:37.769439: step 13655, loss 0.000826462, acc 1
2016-09-05T18:37:37.976694: step 13656, loss 0.000723713, acc 1
2016-09-05T18:37:38.184344: step 13657, loss 0.000881289, acc 1
2016-09-05T18:37:38.399252: step 13658, loss 0.000762804, acc 1
2016-09-05T18:37:38.621534: step 13659, loss 0.000975966, acc 1
2016-09-05T18:37:38.845513: step 13660, loss 0.000849317, acc 1
2016-09-05T18:37:39.076025: step 13661, loss 0.000952125, acc 1
2016-09-05T18:37:39.276330: step 13662, loss 0.000707379, acc 1
2016-09-05T18:37:39.483980: step 13663, loss 0.000800295, acc 1
2016-09-05T18:37:39.691228: step 13664, loss 0.000894057, acc 1
2016-09-05T18:37:39.920914: step 13665, loss 0.000721756, acc 1
2016-09-05T18:37:40.134485: step 13666, loss 0.000704784, acc 1
2016-09-05T18:37:40.344046: step 13667, loss 0.000765474, acc 1
2016-09-05T18:37:40.589633: step 13668, loss 0.000741454, acc 1
2016-09-05T18:37:40.779363: step 13669, loss 0.000679968, acc 1
2016-09-05T18:37:40.986515: step 13670, loss 0.000710302, acc 1
2016-09-05T18:37:41.195316: step 13671, loss 0.000783931, acc 1
2016-09-05T18:37:41.411386: step 13672, loss 0.000795843, acc 1
2016-09-05T18:37:41.614120: step 13673, loss 0.000863293, acc 1
2016-09-05T18:37:41.832077: step 13674, loss 0.000798116, acc 1
2016-09-05T18:37:42.032711: step 13675, loss 0.000756957, acc 1
2016-09-05T18:37:42.256235: step 13676, loss 0.000888672, acc 1
2016-09-05T18:37:42.477709: step 13677, loss 0.00106917, acc 1
2016-09-05T18:37:42.722160: step 13678, loss 0.000711344, acc 1
2016-09-05T18:37:42.930167: step 13679, loss 0.00134993, acc 1
2016-09-05T18:37:43.174928: step 13680, loss 0.000886703, acc 1
2016-09-05T18:37:43.423121: step 13681, loss 0.000796297, acc 1
2016-09-05T18:37:43.634812: step 13682, loss 0.00081239, acc 1
2016-09-05T18:37:43.851972: step 13683, loss 0.00100354, acc 1
2016-09-05T18:37:44.076373: step 13684, loss 0.000803957, acc 1
2016-09-05T18:37:44.319530: step 13685, loss 0.000732883, acc 1
2016-09-05T18:37:44.541431: step 13686, loss 0.00069337, acc 1
2016-09-05T18:37:44.761719: step 13687, loss 0.000789573, acc 1
2016-09-05T18:37:44.973947: step 13688, loss 0.000713622, acc 1
2016-09-05T18:37:45.212009: step 13689, loss 0.000817945, acc 1
2016-09-05T18:37:45.446283: step 13690, loss 0.000769734, acc 1
2016-09-05T18:37:45.645833: step 13691, loss 0.000702553, acc 1
2016-09-05T18:37:45.866290: step 13692, loss 0.00100276, acc 1
2016-09-05T18:37:46.082382: step 13693, loss 0.000731235, acc 1
2016-09-05T18:37:46.289487: step 13694, loss 0.000822818, acc 1
2016-09-05T18:37:46.496010: step 13695, loss 0.000716283, acc 1
2016-09-05T18:37:46.755745: step 13696, loss 0.000682105, acc 1
2016-09-05T18:37:46.954907: step 13697, loss 0.000790194, acc 1
2016-09-05T18:37:47.186146: step 13698, loss 0.000746169, acc 1
2016-09-05T18:37:47.406245: step 13699, loss 0.000735768, acc 1
2016-09-05T18:37:47.625029: step 13700, loss 0.000753376, acc 1

Evaluation:
2016-09-05T18:37:48.232277: step 13700, loss 1.46379, acc 0.725

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-13700

2016-09-05T18:37:48.952956: step 13701, loss 0.000779435, acc 1
2016-09-05T18:37:49.211146: step 13702, loss 0.000967075, acc 1
2016-09-05T18:37:49.418393: step 13703, loss 0.000910166, acc 1
2016-09-05T18:37:49.652076: step 13704, loss 0.000979232, acc 1
2016-09-05T18:37:49.898602: step 13705, loss 0.000748676, acc 1
2016-09-05T18:37:50.108742: step 13706, loss 0.000866324, acc 1
2016-09-05T18:37:50.323188: step 13707, loss 0.00125041, acc 1
2016-09-05T18:37:50.535198: step 13708, loss 0.000746131, acc 1
2016-09-05T18:37:50.769406: step 13709, loss 0.000880761, acc 1
2016-09-05T18:37:50.989383: step 13710, loss 0.00108808, acc 1
2016-09-05T18:37:51.200884: step 13711, loss 0.000858394, acc 1
2016-09-05T18:37:51.405659: step 13712, loss 0.000774063, acc 1
2016-09-05T18:37:51.607396: step 13713, loss 0.00108885, acc 1
2016-09-05T18:37:51.810763: step 13714, loss 0.0009192, acc 1
2016-09-05T18:37:52.022526: step 13715, loss 0.00081395, acc 1
2016-09-05T18:37:52.238126: step 13716, loss 0.000790544, acc 1
2016-09-05T18:37:52.474956: step 13717, loss 0.000859143, acc 1
2016-09-05T18:37:52.702440: step 13718, loss 0.000741797, acc 1
2016-09-05T18:37:52.906248: step 13719, loss 0.000843751, acc 1
2016-09-05T18:37:53.121011: step 13720, loss 0.000862111, acc 1
2016-09-05T18:37:53.333326: step 13721, loss 0.000796942, acc 1
2016-09-05T18:37:53.538517: step 13722, loss 0.00102002, acc 1
2016-09-05T18:37:53.749693: step 13723, loss 0.000946585, acc 1
2016-09-05T18:37:53.968044: step 13724, loss 0.000785396, acc 1
2016-09-05T18:37:54.187533: step 13725, loss 0.000823276, acc 1
2016-09-05T18:37:54.424288: step 13726, loss 0.000775218, acc 1
2016-09-05T18:37:54.630479: step 13727, loss 0.000985258, acc 1
2016-09-05T18:37:54.837662: step 13728, loss 0.00104861, acc 1
2016-09-05T18:37:55.071861: step 13729, loss 0.000802403, acc 1
2016-09-05T18:37:55.283440: step 13730, loss 0.000787112, acc 1
2016-09-05T18:37:55.521922: step 13731, loss 0.00076729, acc 1
2016-09-05T18:37:55.738450: step 13732, loss 0.000756103, acc 1
2016-09-05T18:37:55.946300: step 13733, loss 0.000754998, acc 1
2016-09-05T18:37:56.143676: step 13734, loss 0.000819245, acc 1
2016-09-05T18:37:56.347557: step 13735, loss 0.000780732, acc 1
2016-09-05T18:37:56.547396: step 13736, loss 0.000877879, acc 1
2016-09-05T18:37:56.761046: step 13737, loss 0.000822676, acc 1
2016-09-05T18:37:56.962379: step 13738, loss 0.000764254, acc 1
2016-09-05T18:37:57.195483: step 13739, loss 0.000766265, acc 1
2016-09-05T18:37:57.403275: step 13740, loss 0.000862824, acc 1
2016-09-05T18:37:57.633466: step 13741, loss 0.000759043, acc 1
2016-09-05T18:37:57.858584: step 13742, loss 0.000683715, acc 1
2016-09-05T18:37:58.083752: step 13743, loss 0.000723564, acc 1
2016-09-05T18:37:58.305101: step 13744, loss 0.000801849, acc 1
2016-09-05T18:37:58.534486: step 13745, loss 0.000970594, acc 1
2016-09-05T18:37:58.777407: step 13746, loss 0.000964064, acc 1
2016-09-05T18:37:58.976813: step 13747, loss 0.000718202, acc 1
2016-09-05T18:37:59.181741: step 13748, loss 0.000986526, acc 1
2016-09-05T18:37:59.393223: step 13749, loss 0.00302805, acc 1
2016-09-05T18:37:59.612210: step 13750, loss 0.00165508, acc 1
2016-09-05T18:37:59.838544: step 13751, loss 0.00113789, acc 1
2016-09-05T18:38:00.084391: step 13752, loss 0.00156148, acc 1
2016-09-05T18:38:00.304840: step 13753, loss 0.000871813, acc 1
2016-09-05T18:38:00.517321: step 13754, loss 0.00106656, acc 1
2016-09-05T18:38:00.730819: step 13755, loss 0.00107021, acc 1
2016-09-05T18:38:00.940244: step 13756, loss 0.00111846, acc 1
2016-09-05T18:38:01.188586: step 13757, loss 0.0010199, acc 1
2016-09-05T18:38:01.396272: step 13758, loss 0.00117956, acc 1
2016-09-05T18:38:01.601125: step 13759, loss 0.00116964, acc 1
2016-09-05T18:38:01.798472: step 13760, loss 0.00113213, acc 1
2016-09-05T18:38:02.006520: step 13761, loss 0.00115339, acc 1
2016-09-05T18:38:02.228691: step 13762, loss 0.00131865, acc 1
2016-09-05T18:38:02.444961: step 13763, loss 0.00125369, acc 1
2016-09-05T18:38:02.666052: step 13764, loss 0.00132671, acc 1
2016-09-05T18:38:02.884503: step 13765, loss 0.00120379, acc 1
2016-09-05T18:38:03.090758: step 13766, loss 0.00120937, acc 1
2016-09-05T18:38:03.312291: step 13767, loss 0.00146087, acc 1
2016-09-05T18:38:03.518429: step 13768, loss 0.00119668, acc 1
2016-09-05T18:38:03.723237: step 13769, loss 0.00127166, acc 1
2016-09-05T18:38:03.935006: step 13770, loss 0.00137237, acc 1
2016-09-05T18:38:04.176858: step 13771, loss 0.00139303, acc 1
2016-09-05T18:38:04.407687: step 13772, loss 0.00134379, acc 1
2016-09-05T18:38:04.622610: step 13773, loss 0.00123879, acc 1
2016-09-05T18:38:04.754920: step 13774, loss 0.00113767, acc 1
2016-09-05T18:38:04.984531: step 13775, loss 0.00112562, acc 1
2016-09-05T18:38:05.215646: step 13776, loss 0.00154426, acc 1
2016-09-05T18:38:05.428481: step 13777, loss 0.00106548, acc 1
2016-09-05T18:38:05.642252: step 13778, loss 0.00133724, acc 1
2016-09-05T18:38:05.855960: step 13779, loss 0.00272857, acc 1
2016-09-05T18:38:06.077434: step 13780, loss 0.00114401, acc 1
2016-09-05T18:38:06.330152: step 13781, loss 0.0010295, acc 1
2016-09-05T18:38:06.546654: step 13782, loss 0.00132842, acc 1
2016-09-05T18:38:06.744619: step 13783, loss 0.00120122, acc 1
2016-09-05T18:38:06.960274: step 13784, loss 0.00232024, acc 1
2016-09-05T18:38:07.173940: step 13785, loss 0.00120603, acc 1
2016-09-05T18:38:07.397314: step 13786, loss 0.00145321, acc 1
2016-09-05T18:38:07.616318: step 13787, loss 0.00113444, acc 1
2016-09-05T18:38:07.839732: step 13788, loss 0.00117321, acc 1
2016-09-05T18:38:08.071579: step 13789, loss 0.00126825, acc 1
2016-09-05T18:38:08.300552: step 13790, loss 0.00122013, acc 1
2016-09-05T18:38:08.551576: step 13791, loss 0.00121865, acc 1
2016-09-05T18:38:08.763597: step 13792, loss 0.00125749, acc 1
2016-09-05T18:38:08.976677: step 13793, loss 0.00124898, acc 1
2016-09-05T18:38:09.175158: step 13794, loss 0.00126735, acc 1
2016-09-05T18:38:09.378861: step 13795, loss 0.00127567, acc 1
2016-09-05T18:38:09.604401: step 13796, loss 0.00123776, acc 1
2016-09-05T18:38:09.861136: step 13797, loss 0.00127182, acc 1
2016-09-05T18:38:10.071870: step 13798, loss 0.00121505, acc 1
2016-09-05T18:38:10.271812: step 13799, loss 0.00159404, acc 1
2016-09-05T18:38:10.476504: step 13800, loss 0.00133842, acc 1

Evaluation:
2016-09-05T18:38:11.058355: step 13800, loss 1.78466, acc 0.712

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-13800

2016-09-05T18:38:11.827394: step 13801, loss 0.00115446, acc 1
2016-09-05T18:38:12.048459: step 13802, loss 0.00138137, acc 1
2016-09-05T18:38:12.277587: step 13803, loss 0.00113057, acc 1
2016-09-05T18:38:12.469423: step 13804, loss 0.00110917, acc 1
2016-09-05T18:38:12.692225: step 13805, loss 0.00126027, acc 1
2016-09-05T18:38:12.893764: step 13806, loss 0.00115031, acc 1
2016-09-05T18:38:13.103040: step 13807, loss 0.00107429, acc 1
2016-09-05T18:38:13.332246: step 13808, loss 0.00110902, acc 1
2016-09-05T18:38:13.597822: step 13809, loss 0.00103014, acc 1
2016-09-05T18:38:13.805720: step 13810, loss 0.000982707, acc 1
2016-09-05T18:38:14.013848: step 13811, loss 0.000982329, acc 1
2016-09-05T18:38:14.232747: step 13812, loss 0.00103459, acc 1
2016-09-05T18:38:14.445473: step 13813, loss 0.00103544, acc 1
2016-09-05T18:38:14.697878: step 13814, loss 0.000989282, acc 1
2016-09-05T18:38:14.901595: step 13815, loss 0.0010363, acc 1
2016-09-05T18:38:15.121990: step 13816, loss 0.00100243, acc 1
2016-09-05T18:38:15.335140: step 13817, loss 0.00094889, acc 1
2016-09-05T18:38:15.559081: step 13818, loss 0.000964174, acc 1
2016-09-05T18:38:15.798747: step 13819, loss 0.00132095, acc 1
2016-09-05T18:38:15.993029: step 13820, loss 0.00092528, acc 1
2016-09-05T18:38:16.214749: step 13821, loss 0.00094951, acc 1
2016-09-05T18:38:16.415526: step 13822, loss 0.00121675, acc 1
2016-09-05T18:38:16.626406: step 13823, loss 0.00087263, acc 1
2016-09-05T18:38:16.834315: step 13824, loss 0.000805648, acc 1
2016-09-05T18:38:17.071736: step 13825, loss 0.000771519, acc 1
2016-09-05T18:38:17.310951: step 13826, loss 0.000869107, acc 1
2016-09-05T18:38:17.531183: step 13827, loss 0.000907319, acc 1
2016-09-05T18:38:17.730506: step 13828, loss 0.000974805, acc 1
2016-09-05T18:38:17.935338: step 13829, loss 0.0067543, acc 1
2016-09-05T18:38:18.146388: step 13830, loss 0.000908227, acc 1
2016-09-05T18:38:18.363878: step 13831, loss 0.00462121, acc 1
2016-09-05T18:38:18.558951: step 13832, loss 0.00856891, acc 1
2016-09-05T18:38:18.787090: step 13833, loss 0.00157468, acc 1
2016-09-05T18:38:19.007872: step 13834, loss 0.00181562, acc 1
2016-09-05T18:38:19.248889: step 13835, loss 0.0204717, acc 0.98
2016-09-05T18:38:19.458195: step 13836, loss 0.00262077, acc 1
2016-09-05T18:38:19.675807: step 13837, loss 0.00312067, acc 1
2016-09-05T18:38:19.895554: step 13838, loss 0.00378605, acc 1
2016-09-05T18:38:20.123775: step 13839, loss 0.00434667, acc 1
2016-09-05T18:38:20.360799: step 13840, loss 0.06111, acc 0.98
2016-09-05T18:38:20.569657: step 13841, loss 0.00541433, acc 1
2016-09-05T18:38:20.798595: step 13842, loss 0.00608953, acc 1
2016-09-05T18:38:21.006924: step 13843, loss 0.0069897, acc 1
2016-09-05T18:38:21.249421: step 13844, loss 0.0171083, acc 1
2016-09-05T18:38:21.465919: step 13845, loss 0.0106689, acc 1
2016-09-05T18:38:21.679971: step 13846, loss 0.014921, acc 1
2016-09-05T18:38:21.884721: step 13847, loss 0.0114783, acc 1
2016-09-05T18:38:22.095670: step 13848, loss 0.0118415, acc 1
2016-09-05T18:38:22.299342: step 13849, loss 0.0126601, acc 1
2016-09-05T18:38:22.514581: step 13850, loss 0.0136553, acc 1
2016-09-05T18:38:22.734261: step 13851, loss 0.0143707, acc 1
2016-09-05T18:38:22.953695: step 13852, loss 0.0151288, acc 1
2016-09-05T18:38:23.185151: step 13853, loss 0.0158153, acc 1
2016-09-05T18:38:23.389540: step 13854, loss 0.0164289, acc 1
2016-09-05T18:38:23.604878: step 13855, loss 0.0169705, acc 1
2016-09-05T18:38:23.811782: step 13856, loss 0.0174411, acc 1
2016-09-05T18:38:24.010699: step 13857, loss 0.017844, acc 1
2016-09-05T18:38:24.212829: step 13858, loss 0.0181826, acc 1
2016-09-05T18:38:24.438816: step 13859, loss 0.0185239, acc 1
2016-09-05T18:38:24.645547: step 13860, loss 0.018681, acc 1
2016-09-05T18:38:24.877892: step 13861, loss 0.018849, acc 1
2016-09-05T18:38:25.092329: step 13862, loss 0.0189685, acc 1
2016-09-05T18:38:25.298680: step 13863, loss 0.0190434, acc 1
2016-09-05T18:38:25.522040: step 13864, loss 0.0190898, acc 1
2016-09-05T18:38:25.774461: step 13865, loss 0.0190752, acc 1
2016-09-05T18:38:25.992719: step 13866, loss 0.0190394, acc 1
2016-09-05T18:38:26.219784: step 13867, loss 0.0189737, acc 1
2016-09-05T18:38:26.462740: step 13868, loss 0.0188814, acc 1
2016-09-05T18:38:26.672638: step 13869, loss 0.0187651, acc 1
2016-09-05T18:38:26.899276: step 13870, loss 0.018628, acc 1
2016-09-05T18:38:27.096209: step 13871, loss 0.0184722, acc 1
2016-09-05T18:38:27.315825: step 13872, loss 0.0183002, acc 1
2016-09-05T18:38:27.512222: step 13873, loss 0.0181165, acc 1
2016-09-05T18:38:27.714061: step 13874, loss 0.0179164, acc 1
2016-09-05T18:38:27.914522: step 13875, loss 0.0179215, acc 1
2016-09-05T18:38:28.121799: step 13876, loss 0.0174888, acc 1
2016-09-05T18:38:28.331851: step 13877, loss 0.0173433, acc 1
2016-09-05T18:38:28.544455: step 13878, loss 0.0170299, acc 1
2016-09-05T18:38:28.751070: step 13879, loss 0.0167929, acc 1
2016-09-05T18:38:28.970326: step 13880, loss 0.0165522, acc 1
2016-09-05T18:38:29.184898: step 13881, loss 0.0163092, acc 1
2016-09-05T18:38:29.427078: step 13882, loss 0.0160671, acc 1
2016-09-05T18:38:29.617115: step 13883, loss 0.0158181, acc 1
2016-09-05T18:38:29.826297: step 13884, loss 0.0155719, acc 1
2016-09-05T18:38:30.030341: step 13885, loss 0.0153253, acc 1
2016-09-05T18:38:30.232246: step 13886, loss 0.0150798, acc 1
2016-09-05T18:38:30.444415: step 13887, loss 0.014843, acc 1
2016-09-05T18:38:30.663980: step 13888, loss 0.0145924, acc 1
2016-09-05T18:38:30.863679: step 13889, loss 0.0143521, acc 1
2016-09-05T18:38:31.092722: step 13890, loss 0.0141126, acc 1
2016-09-05T18:38:31.307877: step 13891, loss 0.0138803, acc 1
2016-09-05T18:38:31.537959: step 13892, loss 0.0136421, acc 1
2016-09-05T18:38:31.762733: step 13893, loss 0.0134113, acc 1
2016-09-05T18:38:31.968385: step 13894, loss 0.0131915, acc 1
2016-09-05T18:38:32.184526: step 13895, loss 0.0129581, acc 1
2016-09-05T18:38:32.386249: step 13896, loss 0.0127364, acc 1
2016-09-05T18:38:32.599458: step 13897, loss 0.0125186, acc 1
2016-09-05T18:38:32.803519: step 13898, loss 0.0123032, acc 1
2016-09-05T18:38:33.025404: step 13899, loss 0.0120915, acc 1
2016-09-05T18:38:33.236545: step 13900, loss 0.0118834, acc 1

Evaluation:
2016-09-05T18:38:33.864215: step 13900, loss 3.73074, acc 0.723

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-13900

2016-09-05T18:38:34.700516: step 13901, loss 0.0117253, acc 1
2016-09-05T18:38:34.917552: step 13902, loss 0.0114839, acc 1
2016-09-05T18:38:35.130944: step 13903, loss 0.0113423, acc 1
2016-09-05T18:38:35.338361: step 13904, loss 0.0110913, acc 1
2016-09-05T18:38:35.578134: step 13905, loss 0.0108934, acc 1
2016-09-05T18:38:35.796398: step 13906, loss 0.0107051, acc 1
2016-09-05T18:38:36.011905: step 13907, loss 0.0105216, acc 1
2016-09-05T18:38:36.204820: step 13908, loss 0.0105527, acc 1
2016-09-05T18:38:36.404823: step 13909, loss 0.0102027, acc 1
2016-09-05T18:38:36.610120: step 13910, loss 0.0100737, acc 1
2016-09-05T18:38:36.810864: step 13911, loss 0.00982765, acc 1
2016-09-05T18:38:37.011809: step 13912, loss 0.0096648, acc 1
2016-09-05T18:38:37.237805: step 13913, loss 0.00950251, acc 1
2016-09-05T18:38:37.456088: step 13914, loss 0.0195682, acc 1
2016-09-05T18:38:37.677804: step 13915, loss 0.00930828, acc 1
2016-09-05T18:38:37.884807: step 13916, loss 0.00930935, acc 1
2016-09-05T18:38:38.089537: step 13917, loss 0.00955062, acc 1
2016-09-05T18:38:38.314718: step 13918, loss 0.0104754, acc 1
2016-09-05T18:38:38.530964: step 13919, loss 0.00941452, acc 1
2016-09-05T18:38:38.737412: step 13920, loss 0.0193464, acc 1
2016-09-05T18:38:38.991348: step 13921, loss 0.00940645, acc 1
2016-09-05T18:38:39.221430: step 13922, loss 0.00972195, acc 1
2016-09-05T18:38:39.426227: step 13923, loss 0.00941544, acc 1
2016-09-05T18:38:39.652371: step 13924, loss 0.00966381, acc 1
2016-09-05T18:38:39.870132: step 13925, loss 0.009514, acc 1
2016-09-05T18:38:40.084463: step 13926, loss 0.009566, acc 1
2016-09-05T18:38:40.313417: step 13927, loss 0.00963003, acc 1
2016-09-05T18:38:40.537465: step 13928, loss 0.00967111, acc 1
2016-09-05T18:38:40.749240: step 13929, loss 0.00971827, acc 1
2016-09-05T18:38:40.966837: step 13930, loss 0.0097459, acc 1
2016-09-05T18:38:41.172988: step 13931, loss 0.00976736, acc 1
2016-09-05T18:38:41.376622: step 13932, loss 0.00977942, acc 1
2016-09-05T18:38:41.582977: step 13933, loss 0.00977329, acc 1
2016-09-05T18:38:41.781393: step 13934, loss 0.00975947, acc 1
2016-09-05T18:38:41.978200: step 13935, loss 0.00973357, acc 1
2016-09-05T18:38:42.188667: step 13936, loss 0.00976931, acc 1
2016-09-05T18:38:42.390144: step 13937, loss 0.00976263, acc 1
2016-09-05T18:38:42.588393: step 13938, loss 0.00960019, acc 1
2016-09-05T18:38:42.808112: step 13939, loss 0.00954135, acc 1
2016-09-05T18:38:43.020197: step 13940, loss 0.00946759, acc 1
2016-09-05T18:38:43.247071: step 13941, loss 0.0094354, acc 1
2016-09-05T18:38:43.458141: step 13942, loss 0.0093095, acc 1
2016-09-05T18:38:43.674877: step 13943, loss 0.00966963, acc 1
2016-09-05T18:38:43.884973: step 13944, loss 0.0138489, acc 1
2016-09-05T18:38:44.141958: step 13945, loss 0.0116587, acc 1
2016-09-05T18:38:44.369369: step 13946, loss 0.00907058, acc 1
2016-09-05T18:38:44.583987: step 13947, loss 0.00907764, acc 1
2016-09-05T18:38:44.784585: step 13948, loss 0.00909142, acc 1
2016-09-05T18:38:45.010856: step 13949, loss 0.00910509, acc 1
2016-09-05T18:38:45.242231: step 13950, loss 0.00911753, acc 1
2016-09-05T18:38:45.469026: step 13951, loss 0.00913496, acc 1
2016-09-05T18:38:45.688524: step 13952, loss 0.00912297, acc 1
2016-09-05T18:38:45.882654: step 13953, loss 0.00914116, acc 1
2016-09-05T18:38:46.085209: step 13954, loss 0.00909757, acc 1
2016-09-05T18:38:46.293040: step 13955, loss 0.0093439, acc 1
2016-09-05T18:38:46.523148: step 13956, loss 0.00907898, acc 1
2016-09-05T18:38:46.745045: step 13957, loss 0.00919242, acc 1
2016-09-05T18:38:46.979376: step 13958, loss 0.00923949, acc 1
2016-09-05T18:38:47.197626: step 13959, loss 0.0100414, acc 1
2016-09-05T18:38:47.401494: step 13960, loss 0.00879932, acc 1
2016-09-05T18:38:47.611722: step 13961, loss 0.00887463, acc 1
2016-09-05T18:38:47.837427: step 13962, loss 0.0100333, acc 1
2016-09-05T18:38:48.046498: step 13963, loss 0.00852537, acc 1
2016-09-05T18:38:48.270359: step 13964, loss 0.00839839, acc 1
2016-09-05T18:38:48.503981: step 13965, loss 0.00830968, acc 1
2016-09-05T18:38:48.715005: step 13966, loss 0.0923267, acc 0.98
2016-09-05T18:38:48.951204: step 13967, loss 0.00799539, acc 1
2016-09-05T18:38:49.113341: step 13968, loss 0.00802568, acc 1
2016-09-05T18:38:49.371981: step 13969, loss 0.00818908, acc 1
2016-09-05T18:38:49.585735: step 13970, loss 0.0644861, acc 0.98
2016-09-05T18:38:49.808331: step 13971, loss 0.00885142, acc 1
2016-09-05T18:38:50.025111: step 13972, loss 0.00927802, acc 1
2016-09-05T18:38:50.242046: step 13973, loss 0.0096927, acc 1
2016-09-05T18:38:50.436508: step 13974, loss 0.0101582, acc 1
2016-09-05T18:38:50.657005: step 13975, loss 0.0106276, acc 1
2016-09-05T18:38:50.860896: step 13976, loss 0.0180593, acc 1
2016-09-05T18:38:51.089530: step 13977, loss 0.0115338, acc 1
2016-09-05T18:38:51.327737: step 13978, loss 0.0119726, acc 1
2016-09-05T18:38:51.536662: step 13979, loss 0.0123986, acc 1
2016-09-05T18:38:51.755775: step 13980, loss 0.0127988, acc 1
2016-09-05T18:38:51.958699: step 13981, loss 0.01317, acc 1
2016-09-05T18:38:52.178053: step 13982, loss 0.0135038, acc 1
2016-09-05T18:38:52.395201: step 13983, loss 0.0138056, acc 1
2016-09-05T18:38:52.640893: step 13984, loss 0.0140728, acc 1
2016-09-05T18:38:52.841220: step 13985, loss 0.0143063, acc 1
2016-09-05T18:38:53.051855: step 13986, loss 0.0145062, acc 1
2016-09-05T18:38:53.258466: step 13987, loss 0.0146757, acc 1
2016-09-05T18:38:53.473298: step 13988, loss 0.0148134, acc 1
2016-09-05T18:38:53.694969: step 13989, loss 0.0149239, acc 1
2016-09-05T18:38:53.904635: step 13990, loss 0.015008, acc 1
2016-09-05T18:38:54.121647: step 13991, loss 0.0150723, acc 1
2016-09-05T18:38:54.344840: step 13992, loss 0.0151051, acc 1
2016-09-05T18:38:54.571548: step 13993, loss 0.0151219, acc 1
2016-09-05T18:38:54.783565: step 13994, loss 0.0151199, acc 1
2016-09-05T18:38:55.028260: step 13995, loss 0.0151058, acc 1
2016-09-05T18:38:55.276650: step 13996, loss 0.0150718, acc 1
2016-09-05T18:38:55.495569: step 13997, loss 0.0150163, acc 1
2016-09-05T18:38:55.708961: step 13998, loss 0.0149548, acc 1
2016-09-05T18:38:55.938584: step 13999, loss 0.0148819, acc 1
2016-09-05T18:38:56.176015: step 14000, loss 0.0147989, acc 1

Evaluation:
2016-09-05T18:38:56.756293: step 14000, loss 5.28759, acc 0.729

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-14000

2016-09-05T18:38:57.544418: step 14001, loss 0.0147069, acc 1
2016-09-05T18:38:57.756841: step 14002, loss 0.014607, acc 1
2016-09-05T18:38:57.995156: step 14003, loss 0.0145001, acc 1
2016-09-05T18:38:58.214478: step 14004, loss 0.0143871, acc 1
2016-09-05T18:38:58.427576: step 14005, loss 0.0142687, acc 1
2016-09-05T18:38:58.650716: step 14006, loss 0.0141458, acc 1
2016-09-05T18:38:58.862853: step 14007, loss 0.0140187, acc 1
2016-09-05T18:38:59.111363: step 14008, loss 0.0139002, acc 1
2016-09-05T18:38:59.323364: step 14009, loss 0.0137551, acc 1
2016-09-05T18:38:59.534443: step 14010, loss 0.0136297, acc 1
2016-09-05T18:38:59.757343: step 14011, loss 0.0134822, acc 1
2016-09-05T18:39:00.006657: step 14012, loss 0.013343, acc 1
2016-09-05T18:39:00.252218: step 14013, loss 0.0132041, acc 1
2016-09-05T18:39:00.461993: step 14014, loss 0.0130617, acc 1
2016-09-05T18:39:00.664609: step 14015, loss 0.01292, acc 1
2016-09-05T18:39:00.876946: step 14016, loss 0.012778, acc 1
2016-09-05T18:39:01.098660: step 14017, loss 0.0126359, acc 1
2016-09-05T18:39:01.324442: step 14018, loss 0.0155406, acc 1
2016-09-05T18:39:01.543917: step 14019, loss 0.0123524, acc 1
2016-09-05T18:39:01.742154: step 14020, loss 0.0128408, acc 1
2016-09-05T18:39:01.944937: step 14021, loss 0.0120716, acc 1
2016-09-05T18:39:02.147166: step 14022, loss 0.0119327, acc 1
2016-09-05T18:39:02.358270: step 14023, loss 0.0117948, acc 1
2016-09-05T18:39:02.551082: step 14024, loss 0.0116576, acc 1
2016-09-05T18:39:02.773944: step 14025, loss 0.0115219, acc 1
2016-09-05T18:39:02.977124: step 14026, loss 0.0116365, acc 1
2016-09-05T18:39:03.193420: step 14027, loss 0.0112538, acc 1
2016-09-05T18:39:03.392306: step 14028, loss 0.0111206, acc 1
2016-09-05T18:39:03.599251: step 14029, loss 0.0109894, acc 1
2016-09-05T18:39:03.818822: step 14030, loss 0.0108595, acc 1
2016-09-05T18:39:04.013063: step 14031, loss 0.0107304, acc 1
2016-09-05T18:39:04.233788: step 14032, loss 0.0106028, acc 1
2016-09-05T18:39:04.457433: step 14033, loss 0.0104765, acc 1
2016-09-05T18:39:04.671967: step 14034, loss 0.0103772, acc 1
2016-09-05T18:39:04.871959: step 14035, loss 0.0102279, acc 1
2016-09-05T18:39:05.090291: step 14036, loss 0.010106, acc 1
2016-09-05T18:39:05.295391: step 14037, loss 0.00998461, acc 1
2016-09-05T18:39:05.507369: step 14038, loss 0.00986496, acc 1
2016-09-05T18:39:05.715489: step 14039, loss 0.00974669, acc 1
2016-09-05T18:39:05.917214: step 14040, loss 0.00962974, acc 1
2016-09-05T18:39:06.125562: step 14041, loss 0.00951413, acc 1
2016-09-05T18:39:06.343358: step 14042, loss 0.00939986, acc 1
2016-09-05T18:39:06.556780: step 14043, loss 0.00928696, acc 1
2016-09-05T18:39:06.764457: step 14044, loss 0.00918829, acc 1
2016-09-05T18:39:06.974424: step 14045, loss 0.00906642, acc 1
2016-09-05T18:39:07.205297: step 14046, loss 0.00895951, acc 1
2016-09-05T18:39:07.457836: step 14047, loss 0.00884878, acc 1
2016-09-05T18:39:07.677058: step 14048, loss 0.00874295, acc 1
2016-09-05T18:39:07.884734: step 14049, loss 0.0086382, acc 1
2016-09-05T18:39:08.094801: step 14050, loss 0.00853721, acc 1
2016-09-05T18:39:08.295606: step 14051, loss 0.00843167, acc 1
2016-09-05T18:39:08.487641: step 14052, loss 0.00833063, acc 1
2016-09-05T18:39:08.699475: step 14053, loss 0.00881675, acc 1
2016-09-05T18:39:08.908959: step 14054, loss 0.00813489, acc 1
2016-09-05T18:39:09.118366: step 14055, loss 0.00803997, acc 1
2016-09-05T18:39:09.347250: step 14056, loss 0.0079462, acc 1
2016-09-05T18:39:09.560415: step 14057, loss 0.00785338, acc 1
2016-09-05T18:39:09.768136: step 14058, loss 0.00776148, acc 1
2016-09-05T18:39:10.010378: step 14059, loss 0.00767352, acc 1
2016-09-05T18:39:10.201382: step 14060, loss 0.0075809, acc 1
2016-09-05T18:39:10.405964: step 14061, loss 0.00752751, acc 1
2016-09-05T18:39:10.613757: step 14062, loss 0.0074042, acc 1
2016-09-05T18:39:10.837014: step 14063, loss 0.00731768, acc 1
2016-09-05T18:39:11.048054: step 14064, loss 0.00723145, acc 1
2016-09-05T18:39:11.271419: step 14065, loss 0.00714753, acc 1
2016-09-05T18:39:11.493377: step 14066, loss 0.00706473, acc 1
2016-09-05T18:39:11.720156: step 14067, loss 0.00698032, acc 1
2016-09-05T18:39:11.919629: step 14068, loss 0.0068977, acc 1
2016-09-05T18:39:12.128380: step 14069, loss 0.00681632, acc 1
2016-09-05T18:39:12.335690: step 14070, loss 0.00686992, acc 1
2016-09-05T18:39:12.534534: step 14071, loss 0.00665778, acc 1
2016-09-05T18:39:12.737737: step 14072, loss 0.00657923, acc 1
2016-09-05T18:39:12.938437: step 14073, loss 0.00651358, acc 1
2016-09-05T18:39:13.150586: step 14074, loss 0.00642585, acc 1
2016-09-05T18:39:13.348282: step 14075, loss 0.00635099, acc 1
2016-09-05T18:39:13.553861: step 14076, loss 0.00627626, acc 1
2016-09-05T18:39:13.762208: step 14077, loss 0.00620233, acc 1
2016-09-05T18:39:13.968893: step 14078, loss 0.00613239, acc 1
2016-09-05T18:39:14.197051: step 14079, loss 0.00605782, acc 1
2016-09-05T18:39:14.436645: step 14080, loss 0.00598672, acc 1
2016-09-05T18:39:14.641187: step 14081, loss 0.00591794, acc 1
2016-09-05T18:39:14.853964: step 14082, loss 0.0058917, acc 1
2016-09-05T18:39:15.057206: step 14083, loss 0.00579528, acc 1
2016-09-05T18:39:15.265050: step 14084, loss 0.0123168, acc 1
2016-09-05T18:39:15.484886: step 14085, loss 0.00564732, acc 1
2016-09-05T18:39:15.705333: step 14086, loss 0.00558573, acc 1
2016-09-05T18:39:15.933232: step 14087, loss 0.00562274, acc 1
2016-09-05T18:39:16.133005: step 14088, loss 0.00547968, acc 1
2016-09-05T18:39:16.334795: step 14089, loss 0.00542857, acc 1
2016-09-05T18:39:16.544444: step 14090, loss 0.00539934, acc 1
2016-09-05T18:39:16.777237: step 14091, loss 0.00533561, acc 1
2016-09-05T18:39:16.986712: step 14092, loss 0.00529072, acc 1
2016-09-05T18:39:17.235954: step 14093, loss 0.00524698, acc 1
2016-09-05T18:39:17.471200: step 14094, loss 0.00520326, acc 1
2016-09-05T18:39:17.687043: step 14095, loss 0.0051557, acc 1
2016-09-05T18:39:17.907616: step 14096, loss 0.00524102, acc 1
2016-09-05T18:39:18.138825: step 14097, loss 0.0051342, acc 1
2016-09-05T18:39:18.364949: step 14098, loss 0.00501918, acc 1
2016-09-05T18:39:18.553824: step 14099, loss 0.00513321, acc 1
2016-09-05T18:39:18.769378: step 14100, loss 0.0060207, acc 1

Evaluation:
2016-09-05T18:39:19.432515: step 14100, loss 3.51704, acc 0.708

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-14100

2016-09-05T18:39:20.168005: step 14101, loss 0.00540561, acc 1
2016-09-05T18:39:20.401393: step 14102, loss 0.00483839, acc 1
2016-09-05T18:39:20.593358: step 14103, loss 0.00481743, acc 1
2016-09-05T18:39:20.820805: step 14104, loss 0.00477828, acc 1
2016-09-05T18:39:21.014205: step 14105, loss 0.00470812, acc 1
2016-09-05T18:39:21.222519: step 14106, loss 0.00897945, acc 1
2016-09-05T18:39:21.431057: step 14107, loss 0.00468291, acc 1
2016-09-05T18:39:21.640430: step 14108, loss 0.0047141, acc 1
2016-09-05T18:39:21.832015: step 14109, loss 0.00454163, acc 1
2016-09-05T18:39:22.039470: step 14110, loss 0.00450406, acc 1
2016-09-05T18:39:22.244953: step 14111, loss 0.00446411, acc 1
2016-09-05T18:39:22.451061: step 14112, loss 0.00442097, acc 1
2016-09-05T18:39:22.656854: step 14113, loss 0.00438068, acc 1
2016-09-05T18:39:22.884405: step 14114, loss 0.00434202, acc 1
2016-09-05T18:39:23.104658: step 14115, loss 0.00429462, acc 1
2016-09-05T18:39:23.378145: step 14116, loss 0.0042526, acc 1
2016-09-05T18:39:23.588335: step 14117, loss 0.00421053, acc 1
2016-09-05T18:39:23.811422: step 14118, loss 0.00418439, acc 1
2016-09-05T18:39:24.051773: step 14119, loss 0.00412467, acc 1
2016-09-05T18:39:24.243911: step 14120, loss 0.0040832, acc 1
2016-09-05T18:39:24.467803: step 14121, loss 0.0040398, acc 1
2016-09-05T18:39:24.664537: step 14122, loss 0.00399594, acc 1
2016-09-05T18:39:24.863934: step 14123, loss 0.00400083, acc 1
2016-09-05T18:39:25.067745: step 14124, loss 0.00391988, acc 1
2016-09-05T18:39:25.276632: step 14125, loss 0.00387241, acc 1
2016-09-05T18:39:25.489318: step 14126, loss 0.00382819, acc 1
2016-09-05T18:39:25.721344: step 14127, loss 0.0037838, acc 1
2016-09-05T18:39:25.941488: step 14128, loss 0.00381148, acc 1
2016-09-05T18:39:26.158591: step 14129, loss 0.00370243, acc 1
2016-09-05T18:39:26.378060: step 14130, loss 0.00365981, acc 1
2016-09-05T18:39:26.583147: step 14131, loss 0.00362283, acc 1
2016-09-05T18:39:26.777787: step 14132, loss 0.00358025, acc 1
2016-09-05T18:39:26.987456: step 14133, loss 0.00353838, acc 1
2016-09-05T18:39:27.191346: step 14134, loss 0.00349894, acc 1
2016-09-05T18:39:27.407285: step 14135, loss 0.00345796, acc 1
2016-09-05T18:39:27.619948: step 14136, loss 0.00345404, acc 1
2016-09-05T18:39:27.839283: step 14137, loss 0.00351983, acc 1
2016-09-05T18:39:28.071635: step 14138, loss 0.00336376, acc 1
2016-09-05T18:39:28.311533: step 14139, loss 0.00332839, acc 1
2016-09-05T18:39:28.521155: step 14140, loss 0.00326647, acc 1
2016-09-05T18:39:28.739208: step 14141, loss 0.00327416, acc 1
2016-09-05T18:39:28.969425: step 14142, loss 0.00319549, acc 1
2016-09-05T18:39:29.199449: step 14143, loss 0.00315674, acc 1
2016-09-05T18:39:29.406956: step 14144, loss 0.00312909, acc 1
2016-09-05T18:39:29.615959: step 14145, loss 0.00308804, acc 1
2016-09-05T18:39:29.820250: step 14146, loss 0.00305351, acc 1
2016-09-05T18:39:30.032258: step 14147, loss 0.00302019, acc 1
2016-09-05T18:39:30.258352: step 14148, loss 0.00298167, acc 1
2016-09-05T18:39:30.484837: step 14149, loss 0.00299792, acc 1
2016-09-05T18:39:30.694064: step 14150, loss 0.00301309, acc 1
2016-09-05T18:39:30.913475: step 14151, loss 0.00288304, acc 1
2016-09-05T18:39:31.123916: step 14152, loss 0.00285519, acc 1
2016-09-05T18:39:31.330436: step 14153, loss 0.00288176, acc 1
2016-09-05T18:39:31.524454: step 14154, loss 0.00279578, acc 1
2016-09-05T18:39:31.726420: step 14155, loss 0.00275993, acc 1
2016-09-05T18:39:31.928293: step 14156, loss 0.00277427, acc 1
2016-09-05T18:39:32.147148: step 14157, loss 0.00269519, acc 1
2016-09-05T18:39:32.362702: step 14158, loss 0.00266224, acc 1
2016-09-05T18:39:32.576868: step 14159, loss 0.00274432, acc 1
2016-09-05T18:39:32.800579: step 14160, loss 0.00260634, acc 1
2016-09-05T18:39:33.040981: step 14161, loss 0.0025744, acc 1
2016-09-05T18:39:33.160727: step 14162, loss 0.00262343, acc 1
2016-09-05T18:39:33.382629: step 14163, loss 0.00270701, acc 1
2016-09-05T18:39:33.588310: step 14164, loss 0.00249216, acc 1
2016-09-05T18:39:33.815346: step 14165, loss 0.00247557, acc 1
2016-09-05T18:39:34.044303: step 14166, loss 0.00243722, acc 1
2016-09-05T18:39:34.266484: step 14167, loss 0.00241636, acc 1
2016-09-05T18:39:34.466492: step 14168, loss 0.00242629, acc 1
2016-09-05T18:39:34.690125: step 14169, loss 0.00237071, acc 1
2016-09-05T18:39:34.906615: step 14170, loss 0.00235324, acc 1
2016-09-05T18:39:35.134651: step 14171, loss 0.00242843, acc 1
2016-09-05T18:39:35.357203: step 14172, loss 0.00229177, acc 1
2016-09-05T18:39:35.552290: step 14173, loss 0.00226585, acc 1
2016-09-05T18:39:35.752319: step 14174, loss 0.00223517, acc 1
2016-09-05T18:39:35.963522: step 14175, loss 0.00221813, acc 1
2016-09-05T18:39:36.176532: step 14176, loss 0.00228052, acc 1
2016-09-05T18:39:36.380026: step 14177, loss 0.00216219, acc 1
2016-09-05T18:39:36.592808: step 14178, loss 0.00215296, acc 1
2016-09-05T18:39:36.804792: step 14179, loss 0.00218543, acc 1
2016-09-05T18:39:37.031940: step 14180, loss 0.00211257, acc 1
2016-09-05T18:39:37.267512: step 14181, loss 0.00214299, acc 1
2016-09-05T18:39:37.481184: step 14182, loss 0.00207457, acc 1
2016-09-05T18:39:37.691458: step 14183, loss 0.00204884, acc 1
2016-09-05T18:39:37.916583: step 14184, loss 0.002039, acc 1
2016-09-05T18:39:38.161415: step 14185, loss 0.00200004, acc 1
2016-09-05T18:39:38.387689: step 14186, loss 0.00208242, acc 1
2016-09-05T18:39:38.601601: step 14187, loss 0.00222388, acc 1
2016-09-05T18:39:38.789194: step 14188, loss 0.00220551, acc 1
2016-09-05T18:39:38.997395: step 14189, loss 0.002034, acc 1
2016-09-05T18:39:39.205323: step 14190, loss 0.00197969, acc 1
2016-09-05T18:39:39.423204: step 14191, loss 0.00192117, acc 1
2016-09-05T18:39:39.630344: step 14192, loss 0.00186454, acc 1
2016-09-05T18:39:39.868354: step 14193, loss 0.00186618, acc 1
2016-09-05T18:39:40.072487: step 14194, loss 0.00209027, acc 1
2016-09-05T18:39:40.281376: step 14195, loss 0.00184633, acc 1
2016-09-05T18:39:40.491522: step 14196, loss 0.00216591, acc 1
2016-09-05T18:39:40.696386: step 14197, loss 0.00208468, acc 1
2016-09-05T18:39:40.902360: step 14198, loss 0.00178438, acc 1
2016-09-05T18:39:41.122577: step 14199, loss 0.00200924, acc 1
2016-09-05T18:39:41.360362: step 14200, loss 0.00172592, acc 1

Evaluation:
2016-09-05T18:39:42.008509: step 14200, loss 1.99468, acc 0.717

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-14200

2016-09-05T18:39:42.809440: step 14201, loss 0.00188554, acc 1
2016-09-05T18:39:43.018359: step 14202, loss 0.00182131, acc 1
2016-09-05T18:39:43.219754: step 14203, loss 0.00174709, acc 1
2016-09-05T18:39:43.425400: step 14204, loss 0.00176157, acc 1
2016-09-05T18:39:43.631592: step 14205, loss 0.00197917, acc 1
2016-09-05T18:39:43.839713: step 14206, loss 0.00215442, acc 1
2016-09-05T18:39:44.079415: step 14207, loss 0.00163119, acc 1
2016-09-05T18:39:44.353859: step 14208, loss 0.00160002, acc 1
2016-09-05T18:39:44.600412: step 14209, loss 0.00165438, acc 1
2016-09-05T18:39:44.841646: step 14210, loss 0.00168533, acc 1
2016-09-05T18:39:45.043290: step 14211, loss 0.00167795, acc 1
2016-09-05T18:39:45.264534: step 14212, loss 0.00197461, acc 1
2016-09-05T18:39:45.492358: step 14213, loss 0.0015912, acc 1
2016-09-05T18:39:45.722540: step 14214, loss 0.00200079, acc 1
2016-09-05T18:39:45.947465: step 14215, loss 0.00152167, acc 1
2016-09-05T18:39:46.190665: step 14216, loss 0.00196677, acc 1
2016-09-05T18:39:46.409432: step 14217, loss 0.00165263, acc 1
2016-09-05T18:39:46.635175: step 14218, loss 0.00150713, acc 1
2016-09-05T18:39:46.858813: step 14219, loss 0.00151486, acc 1
2016-09-05T18:39:47.057035: step 14220, loss 0.001485, acc 1
2016-09-05T18:39:47.276152: step 14221, loss 0.00149058, acc 1
2016-09-05T18:39:47.491819: step 14222, loss 0.00146012, acc 1
2016-09-05T18:39:47.714105: step 14223, loss 0.00301883, acc 1
2016-09-05T18:39:47.923547: step 14224, loss 0.00246856, acc 1
2016-09-05T18:39:48.143472: step 14225, loss 0.00147378, acc 1
2016-09-05T18:39:48.361398: step 14226, loss 0.001472, acc 1
2016-09-05T18:39:48.577184: step 14227, loss 0.00142735, acc 1
2016-09-05T18:39:48.794152: step 14228, loss 0.00140768, acc 1
2016-09-05T18:39:49.019361: step 14229, loss 0.00156764, acc 1
2016-09-05T18:39:49.234601: step 14230, loss 0.00154152, acc 1
2016-09-05T18:39:49.460651: step 14231, loss 0.00136178, acc 1
2016-09-05T18:39:49.687036: step 14232, loss 0.00137287, acc 1
2016-09-05T18:39:49.899371: step 14233, loss 0.00136359, acc 1
2016-09-05T18:39:50.134732: step 14234, loss 0.00138735, acc 1
2016-09-05T18:39:50.351605: step 14235, loss 0.00159382, acc 1
2016-09-05T18:39:50.581462: step 14236, loss 0.00139466, acc 1
2016-09-05T18:39:50.809006: step 14237, loss 0.00131697, acc 1
2016-09-05T18:39:51.035789: step 14238, loss 0.00148787, acc 1
2016-09-05T18:39:51.241100: step 14239, loss 0.00133216, acc 1
2016-09-05T18:39:51.458069: step 14240, loss 0.00134282, acc 1
2016-09-05T18:39:51.699708: step 14241, loss 0.00135506, acc 1
2016-09-05T18:39:51.908098: step 14242, loss 0.00158591, acc 1
2016-09-05T18:39:52.113270: step 14243, loss 0.00160153, acc 1
2016-09-05T18:39:52.318440: step 14244, loss 0.00128648, acc 1
2016-09-05T18:39:52.562406: step 14245, loss 0.00220237, acc 1
2016-09-05T18:39:52.779935: step 14246, loss 0.00130033, acc 1
2016-09-05T18:39:53.013874: step 14247, loss 0.0013747, acc 1
2016-09-05T18:39:53.214896: step 14248, loss 0.00127243, acc 1
2016-09-05T18:39:53.421700: step 14249, loss 0.00123051, acc 1
2016-09-05T18:39:53.625137: step 14250, loss 0.00160784, acc 1
2016-09-05T18:39:53.847632: step 14251, loss 0.00153505, acc 1
2016-09-05T18:39:54.060584: step 14252, loss 0.0012628, acc 1
2016-09-05T18:39:54.285356: step 14253, loss 0.00123576, acc 1
2016-09-05T18:39:54.544313: step 14254, loss 0.00143963, acc 1
2016-09-05T18:39:54.753460: step 14255, loss 0.00119526, acc 1
2016-09-05T18:39:54.951205: step 14256, loss 0.0012691, acc 1
2016-09-05T18:39:55.157063: step 14257, loss 0.00146511, acc 1
2016-09-05T18:39:55.377856: step 14258, loss 0.00138253, acc 1
2016-09-05T18:39:55.613397: step 14259, loss 0.00164974, acc 1
2016-09-05T18:39:55.840968: step 14260, loss 0.00119757, acc 1
2016-09-05T18:39:56.039759: step 14261, loss 0.00115302, acc 1
2016-09-05T18:39:56.260207: step 14262, loss 0.00123991, acc 1
2016-09-05T18:39:56.471829: step 14263, loss 0.00127195, acc 1
2016-09-05T18:39:56.683190: step 14264, loss 0.00117509, acc 1
2016-09-05T18:39:56.894003: step 14265, loss 0.0012386, acc 1
2016-09-05T18:39:57.111455: step 14266, loss 0.00116435, acc 1
2016-09-05T18:39:57.333729: step 14267, loss 0.00122127, acc 1
2016-09-05T18:39:57.523575: step 14268, loss 0.00128345, acc 1
2016-09-05T18:39:57.755767: step 14269, loss 0.00127183, acc 1
2016-09-05T18:39:57.962175: step 14270, loss 0.00111124, acc 1
2016-09-05T18:39:58.161032: step 14271, loss 0.00114776, acc 1
2016-09-05T18:39:58.363454: step 14272, loss 0.00112599, acc 1
2016-09-05T18:39:58.572474: step 14273, loss 0.0011471, acc 1
2016-09-05T18:39:58.774009: step 14274, loss 0.00107964, acc 1
2016-09-05T18:39:58.988188: step 14275, loss 0.00160997, acc 1
2016-09-05T18:39:59.205338: step 14276, loss 0.0012362, acc 1
2016-09-05T18:39:59.437732: step 14277, loss 0.00133644, acc 1
2016-09-05T18:39:59.683913: step 14278, loss 0.00110381, acc 1
2016-09-05T18:39:59.929234: step 14279, loss 0.00113614, acc 1
2016-09-05T18:40:00.157474: step 14280, loss 0.00105058, acc 1
2016-09-05T18:40:00.391301: step 14281, loss 0.00235525, acc 1
2016-09-05T18:40:00.604382: step 14282, loss 0.00121694, acc 1
2016-09-05T18:40:00.802670: step 14283, loss 0.00108226, acc 1
2016-09-05T18:40:01.016507: step 14284, loss 0.00201247, acc 1
2016-09-05T18:40:01.225923: step 14285, loss 0.00122991, acc 1
2016-09-05T18:40:01.443622: step 14286, loss 0.00113569, acc 1
2016-09-05T18:40:01.658234: step 14287, loss 0.00108156, acc 1
2016-09-05T18:40:01.887501: step 14288, loss 0.00104579, acc 1
2016-09-05T18:40:02.087906: step 14289, loss 0.00111952, acc 1
2016-09-05T18:40:02.300022: step 14290, loss 0.00160937, acc 1
2016-09-05T18:40:02.513372: step 14291, loss 0.00101503, acc 1
2016-09-05T18:40:02.748057: step 14292, loss 0.0010471, acc 1
2016-09-05T18:40:02.980364: step 14293, loss 0.00136337, acc 1
2016-09-05T18:40:03.181461: step 14294, loss 0.00121726, acc 1
2016-09-05T18:40:03.409053: step 14295, loss 0.00103008, acc 1
2016-09-05T18:40:03.612813: step 14296, loss 0.00107855, acc 1
2016-09-05T18:40:03.833545: step 14297, loss 0.00149706, acc 1
2016-09-05T18:40:04.046508: step 14298, loss 0.00101211, acc 1
2016-09-05T18:40:04.309283: step 14299, loss 0.00143597, acc 1
2016-09-05T18:40:04.518749: step 14300, loss 0.00125702, acc 1

Evaluation:
2016-09-05T18:40:05.135196: step 14300, loss 1.73936, acc 0.719

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-14300

2016-09-05T18:40:05.849360: step 14301, loss 0.00113117, acc 1
2016-09-05T18:40:06.068847: step 14302, loss 0.00214738, acc 1
2016-09-05T18:40:06.269421: step 14303, loss 0.00103923, acc 1
2016-09-05T18:40:06.467369: step 14304, loss 0.00154683, acc 1
2016-09-05T18:40:06.679606: step 14305, loss 0.00111113, acc 1
2016-09-05T18:40:06.877740: step 14306, loss 0.001027, acc 1
2016-09-05T18:40:07.085503: step 14307, loss 0.00113186, acc 1
2016-09-05T18:40:07.303654: step 14308, loss 0.00117624, acc 1
2016-09-05T18:40:07.530860: step 14309, loss 0.0014174, acc 1
2016-09-05T18:40:07.759027: step 14310, loss 0.00111563, acc 1
2016-09-05T18:40:08.011566: step 14311, loss 0.00115247, acc 1
2016-09-05T18:40:08.235137: step 14312, loss 0.00105952, acc 1
2016-09-05T18:40:08.451812: step 14313, loss 0.00096121, acc 1
2016-09-05T18:40:08.647026: step 14314, loss 0.00145521, acc 1
2016-09-05T18:40:08.861397: step 14315, loss 0.00124483, acc 1
2016-09-05T18:40:09.102187: step 14316, loss 0.000997598, acc 1
2016-09-05T18:40:09.339815: step 14317, loss 0.00150243, acc 1
2016-09-05T18:40:09.564630: step 14318, loss 0.0051981, acc 1
2016-09-05T18:40:09.795206: step 14319, loss 0.0010654, acc 1
2016-09-05T18:40:10.000058: step 14320, loss 0.000952359, acc 1
2016-09-05T18:40:10.240040: step 14321, loss 0.00122668, acc 1
2016-09-05T18:40:10.462717: step 14322, loss 0.00203991, acc 1
2016-09-05T18:40:10.666717: step 14323, loss 0.00153585, acc 1
2016-09-05T18:40:10.877193: step 14324, loss 0.00115674, acc 1
2016-09-05T18:40:11.080610: step 14325, loss 0.00250953, acc 1
2016-09-05T18:40:11.287627: step 14326, loss 0.00141001, acc 1
2016-09-05T18:40:11.496141: step 14327, loss 0.00198674, acc 1
2016-09-05T18:40:11.703186: step 14328, loss 0.00128356, acc 1
2016-09-05T18:40:11.903623: step 14329, loss 0.00124196, acc 1
2016-09-05T18:40:12.129129: step 14330, loss 0.00122356, acc 1
2016-09-05T18:40:12.333696: step 14331, loss 0.00127276, acc 1
2016-09-05T18:40:12.563375: step 14332, loss 0.00123003, acc 1
2016-09-05T18:40:12.798870: step 14333, loss 0.0011735, acc 1
2016-09-05T18:40:13.033678: step 14334, loss 0.00116644, acc 1
2016-09-05T18:40:13.269716: step 14335, loss 0.00296405, acc 1
2016-09-05T18:40:13.493609: step 14336, loss 0.00145072, acc 1
2016-09-05T18:40:13.776422: step 14337, loss 0.00116311, acc 1
2016-09-05T18:40:13.992651: step 14338, loss 0.00155043, acc 1
2016-09-05T18:40:14.207325: step 14339, loss 0.00117198, acc 1
2016-09-05T18:40:14.424100: step 14340, loss 0.00116849, acc 1
2016-09-05T18:40:14.662718: step 14341, loss 0.00130015, acc 1
2016-09-05T18:40:14.896446: step 14342, loss 0.00119253, acc 1
2016-09-05T18:40:15.093028: step 14343, loss 0.00121834, acc 1
2016-09-05T18:40:15.299450: step 14344, loss 0.00116514, acc 1
2016-09-05T18:40:15.496065: step 14345, loss 0.00144667, acc 1
2016-09-05T18:40:15.706980: step 14346, loss 0.00116026, acc 1
2016-09-05T18:40:15.910331: step 14347, loss 0.00115856, acc 1
2016-09-05T18:40:16.136019: step 14348, loss 0.00113229, acc 1
2016-09-05T18:40:16.364698: step 14349, loss 0.00138041, acc 1
2016-09-05T18:40:16.581094: step 14350, loss 0.00112766, acc 1
2016-09-05T18:40:16.776263: step 14351, loss 0.00113512, acc 1
2016-09-05T18:40:17.007460: step 14352, loss 0.00112669, acc 1
2016-09-05T18:40:17.211145: step 14353, loss 0.00112105, acc 1
2016-09-05T18:40:17.421809: step 14354, loss 0.00108657, acc 1
2016-09-05T18:40:17.633032: step 14355, loss 0.00241121, acc 1
2016-09-05T18:40:17.774378: step 14356, loss 0.00115104, acc 1
2016-09-05T18:40:18.014149: step 14357, loss 0.00117032, acc 1
2016-09-05T18:40:18.232247: step 14358, loss 0.00122755, acc 1
2016-09-05T18:40:18.451438: step 14359, loss 0.00106316, acc 1
2016-09-05T18:40:18.652653: step 14360, loss 0.00104981, acc 1
2016-09-05T18:40:18.864207: step 14361, loss 0.00106851, acc 1
2016-09-05T18:40:19.079383: step 14362, loss 0.00104542, acc 1
2016-09-05T18:40:19.309440: step 14363, loss 0.00111995, acc 1
2016-09-05T18:40:19.509416: step 14364, loss 0.00116779, acc 1
2016-09-05T18:40:19.720990: step 14365, loss 0.000996294, acc 1
2016-09-05T18:40:19.944904: step 14366, loss 0.00211046, acc 1
2016-09-05T18:40:20.164085: step 14367, loss 0.00103769, acc 1
2016-09-05T18:40:20.375612: step 14368, loss 0.00104397, acc 1
2016-09-05T18:40:20.598707: step 14369, loss 0.00102984, acc 1
2016-09-05T18:40:20.808495: step 14370, loss 0.00102681, acc 1
2016-09-05T18:40:21.027304: step 14371, loss 0.000985723, acc 1
2016-09-05T18:40:21.253218: step 14372, loss 0.00107148, acc 1
2016-09-05T18:40:21.496931: step 14373, loss 0.000972917, acc 1
2016-09-05T18:40:21.720790: step 14374, loss 0.000976919, acc 1
2016-09-05T18:40:21.918691: step 14375, loss 0.0015468, acc 1
2016-09-05T18:40:22.141825: step 14376, loss 0.000912079, acc 1
2016-09-05T18:40:22.380594: step 14377, loss 0.00103101, acc 1
2016-09-05T18:40:22.634478: step 14378, loss 0.00126128, acc 1
2016-09-05T18:40:22.872098: step 14379, loss 0.000919722, acc 1
2016-09-05T18:40:23.091978: step 14380, loss 0.000906144, acc 1
2016-09-05T18:40:23.301663: step 14381, loss 0.000976064, acc 1
2016-09-05T18:40:23.499999: step 14382, loss 0.000909676, acc 1
2016-09-05T18:40:23.736311: step 14383, loss 0.000954066, acc 1
2016-09-05T18:40:23.962457: step 14384, loss 0.000955028, acc 1
2016-09-05T18:40:24.177342: step 14385, loss 0.000968962, acc 1
2016-09-05T18:40:24.394203: step 14386, loss 0.00091862, acc 1
2016-09-05T18:40:24.604212: step 14387, loss 0.000914016, acc 1
2016-09-05T18:40:24.811628: step 14388, loss 0.000964923, acc 1
2016-09-05T18:40:25.037796: step 14389, loss 0.00103656, acc 1
2016-09-05T18:40:25.251530: step 14390, loss 0.00097508, acc 1
2016-09-05T18:40:25.490299: step 14391, loss 0.00104623, acc 1
2016-09-05T18:40:25.706563: step 14392, loss 0.00163673, acc 1
2016-09-05T18:40:25.917201: step 14393, loss 0.000875287, acc 1
2016-09-05T18:40:26.129397: step 14394, loss 0.00085792, acc 1
2016-09-05T18:40:26.348815: step 14395, loss 0.000932933, acc 1
2016-09-05T18:40:26.585367: step 14396, loss 0.000844174, acc 1
2016-09-05T18:40:26.792485: step 14397, loss 0.000893753, acc 1
2016-09-05T18:40:26.998726: step 14398, loss 0.000916053, acc 1
2016-09-05T18:40:27.199418: step 14399, loss 0.000984678, acc 1
2016-09-05T18:40:27.417394: step 14400, loss 0.000983997, acc 1

Evaluation:
2016-09-05T18:40:28.021992: step 14400, loss 1.62007, acc 0.721

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-14400

2016-09-05T18:40:28.765748: step 14401, loss 0.0009419, acc 1
2016-09-05T18:40:28.998824: step 14402, loss 0.000839091, acc 1
2016-09-05T18:40:29.230074: step 14403, loss 0.000896869, acc 1
2016-09-05T18:40:29.440401: step 14404, loss 0.000812303, acc 1
2016-09-05T18:40:29.661306: step 14405, loss 0.000928558, acc 1
2016-09-05T18:40:29.885815: step 14406, loss 0.000935823, acc 1
2016-09-05T18:40:30.135836: step 14407, loss 0.00101443, acc 1
2016-09-05T18:40:30.348024: step 14408, loss 0.000837968, acc 1
2016-09-05T18:40:30.557098: step 14409, loss 0.000860901, acc 1
2016-09-05T18:40:30.778786: step 14410, loss 0.000976528, acc 1
2016-09-05T18:40:31.019165: step 14411, loss 0.00127988, acc 1
2016-09-05T18:40:31.209105: step 14412, loss 0.000917356, acc 1
2016-09-05T18:40:31.446526: step 14413, loss 0.00101629, acc 1
2016-09-05T18:40:31.644261: step 14414, loss 0.000971581, acc 1
2016-09-05T18:40:31.853962: step 14415, loss 0.00116399, acc 1
2016-09-05T18:40:32.072743: step 14416, loss 0.000850425, acc 1
2016-09-05T18:40:32.294532: step 14417, loss 0.00161512, acc 1
2016-09-05T18:40:32.510469: step 14418, loss 0.000876305, acc 1
2016-09-05T18:40:32.758111: step 14419, loss 0.000928154, acc 1
2016-09-05T18:40:32.957002: step 14420, loss 0.00111386, acc 1
2016-09-05T18:40:33.169083: step 14421, loss 0.000992887, acc 1
2016-09-05T18:40:33.379244: step 14422, loss 0.000811048, acc 1
2016-09-05T18:40:33.617777: step 14423, loss 0.000874041, acc 1
2016-09-05T18:40:33.859348: step 14424, loss 0.000829324, acc 1
2016-09-05T18:40:34.063749: step 14425, loss 0.000825589, acc 1
2016-09-05T18:40:34.269979: step 14426, loss 0.000747225, acc 1
2016-09-05T18:40:34.481231: step 14427, loss 0.00091398, acc 1
2016-09-05T18:40:34.719675: step 14428, loss 0.000911272, acc 1
2016-09-05T18:40:34.943491: step 14429, loss 0.000818396, acc 1
2016-09-05T18:40:35.179977: step 14430, loss 0.000790066, acc 1
2016-09-05T18:40:35.385992: step 14431, loss 0.000881377, acc 1
2016-09-05T18:40:35.599933: step 14432, loss 0.000807041, acc 1
2016-09-05T18:40:35.848691: step 14433, loss 0.000964948, acc 1
2016-09-05T18:40:36.080604: step 14434, loss 0.000911558, acc 1
2016-09-05T18:40:36.299759: step 14435, loss 0.00126, acc 1
2016-09-05T18:40:36.521131: step 14436, loss 0.000944326, acc 1
2016-09-05T18:40:36.746346: step 14437, loss 0.000781504, acc 1
2016-09-05T18:40:36.961740: step 14438, loss 0.000977011, acc 1
2016-09-05T18:40:37.194071: step 14439, loss 0.00103617, acc 1
2016-09-05T18:40:37.398463: step 14440, loss 0.00075888, acc 1
2016-09-05T18:40:37.620213: step 14441, loss 0.000887581, acc 1
2016-09-05T18:40:37.835580: step 14442, loss 0.000989484, acc 1
2016-09-05T18:40:38.052625: step 14443, loss 0.000765697, acc 1
2016-09-05T18:40:38.282313: step 14444, loss 0.000882922, acc 1
2016-09-05T18:40:38.488727: step 14445, loss 0.000832348, acc 1
2016-09-05T18:40:38.691729: step 14446, loss 0.00100015, acc 1
2016-09-05T18:40:38.917145: step 14447, loss 0.000843417, acc 1
2016-09-05T18:40:39.129222: step 14448, loss 0.000978935, acc 1
2016-09-05T18:40:39.357757: step 14449, loss 0.000772865, acc 1
2016-09-05T18:40:39.608276: step 14450, loss 0.000766455, acc 1
2016-09-05T18:40:39.831948: step 14451, loss 0.000877349, acc 1
2016-09-05T18:40:40.069629: step 14452, loss 0.000855759, acc 1
2016-09-05T18:40:40.297923: step 14453, loss 0.000826465, acc 1
2016-09-05T18:40:40.546118: step 14454, loss 0.00116081, acc 1
2016-09-05T18:40:40.770775: step 14455, loss 0.000777725, acc 1
2016-09-05T18:40:40.991876: step 14456, loss 0.00156239, acc 1
2016-09-05T18:40:41.238763: step 14457, loss 0.00092782, acc 1
2016-09-05T18:40:41.460689: step 14458, loss 0.00087955, acc 1
2016-09-05T18:40:41.668390: step 14459, loss 0.00076323, acc 1
2016-09-05T18:40:41.884720: step 14460, loss 0.000966281, acc 1
2016-09-05T18:40:42.103343: step 14461, loss 0.000980905, acc 1
2016-09-05T18:40:42.320525: step 14462, loss 0.00125597, acc 1
2016-09-05T18:40:42.531032: step 14463, loss 0.000748394, acc 1
2016-09-05T18:40:42.745038: step 14464, loss 0.000747705, acc 1
2016-09-05T18:40:42.954583: step 14465, loss 0.000871783, acc 1
2016-09-05T18:40:43.169677: step 14466, loss 0.00129128, acc 1
2016-09-05T18:40:43.376436: step 14467, loss 0.000791236, acc 1
2016-09-05T18:40:43.590204: step 14468, loss 0.000886156, acc 1
2016-09-05T18:40:43.802050: step 14469, loss 0.000906206, acc 1
2016-09-05T18:40:44.018253: step 14470, loss 0.000848189, acc 1
2016-09-05T18:40:44.274562: step 14471, loss 0.000943592, acc 1
2016-09-05T18:40:44.502273: step 14472, loss 0.000949187, acc 1
2016-09-05T18:40:44.710532: step 14473, loss 0.000888687, acc 1
2016-09-05T18:40:44.942184: step 14474, loss 0.000734818, acc 1
2016-09-05T18:40:45.176809: step 14475, loss 0.001087, acc 1
2016-09-05T18:40:45.390248: step 14476, loss 0.000783308, acc 1
2016-09-05T18:40:45.597227: step 14477, loss 0.00121562, acc 1
2016-09-05T18:40:45.801468: step 14478, loss 0.000953628, acc 1
2016-09-05T18:40:46.032600: step 14479, loss 0.00118679, acc 1
2016-09-05T18:40:46.268995: step 14480, loss 0.0007955, acc 1
2016-09-05T18:40:46.485294: step 14481, loss 0.00117022, acc 1
2016-09-05T18:40:46.691319: step 14482, loss 0.000782984, acc 1
2016-09-05T18:40:46.906931: step 14483, loss 0.000907979, acc 1
2016-09-05T18:40:47.098948: step 14484, loss 0.000855135, acc 1
2016-09-05T18:40:47.305792: step 14485, loss 0.000908402, acc 1
2016-09-05T18:40:47.519057: step 14486, loss 0.000731582, acc 1
2016-09-05T18:40:47.725249: step 14487, loss 0.00104274, acc 1
2016-09-05T18:40:47.945359: step 14488, loss 0.000965928, acc 1
2016-09-05T18:40:48.158682: step 14489, loss 0.00103148, acc 1
2016-09-05T18:40:48.381371: step 14490, loss 0.00138636, acc 1
2016-09-05T18:40:48.600267: step 14491, loss 0.000752815, acc 1
2016-09-05T18:40:48.812117: step 14492, loss 0.000880929, acc 1
2016-09-05T18:40:49.026246: step 14493, loss 0.000861382, acc 1
2016-09-05T18:40:49.240223: step 14494, loss 0.000916643, acc 1
2016-09-05T18:40:49.458113: step 14495, loss 0.000846149, acc 1
2016-09-05T18:40:49.701382: step 14496, loss 0.00110058, acc 1
2016-09-05T18:40:49.922148: step 14497, loss 0.000744807, acc 1
2016-09-05T18:40:50.139475: step 14498, loss 0.000828719, acc 1
2016-09-05T18:40:50.375936: step 14499, loss 0.00103244, acc 1
2016-09-05T18:40:50.599843: step 14500, loss 0.000754274, acc 1

Evaluation:
2016-09-05T18:40:51.223562: step 14500, loss 1.63746, acc 0.721

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-14500

2016-09-05T18:40:51.952483: step 14501, loss 0.000894015, acc 1
2016-09-05T18:40:52.176957: step 14502, loss 0.000906523, acc 1
2016-09-05T18:40:52.388351: step 14503, loss 0.00119575, acc 1
2016-09-05T18:40:52.619355: step 14504, loss 0.000772426, acc 1
2016-09-05T18:40:52.874466: step 14505, loss 0.000968246, acc 1
2016-09-05T18:40:53.088961: step 14506, loss 0.000981654, acc 1
2016-09-05T18:40:53.305087: step 14507, loss 0.000792799, acc 1
2016-09-05T18:40:53.521799: step 14508, loss 0.000790526, acc 1
2016-09-05T18:40:53.761517: step 14509, loss 0.000851794, acc 1
2016-09-05T18:40:53.977781: step 14510, loss 0.000798205, acc 1
2016-09-05T18:40:54.193775: step 14511, loss 0.000826851, acc 1
2016-09-05T18:40:54.392821: step 14512, loss 0.000745201, acc 1
2016-09-05T18:40:54.615748: step 14513, loss 0.00180168, acc 1
2016-09-05T18:40:54.827373: step 14514, loss 0.000817617, acc 1
2016-09-05T18:40:55.050626: step 14515, loss 0.000789378, acc 1
2016-09-05T18:40:55.284051: step 14516, loss 0.00102457, acc 1
2016-09-05T18:40:55.508170: step 14517, loss 0.000802111, acc 1
2016-09-05T18:40:55.733329: step 14518, loss 0.000808003, acc 1
2016-09-05T18:40:55.953519: step 14519, loss 0.000886782, acc 1
2016-09-05T18:40:56.157592: step 14520, loss 0.00107281, acc 1
2016-09-05T18:40:56.395002: step 14521, loss 0.000874198, acc 1
2016-09-05T18:40:56.609121: step 14522, loss 0.00116904, acc 1
2016-09-05T18:40:56.810870: step 14523, loss 0.000783859, acc 1
2016-09-05T18:40:57.029406: step 14524, loss 0.000923775, acc 1
2016-09-05T18:40:57.241817: step 14525, loss 0.00105528, acc 1
2016-09-05T18:40:57.467190: step 14526, loss 0.000761846, acc 1
2016-09-05T18:40:57.700748: step 14527, loss 0.000954336, acc 1
2016-09-05T18:40:57.928106: step 14528, loss 0.00103795, acc 1
2016-09-05T18:40:58.141387: step 14529, loss 0.00132322, acc 1
2016-09-05T18:40:58.372662: step 14530, loss 0.00079924, acc 1
2016-09-05T18:40:58.595787: step 14531, loss 0.000749654, acc 1
2016-09-05T18:40:58.832301: step 14532, loss 0.00106973, acc 1
2016-09-05T18:40:59.057788: step 14533, loss 0.000920041, acc 1
2016-09-05T18:40:59.273435: step 14534, loss 0.000823463, acc 1
2016-09-05T18:40:59.521433: step 14535, loss 0.000823089, acc 1
2016-09-05T18:40:59.720485: step 14536, loss 0.000732297, acc 1
2016-09-05T18:40:59.924908: step 14537, loss 0.00108527, acc 1
2016-09-05T18:41:00.137422: step 14538, loss 0.000957574, acc 1
2016-09-05T18:41:00.378061: step 14539, loss 0.000751708, acc 1
2016-09-05T18:41:00.602302: step 14540, loss 0.000765375, acc 1
2016-09-05T18:41:00.792006: step 14541, loss 0.00107085, acc 1
2016-09-05T18:41:01.013391: step 14542, loss 0.000794624, acc 1
2016-09-05T18:41:01.225185: step 14543, loss 0.000783973, acc 1
2016-09-05T18:41:01.436290: step 14544, loss 0.000774852, acc 1
2016-09-05T18:41:01.640541: step 14545, loss 0.0012311, acc 1
2016-09-05T18:41:01.858320: step 14546, loss 0.000789936, acc 1
2016-09-05T18:41:02.070275: step 14547, loss 0.000807052, acc 1
2016-09-05T18:41:02.278022: step 14548, loss 0.000926152, acc 1
2016-09-05T18:41:02.495478: step 14549, loss 0.00104134, acc 1
2016-09-05T18:41:02.660737: step 14550, loss 0.00120724, acc 1
2016-09-05T18:41:02.867624: step 14551, loss 0.000929797, acc 1
2016-09-05T18:41:03.091124: step 14552, loss 0.00104495, acc 1
2016-09-05T18:41:03.303708: step 14553, loss 0.000731214, acc 1
2016-09-05T18:41:03.545269: step 14554, loss 0.000784717, acc 1
2016-09-05T18:41:03.755561: step 14555, loss 0.000832491, acc 1
2016-09-05T18:41:03.974616: step 14556, loss 0.000874242, acc 1
2016-09-05T18:41:04.162979: step 14557, loss 0.000752433, acc 1
2016-09-05T18:41:04.365841: step 14558, loss 0.000768592, acc 1
2016-09-05T18:41:04.568052: step 14559, loss 0.00125817, acc 1
2016-09-05T18:41:04.774555: step 14560, loss 0.000969495, acc 1
2016-09-05T18:41:04.978625: step 14561, loss 0.000801594, acc 1
2016-09-05T18:41:05.218268: step 14562, loss 0.00079596, acc 1
2016-09-05T18:41:05.467532: step 14563, loss 0.000795936, acc 1
2016-09-05T18:41:05.673901: step 14564, loss 0.00139796, acc 1
2016-09-05T18:41:05.896654: step 14565, loss 0.000814456, acc 1
2016-09-05T18:41:06.104128: step 14566, loss 0.0012274, acc 1
2016-09-05T18:41:06.332931: step 14567, loss 0.000752466, acc 1
2016-09-05T18:41:06.541535: step 14568, loss 0.000944705, acc 1
2016-09-05T18:41:06.767719: step 14569, loss 0.00105455, acc 1
2016-09-05T18:41:06.994224: step 14570, loss 0.000743694, acc 1
2016-09-05T18:41:07.209647: step 14571, loss 0.00129816, acc 1
2016-09-05T18:41:07.410861: step 14572, loss 0.000746746, acc 1
2016-09-05T18:41:07.648623: step 14573, loss 0.000785401, acc 1
2016-09-05T18:41:07.855722: step 14574, loss 0.000815158, acc 1
2016-09-05T18:41:08.052692: step 14575, loss 0.000786626, acc 1
2016-09-05T18:41:08.253542: step 14576, loss 0.00107295, acc 1
2016-09-05T18:41:08.471406: step 14577, loss 0.000931322, acc 1
2016-09-05T18:41:08.709233: step 14578, loss 0.000823825, acc 1
2016-09-05T18:41:08.900353: step 14579, loss 0.000753567, acc 1
2016-09-05T18:41:09.111520: step 14580, loss 0.000837801, acc 1
2016-09-05T18:41:09.311654: step 14581, loss 0.000753529, acc 1
2016-09-05T18:41:09.519022: step 14582, loss 0.000885217, acc 1
2016-09-05T18:41:09.733191: step 14583, loss 0.000788313, acc 1
2016-09-05T18:41:10.005396: step 14584, loss 0.000866399, acc 1
2016-09-05T18:41:10.232309: step 14585, loss 0.000732199, acc 1
2016-09-05T18:41:10.450201: step 14586, loss 0.000743742, acc 1
2016-09-05T18:41:10.664603: step 14587, loss 0.000758903, acc 1
2016-09-05T18:41:10.878392: step 14588, loss 0.000711743, acc 1
2016-09-05T18:41:11.114170: step 14589, loss 0.000750204, acc 1
2016-09-05T18:41:11.337586: step 14590, loss 0.000802253, acc 1
2016-09-05T18:41:11.555477: step 14591, loss 0.000756736, acc 1
2016-09-05T18:41:11.750363: step 14592, loss 0.000832909, acc 1
2016-09-05T18:41:11.960824: step 14593, loss 0.00118452, acc 1
2016-09-05T18:41:12.162675: step 14594, loss 0.00100551, acc 1
2016-09-05T18:41:12.375058: step 14595, loss 0.000717799, acc 1
2016-09-05T18:41:12.581992: step 14596, loss 0.000838163, acc 1
2016-09-05T18:41:12.821415: step 14597, loss 0.000691446, acc 1
2016-09-05T18:41:13.043646: step 14598, loss 0.000927859, acc 1
2016-09-05T18:41:13.247809: step 14599, loss 0.000828962, acc 1
2016-09-05T18:41:13.446172: step 14600, loss 0.000757983, acc 1

Evaluation:
2016-09-05T18:41:14.058372: step 14600, loss 1.58187, acc 0.723

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-14600

2016-09-05T18:41:14.789469: step 14601, loss 0.000814165, acc 1
2016-09-05T18:41:14.992226: step 14602, loss 0.00216748, acc 1
2016-09-05T18:41:15.209738: step 14603, loss 0.000759071, acc 1
2016-09-05T18:41:15.430119: step 14604, loss 0.000819297, acc 1
2016-09-05T18:41:15.667780: step 14605, loss 0.000732677, acc 1
2016-09-05T18:41:15.871188: step 14606, loss 0.000755681, acc 1
2016-09-05T18:41:16.092048: step 14607, loss 0.00075402, acc 1
2016-09-05T18:41:16.326495: step 14608, loss 0.000779957, acc 1
2016-09-05T18:41:16.576790: step 14609, loss 0.000727748, acc 1
2016-09-05T18:41:16.789086: step 14610, loss 0.000744818, acc 1
2016-09-05T18:41:17.004544: step 14611, loss 0.000869278, acc 1
2016-09-05T18:41:17.255096: step 14612, loss 0.000999819, acc 1
2016-09-05T18:41:17.484306: step 14613, loss 0.000689108, acc 1
2016-09-05T18:41:17.711546: step 14614, loss 0.00126795, acc 1
2016-09-05T18:41:17.926247: step 14615, loss 0.000999145, acc 1
2016-09-05T18:41:18.137398: step 14616, loss 0.000724929, acc 1
2016-09-05T18:41:18.347544: step 14617, loss 0.000734394, acc 1
2016-09-05T18:41:18.578210: step 14618, loss 0.00100489, acc 1
2016-09-05T18:41:18.785531: step 14619, loss 0.00069294, acc 1
2016-09-05T18:41:19.006682: step 14620, loss 0.000746487, acc 1
2016-09-05T18:41:19.213179: step 14621, loss 0.000747451, acc 1
2016-09-05T18:41:19.425637: step 14622, loss 0.000853699, acc 1
2016-09-05T18:41:19.657985: step 14623, loss 0.000733597, acc 1
2016-09-05T18:41:19.868982: step 14624, loss 0.000890495, acc 1
2016-09-05T18:41:20.109366: step 14625, loss 0.000773406, acc 1
2016-09-05T18:41:20.310992: step 14626, loss 0.000788809, acc 1
2016-09-05T18:41:20.519487: step 14627, loss 0.000710648, acc 1
2016-09-05T18:41:20.729091: step 14628, loss 0.000833576, acc 1
2016-09-05T18:41:20.930370: step 14629, loss 0.000662526, acc 1
2016-09-05T18:41:21.129725: step 14630, loss 0.000737426, acc 1
2016-09-05T18:41:21.329437: step 14631, loss 0.000753813, acc 1
2016-09-05T18:41:21.525904: step 14632, loss 0.000697842, acc 1
2016-09-05T18:41:21.735429: step 14633, loss 0.00091419, acc 1
2016-09-05T18:41:21.937999: step 14634, loss 0.000869205, acc 1
2016-09-05T18:41:22.170519: step 14635, loss 0.000781557, acc 1
2016-09-05T18:41:22.381018: step 14636, loss 0.000760937, acc 1
2016-09-05T18:41:22.596891: step 14637, loss 0.000814759, acc 1
2016-09-05T18:41:22.805155: step 14638, loss 0.000701296, acc 1
2016-09-05T18:41:23.041179: step 14639, loss 0.000787921, acc 1
2016-09-05T18:41:23.260279: step 14640, loss 0.000837362, acc 1
2016-09-05T18:41:23.516657: step 14641, loss 0.000708095, acc 1
2016-09-05T18:41:23.756938: step 14642, loss 0.000828684, acc 1
2016-09-05T18:41:23.953818: step 14643, loss 0.000854613, acc 1
2016-09-05T18:41:24.169070: step 14644, loss 0.000681931, acc 1
2016-09-05T18:41:24.376475: step 14645, loss 0.000750456, acc 1
2016-09-05T18:41:24.584748: step 14646, loss 0.000709209, acc 1
2016-09-05T18:41:24.791993: step 14647, loss 0.000747349, acc 1
2016-09-05T18:41:25.020522: step 14648, loss 0.000676391, acc 1
2016-09-05T18:41:25.249432: step 14649, loss 0.000714692, acc 1
2016-09-05T18:41:25.465127: step 14650, loss 0.000926132, acc 1
2016-09-05T18:41:25.673250: step 14651, loss 0.000738662, acc 1
2016-09-05T18:41:25.889542: step 14652, loss 0.000745749, acc 1
2016-09-05T18:41:26.099982: step 14653, loss 0.000658774, acc 1
2016-09-05T18:41:26.315380: step 14654, loss 0.000679266, acc 1
2016-09-05T18:41:26.527579: step 14655, loss 0.00169906, acc 1
2016-09-05T18:41:26.756077: step 14656, loss 0.00120871, acc 1
2016-09-05T18:41:26.980104: step 14657, loss 0.00111062, acc 1
2016-09-05T18:41:27.174371: step 14658, loss 0.000917078, acc 1
2016-09-05T18:41:27.392445: step 14659, loss 0.000779506, acc 1
2016-09-05T18:41:27.594962: step 14660, loss 0.000865333, acc 1
2016-09-05T18:41:27.810227: step 14661, loss 0.000777831, acc 1
2016-09-05T18:41:28.022930: step 14662, loss 0.000681062, acc 1
2016-09-05T18:41:28.226956: step 14663, loss 0.000669126, acc 1
2016-09-05T18:41:28.426671: step 14664, loss 0.00107335, acc 1
2016-09-05T18:41:28.638977: step 14665, loss 0.000758747, acc 1
2016-09-05T18:41:28.869452: step 14666, loss 0.000817762, acc 1
2016-09-05T18:41:29.089403: step 14667, loss 0.00117435, acc 1
2016-09-05T18:41:29.297425: step 14668, loss 0.000916754, acc 1
2016-09-05T18:41:29.563912: step 14669, loss 0.000858314, acc 1
2016-09-05T18:41:29.798492: step 14670, loss 0.000686532, acc 1
2016-09-05T18:41:29.999720: step 14671, loss 0.000722834, acc 1
2016-09-05T18:41:30.203443: step 14672, loss 0.000808314, acc 1
2016-09-05T18:41:30.408414: step 14673, loss 0.000702059, acc 1
2016-09-05T18:41:30.614480: step 14674, loss 0.000792225, acc 1
2016-09-05T18:41:30.827446: step 14675, loss 0.000738304, acc 1
2016-09-05T18:41:31.069547: step 14676, loss 0.000799801, acc 1
2016-09-05T18:41:31.296417: step 14677, loss 0.000703534, acc 1
2016-09-05T18:41:31.506331: step 14678, loss 0.000655542, acc 1
2016-09-05T18:41:31.720198: step 14679, loss 0.000778468, acc 1
2016-09-05T18:41:31.948929: step 14680, loss 0.000889865, acc 1
2016-09-05T18:41:32.174346: step 14681, loss 0.000739485, acc 1
2016-09-05T18:41:32.385044: step 14682, loss 0.00076152, acc 1
2016-09-05T18:41:32.622202: step 14683, loss 0.000674576, acc 1
2016-09-05T18:41:32.848506: step 14684, loss 0.000760434, acc 1
2016-09-05T18:41:33.069927: step 14685, loss 0.000764856, acc 1
2016-09-05T18:41:33.292648: step 14686, loss 0.000738449, acc 1
2016-09-05T18:41:33.517016: step 14687, loss 0.000865211, acc 1
2016-09-05T18:41:33.725202: step 14688, loss 0.000691395, acc 1
2016-09-05T18:41:33.934795: step 14689, loss 0.000808851, acc 1
2016-09-05T18:41:34.159455: step 14690, loss 0.000946866, acc 1
2016-09-05T18:41:34.376400: step 14691, loss 0.000805401, acc 1
2016-09-05T18:41:34.596661: step 14692, loss 0.000897475, acc 1
2016-09-05T18:41:34.811193: step 14693, loss 0.000643785, acc 1
2016-09-05T18:41:35.044064: step 14694, loss 0.00165678, acc 1
2016-09-05T18:41:35.254927: step 14695, loss 0.000844078, acc 1
2016-09-05T18:41:35.485137: step 14696, loss 0.000749641, acc 1
2016-09-05T18:41:35.684268: step 14697, loss 0.0007067, acc 1
2016-09-05T18:41:35.910370: step 14698, loss 0.00081485, acc 1
2016-09-05T18:41:36.152236: step 14699, loss 0.000905945, acc 1
2016-09-05T18:41:36.355461: step 14700, loss 0.000828857, acc 1

Evaluation:
2016-09-05T18:41:36.979397: step 14700, loss 1.63669, acc 0.714

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-14700

2016-09-05T18:41:37.785463: step 14701, loss 0.0036347, acc 1
2016-09-05T18:41:37.997232: step 14702, loss 0.000768573, acc 1
2016-09-05T18:41:38.208782: step 14703, loss 0.000884972, acc 1
2016-09-05T18:41:38.441797: step 14704, loss 0.000708547, acc 1
2016-09-05T18:41:38.642976: step 14705, loss 0.00099987, acc 1
2016-09-05T18:41:38.856724: step 14706, loss 0.000743094, acc 1
2016-09-05T18:41:39.091891: step 14707, loss 0.000726578, acc 1
2016-09-05T18:41:39.294566: step 14708, loss 0.000961159, acc 1
2016-09-05T18:41:39.510760: step 14709, loss 0.00081629, acc 1
2016-09-05T18:41:39.725656: step 14710, loss 0.00100643, acc 1
2016-09-05T18:41:39.932111: step 14711, loss 0.00128682, acc 1
2016-09-05T18:41:40.159848: step 14712, loss 0.000887386, acc 1
2016-09-05T18:41:40.391125: step 14713, loss 0.00156039, acc 1
2016-09-05T18:41:40.613642: step 14714, loss 0.00118094, acc 1
2016-09-05T18:41:40.876702: step 14715, loss 0.000838213, acc 1
2016-09-05T18:41:41.087377: step 14716, loss 0.000895652, acc 1
2016-09-05T18:41:41.300071: step 14717, loss 0.00128001, acc 1
2016-09-05T18:41:41.516095: step 14718, loss 0.000841103, acc 1
2016-09-05T18:41:41.720121: step 14719, loss 0.000940251, acc 1
2016-09-05T18:41:41.938071: step 14720, loss 0.000981849, acc 1
2016-09-05T18:41:42.148251: step 14721, loss 0.00102348, acc 1
2016-09-05T18:41:42.348114: step 14722, loss 0.000914753, acc 1
2016-09-05T18:41:42.550387: step 14723, loss 0.000889638, acc 1
2016-09-05T18:41:42.780816: step 14724, loss 0.000919881, acc 1
2016-09-05T18:41:42.996696: step 14725, loss 0.000874343, acc 1
2016-09-05T18:41:43.213596: step 14726, loss 0.000980687, acc 1
2016-09-05T18:41:43.414081: step 14727, loss 0.000859477, acc 1
2016-09-05T18:41:43.616844: step 14728, loss 0.00118249, acc 1
2016-09-05T18:41:43.829817: step 14729, loss 0.000892586, acc 1
2016-09-05T18:41:44.054579: step 14730, loss 0.000940074, acc 1
2016-09-05T18:41:44.252279: step 14731, loss 0.000841399, acc 1
2016-09-05T18:41:44.474257: step 14732, loss 0.000888295, acc 1
2016-09-05T18:41:44.687715: step 14733, loss 0.000985895, acc 1
2016-09-05T18:41:44.936087: step 14734, loss 0.000998118, acc 1
2016-09-05T18:41:45.151090: step 14735, loss 0.000836661, acc 1
2016-09-05T18:41:45.355466: step 14736, loss 0.000976923, acc 1
2016-09-05T18:41:45.580965: step 14737, loss 0.000915132, acc 1
2016-09-05T18:41:45.795956: step 14738, loss 0.000879958, acc 1
2016-09-05T18:41:46.025408: step 14739, loss 0.00129971, acc 1
2016-09-05T18:41:46.245588: step 14740, loss 0.00101663, acc 1
2016-09-05T18:41:46.459166: step 14741, loss 0.00101595, acc 1
2016-09-05T18:41:46.663418: step 14742, loss 0.000799054, acc 1
2016-09-05T18:41:46.885185: step 14743, loss 0.000806002, acc 1
2016-09-05T18:41:47.013742: step 14744, loss 0.000821118, acc 1
2016-09-05T18:41:47.277393: step 14745, loss 0.000861006, acc 1
2016-09-05T18:41:47.517883: step 14746, loss 0.000814088, acc 1
2016-09-05T18:41:47.755640: step 14747, loss 0.000837885, acc 1
2016-09-05T18:41:47.965732: step 14748, loss 0.000911275, acc 1
2016-09-05T18:41:48.182729: step 14749, loss 0.000734009, acc 1
2016-09-05T18:41:48.394195: step 14750, loss 0.000764194, acc 1
2016-09-05T18:41:48.601829: step 14751, loss 0.00102158, acc 1
2016-09-05T18:41:48.817543: step 14752, loss 0.00128761, acc 1
2016-09-05T18:41:49.042061: step 14753, loss 0.00074575, acc 1
2016-09-05T18:41:49.269396: step 14754, loss 0.000950794, acc 1
2016-09-05T18:41:49.472621: step 14755, loss 0.00117936, acc 1
2016-09-05T18:41:49.669431: step 14756, loss 0.000755536, acc 1
2016-09-05T18:41:49.892190: step 14757, loss 0.000762184, acc 1
2016-09-05T18:41:50.103711: step 14758, loss 0.000724553, acc 1
2016-09-05T18:41:50.310614: step 14759, loss 0.000787149, acc 1
2016-09-05T18:41:50.545128: step 14760, loss 0.000735106, acc 1
2016-09-05T18:41:50.789585: step 14761, loss 0.000734488, acc 1
2016-09-05T18:41:51.003169: step 14762, loss 0.000771005, acc 1
2016-09-05T18:41:51.217683: step 14763, loss 0.0010025, acc 1
2016-09-05T18:41:51.420681: step 14764, loss 0.000723488, acc 1
2016-09-05T18:41:51.632515: step 14765, loss 0.000764102, acc 1
2016-09-05T18:41:51.829821: step 14766, loss 0.000684562, acc 1
2016-09-05T18:41:52.057412: step 14767, loss 0.000807502, acc 1
2016-09-05T18:41:52.270617: step 14768, loss 0.00096061, acc 1
2016-09-05T18:41:52.498562: step 14769, loss 0.00104091, acc 1
2016-09-05T18:41:52.707042: step 14770, loss 0.000671857, acc 1
2016-09-05T18:41:52.921048: step 14771, loss 0.000666233, acc 1
2016-09-05T18:41:53.138144: step 14772, loss 0.000723457, acc 1
2016-09-05T18:41:53.348550: step 14773, loss 0.000717089, acc 1
2016-09-05T18:41:53.555901: step 14774, loss 0.00068971, acc 1
2016-09-05T18:41:53.806312: step 14775, loss 0.000772036, acc 1
2016-09-05T18:41:54.009374: step 14776, loss 0.000803991, acc 1
2016-09-05T18:41:54.231930: step 14777, loss 0.000655235, acc 1
2016-09-05T18:41:54.440278: step 14778, loss 0.000943473, acc 1
2016-09-05T18:41:54.649088: step 14779, loss 0.000695519, acc 1
2016-09-05T18:41:54.884387: step 14780, loss 0.000777173, acc 1
2016-09-05T18:41:55.105444: step 14781, loss 0.000672404, acc 1
2016-09-05T18:41:55.324381: step 14782, loss 0.000681588, acc 1
2016-09-05T18:41:55.525503: step 14783, loss 0.000698004, acc 1
2016-09-05T18:41:55.744436: step 14784, loss 0.000782896, acc 1
2016-09-05T18:41:55.993225: step 14785, loss 0.000837036, acc 1
2016-09-05T18:41:56.214124: step 14786, loss 0.000741771, acc 1
2016-09-05T18:41:56.421827: step 14787, loss 0.000686444, acc 1
2016-09-05T18:41:56.635356: step 14788, loss 0.000643132, acc 1
2016-09-05T18:41:56.834566: step 14789, loss 0.000745074, acc 1
2016-09-05T18:41:57.041386: step 14790, loss 0.000691881, acc 1
2016-09-05T18:41:57.247537: step 14791, loss 0.000658549, acc 1
2016-09-05T18:41:57.476601: step 14792, loss 0.000701894, acc 1
2016-09-05T18:41:57.687280: step 14793, loss 0.00088718, acc 1
2016-09-05T18:41:57.911989: step 14794, loss 0.000680582, acc 1
2016-09-05T18:41:58.139002: step 14795, loss 0.000661261, acc 1
2016-09-05T18:41:58.344536: step 14796, loss 0.00078108, acc 1
2016-09-05T18:41:58.565318: step 14797, loss 0.000708474, acc 1
2016-09-05T18:41:58.773099: step 14798, loss 0.00094332, acc 1
2016-09-05T18:41:59.009923: step 14799, loss 0.000722308, acc 1
2016-09-05T18:41:59.240422: step 14800, loss 0.000824461, acc 1

Evaluation:
2016-09-05T18:41:59.832004: step 14800, loss 1.5025, acc 0.717

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-14800

2016-09-05T18:42:00.583259: step 14801, loss 0.000725904, acc 1
2016-09-05T18:42:00.791138: step 14802, loss 0.000657812, acc 1
2016-09-05T18:42:01.012492: step 14803, loss 0.000997848, acc 1
2016-09-05T18:42:01.207347: step 14804, loss 0.00120179, acc 1
2016-09-05T18:42:01.427696: step 14805, loss 0.000674982, acc 1
2016-09-05T18:42:01.636158: step 14806, loss 0.000659328, acc 1
2016-09-05T18:42:01.865468: step 14807, loss 0.000732157, acc 1
2016-09-05T18:42:02.094939: step 14808, loss 0.000712055, acc 1
2016-09-05T18:42:02.316973: step 14809, loss 0.000795109, acc 1
2016-09-05T18:42:02.542453: step 14810, loss 0.00100685, acc 1
2016-09-05T18:42:02.779836: step 14811, loss 0.000637565, acc 1
2016-09-05T18:42:03.008950: step 14812, loss 0.000701456, acc 1
2016-09-05T18:42:03.228842: step 14813, loss 0.00155776, acc 1
2016-09-05T18:42:03.461987: step 14814, loss 0.000956377, acc 1
2016-09-05T18:42:03.698910: step 14815, loss 0.000751641, acc 1
2016-09-05T18:42:03.915729: step 14816, loss 0.000640783, acc 1
2016-09-05T18:42:04.125648: step 14817, loss 0.00108024, acc 1
2016-09-05T18:42:04.340452: step 14818, loss 0.00092111, acc 1
2016-09-05T18:42:04.574155: step 14819, loss 0.000703705, acc 1
2016-09-05T18:42:04.779452: step 14820, loss 0.000826104, acc 1
2016-09-05T18:42:05.006687: step 14821, loss 0.00066417, acc 1
2016-09-05T18:42:05.218321: step 14822, loss 0.000678687, acc 1
2016-09-05T18:42:05.421961: step 14823, loss 0.000914185, acc 1
2016-09-05T18:42:05.644491: step 14824, loss 0.000925305, acc 1
2016-09-05T18:42:05.861815: step 14825, loss 0.000661031, acc 1
2016-09-05T18:42:06.067447: step 14826, loss 0.000928122, acc 1
2016-09-05T18:42:06.291363: step 14827, loss 0.00072588, acc 1
2016-09-05T18:42:06.500095: step 14828, loss 0.000754412, acc 1
2016-09-05T18:42:06.727357: step 14829, loss 0.000734061, acc 1
2016-09-05T18:42:06.936386: step 14830, loss 0.000759301, acc 1
2016-09-05T18:42:07.156972: step 14831, loss 0.000856702, acc 1
2016-09-05T18:42:07.364452: step 14832, loss 0.00078694, acc 1
2016-09-05T18:42:07.603901: step 14833, loss 0.000870375, acc 1
2016-09-05T18:42:07.849787: step 14834, loss 0.000733291, acc 1
2016-09-05T18:42:08.051439: step 14835, loss 0.000731141, acc 1
2016-09-05T18:42:08.265565: step 14836, loss 0.000724422, acc 1
2016-09-05T18:42:08.469911: step 14837, loss 0.000668772, acc 1
2016-09-05T18:42:08.695957: step 14838, loss 0.000735736, acc 1
2016-09-05T18:42:08.915091: step 14839, loss 0.000676191, acc 1
2016-09-05T18:42:09.155681: step 14840, loss 0.000687773, acc 1
2016-09-05T18:42:09.352035: step 14841, loss 0.000676149, acc 1
2016-09-05T18:42:09.586423: step 14842, loss 0.000946, acc 1
2016-09-05T18:42:09.780653: step 14843, loss 0.000761547, acc 1
2016-09-05T18:42:09.991650: step 14844, loss 0.000707921, acc 1
2016-09-05T18:42:10.208452: step 14845, loss 0.000883758, acc 1
2016-09-05T18:42:10.427874: step 14846, loss 0.000734625, acc 1
2016-09-05T18:42:10.648063: step 14847, loss 0.000781631, acc 1
2016-09-05T18:42:10.861122: step 14848, loss 0.000927416, acc 1
2016-09-05T18:42:11.088393: step 14849, loss 0.000709528, acc 1
2016-09-05T18:42:11.289261: step 14850, loss 0.000668148, acc 1
2016-09-05T18:42:11.504238: step 14851, loss 0.00072351, acc 1
2016-09-05T18:42:11.714362: step 14852, loss 0.000646008, acc 1
2016-09-05T18:42:11.926184: step 14853, loss 0.000748656, acc 1
2016-09-05T18:42:12.141516: step 14854, loss 0.000870968, acc 1
2016-09-05T18:42:12.359832: step 14855, loss 0.00103925, acc 1
2016-09-05T18:42:12.574902: step 14856, loss 0.000653098, acc 1
2016-09-05T18:42:12.808905: step 14857, loss 0.000653787, acc 1
2016-09-05T18:42:13.031033: step 14858, loss 0.000604483, acc 1
2016-09-05T18:42:13.270825: step 14859, loss 0.000721728, acc 1
2016-09-05T18:42:13.533508: step 14860, loss 0.000748195, acc 1
2016-09-05T18:42:13.745037: step 14861, loss 0.000662802, acc 1
2016-09-05T18:42:13.961738: step 14862, loss 0.000735363, acc 1
2016-09-05T18:42:14.179108: step 14863, loss 0.000681963, acc 1
2016-09-05T18:42:14.416297: step 14864, loss 0.00063696, acc 1
2016-09-05T18:42:14.620730: step 14865, loss 0.000604699, acc 1
2016-09-05T18:42:14.836648: step 14866, loss 0.000636905, acc 1
2016-09-05T18:42:15.037149: step 14867, loss 0.000644246, acc 1
2016-09-05T18:42:15.238167: step 14868, loss 0.000774753, acc 1
2016-09-05T18:42:15.456333: step 14869, loss 0.000887543, acc 1
2016-09-05T18:42:15.677264: step 14870, loss 0.000681092, acc 1
2016-09-05T18:42:15.906112: step 14871, loss 0.000643633, acc 1
2016-09-05T18:42:16.141263: step 14872, loss 0.000762585, acc 1
2016-09-05T18:42:16.346781: step 14873, loss 0.000774846, acc 1
2016-09-05T18:42:16.545784: step 14874, loss 0.000606633, acc 1
2016-09-05T18:42:16.764677: step 14875, loss 0.00076119, acc 1
2016-09-05T18:42:16.973226: step 14876, loss 0.000955959, acc 1
2016-09-05T18:42:17.209846: step 14877, loss 0.000642376, acc 1
2016-09-05T18:42:17.431421: step 14878, loss 0.000694921, acc 1
2016-09-05T18:42:17.654370: step 14879, loss 0.000804428, acc 1
2016-09-05T18:42:17.868276: step 14880, loss 0.00062032, acc 1
2016-09-05T18:42:18.109116: step 14881, loss 0.000633575, acc 1
2016-09-05T18:42:18.382545: step 14882, loss 0.00121722, acc 1
2016-09-05T18:42:18.591348: step 14883, loss 0.00068197, acc 1
2016-09-05T18:42:18.822190: step 14884, loss 0.000822738, acc 1
2016-09-05T18:42:19.060012: step 14885, loss 0.00069457, acc 1
2016-09-05T18:42:19.281830: step 14886, loss 0.000865143, acc 1
2016-09-05T18:42:19.484697: step 14887, loss 0.000741076, acc 1
2016-09-05T18:42:19.713194: step 14888, loss 0.000914776, acc 1
2016-09-05T18:42:19.938696: step 14889, loss 0.000682456, acc 1
2016-09-05T18:42:20.177792: step 14890, loss 0.000640653, acc 1
2016-09-05T18:42:20.400283: step 14891, loss 0.000699589, acc 1
2016-09-05T18:42:20.617363: step 14892, loss 0.000655391, acc 1
2016-09-05T18:42:20.834107: step 14893, loss 0.000826769, acc 1
2016-09-05T18:42:21.043921: step 14894, loss 0.000657532, acc 1
2016-09-05T18:42:21.267105: step 14895, loss 0.000821589, acc 1
2016-09-05T18:42:21.483990: step 14896, loss 0.00060256, acc 1
2016-09-05T18:42:21.696352: step 14897, loss 0.000801156, acc 1
2016-09-05T18:42:21.896401: step 14898, loss 0.000644544, acc 1
2016-09-05T18:42:22.107769: step 14899, loss 0.000703303, acc 1
2016-09-05T18:42:22.319498: step 14900, loss 0.000753427, acc 1

Evaluation:
2016-09-05T18:42:22.928985: step 14900, loss 1.55667, acc 0.716

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-14900

2016-09-05T18:42:23.609894: step 14901, loss 0.000669119, acc 1
2016-09-05T18:42:23.802549: step 14902, loss 0.000764865, acc 1
2016-09-05T18:42:24.011199: step 14903, loss 0.000703334, acc 1
2016-09-05T18:42:24.229661: step 14904, loss 0.000718371, acc 1
2016-09-05T18:42:24.433675: step 14905, loss 0.000940948, acc 1
2016-09-05T18:42:24.650849: step 14906, loss 0.000997916, acc 1
2016-09-05T18:42:24.854586: step 14907, loss 0.000614686, acc 1
2016-09-05T18:42:25.070766: step 14908, loss 0.00093341, acc 1
2016-09-05T18:42:25.276445: step 14909, loss 0.000745822, acc 1
2016-09-05T18:42:25.530904: step 14910, loss 0.001275, acc 1
2016-09-05T18:42:25.732263: step 14911, loss 0.000677032, acc 1
2016-09-05T18:42:25.943950: step 14912, loss 0.000929736, acc 1
2016-09-05T18:42:26.138599: step 14913, loss 0.000792983, acc 1
2016-09-05T18:42:26.341068: step 14914, loss 0.000833979, acc 1
2016-09-05T18:42:26.539718: step 14915, loss 0.000776671, acc 1
2016-09-05T18:42:26.748982: step 14916, loss 0.000712297, acc 1
2016-09-05T18:42:26.973099: step 14917, loss 0.000758577, acc 1
2016-09-05T18:42:27.189813: step 14918, loss 0.000819426, acc 1
2016-09-05T18:42:27.413271: step 14919, loss 0.000855286, acc 1
2016-09-05T18:42:27.651907: step 14920, loss 0.00168849, acc 1
2016-09-05T18:42:27.863842: step 14921, loss 0.000860027, acc 1
2016-09-05T18:42:28.075463: step 14922, loss 0.000741886, acc 1
2016-09-05T18:42:28.276029: step 14923, loss 0.00083522, acc 1
2016-09-05T18:42:28.500099: step 14924, loss 0.00142398, acc 1
2016-09-05T18:42:28.702393: step 14925, loss 0.000809884, acc 1
2016-09-05T18:42:28.921248: step 14926, loss 0.00109858, acc 1
2016-09-05T18:42:29.159938: step 14927, loss 0.00102377, acc 1
2016-09-05T18:42:29.356763: step 14928, loss 0.000933637, acc 1
2016-09-05T18:42:29.559092: step 14929, loss 0.000750987, acc 1
2016-09-05T18:42:29.755916: step 14930, loss 0.000757817, acc 1
2016-09-05T18:42:29.970517: step 14931, loss 0.000764763, acc 1
2016-09-05T18:42:30.193659: step 14932, loss 0.000771725, acc 1
2016-09-05T18:42:30.413657: step 14933, loss 0.000876607, acc 1
2016-09-05T18:42:30.636800: step 14934, loss 0.000733895, acc 1
2016-09-05T18:42:30.866298: step 14935, loss 0.0008464, acc 1
2016-09-05T18:42:31.077861: step 14936, loss 0.000740805, acc 1
2016-09-05T18:42:31.277844: step 14937, loss 0.000815315, acc 1
2016-09-05T18:42:31.409613: step 14938, loss 0.000978162, acc 1
2016-09-05T18:42:31.627742: step 14939, loss 0.000998876, acc 1
2016-09-05T18:42:31.856241: step 14940, loss 0.000790698, acc 1
2016-09-05T18:42:32.055809: step 14941, loss 0.000722795, acc 1
2016-09-05T18:42:32.284965: step 14942, loss 0.0007245, acc 1
2016-09-05T18:42:32.491800: step 14943, loss 0.000758257, acc 1
2016-09-05T18:42:32.705615: step 14944, loss 0.000736244, acc 1
2016-09-05T18:42:32.901998: step 14945, loss 0.000737591, acc 1
2016-09-05T18:42:33.117741: step 14946, loss 0.000845997, acc 1
2016-09-05T18:42:33.347896: step 14947, loss 0.000779651, acc 1
2016-09-05T18:42:33.571306: step 14948, loss 0.000722087, acc 1
2016-09-05T18:42:33.815149: step 14949, loss 0.000731138, acc 1
2016-09-05T18:42:34.030005: step 14950, loss 0.000733486, acc 1
2016-09-05T18:42:34.252114: step 14951, loss 0.000775239, acc 1
2016-09-05T18:42:34.459073: step 14952, loss 0.000726261, acc 1
2016-09-05T18:42:34.681661: step 14953, loss 0.000787032, acc 1
2016-09-05T18:42:34.908324: step 14954, loss 0.000910061, acc 1
2016-09-05T18:42:35.123060: step 14955, loss 0.000689078, acc 1
2016-09-05T18:42:35.334510: step 14956, loss 0.000743367, acc 1
2016-09-05T18:42:35.586798: step 14957, loss 0.000717161, acc 1
2016-09-05T18:42:35.807626: step 14958, loss 0.00133522, acc 1
2016-09-05T18:42:36.024241: step 14959, loss 0.000704501, acc 1
2016-09-05T18:42:36.243236: step 14960, loss 0.000656836, acc 1
2016-09-05T18:42:36.480036: step 14961, loss 0.000775232, acc 1
2016-09-05T18:42:36.693150: step 14962, loss 0.000696913, acc 1
2016-09-05T18:42:36.923856: step 14963, loss 0.000791346, acc 1
2016-09-05T18:42:37.141790: step 14964, loss 0.000646878, acc 1
2016-09-05T18:42:37.350207: step 14965, loss 0.000673644, acc 1
2016-09-05T18:42:37.559538: step 14966, loss 0.00071855, acc 1
2016-09-05T18:42:37.771993: step 14967, loss 0.000686748, acc 1
2016-09-05T18:42:38.005015: step 14968, loss 0.000799669, acc 1
2016-09-05T18:42:38.226911: step 14969, loss 0.000600669, acc 1
2016-09-05T18:42:38.445993: step 14970, loss 0.000752422, acc 1
2016-09-05T18:42:38.652551: step 14971, loss 0.00064491, acc 1
2016-09-05T18:42:38.869880: step 14972, loss 0.000625958, acc 1
2016-09-05T18:42:39.087245: step 14973, loss 0.000595321, acc 1
2016-09-05T18:42:39.303985: step 14974, loss 0.000647713, acc 1
2016-09-05T18:42:39.514215: step 14975, loss 0.000897214, acc 1
2016-09-05T18:42:39.753487: step 14976, loss 0.000807527, acc 1
2016-09-05T18:42:39.975888: step 14977, loss 0.000661288, acc 1
2016-09-05T18:42:40.177501: step 14978, loss 0.000653599, acc 1
2016-09-05T18:42:40.429651: step 14979, loss 0.000694553, acc 1
2016-09-05T18:42:40.635775: step 14980, loss 0.000591685, acc 1
2016-09-05T18:42:40.861477: step 14981, loss 0.000688698, acc 1
2016-09-05T18:42:41.084026: step 14982, loss 0.000839326, acc 1
2016-09-05T18:42:41.289292: step 14983, loss 0.000625845, acc 1
2016-09-05T18:42:41.493610: step 14984, loss 0.000831301, acc 1
2016-09-05T18:42:41.712738: step 14985, loss 0.0010123, acc 1
2016-09-05T18:42:41.916855: step 14986, loss 0.000747734, acc 1
2016-09-05T18:42:42.131121: step 14987, loss 0.000762202, acc 1
2016-09-05T18:42:42.351867: step 14988, loss 0.000756844, acc 1
2016-09-05T18:42:42.549599: step 14989, loss 0.000677921, acc 1
2016-09-05T18:42:42.768586: step 14990, loss 0.000661854, acc 1
2016-09-05T18:42:42.987188: step 14991, loss 0.000615862, acc 1
2016-09-05T18:42:43.203941: step 14992, loss 0.000665358, acc 1
2016-09-05T18:42:43.410591: step 14993, loss 0.000743741, acc 1
2016-09-05T18:42:43.638471: step 14994, loss 0.000828246, acc 1
2016-09-05T18:42:43.847931: step 14995, loss 0.00114459, acc 1
2016-09-05T18:42:44.079563: step 14996, loss 0.000878345, acc 1
2016-09-05T18:42:44.281062: step 14997, loss 0.000641912, acc 1
2016-09-05T18:42:44.517033: step 14998, loss 0.000659708, acc 1
2016-09-05T18:42:44.719239: step 14999, loss 0.000708155, acc 1
2016-09-05T18:42:44.943073: step 15000, loss 0.000631211, acc 1

Evaluation:
2016-09-05T18:42:45.552138: step 15000, loss 1.54475, acc 0.718

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-15000

2016-09-05T18:42:46.365420: step 15001, loss 0.000608597, acc 1
2016-09-05T18:42:46.590873: step 15002, loss 0.00079921, acc 1
2016-09-05T18:42:46.859672: step 15003, loss 0.00073325, acc 1
2016-09-05T18:42:47.102987: step 15004, loss 0.000772626, acc 1
2016-09-05T18:42:47.331375: step 15005, loss 0.000838341, acc 1
2016-09-05T18:42:47.530402: step 15006, loss 0.000616797, acc 1
2016-09-05T18:42:47.749102: step 15007, loss 0.000756533, acc 1
2016-09-05T18:42:47.957444: step 15008, loss 0.000721809, acc 1
2016-09-05T18:42:48.171731: step 15009, loss 0.000770859, acc 1
2016-09-05T18:42:48.378921: step 15010, loss 0.00087045, acc 1
2016-09-05T18:42:48.577281: step 15011, loss 0.000634512, acc 1
2016-09-05T18:42:48.801149: step 15012, loss 0.000712523, acc 1
2016-09-05T18:42:49.001559: step 15013, loss 0.000748023, acc 1
2016-09-05T18:42:49.226903: step 15014, loss 0.000643443, acc 1
2016-09-05T18:42:49.439996: step 15015, loss 0.000616971, acc 1
2016-09-05T18:42:49.673649: step 15016, loss 0.00068557, acc 1
2016-09-05T18:42:49.871281: step 15017, loss 0.00073597, acc 1
2016-09-05T18:42:50.084310: step 15018, loss 0.000840923, acc 1
2016-09-05T18:42:50.285400: step 15019, loss 0.000707485, acc 1
2016-09-05T18:42:50.535530: step 15020, loss 0.000651814, acc 1
2016-09-05T18:42:50.778462: step 15021, loss 0.000647986, acc 1
2016-09-05T18:42:50.998602: step 15022, loss 0.000645517, acc 1
2016-09-05T18:42:51.210098: step 15023, loss 0.000759002, acc 1
2016-09-05T18:42:51.436118: step 15024, loss 0.000607496, acc 1
2016-09-05T18:42:51.662281: step 15025, loss 0.00065742, acc 1
2016-09-05T18:42:51.903355: step 15026, loss 0.000796886, acc 1
2016-09-05T18:42:52.112762: step 15027, loss 0.00113591, acc 1
2016-09-05T18:42:52.320459: step 15028, loss 0.000598224, acc 1
2016-09-05T18:42:52.547063: step 15029, loss 0.00080256, acc 1
2016-09-05T18:42:52.751528: step 15030, loss 0.000782509, acc 1
2016-09-05T18:42:52.957496: step 15031, loss 0.000598695, acc 1
2016-09-05T18:42:53.189459: step 15032, loss 0.000656078, acc 1
2016-09-05T18:42:53.413256: step 15033, loss 0.000668002, acc 1
2016-09-05T18:42:53.615888: step 15034, loss 0.000706633, acc 1
2016-09-05T18:42:53.831312: step 15035, loss 0.000843709, acc 1
2016-09-05T18:42:54.042215: step 15036, loss 0.000761355, acc 1
2016-09-05T18:42:54.251049: step 15037, loss 0.000768778, acc 1
2016-09-05T18:42:54.466834: step 15038, loss 0.000898249, acc 1
2016-09-05T18:42:54.678413: step 15039, loss 0.000644292, acc 1
2016-09-05T18:42:54.923231: step 15040, loss 0.00125202, acc 1
2016-09-05T18:42:55.123765: step 15041, loss 0.000816507, acc 1
2016-09-05T18:42:55.331330: step 15042, loss 0.000732106, acc 1
2016-09-05T18:42:55.550520: step 15043, loss 0.000610465, acc 1
2016-09-05T18:42:55.798207: step 15044, loss 0.000687644, acc 1
2016-09-05T18:42:56.001258: step 15045, loss 0.000673059, acc 1
2016-09-05T18:42:56.227525: step 15046, loss 0.000691533, acc 1
2016-09-05T18:42:56.453029: step 15047, loss 0.000623847, acc 1
2016-09-05T18:42:56.690463: step 15048, loss 0.000688141, acc 1
2016-09-05T18:42:56.936498: step 15049, loss 0.000697405, acc 1
2016-09-05T18:42:57.131409: step 15050, loss 0.000635415, acc 1
2016-09-05T18:42:57.362429: step 15051, loss 0.000672393, acc 1
2016-09-05T18:42:57.570580: step 15052, loss 0.00113904, acc 1
2016-09-05T18:42:57.791914: step 15053, loss 0.000694859, acc 1
2016-09-05T18:42:58.017640: step 15054, loss 0.000909138, acc 1
2016-09-05T18:42:58.261394: step 15055, loss 0.000672832, acc 1
2016-09-05T18:42:58.469165: step 15056, loss 0.000675719, acc 1
2016-09-05T18:42:58.693804: step 15057, loss 0.000626255, acc 1
2016-09-05T18:42:58.930441: step 15058, loss 0.000731335, acc 1
2016-09-05T18:42:59.148972: step 15059, loss 0.000612557, acc 1
2016-09-05T18:42:59.357456: step 15060, loss 0.00090336, acc 1
2016-09-05T18:42:59.561091: step 15061, loss 0.000612642, acc 1
2016-09-05T18:42:59.774626: step 15062, loss 0.000862454, acc 1
2016-09-05T18:42:59.996300: step 15063, loss 0.000806705, acc 1
2016-09-05T18:43:00.203836: step 15064, loss 0.000653453, acc 1
2016-09-05T18:43:00.430809: step 15065, loss 0.00132286, acc 1
2016-09-05T18:43:00.670438: step 15066, loss 0.0010673, acc 1
2016-09-05T18:43:00.870740: step 15067, loss 0.000625811, acc 1
2016-09-05T18:43:01.081455: step 15068, loss 0.000614923, acc 1
2016-09-05T18:43:01.277578: step 15069, loss 0.000719902, acc 1
2016-09-05T18:43:01.477237: step 15070, loss 0.000736519, acc 1
2016-09-05T18:43:01.684667: step 15071, loss 0.000693691, acc 1
2016-09-05T18:43:01.889203: step 15072, loss 0.000703579, acc 1
2016-09-05T18:43:02.124085: step 15073, loss 0.000796255, acc 1
2016-09-05T18:43:02.335690: step 15074, loss 0.000659048, acc 1
2016-09-05T18:43:02.558547: step 15075, loss 0.00073986, acc 1
2016-09-05T18:43:02.787475: step 15076, loss 0.000672983, acc 1
2016-09-05T18:43:02.999976: step 15077, loss 0.000785312, acc 1
2016-09-05T18:43:03.202201: step 15078, loss 0.000736059, acc 1
2016-09-05T18:43:03.421483: step 15079, loss 0.00073119, acc 1
2016-09-05T18:43:03.622957: step 15080, loss 0.000936584, acc 1
2016-09-05T18:43:03.830797: step 15081, loss 0.00070189, acc 1
2016-09-05T18:43:04.044830: step 15082, loss 0.000661685, acc 1
2016-09-05T18:43:04.286902: step 15083, loss 0.000606553, acc 1
2016-09-05T18:43:04.497458: step 15084, loss 0.000612925, acc 1
2016-09-05T18:43:04.705683: step 15085, loss 0.000725914, acc 1
2016-09-05T18:43:04.901956: step 15086, loss 0.000633827, acc 1
2016-09-05T18:43:05.118235: step 15087, loss 0.000725112, acc 1
2016-09-05T18:43:05.333320: step 15088, loss 0.0006396, acc 1
2016-09-05T18:43:05.597448: step 15089, loss 0.000726374, acc 1
2016-09-05T18:43:05.818170: step 15090, loss 0.000651991, acc 1
2016-09-05T18:43:06.020570: step 15091, loss 0.000659039, acc 1
2016-09-05T18:43:06.234282: step 15092, loss 0.000642587, acc 1
2016-09-05T18:43:06.445674: step 15093, loss 0.00100671, acc 1
2016-09-05T18:43:06.662908: step 15094, loss 0.000642027, acc 1
2016-09-05T18:43:06.876996: step 15095, loss 0.00087197, acc 1
2016-09-05T18:43:07.115112: step 15096, loss 0.000672497, acc 1
2016-09-05T18:43:07.332895: step 15097, loss 0.000614465, acc 1
2016-09-05T18:43:07.541409: step 15098, loss 0.000645364, acc 1
2016-09-05T18:43:07.778560: step 15099, loss 0.000698989, acc 1
2016-09-05T18:43:07.976871: step 15100, loss 0.000790213, acc 1

Evaluation:
2016-09-05T18:43:08.579821: step 15100, loss 1.54502, acc 0.714

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-15100

2016-09-05T18:43:09.299767: step 15101, loss 0.000685939, acc 1
2016-09-05T18:43:09.558756: step 15102, loss 0.000570852, acc 1
2016-09-05T18:43:09.760591: step 15103, loss 0.000843283, acc 1
2016-09-05T18:43:09.966114: step 15104, loss 0.000874749, acc 1
2016-09-05T18:43:10.185881: step 15105, loss 0.000756218, acc 1
2016-09-05T18:43:10.417897: step 15106, loss 0.00102314, acc 1
2016-09-05T18:43:10.655399: step 15107, loss 0.00064429, acc 1
2016-09-05T18:43:10.863061: step 15108, loss 0.000664582, acc 1
2016-09-05T18:43:11.073702: step 15109, loss 0.00061991, acc 1
2016-09-05T18:43:11.294716: step 15110, loss 0.000594773, acc 1
2016-09-05T18:43:11.538332: step 15111, loss 0.000621981, acc 1
2016-09-05T18:43:11.776874: step 15112, loss 0.000694936, acc 1
2016-09-05T18:43:12.012002: step 15113, loss 0.000853907, acc 1
2016-09-05T18:43:12.237224: step 15114, loss 0.000688553, acc 1
2016-09-05T18:43:12.481081: step 15115, loss 0.000642755, acc 1
2016-09-05T18:43:12.694542: step 15116, loss 0.000620924, acc 1
2016-09-05T18:43:12.886768: step 15117, loss 0.00122967, acc 1
2016-09-05T18:43:13.099884: step 15118, loss 0.000696034, acc 1
2016-09-05T18:43:13.330194: step 15119, loss 0.000849607, acc 1
2016-09-05T18:43:13.579956: step 15120, loss 0.000828164, acc 1
2016-09-05T18:43:13.801853: step 15121, loss 0.000664325, acc 1
2016-09-05T18:43:14.009734: step 15122, loss 0.000968625, acc 1
2016-09-05T18:43:14.222255: step 15123, loss 0.000670977, acc 1
2016-09-05T18:43:14.437213: step 15124, loss 0.00085645, acc 1
2016-09-05T18:43:14.642483: step 15125, loss 0.000892875, acc 1
2016-09-05T18:43:14.848215: step 15126, loss 0.000692366, acc 1
2016-09-05T18:43:15.061356: step 15127, loss 0.000755297, acc 1
2016-09-05T18:43:15.302493: step 15128, loss 0.000883046, acc 1
2016-09-05T18:43:15.521210: step 15129, loss 0.000746491, acc 1
2016-09-05T18:43:15.723216: step 15130, loss 0.000705816, acc 1
2016-09-05T18:43:15.924397: step 15131, loss 0.000737136, acc 1
2016-09-05T18:43:16.056114: step 15132, loss 0.000621382, acc 1
2016-09-05T18:43:16.290202: step 15133, loss 0.000699506, acc 1
2016-09-05T18:43:16.524339: step 15134, loss 0.000660826, acc 1
2016-09-05T18:43:16.730107: step 15135, loss 0.000849695, acc 1
2016-09-05T18:43:16.934265: step 15136, loss 0.00102817, acc 1
2016-09-05T18:43:17.163837: step 15137, loss 0.000743777, acc 1
2016-09-05T18:43:17.375693: step 15138, loss 0.000690552, acc 1
2016-09-05T18:43:17.616805: step 15139, loss 0.000668862, acc 1
2016-09-05T18:43:17.825364: step 15140, loss 0.000715221, acc 1
2016-09-05T18:43:18.040954: step 15141, loss 0.000940767, acc 1
2016-09-05T18:43:18.239371: step 15142, loss 0.000649247, acc 1
2016-09-05T18:43:18.455708: step 15143, loss 0.000698806, acc 1
2016-09-05T18:43:18.681375: step 15144, loss 0.00078617, acc 1
2016-09-05T18:43:18.897589: step 15145, loss 0.000969416, acc 1
2016-09-05T18:43:19.121398: step 15146, loss 0.000644853, acc 1
2016-09-05T18:43:19.306607: step 15147, loss 0.000673761, acc 1
2016-09-05T18:43:19.530120: step 15148, loss 0.000652659, acc 1
2016-09-05T18:43:19.733322: step 15149, loss 0.000631019, acc 1
2016-09-05T18:43:19.942192: step 15150, loss 0.000909046, acc 1
2016-09-05T18:43:20.121740: step 15151, loss 0.000723533, acc 1
2016-09-05T18:43:20.355813: step 15152, loss 0.000739804, acc 1
2016-09-05T18:43:20.557042: step 15153, loss 0.00073636, acc 1
2016-09-05T18:43:20.764565: step 15154, loss 0.00063985, acc 1
2016-09-05T18:43:20.970205: step 15155, loss 0.000670965, acc 1
2016-09-05T18:43:21.187100: step 15156, loss 0.000660528, acc 1
2016-09-05T18:43:21.400930: step 15157, loss 0.000677472, acc 1
2016-09-05T18:43:21.628264: step 15158, loss 0.000814872, acc 1
2016-09-05T18:43:21.839975: step 15159, loss 0.000650943, acc 1
2016-09-05T18:43:22.072109: step 15160, loss 0.000767624, acc 1
2016-09-05T18:43:22.280869: step 15161, loss 0.0008192, acc 1
2016-09-05T18:43:22.487196: step 15162, loss 0.000690857, acc 1
2016-09-05T18:43:22.686237: step 15163, loss 0.000839704, acc 1
2016-09-05T18:43:22.906768: step 15164, loss 0.00069418, acc 1
2016-09-05T18:43:23.120896: step 15165, loss 0.00107471, acc 1
2016-09-05T18:43:23.329382: step 15166, loss 0.000770675, acc 1
2016-09-05T18:43:23.547503: step 15167, loss 0.000653069, acc 1
2016-09-05T18:43:23.754388: step 15168, loss 0.000708863, acc 1
2016-09-05T18:43:23.992447: step 15169, loss 0.000648474, acc 1
2016-09-05T18:43:24.192964: step 15170, loss 0.000655665, acc 1
2016-09-05T18:43:24.406760: step 15171, loss 0.000628507, acc 1
2016-09-05T18:43:24.626560: step 15172, loss 0.000726872, acc 1
2016-09-05T18:43:24.857087: step 15173, loss 0.000700851, acc 1
2016-09-05T18:43:25.063647: step 15174, loss 0.000795249, acc 1
2016-09-05T18:43:25.296165: step 15175, loss 0.00158259, acc 1
2016-09-05T18:43:25.493891: step 15176, loss 0.000616307, acc 1
2016-09-05T18:43:25.693449: step 15177, loss 0.000694498, acc 1
2016-09-05T18:43:25.894167: step 15178, loss 0.000632278, acc 1
2016-09-05T18:43:26.105854: step 15179, loss 0.000873971, acc 1
2016-09-05T18:43:26.316829: step 15180, loss 0.000628373, acc 1
2016-09-05T18:43:26.577541: step 15181, loss 0.000705172, acc 1
2016-09-05T18:43:26.804511: step 15182, loss 0.000890969, acc 1
2016-09-05T18:43:27.014144: step 15183, loss 0.000695397, acc 1
2016-09-05T18:43:27.232625: step 15184, loss 0.000782294, acc 1
2016-09-05T18:43:27.444484: step 15185, loss 0.000708443, acc 1
2016-09-05T18:43:27.657179: step 15186, loss 0.000694284, acc 1
2016-09-05T18:43:27.864943: step 15187, loss 0.000867191, acc 1
2016-09-05T18:43:28.078503: step 15188, loss 0.000704582, acc 1
2016-09-05T18:43:28.286825: step 15189, loss 0.000907514, acc 1
2016-09-05T18:43:28.515772: step 15190, loss 0.000666919, acc 1
2016-09-05T18:43:28.726410: step 15191, loss 0.00107946, acc 1
2016-09-05T18:43:28.935515: step 15192, loss 0.000660781, acc 1
2016-09-05T18:43:29.135157: step 15193, loss 0.000676733, acc 1
2016-09-05T18:43:29.345193: step 15194, loss 0.000866457, acc 1
2016-09-05T18:43:29.591434: step 15195, loss 0.000633039, acc 1
2016-09-05T18:43:29.834221: step 15196, loss 0.00075916, acc 1
2016-09-05T18:43:30.052391: step 15197, loss 0.000668851, acc 1
2016-09-05T18:43:30.275920: step 15198, loss 0.000720286, acc 1
2016-09-05T18:43:30.487522: step 15199, loss 0.000678796, acc 1
2016-09-05T18:43:30.725422: step 15200, loss 0.000668431, acc 1

Evaluation:
2016-09-05T18:43:31.342583: step 15200, loss 1.62285, acc 0.718

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-15200

2016-09-05T18:43:32.077417: step 15201, loss 0.000753655, acc 1
2016-09-05T18:43:32.292784: step 15202, loss 0.00074196, acc 1
2016-09-05T18:43:32.501742: step 15203, loss 0.00067681, acc 1
2016-09-05T18:43:32.695692: step 15204, loss 0.000660646, acc 1
2016-09-05T18:43:32.897930: step 15205, loss 0.000707878, acc 1
2016-09-05T18:43:33.103369: step 15206, loss 0.000691725, acc 1
2016-09-05T18:43:33.346049: step 15207, loss 0.000728204, acc 1
2016-09-05T18:43:33.566865: step 15208, loss 0.000772219, acc 1
2016-09-05T18:43:33.780846: step 15209, loss 0.000731816, acc 1
2016-09-05T18:43:33.986802: step 15210, loss 0.000733388, acc 1
2016-09-05T18:43:34.209889: step 15211, loss 0.000633058, acc 1
2016-09-05T18:43:34.420901: step 15212, loss 0.000810462, acc 1
2016-09-05T18:43:34.664124: step 15213, loss 0.000606445, acc 1
2016-09-05T18:43:34.886197: step 15214, loss 0.000618426, acc 1
2016-09-05T18:43:35.092601: step 15215, loss 0.000647284, acc 1
2016-09-05T18:43:35.298797: step 15216, loss 0.000733918, acc 1
2016-09-05T18:43:35.524019: step 15217, loss 0.000758901, acc 1
2016-09-05T18:43:35.756226: step 15218, loss 0.00110811, acc 1
2016-09-05T18:43:35.983901: step 15219, loss 0.000599935, acc 1
2016-09-05T18:43:36.207690: step 15220, loss 0.000657662, acc 1
2016-09-05T18:43:36.415557: step 15221, loss 0.00107517, acc 1
2016-09-05T18:43:36.625097: step 15222, loss 0.000773977, acc 1
2016-09-05T18:43:36.830719: step 15223, loss 0.000622096, acc 1
2016-09-05T18:43:37.046237: step 15224, loss 0.000582021, acc 1
2016-09-05T18:43:37.260947: step 15225, loss 0.000630967, acc 1
2016-09-05T18:43:37.496167: step 15226, loss 0.000614789, acc 1
2016-09-05T18:43:37.697474: step 15227, loss 0.000670091, acc 1
2016-09-05T18:43:37.907389: step 15228, loss 0.000661295, acc 1
2016-09-05T18:43:38.119032: step 15229, loss 0.00071215, acc 1
2016-09-05T18:43:38.343966: step 15230, loss 0.000690369, acc 1
2016-09-05T18:43:38.589440: step 15231, loss 0.000707744, acc 1
2016-09-05T18:43:38.793119: step 15232, loss 0.000575122, acc 1
2016-09-05T18:43:39.010926: step 15233, loss 0.000614216, acc 1
2016-09-05T18:43:39.215706: step 15234, loss 0.000593416, acc 1
2016-09-05T18:43:39.429742: step 15235, loss 0.000636124, acc 1
2016-09-05T18:43:39.642206: step 15236, loss 0.000774737, acc 1
2016-09-05T18:43:39.851229: step 15237, loss 0.00077768, acc 1
2016-09-05T18:43:40.059904: step 15238, loss 0.000727877, acc 1
2016-09-05T18:43:40.276846: step 15239, loss 0.00116053, acc 1
2016-09-05T18:43:40.505064: step 15240, loss 0.000663862, acc 1
2016-09-05T18:43:40.744060: step 15241, loss 0.000649139, acc 1
2016-09-05T18:43:40.966213: step 15242, loss 0.0008217, acc 1
2016-09-05T18:43:41.174740: step 15243, loss 0.000625493, acc 1
2016-09-05T18:43:41.413479: step 15244, loss 0.000620256, acc 1
2016-09-05T18:43:41.639248: step 15245, loss 0.000646049, acc 1
2016-09-05T18:43:41.843103: step 15246, loss 0.000913926, acc 1
2016-09-05T18:43:42.062817: step 15247, loss 0.000597772, acc 1
2016-09-05T18:43:42.287068: step 15248, loss 0.000730022, acc 1
2016-09-05T18:43:42.502512: step 15249, loss 0.000762141, acc 1
2016-09-05T18:43:42.728236: step 15250, loss 0.000753217, acc 1
2016-09-05T18:43:42.948948: step 15251, loss 0.000775407, acc 1
2016-09-05T18:43:43.181538: step 15252, loss 0.000585224, acc 1
2016-09-05T18:43:43.429505: step 15253, loss 0.000978134, acc 1
2016-09-05T18:43:43.648237: step 15254, loss 0.000590911, acc 1
2016-09-05T18:43:43.870901: step 15255, loss 0.000983574, acc 1
2016-09-05T18:43:44.096281: step 15256, loss 0.000633871, acc 1
2016-09-05T18:43:44.318959: step 15257, loss 0.000750362, acc 1
2016-09-05T18:43:44.550968: step 15258, loss 0.001272, acc 1
2016-09-05T18:43:44.780314: step 15259, loss 0.000693533, acc 1
2016-09-05T18:43:45.021229: step 15260, loss 0.00066074, acc 1
2016-09-05T18:43:45.271700: step 15261, loss 0.00065246, acc 1
2016-09-05T18:43:45.501570: step 15262, loss 0.000786092, acc 1
2016-09-05T18:43:45.715225: step 15263, loss 0.00125251, acc 1
2016-09-05T18:43:45.947464: step 15264, loss 0.000657564, acc 1
2016-09-05T18:43:46.187760: step 15265, loss 0.000828255, acc 1
2016-09-05T18:43:46.404328: step 15266, loss 0.000736993, acc 1
2016-09-05T18:43:46.615452: step 15267, loss 0.000658533, acc 1
2016-09-05T18:43:46.825529: step 15268, loss 0.000734532, acc 1
2016-09-05T18:43:47.044224: step 15269, loss 0.000633779, acc 1
2016-09-05T18:43:47.260663: step 15270, loss 0.000831181, acc 1
2016-09-05T18:43:47.501836: step 15271, loss 0.000656688, acc 1
2016-09-05T18:43:47.718261: step 15272, loss 0.000799345, acc 1
2016-09-05T18:43:47.923512: step 15273, loss 0.000647313, acc 1
2016-09-05T18:43:48.123275: step 15274, loss 0.000685389, acc 1
2016-09-05T18:43:48.348052: step 15275, loss 0.000633468, acc 1
2016-09-05T18:43:48.561032: step 15276, loss 0.000710513, acc 1
2016-09-05T18:43:48.782099: step 15277, loss 0.000875167, acc 1
2016-09-05T18:43:49.003776: step 15278, loss 0.000816122, acc 1
2016-09-05T18:43:49.226182: step 15279, loss 0.000635943, acc 1
2016-09-05T18:43:49.437185: step 15280, loss 0.000666627, acc 1
2016-09-05T18:43:49.671934: step 15281, loss 0.000686143, acc 1
2016-09-05T18:43:49.907474: step 15282, loss 0.000715823, acc 1
2016-09-05T18:43:50.124140: step 15283, loss 0.000773516, acc 1
2016-09-05T18:43:50.345728: step 15284, loss 0.000735276, acc 1
2016-09-05T18:43:50.567769: step 15285, loss 0.000642936, acc 1
2016-09-05T18:43:50.817452: step 15286, loss 0.0006738, acc 1
2016-09-05T18:43:51.043674: step 15287, loss 0.000678987, acc 1
2016-09-05T18:43:51.272879: step 15288, loss 0.000939288, acc 1
2016-09-05T18:43:51.522300: step 15289, loss 0.000688953, acc 1
2016-09-05T18:43:51.711537: step 15290, loss 0.00064373, acc 1
2016-09-05T18:43:51.944158: step 15291, loss 0.00081438, acc 1
2016-09-05T18:43:52.153309: step 15292, loss 0.000683734, acc 1
2016-09-05T18:43:52.368692: step 15293, loss 0.00067813, acc 1
2016-09-05T18:43:52.581313: step 15294, loss 0.000772342, acc 1
2016-09-05T18:43:52.789667: step 15295, loss 0.000953796, acc 1
2016-09-05T18:43:53.003654: step 15296, loss 0.000940922, acc 1
2016-09-05T18:43:53.225557: step 15297, loss 0.000635443, acc 1
2016-09-05T18:43:53.452982: step 15298, loss 0.000618684, acc 1
2016-09-05T18:43:53.675174: step 15299, loss 0.000949889, acc 1
2016-09-05T18:43:53.906598: step 15300, loss 0.00072011, acc 1

Evaluation:
2016-09-05T18:43:54.519379: step 15300, loss 1.59339, acc 0.717

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-15300

2016-09-05T18:43:55.284033: step 15301, loss 0.000750616, acc 1
2016-09-05T18:43:55.487010: step 15302, loss 0.00170949, acc 1
2016-09-05T18:43:55.720950: step 15303, loss 0.000665835, acc 1
2016-09-05T18:43:55.926736: step 15304, loss 0.000633648, acc 1
2016-09-05T18:43:56.162134: step 15305, loss 0.000614583, acc 1
2016-09-05T18:43:56.391619: step 15306, loss 0.00079518, acc 1
2016-09-05T18:43:56.594490: step 15307, loss 0.000684048, acc 1
2016-09-05T18:43:56.805046: step 15308, loss 0.000706444, acc 1
2016-09-05T18:43:57.006714: step 15309, loss 0.000630753, acc 1
2016-09-05T18:43:57.209514: step 15310, loss 0.000745156, acc 1
2016-09-05T18:43:57.422986: step 15311, loss 0.000637923, acc 1
2016-09-05T18:43:57.643131: step 15312, loss 0.00070455, acc 1
2016-09-05T18:43:57.856422: step 15313, loss 0.000717357, acc 1
2016-09-05T18:43:58.069152: step 15314, loss 0.000947153, acc 1
2016-09-05T18:43:58.277631: step 15315, loss 0.0010054, acc 1
2016-09-05T18:43:58.509031: step 15316, loss 0.0007346, acc 1
2016-09-05T18:43:58.701199: step 15317, loss 0.000676101, acc 1
2016-09-05T18:43:58.911680: step 15318, loss 0.000778882, acc 1
2016-09-05T18:43:59.114605: step 15319, loss 0.000638111, acc 1
2016-09-05T18:43:59.325565: step 15320, loss 0.000900208, acc 1
2016-09-05T18:43:59.556329: step 15321, loss 0.000652155, acc 1
2016-09-05T18:43:59.761655: step 15322, loss 0.000655507, acc 1
2016-09-05T18:44:00.003003: step 15323, loss 0.000683106, acc 1
2016-09-05T18:44:00.194278: step 15324, loss 0.000829398, acc 1
2016-09-05T18:44:00.422177: step 15325, loss 0.000744234, acc 1
2016-09-05T18:44:00.550070: step 15326, loss 0.000613149, acc 1
2016-09-05T18:44:00.759312: step 15327, loss 0.00067056, acc 1
2016-09-05T18:44:00.958372: step 15328, loss 0.000632236, acc 1
2016-09-05T18:44:01.179163: step 15329, loss 0.000685647, acc 1
2016-09-05T18:44:01.410533: step 15330, loss 0.000775655, acc 1
2016-09-05T18:44:01.634497: step 15331, loss 0.000734776, acc 1
2016-09-05T18:44:01.835212: step 15332, loss 0.000672202, acc 1
2016-09-05T18:44:02.027851: step 15333, loss 0.000854408, acc 1
2016-09-05T18:44:02.242587: step 15334, loss 0.00075349, acc 1
2016-09-05T18:44:02.458711: step 15335, loss 0.00068941, acc 1
2016-09-05T18:44:02.658396: step 15336, loss 0.000656311, acc 1
2016-09-05T18:44:02.873454: step 15337, loss 0.000612426, acc 1
2016-09-05T18:44:03.091583: step 15338, loss 0.000742631, acc 1
2016-09-05T18:44:03.323867: step 15339, loss 0.000683542, acc 1
2016-09-05T18:44:03.567635: step 15340, loss 0.000628999, acc 1
2016-09-05T18:44:03.790939: step 15341, loss 0.000663706, acc 1
2016-09-05T18:44:04.029316: step 15342, loss 0.000644602, acc 1
2016-09-05T18:44:04.250768: step 15343, loss 0.000644674, acc 1
2016-09-05T18:44:04.461439: step 15344, loss 0.00104313, acc 1
2016-09-05T18:44:04.680504: step 15345, loss 0.000624883, acc 1
2016-09-05T18:44:04.903472: step 15346, loss 0.000606921, acc 1
2016-09-05T18:44:05.149881: step 15347, loss 0.000580479, acc 1
2016-09-05T18:44:05.372082: step 15348, loss 0.000675004, acc 1
2016-09-05T18:44:05.576323: step 15349, loss 0.000662538, acc 1
2016-09-05T18:44:05.792184: step 15350, loss 0.000643209, acc 1
2016-09-05T18:44:06.007252: step 15351, loss 0.000960494, acc 1
2016-09-05T18:44:06.250868: step 15352, loss 0.000845299, acc 1
2016-09-05T18:44:06.482604: step 15353, loss 0.00116647, acc 1
2016-09-05T18:44:06.688402: step 15354, loss 0.000628622, acc 1
2016-09-05T18:44:06.889387: step 15355, loss 0.000862128, acc 1
2016-09-05T18:44:07.099803: step 15356, loss 0.00066375, acc 1
2016-09-05T18:44:07.328096: step 15357, loss 0.000624273, acc 1
2016-09-05T18:44:07.572332: step 15358, loss 0.000666788, acc 1
2016-09-05T18:44:07.796422: step 15359, loss 0.000627326, acc 1
2016-09-05T18:44:08.004128: step 15360, loss 0.000699831, acc 1
2016-09-05T18:44:08.207102: step 15361, loss 0.000643631, acc 1
2016-09-05T18:44:08.421474: step 15362, loss 0.000645409, acc 1
2016-09-05T18:44:08.669241: step 15363, loss 0.000759363, acc 1
2016-09-05T18:44:08.908415: step 15364, loss 0.000923287, acc 1
2016-09-05T18:44:09.108412: step 15365, loss 0.000620953, acc 1
2016-09-05T18:44:09.319506: step 15366, loss 0.000905796, acc 1
2016-09-05T18:44:09.531538: step 15367, loss 0.000885762, acc 1
2016-09-05T18:44:09.731934: step 15368, loss 0.000850223, acc 1
2016-09-05T18:44:09.929098: step 15369, loss 0.00089061, acc 1
2016-09-05T18:44:10.132298: step 15370, loss 0.000627691, acc 1
2016-09-05T18:44:10.341102: step 15371, loss 0.000640778, acc 1
2016-09-05T18:44:10.559445: step 15372, loss 0.000721659, acc 1
2016-09-05T18:44:10.798182: step 15373, loss 0.000641839, acc 1
2016-09-05T18:44:11.025875: step 15374, loss 0.000694528, acc 1
2016-09-05T18:44:11.227840: step 15375, loss 0.000707213, acc 1
2016-09-05T18:44:11.471460: step 15376, loss 0.000960859, acc 1
2016-09-05T18:44:11.721595: step 15377, loss 0.000837977, acc 1
2016-09-05T18:44:11.923072: step 15378, loss 0.000765641, acc 1
2016-09-05T18:44:12.136444: step 15379, loss 0.000701218, acc 1
2016-09-05T18:44:12.338790: step 15380, loss 0.000636951, acc 1
2016-09-05T18:44:12.564905: step 15381, loss 0.000628326, acc 1
2016-09-05T18:44:12.790124: step 15382, loss 0.000637797, acc 1
2016-09-05T18:44:13.013441: step 15383, loss 0.000951784, acc 1
2016-09-05T18:44:13.233274: step 15384, loss 0.000865501, acc 1
2016-09-05T18:44:13.457630: step 15385, loss 0.000626486, acc 1
2016-09-05T18:44:13.674843: step 15386, loss 0.000700186, acc 1
2016-09-05T18:44:13.896296: step 15387, loss 0.000634495, acc 1
2016-09-05T18:44:14.117322: step 15388, loss 0.000850074, acc 1
2016-09-05T18:44:14.347841: step 15389, loss 0.000702436, acc 1
2016-09-05T18:44:14.562639: step 15390, loss 0.000707733, acc 1
2016-09-05T18:44:14.778146: step 15391, loss 0.000724625, acc 1
2016-09-05T18:44:14.998027: step 15392, loss 0.000648878, acc 1
2016-09-05T18:44:15.211041: step 15393, loss 0.000615209, acc 1
2016-09-05T18:44:15.460310: step 15394, loss 0.000607329, acc 1
2016-09-05T18:44:15.673929: step 15395, loss 0.000596792, acc 1
2016-09-05T18:44:15.880614: step 15396, loss 0.000627497, acc 1
2016-09-05T18:44:16.090228: step 15397, loss 0.000667213, acc 1
2016-09-05T18:44:16.319907: step 15398, loss 0.000637732, acc 1
2016-09-05T18:44:16.533407: step 15399, loss 0.000758698, acc 1
2016-09-05T18:44:16.755613: step 15400, loss 0.000822863, acc 1

Evaluation:
2016-09-05T18:44:17.351134: step 15400, loss 1.60423, acc 0.717

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-15400

2016-09-05T18:44:18.132603: step 15401, loss 0.000824088, acc 1
2016-09-05T18:44:18.363586: step 15402, loss 0.000616376, acc 1
2016-09-05T18:44:18.597882: step 15403, loss 0.000770712, acc 1
2016-09-05T18:44:18.800825: step 15404, loss 0.000642454, acc 1
2016-09-05T18:44:18.999570: step 15405, loss 0.000584134, acc 1
2016-09-05T18:44:19.206965: step 15406, loss 0.000709005, acc 1
2016-09-05T18:44:19.413109: step 15407, loss 0.000606721, acc 1
2016-09-05T18:44:19.630433: step 15408, loss 0.000715085, acc 1
2016-09-05T18:44:19.836510: step 15409, loss 0.000726423, acc 1
2016-09-05T18:44:20.064530: step 15410, loss 0.000952926, acc 1
2016-09-05T18:44:20.301420: step 15411, loss 0.000727976, acc 1
2016-09-05T18:44:20.515731: step 15412, loss 0.000768932, acc 1
2016-09-05T18:44:20.728786: step 15413, loss 0.000585508, acc 1
2016-09-05T18:44:20.930074: step 15414, loss 0.00108214, acc 1
2016-09-05T18:44:21.144480: step 15415, loss 0.000600756, acc 1
2016-09-05T18:44:21.350628: step 15416, loss 0.000743897, acc 1
2016-09-05T18:44:21.554182: step 15417, loss 0.000797179, acc 1
2016-09-05T18:44:21.776990: step 15418, loss 0.000601369, acc 1
2016-09-05T18:44:21.997116: step 15419, loss 0.000631533, acc 1
2016-09-05T18:44:22.215962: step 15420, loss 0.000616333, acc 1
2016-09-05T18:44:22.447970: step 15421, loss 0.00169296, acc 1
2016-09-05T18:44:22.646493: step 15422, loss 0.000656606, acc 1
2016-09-05T18:44:22.850410: step 15423, loss 0.000615246, acc 1
2016-09-05T18:44:23.080859: step 15424, loss 0.000618499, acc 1
2016-09-05T18:44:23.307231: step 15425, loss 0.000756455, acc 1
2016-09-05T18:44:23.562461: step 15426, loss 0.00065158, acc 1
2016-09-05T18:44:23.784001: step 15427, loss 0.000861, acc 1
2016-09-05T18:44:23.990474: step 15428, loss 0.00088589, acc 1
2016-09-05T18:44:24.220322: step 15429, loss 0.000641262, acc 1
2016-09-05T18:44:24.451720: step 15430, loss 0.000620603, acc 1
2016-09-05T18:44:24.661890: step 15431, loss 0.000715873, acc 1
2016-09-05T18:44:24.877233: step 15432, loss 0.000733837, acc 1
2016-09-05T18:44:25.075454: step 15433, loss 0.000627993, acc 1
2016-09-05T18:44:25.275583: step 15434, loss 0.000638795, acc 1
2016-09-05T18:44:25.486289: step 15435, loss 0.000678828, acc 1
2016-09-05T18:44:25.751707: step 15436, loss 0.00203025, acc 1
2016-09-05T18:44:26.014985: step 15437, loss 0.000674873, acc 1
2016-09-05T18:44:26.226775: step 15438, loss 0.000705206, acc 1
2016-09-05T18:44:26.459225: step 15439, loss 0.000703763, acc 1
2016-09-05T18:44:26.680490: step 15440, loss 0.000839001, acc 1
2016-09-05T18:44:26.905273: step 15441, loss 0.000909406, acc 1
2016-09-05T18:44:27.132542: step 15442, loss 0.00104863, acc 1
2016-09-05T18:44:27.369478: step 15443, loss 0.000726283, acc 1
2016-09-05T18:44:27.598530: step 15444, loss 0.000820007, acc 1
2016-09-05T18:44:27.804098: step 15445, loss 0.000866299, acc 1
2016-09-05T18:44:28.036597: step 15446, loss 0.00106279, acc 1
2016-09-05T18:44:28.284797: step 15447, loss 0.00073509, acc 1
2016-09-05T18:44:28.500353: step 15448, loss 0.000896056, acc 1
2016-09-05T18:44:28.708102: step 15449, loss 0.000717192, acc 1
2016-09-05T18:44:28.919202: step 15450, loss 0.000870836, acc 1
2016-09-05T18:44:29.172428: step 15451, loss 0.000731914, acc 1
2016-09-05T18:44:29.375597: step 15452, loss 0.000706746, acc 1
2016-09-05T18:44:29.589038: step 15453, loss 0.000719309, acc 1
2016-09-05T18:44:29.789084: step 15454, loss 0.000912767, acc 1
2016-09-05T18:44:30.005968: step 15455, loss 0.000747742, acc 1
2016-09-05T18:44:30.205674: step 15456, loss 0.000722129, acc 1
2016-09-05T18:44:30.410679: step 15457, loss 0.000807405, acc 1
2016-09-05T18:44:30.611559: step 15458, loss 0.000730077, acc 1
2016-09-05T18:44:30.823850: step 15459, loss 0.000733198, acc 1
2016-09-05T18:44:31.033188: step 15460, loss 0.000812476, acc 1
2016-09-05T18:44:31.252425: step 15461, loss 0.00085686, acc 1
2016-09-05T18:44:31.473018: step 15462, loss 0.000831703, acc 1
2016-09-05T18:44:31.702540: step 15463, loss 0.000754307, acc 1
2016-09-05T18:44:31.906487: step 15464, loss 0.000775346, acc 1
2016-09-05T18:44:32.124795: step 15465, loss 0.000706605, acc 1
2016-09-05T18:44:32.333580: step 15466, loss 0.000849431, acc 1
2016-09-05T18:44:32.547064: step 15467, loss 0.00208021, acc 1
2016-09-05T18:44:32.764429: step 15468, loss 0.000665882, acc 1
2016-09-05T18:44:32.989440: step 15469, loss 0.00070549, acc 1
2016-09-05T18:44:33.232560: step 15470, loss 0.000755248, acc 1
2016-09-05T18:44:33.436505: step 15471, loss 0.00197716, acc 1
2016-09-05T18:44:33.633126: step 15472, loss 0.00096953, acc 1
2016-09-05T18:44:33.832447: step 15473, loss 0.00134469, acc 1
2016-09-05T18:44:34.040631: step 15474, loss 0.000823885, acc 1
2016-09-05T18:44:34.243947: step 15475, loss 0.00107805, acc 1
2016-09-05T18:44:34.463215: step 15476, loss 0.0011312, acc 1
2016-09-05T18:44:34.661737: step 15477, loss 0.000857718, acc 1
2016-09-05T18:44:34.871022: step 15478, loss 0.00112099, acc 1
2016-09-05T18:44:35.097643: step 15479, loss 0.00090557, acc 1
2016-09-05T18:44:35.329387: step 15480, loss 0.00097031, acc 1
2016-09-05T18:44:35.555674: step 15481, loss 0.00128946, acc 1
2016-09-05T18:44:35.805319: step 15482, loss 0.0010227, acc 1
2016-09-05T18:44:36.045538: step 15483, loss 0.00103275, acc 1
2016-09-05T18:44:36.274491: step 15484, loss 0.0010157, acc 1
2016-09-05T18:44:36.488089: step 15485, loss 0.00113659, acc 1
2016-09-05T18:44:36.701069: step 15486, loss 0.00101589, acc 1
2016-09-05T18:44:36.933929: step 15487, loss 0.00103321, acc 1
2016-09-05T18:44:37.162420: step 15488, loss 0.00103325, acc 1
2016-09-05T18:44:37.364025: step 15489, loss 0.00101576, acc 1
2016-09-05T18:44:37.580838: step 15490, loss 0.00102724, acc 1
2016-09-05T18:44:37.812697: step 15491, loss 0.000966018, acc 1
2016-09-05T18:44:38.041048: step 15492, loss 0.000957059, acc 1
2016-09-05T18:44:38.267429: step 15493, loss 0.00109123, acc 1
2016-09-05T18:44:38.481795: step 15494, loss 0.000940032, acc 1
2016-09-05T18:44:38.687241: step 15495, loss 0.000934485, acc 1
2016-09-05T18:44:38.924530: step 15496, loss 0.000908622, acc 1
2016-09-05T18:44:39.163676: step 15497, loss 0.000984719, acc 1
2016-09-05T18:44:39.395695: step 15498, loss 0.000900401, acc 1
2016-09-05T18:44:39.608357: step 15499, loss 0.000924025, acc 1
2016-09-05T18:44:39.821216: step 15500, loss 0.00088424, acc 1

Evaluation:
2016-09-05T18:44:40.419129: step 15500, loss 1.73996, acc 0.715

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-15500

2016-09-05T18:44:41.129807: step 15501, loss 0.000849492, acc 1
2016-09-05T18:44:41.390512: step 15502, loss 0.000853677, acc 1
2016-09-05T18:44:41.601993: step 15503, loss 0.000843173, acc 1
2016-09-05T18:44:41.830843: step 15504, loss 0.000851016, acc 1
2016-09-05T18:44:42.049766: step 15505, loss 0.000816063, acc 1
2016-09-05T18:44:42.285415: step 15506, loss 0.000842977, acc 1
2016-09-05T18:44:42.505822: step 15507, loss 0.000803968, acc 1
2016-09-05T18:44:42.739106: step 15508, loss 0.000900339, acc 1
2016-09-05T18:44:42.949499: step 15509, loss 0.000793643, acc 1
2016-09-05T18:44:43.175040: step 15510, loss 0.00093155, acc 1
2016-09-05T18:44:43.420102: step 15511, loss 0.000789549, acc 1
2016-09-05T18:44:43.628188: step 15512, loss 0.000718628, acc 1
2016-09-05T18:44:43.839234: step 15513, loss 0.000891052, acc 1
2016-09-05T18:44:44.036470: step 15514, loss 0.00101171, acc 1
2016-09-05T18:44:44.269062: step 15515, loss 0.00120948, acc 1
2016-09-05T18:44:44.475948: step 15516, loss 0.000732815, acc 1
2016-09-05T18:44:44.721844: step 15517, loss 0.000701971, acc 1
2016-09-05T18:44:44.947855: step 15518, loss 0.000933574, acc 1
2016-09-05T18:44:45.231724: step 15519, loss 0.000705686, acc 1
2016-09-05T18:44:45.368463: step 15520, loss 0.000657961, acc 1
2016-09-05T18:44:45.583481: step 15521, loss 0.000684621, acc 1
2016-09-05T18:44:45.798565: step 15522, loss 0.000769661, acc 1
2016-09-05T18:44:46.029457: step 15523, loss 0.000936019, acc 1
2016-09-05T18:44:46.262251: step 15524, loss 0.000896813, acc 1
2016-09-05T18:44:46.462416: step 15525, loss 0.000700541, acc 1
2016-09-05T18:44:46.681127: step 15526, loss 0.000845905, acc 1
2016-09-05T18:44:46.890088: step 15527, loss 0.000625999, acc 1
2016-09-05T18:44:47.105844: step 15528, loss 0.000900539, acc 1
2016-09-05T18:44:47.341416: step 15529, loss 0.000694308, acc 1
2016-09-05T18:44:47.571868: step 15530, loss 0.000884234, acc 1
2016-09-05T18:44:47.782967: step 15531, loss 0.0006462, acc 1
2016-09-05T18:44:48.006367: step 15532, loss 0.000714132, acc 1
2016-09-05T18:44:48.216821: step 15533, loss 0.000645087, acc 1
2016-09-05T18:44:48.458769: step 15534, loss 0.000616422, acc 1
2016-09-05T18:44:48.689861: step 15535, loss 0.00064961, acc 1
2016-09-05T18:44:48.904711: step 15536, loss 0.00062046, acc 1
2016-09-05T18:44:49.132789: step 15537, loss 0.000767733, acc 1
2016-09-05T18:44:49.353452: step 15538, loss 0.000721848, acc 1
2016-09-05T18:44:49.561416: step 15539, loss 0.000716567, acc 1
2016-09-05T18:44:49.778536: step 15540, loss 0.000626948, acc 1
2016-09-05T18:44:49.985196: step 15541, loss 0.00101924, acc 1
2016-09-05T18:44:50.182662: step 15542, loss 0.000715455, acc 1
2016-09-05T18:44:50.390384: step 15543, loss 0.000817771, acc 1
2016-09-05T18:44:50.595650: step 15544, loss 0.000657417, acc 1
2016-09-05T18:44:50.811616: step 15545, loss 0.000679256, acc 1
2016-09-05T18:44:51.016834: step 15546, loss 0.000632516, acc 1
2016-09-05T18:44:51.252757: step 15547, loss 0.00075796, acc 1
2016-09-05T18:44:51.510499: step 15548, loss 0.000712139, acc 1
2016-09-05T18:44:51.709546: step 15549, loss 0.000696445, acc 1
2016-09-05T18:44:51.935323: step 15550, loss 0.000673445, acc 1
2016-09-05T18:44:52.190529: step 15551, loss 0.000638315, acc 1
2016-09-05T18:44:52.417097: step 15552, loss 0.000720454, acc 1
2016-09-05T18:44:52.621234: step 15553, loss 0.000658825, acc 1
2016-09-05T18:44:52.831887: step 15554, loss 0.000614346, acc 1
2016-09-05T18:44:53.049672: step 15555, loss 0.00068034, acc 1
2016-09-05T18:44:53.272259: step 15556, loss 0.000731941, acc 1
2016-09-05T18:44:53.497618: step 15557, loss 0.000710741, acc 1
2016-09-05T18:44:53.728219: step 15558, loss 0.00082135, acc 1
2016-09-05T18:44:53.947734: step 15559, loss 0.00060906, acc 1
2016-09-05T18:44:54.151072: step 15560, loss 0.000605962, acc 1
2016-09-05T18:44:54.387207: step 15561, loss 0.000623087, acc 1
2016-09-05T18:44:54.596821: step 15562, loss 0.000743585, acc 1
2016-09-05T18:44:54.810731: step 15563, loss 0.000661606, acc 1
2016-09-05T18:44:55.025397: step 15564, loss 0.000818318, acc 1
2016-09-05T18:44:55.251930: step 15565, loss 0.000734325, acc 1
2016-09-05T18:44:55.452976: step 15566, loss 0.000585823, acc 1
2016-09-05T18:44:55.661806: step 15567, loss 0.000710666, acc 1
2016-09-05T18:44:55.870454: step 15568, loss 0.000598992, acc 1
2016-09-05T18:44:56.089655: step 15569, loss 0.000666628, acc 1
2016-09-05T18:44:56.305437: step 15570, loss 0.000635955, acc 1
2016-09-05T18:44:56.512990: step 15571, loss 0.000641924, acc 1
2016-09-05T18:44:56.738038: step 15572, loss 0.00093103, acc 1
2016-09-05T18:44:56.981367: step 15573, loss 0.000618089, acc 1
2016-09-05T18:44:57.188238: step 15574, loss 0.000665759, acc 1
2016-09-05T18:44:57.397006: step 15575, loss 0.00109523, acc 1
2016-09-05T18:44:57.612349: step 15576, loss 0.000903961, acc 1
2016-09-05T18:44:57.823493: step 15577, loss 0.000675139, acc 1
2016-09-05T18:44:58.066140: step 15578, loss 0.00064812, acc 1
2016-09-05T18:44:58.272815: step 15579, loss 0.00117573, acc 1
2016-09-05T18:44:58.494666: step 15580, loss 0.000916834, acc 1
2016-09-05T18:44:58.690761: step 15581, loss 0.000625462, acc 1
2016-09-05T18:44:58.936236: step 15582, loss 0.000679557, acc 1
2016-09-05T18:44:59.183762: step 15583, loss 0.000615474, acc 1
2016-09-05T18:44:59.398300: step 15584, loss 0.000631353, acc 1
2016-09-05T18:44:59.626643: step 15585, loss 0.000779558, acc 1
2016-09-05T18:44:59.848849: step 15586, loss 0.000639434, acc 1
2016-09-05T18:45:00.057720: step 15587, loss 0.00109429, acc 1
2016-09-05T18:45:00.278271: step 15588, loss 0.000619331, acc 1
2016-09-05T18:45:00.479669: step 15589, loss 0.00073744, acc 1
2016-09-05T18:45:00.688355: step 15590, loss 0.000795222, acc 1
2016-09-05T18:45:00.920845: step 15591, loss 0.000690236, acc 1
2016-09-05T18:45:01.135731: step 15592, loss 0.000663144, acc 1
2016-09-05T18:45:01.366499: step 15593, loss 0.000700218, acc 1
2016-09-05T18:45:01.596419: step 15594, loss 0.000660531, acc 1
2016-09-05T18:45:01.810130: step 15595, loss 0.000649143, acc 1
2016-09-05T18:45:02.034620: step 15596, loss 0.000664252, acc 1
2016-09-05T18:45:02.245187: step 15597, loss 0.000728927, acc 1
2016-09-05T18:45:02.480366: step 15598, loss 0.00123474, acc 1
2016-09-05T18:45:02.705602: step 15599, loss 0.000735161, acc 1
2016-09-05T18:45:02.921724: step 15600, loss 0.000606043, acc 1

Evaluation:
2016-09-05T18:45:03.523917: step 15600, loss 1.61247, acc 0.72

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-15600

2016-09-05T18:45:04.246457: step 15601, loss 0.000713977, acc 1
2016-09-05T18:45:04.447501: step 15602, loss 0.000762318, acc 1
2016-09-05T18:45:04.666330: step 15603, loss 0.000695492, acc 1
2016-09-05T18:45:04.888916: step 15604, loss 0.000717452, acc 1
2016-09-05T18:45:05.096016: step 15605, loss 0.00124252, acc 1
2016-09-05T18:45:05.311597: step 15606, loss 0.000643743, acc 1
2016-09-05T18:45:05.530438: step 15607, loss 0.0007827, acc 1
2016-09-05T18:45:05.740555: step 15608, loss 0.000746583, acc 1
2016-09-05T18:45:05.956782: step 15609, loss 0.00103958, acc 1
2016-09-05T18:45:06.158281: step 15610, loss 0.000997155, acc 1
2016-09-05T18:45:06.361497: step 15611, loss 0.000970143, acc 1
2016-09-05T18:45:06.566298: step 15612, loss 0.000657339, acc 1
2016-09-05T18:45:06.781558: step 15613, loss 0.000636637, acc 1
2016-09-05T18:45:07.006640: step 15614, loss 0.000869098, acc 1
2016-09-05T18:45:07.210126: step 15615, loss 0.000658233, acc 1
2016-09-05T18:45:07.443568: step 15616, loss 0.000789733, acc 1
2016-09-05T18:45:07.662699: step 15617, loss 0.000839656, acc 1
2016-09-05T18:45:07.872206: step 15618, loss 0.00080661, acc 1
2016-09-05T18:45:08.071275: step 15619, loss 0.000798706, acc 1
2016-09-05T18:45:08.286805: step 15620, loss 0.000742567, acc 1
2016-09-05T18:45:08.505830: step 15621, loss 0.000672663, acc 1
2016-09-05T18:45:08.740167: step 15622, loss 0.00106754, acc 1
2016-09-05T18:45:08.954439: step 15623, loss 0.000672543, acc 1
2016-09-05T18:45:09.152825: step 15624, loss 0.000717952, acc 1
2016-09-05T18:45:09.387488: step 15625, loss 0.000672087, acc 1
2016-09-05T18:45:09.595294: step 15626, loss 0.000958701, acc 1
2016-09-05T18:45:09.805411: step 15627, loss 0.000730501, acc 1
2016-09-05T18:45:10.014580: step 15628, loss 0.000658643, acc 1
2016-09-05T18:45:10.232862: step 15629, loss 0.000956787, acc 1
2016-09-05T18:45:10.436127: step 15630, loss 0.000668669, acc 1
2016-09-05T18:45:10.660718: step 15631, loss 0.000678085, acc 1
2016-09-05T18:45:10.869407: step 15632, loss 0.000652828, acc 1
2016-09-05T18:45:11.093115: step 15633, loss 0.000660994, acc 1
2016-09-05T18:45:11.316203: step 15634, loss 0.00213535, acc 1
2016-09-05T18:45:11.511576: step 15635, loss 0.000773941, acc 1
2016-09-05T18:45:11.714272: step 15636, loss 0.000660303, acc 1
2016-09-05T18:45:11.923940: step 15637, loss 0.000731292, acc 1
2016-09-05T18:45:12.135353: step 15638, loss 0.000625486, acc 1
2016-09-05T18:45:12.369420: step 15639, loss 0.000775341, acc 1
2016-09-05T18:45:12.587991: step 15640, loss 0.00107144, acc 1
2016-09-05T18:45:12.823716: step 15641, loss 0.000683133, acc 1
2016-09-05T18:45:13.043064: step 15642, loss 0.000741302, acc 1
2016-09-05T18:45:13.249962: step 15643, loss 0.00075104, acc 1
2016-09-05T18:45:13.477709: step 15644, loss 0.000760376, acc 1
2016-09-05T18:45:13.716997: step 15645, loss 0.000822984, acc 1
2016-09-05T18:45:13.929492: step 15646, loss 0.000712981, acc 1
2016-09-05T18:45:14.125770: step 15647, loss 0.000695725, acc 1
2016-09-05T18:45:14.341326: step 15648, loss 0.000723471, acc 1
2016-09-05T18:45:14.569382: step 15649, loss 0.000682132, acc 1
2016-09-05T18:45:14.780009: step 15650, loss 0.00064211, acc 1
2016-09-05T18:45:14.988462: step 15651, loss 0.00067427, acc 1
2016-09-05T18:45:15.215772: step 15652, loss 0.000694438, acc 1
2016-09-05T18:45:15.449093: step 15653, loss 0.000724877, acc 1
2016-09-05T18:45:15.645478: step 15654, loss 0.000635886, acc 1
2016-09-05T18:45:15.857994: step 15655, loss 0.000820234, acc 1
2016-09-05T18:45:16.064883: step 15656, loss 0.000743985, acc 1
2016-09-05T18:45:16.270526: step 15657, loss 0.000733429, acc 1
2016-09-05T18:45:16.472671: step 15658, loss 0.000638611, acc 1
2016-09-05T18:45:16.697156: step 15659, loss 0.000732034, acc 1
2016-09-05T18:45:16.894322: step 15660, loss 0.000690948, acc 1
2016-09-05T18:45:17.134908: step 15661, loss 0.00057703, acc 1
2016-09-05T18:45:17.344959: step 15662, loss 0.000618376, acc 1
2016-09-05T18:45:17.557689: step 15663, loss 0.000581027, acc 1
2016-09-05T18:45:17.767808: step 15664, loss 0.000656346, acc 1
2016-09-05T18:45:17.986265: step 15665, loss 0.000598939, acc 1
2016-09-05T18:45:18.198771: step 15666, loss 0.000606252, acc 1
2016-09-05T18:45:18.449428: step 15667, loss 0.000570749, acc 1
2016-09-05T18:45:18.670174: step 15668, loss 0.00064853, acc 1
2016-09-05T18:45:18.873621: step 15669, loss 0.00219137, acc 1
2016-09-05T18:45:19.109738: step 15670, loss 0.00101112, acc 1
2016-09-05T18:45:19.321198: step 15671, loss 0.000839335, acc 1
2016-09-05T18:45:19.573481: step 15672, loss 0.0011427, acc 1
2016-09-05T18:45:19.765432: step 15673, loss 0.0019044, acc 1
2016-09-05T18:45:19.973982: step 15674, loss 0.000737669, acc 1
2016-09-05T18:45:20.195437: step 15675, loss 0.000746692, acc 1
2016-09-05T18:45:20.414636: step 15676, loss 0.000811218, acc 1
2016-09-05T18:45:20.646388: step 15677, loss 0.000650322, acc 1
2016-09-05T18:45:20.857964: step 15678, loss 0.000801447, acc 1
2016-09-05T18:45:21.088456: step 15679, loss 0.000911164, acc 1
2016-09-05T18:45:21.299571: step 15680, loss 0.000759344, acc 1
2016-09-05T18:45:21.515499: step 15681, loss 0.000960744, acc 1
2016-09-05T18:45:21.722875: step 15682, loss 0.00084518, acc 1
2016-09-05T18:45:21.945495: step 15683, loss 0.00422276, acc 1
2016-09-05T18:45:22.147977: step 15684, loss 0.000838676, acc 1
2016-09-05T18:45:22.364547: step 15685, loss 0.000966487, acc 1
2016-09-05T18:45:22.581539: step 15686, loss 0.0011558, acc 1
2016-09-05T18:45:22.800726: step 15687, loss 0.00208255, acc 1
2016-09-05T18:45:23.009546: step 15688, loss 0.00874294, acc 1
2016-09-05T18:45:23.232137: step 15689, loss 0.00118189, acc 1
2016-09-05T18:45:23.441941: step 15690, loss 0.00144804, acc 1
2016-09-05T18:45:23.666670: step 15691, loss 0.00225047, acc 1
2016-09-05T18:45:23.875495: step 15692, loss 0.0198947, acc 1
2016-09-05T18:45:24.097386: step 15693, loss 0.00253099, acc 1
2016-09-05T18:45:24.316681: step 15694, loss 0.00307779, acc 1
2016-09-05T18:45:24.526970: step 15695, loss 0.00403849, acc 1
2016-09-05T18:45:24.743173: step 15696, loss 0.0395569, acc 0.98
2016-09-05T18:45:24.992230: step 15697, loss 0.00492845, acc 1
2016-09-05T18:45:25.224687: step 15698, loss 0.00557869, acc 1
2016-09-05T18:45:25.426393: step 15699, loss 0.00626072, acc 1
2016-09-05T18:45:25.648525: step 15700, loss 0.00694705, acc 1

Evaluation:
2016-09-05T18:45:26.236538: step 15700, loss 4.14752, acc 0.71

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-15700

2016-09-05T18:45:26.994696: step 15701, loss 0.00761902, acc 1
2016-09-05T18:45:27.203363: step 15702, loss 0.00826322, acc 1
2016-09-05T18:45:27.437388: step 15703, loss 0.00918438, acc 1
2016-09-05T18:45:27.669969: step 15704, loss 0.00944118, acc 1
2016-09-05T18:45:27.881930: step 15705, loss 0.00994871, acc 1
2016-09-05T18:45:28.093007: step 15706, loss 0.0214282, acc 1
2016-09-05T18:45:28.312946: step 15707, loss 0.0108442, acc 1
2016-09-05T18:45:28.547495: step 15708, loss 0.0112433, acc 1
2016-09-05T18:45:28.741543: step 15709, loss 0.0116186, acc 1
2016-09-05T18:45:28.956741: step 15710, loss 0.0119608, acc 1
2016-09-05T18:45:29.168599: step 15711, loss 0.0122673, acc 1
2016-09-05T18:45:29.364521: step 15712, loss 0.0125368, acc 1
2016-09-05T18:45:29.574211: step 15713, loss 0.0127691, acc 1
2016-09-05T18:45:29.691697: step 15714, loss 0.0129648, acc 1
2016-09-05T18:45:29.895969: step 15715, loss 0.013125, acc 1
2016-09-05T18:45:30.127124: step 15716, loss 0.0132514, acc 1
2016-09-05T18:45:30.370427: step 15717, loss 0.0133459, acc 1
2016-09-05T18:45:30.582334: step 15718, loss 0.01341, acc 1
2016-09-05T18:45:30.783664: step 15719, loss 0.0134463, acc 1
2016-09-05T18:45:30.990681: step 15720, loss 0.0134621, acc 1
2016-09-05T18:45:31.199573: step 15721, loss 0.0134439, acc 1
2016-09-05T18:45:31.415439: step 15722, loss 0.0134094, acc 1
2016-09-05T18:45:31.639434: step 15723, loss 0.0133793, acc 1
2016-09-05T18:45:31.857691: step 15724, loss 0.0132836, acc 1
2016-09-05T18:45:32.073021: step 15725, loss 0.0131962, acc 1
2016-09-05T18:45:32.306157: step 15726, loss 0.0130946, acc 1
2016-09-05T18:45:32.535927: step 15727, loss 0.0129806, acc 1
2016-09-05T18:45:32.762944: step 15728, loss 0.0146257, acc 1
2016-09-05T18:45:33.005370: step 15729, loss 0.0127465, acc 1
2016-09-05T18:45:33.213489: step 15730, loss 0.0125719, acc 1
2016-09-05T18:45:33.422643: step 15731, loss 0.0124226, acc 1
2016-09-05T18:45:33.634029: step 15732, loss 0.012269, acc 1
2016-09-05T18:45:33.840572: step 15733, loss 0.0121116, acc 1
2016-09-05T18:45:34.064257: step 15734, loss 0.0119509, acc 1
2016-09-05T18:45:34.274639: step 15735, loss 0.0117873, acc 1
2016-09-05T18:45:34.486131: step 15736, loss 0.0116213, acc 1
2016-09-05T18:45:34.691821: step 15737, loss 0.0114554, acc 1
2016-09-05T18:45:34.927143: step 15738, loss 0.0112841, acc 1
2016-09-05T18:45:35.120250: step 15739, loss 0.0111137, acc 1
2016-09-05T18:45:35.326945: step 15740, loss 0.0109427, acc 1
2016-09-05T18:45:35.530371: step 15741, loss 0.0107713, acc 1
2016-09-05T18:45:35.733121: step 15742, loss 0.0105998, acc 1
2016-09-05T18:45:35.940452: step 15743, loss 0.0104287, acc 1
2016-09-05T18:45:36.157314: step 15744, loss 0.0102581, acc 1
2016-09-05T18:45:36.371506: step 15745, loss 0.0100883, acc 1
2016-09-05T18:45:36.594116: step 15746, loss 0.00991958, acc 1
2016-09-05T18:45:36.812436: step 15747, loss 0.00975205, acc 1
2016-09-05T18:45:37.053851: step 15748, loss 0.00958616, acc 1
2016-09-05T18:45:37.256084: step 15749, loss 0.00942131, acc 1
2016-09-05T18:45:37.450220: step 15750, loss 0.00925841, acc 1
2016-09-05T18:45:37.663514: step 15751, loss 0.00909732, acc 1
2016-09-05T18:45:37.857577: step 15752, loss 0.00893811, acc 1
2016-09-05T18:45:38.059444: step 15753, loss 0.00878091, acc 1
2016-09-05T18:45:38.264223: step 15754, loss 0.00862579, acc 1
2016-09-05T18:45:38.465315: step 15755, loss 0.00847277, acc 1
2016-09-05T18:45:38.671526: step 15756, loss 0.00832281, acc 1
2016-09-05T18:45:38.892340: step 15757, loss 0.00817342, acc 1
2016-09-05T18:45:39.102737: step 15758, loss 0.00802701, acc 1
2016-09-05T18:45:39.326454: step 15759, loss 0.00788352, acc 1
2016-09-05T18:45:39.564184: step 15760, loss 0.00774118, acc 1
2016-09-05T18:45:39.780252: step 15761, loss 0.00760502, acc 1
2016-09-05T18:45:39.979669: step 15762, loss 0.00746457, acc 1
2016-09-05T18:45:40.183167: step 15763, loss 0.00732975, acc 1
2016-09-05T18:45:40.383744: step 15764, loss 0.00719722, acc 1
2016-09-05T18:45:40.577347: step 15765, loss 0.00706709, acc 1
2016-09-05T18:45:40.781834: step 15766, loss 0.00695463, acc 1
2016-09-05T18:45:40.999219: step 15767, loss 0.00681357, acc 1
2016-09-05T18:45:41.196698: step 15768, loss 0.0066898, acc 1
2016-09-05T18:45:41.436644: step 15769, loss 0.00656872, acc 1
2016-09-05T18:45:41.662683: step 15770, loss 0.00644951, acc 1
2016-09-05T18:45:41.891046: step 15771, loss 0.00633268, acc 1
2016-09-05T18:45:42.119031: step 15772, loss 0.00621814, acc 1
2016-09-05T18:45:42.317872: step 15773, loss 0.00610519, acc 1
2016-09-05T18:45:42.512998: step 15774, loss 0.00599902, acc 1
2016-09-05T18:45:42.731901: step 15775, loss 0.00588611, acc 1
2016-09-05T18:45:42.938978: step 15776, loss 0.00578256, acc 1
2016-09-05T18:45:43.164231: step 15777, loss 0.00567515, acc 1
2016-09-05T18:45:43.394375: step 15778, loss 0.00557287, acc 1
2016-09-05T18:45:43.589410: step 15779, loss 0.00547483, acc 1
2016-09-05T18:45:43.811753: step 15780, loss 0.00537334, acc 1
2016-09-05T18:45:44.012972: step 15781, loss 0.00527634, acc 1
2016-09-05T18:45:44.213121: step 15782, loss 0.00518137, acc 1
2016-09-05T18:45:44.415430: step 15783, loss 0.00508801, acc 1
2016-09-05T18:45:44.633509: step 15784, loss 0.00499648, acc 1
2016-09-05T18:45:44.850918: step 15785, loss 0.00490668, acc 1
2016-09-05T18:45:45.091542: step 15786, loss 0.0048205, acc 1
2016-09-05T18:45:45.315674: step 15787, loss 0.00474152, acc 1
2016-09-05T18:45:45.523944: step 15788, loss 0.00464748, acc 1
2016-09-05T18:45:45.725985: step 15789, loss 0.00456456, acc 1
2016-09-05T18:45:45.947898: step 15790, loss 0.00448586, acc 1
2016-09-05T18:45:46.158299: step 15791, loss 0.00440259, acc 1
2016-09-05T18:45:46.384396: step 15792, loss 0.00432446, acc 1
2016-09-05T18:45:46.588432: step 15793, loss 0.00450485, acc 1
2016-09-05T18:45:46.809328: step 15794, loss 0.00417608, acc 1
2016-09-05T18:45:47.046743: step 15795, loss 0.00410041, acc 1
2016-09-05T18:45:47.249321: step 15796, loss 0.00403069, acc 1
2016-09-05T18:45:47.461030: step 15797, loss 0.0039561, acc 1
2016-09-05T18:45:47.670914: step 15798, loss 0.0038949, acc 1
2016-09-05T18:45:47.887341: step 15799, loss 0.0038186, acc 1
2016-09-05T18:45:48.094601: step 15800, loss 0.00379729, acc 1

Evaluation:
2016-09-05T18:45:48.715575: step 15800, loss 2.93424, acc 0.715

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-15800

2016-09-05T18:45:49.500973: step 15801, loss 0.00381443, acc 1
2016-09-05T18:45:49.709408: step 15802, loss 0.00362281, acc 1
2016-09-05T18:45:49.947317: step 15803, loss 0.00356512, acc 1
2016-09-05T18:45:50.166453: step 15804, loss 0.00350162, acc 1
2016-09-05T18:45:50.366514: step 15805, loss 0.00343881, acc 1
2016-09-05T18:45:50.568184: step 15806, loss 0.00337897, acc 1
2016-09-05T18:45:50.793761: step 15807, loss 0.00332078, acc 1
2016-09-05T18:45:50.994859: step 15808, loss 0.00326262, acc 1
2016-09-05T18:45:51.253616: step 15809, loss 0.00322411, acc 1
2016-09-05T18:45:51.473278: step 15810, loss 0.00315275, acc 1
2016-09-05T18:45:51.682612: step 15811, loss 0.00309885, acc 1
2016-09-05T18:45:51.901081: step 15812, loss 0.00304712, acc 1
2016-09-05T18:45:52.116255: step 15813, loss 0.00299437, acc 1
2016-09-05T18:45:52.353374: step 15814, loss 0.00314081, acc 1
2016-09-05T18:45:52.569420: step 15815, loss 0.00289069, acc 1
2016-09-05T18:45:52.791090: step 15816, loss 0.00283989, acc 1
2016-09-05T18:45:53.011155: step 15817, loss 0.00279112, acc 1
2016-09-05T18:45:53.227654: step 15818, loss 0.00274461, acc 1
2016-09-05T18:45:53.441582: step 15819, loss 0.00269797, acc 1
2016-09-05T18:45:53.662548: step 15820, loss 0.0027184, acc 1
2016-09-05T18:45:53.881518: step 15821, loss 0.00262759, acc 1
2016-09-05T18:45:54.104822: step 15822, loss 0.00267624, acc 1
2016-09-05T18:45:54.323267: step 15823, loss 0.00257027, acc 1
2016-09-05T18:45:54.551926: step 15824, loss 0.00248156, acc 1
2016-09-05T18:45:54.765834: step 15825, loss 0.00251786, acc 1
2016-09-05T18:45:54.980268: step 15826, loss 0.00242173, acc 1
2016-09-05T18:45:55.185570: step 15827, loss 0.00236198, acc 1
2016-09-05T18:45:55.401009: step 15828, loss 0.00233222, acc 1
2016-09-05T18:45:55.614518: step 15829, loss 0.00227934, acc 1
2016-09-05T18:45:55.813353: step 15830, loss 0.00224209, acc 1
2016-09-05T18:45:56.032929: step 15831, loss 0.00222959, acc 1
2016-09-05T18:45:56.251117: step 15832, loss 0.00218291, acc 1
2016-09-05T18:45:56.460126: step 15833, loss 0.00214287, acc 1
2016-09-05T18:45:56.689454: step 15834, loss 0.00222953, acc 1
2016-09-05T18:45:56.903994: step 15835, loss 0.00206922, acc 1
2016-09-05T18:45:57.139748: step 15836, loss 0.00202863, acc 1
2016-09-05T18:45:57.340163: step 15837, loss 0.00201075, acc 1
2016-09-05T18:45:57.543382: step 15838, loss 0.00196673, acc 1
2016-09-05T18:45:57.758853: step 15839, loss 0.00239329, acc 1
2016-09-05T18:45:57.987288: step 15840, loss 0.00190486, acc 1
2016-09-05T18:45:58.208563: step 15841, loss 0.00188179, acc 1
2016-09-05T18:45:58.459116: step 15842, loss 0.00192595, acc 1
2016-09-05T18:45:58.682507: step 15843, loss 0.00182572, acc 1
2016-09-05T18:45:58.914725: step 15844, loss 0.00180107, acc 1
2016-09-05T18:45:59.151001: step 15845, loss 0.00177926, acc 1
2016-09-05T18:45:59.360467: step 15846, loss 0.00173454, acc 1
2016-09-05T18:45:59.572605: step 15847, loss 0.00170971, acc 1
2016-09-05T18:45:59.770753: step 15848, loss 0.00175009, acc 1
2016-09-05T18:45:59.996463: step 15849, loss 0.001659, acc 1
2016-09-05T18:46:00.220176: step 15850, loss 0.00166632, acc 1
2016-09-05T18:46:00.435678: step 15851, loss 0.00162442, acc 1
2016-09-05T18:46:00.659398: step 15852, loss 0.00159478, acc 1
2016-09-05T18:46:00.874669: step 15853, loss 0.00159226, acc 1
2016-09-05T18:46:01.072569: step 15854, loss 0.0015696, acc 1
2016-09-05T18:46:01.277768: step 15855, loss 0.00151498, acc 1
2016-09-05T18:46:01.476730: step 15856, loss 0.00154086, acc 1
2016-09-05T18:46:01.681776: step 15857, loss 0.00148803, acc 1
2016-09-05T18:46:01.870688: step 15858, loss 0.00145748, acc 1
2016-09-05T18:46:02.092598: step 15859, loss 0.00161062, acc 1
2016-09-05T18:46:02.296705: step 15860, loss 0.00154531, acc 1
2016-09-05T18:46:02.506079: step 15861, loss 0.00138825, acc 1
2016-09-05T18:46:02.709252: step 15862, loss 0.00140247, acc 1
2016-09-05T18:46:02.907248: step 15863, loss 0.00137504, acc 1
2016-09-05T18:46:03.097373: step 15864, loss 0.00135576, acc 1
2016-09-05T18:46:03.313509: step 15865, loss 0.00197103, acc 1
2016-09-05T18:46:03.518753: step 15866, loss 0.00131699, acc 1
2016-09-05T18:46:03.736584: step 15867, loss 0.00236077, acc 1
2016-09-05T18:46:03.957593: step 15868, loss 0.00126489, acc 1
2016-09-05T18:46:04.169014: step 15869, loss 0.0012623, acc 1
2016-09-05T18:46:04.393825: step 15870, loss 0.00127677, acc 1
2016-09-05T18:46:04.591138: step 15871, loss 0.00122556, acc 1
2016-09-05T18:46:04.814220: step 15872, loss 0.00177574, acc 1
2016-09-05T18:46:05.026593: step 15873, loss 0.00122805, acc 1
2016-09-05T18:46:05.247929: step 15874, loss 0.00123655, acc 1
2016-09-05T18:46:05.451372: step 15875, loss 0.0012654, acc 1
2016-09-05T18:46:05.674614: step 15876, loss 0.00118518, acc 1
2016-09-05T18:46:05.905456: step 15877, loss 0.00168392, acc 1
2016-09-05T18:46:06.120906: step 15878, loss 0.00117388, acc 1
2016-09-05T18:46:06.327326: step 15879, loss 0.00119992, acc 1
2016-09-05T18:46:06.535407: step 15880, loss 0.00127233, acc 1
2016-09-05T18:46:06.738150: step 15881, loss 0.00117085, acc 1
2016-09-05T18:46:06.961320: step 15882, loss 0.00149031, acc 1
2016-09-05T18:46:07.184247: step 15883, loss 0.00118408, acc 1
2016-09-05T18:46:07.426401: step 15884, loss 0.00114804, acc 1
2016-09-05T18:46:07.644201: step 15885, loss 0.00109886, acc 1
2016-09-05T18:46:07.855917: step 15886, loss 0.00107471, acc 1
2016-09-05T18:46:08.082389: step 15887, loss 0.00111295, acc 1
2016-09-05T18:46:08.295146: step 15888, loss 0.00118297, acc 1
2016-09-05T18:46:08.534713: step 15889, loss 0.001088, acc 1
2016-09-05T18:46:08.742411: step 15890, loss 0.00142325, acc 1
2016-09-05T18:46:08.968614: step 15891, loss 0.00110023, acc 1
2016-09-05T18:46:09.168403: step 15892, loss 0.00108187, acc 1
2016-09-05T18:46:09.395040: step 15893, loss 0.00105415, acc 1
2016-09-05T18:46:09.611240: step 15894, loss 0.00118145, acc 1
2016-09-05T18:46:09.867884: step 15895, loss 0.00101615, acc 1
2016-09-05T18:46:10.103521: step 15896, loss 0.00125438, acc 1
2016-09-05T18:46:10.352648: step 15897, loss 0.000974529, acc 1
2016-09-05T18:46:10.570728: step 15898, loss 0.00103895, acc 1
2016-09-05T18:46:10.793539: step 15899, loss 0.00108743, acc 1
2016-09-05T18:46:11.004466: step 15900, loss 0.00110424, acc 1

Evaluation:
2016-09-05T18:46:11.603292: step 15900, loss 1.76901, acc 0.725

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-15900

2016-09-05T18:46:12.340194: step 15901, loss 0.00103536, acc 1
2016-09-05T18:46:12.613357: step 15902, loss 0.00141147, acc 1
2016-09-05T18:46:12.828784: step 15903, loss 0.0009607, acc 1
2016-09-05T18:46:13.056818: step 15904, loss 0.00140286, acc 1
2016-09-05T18:46:13.294789: step 15905, loss 0.000942007, acc 1
2016-09-05T18:46:13.516726: step 15906, loss 0.000978056, acc 1
2016-09-05T18:46:13.734078: step 15907, loss 0.00148568, acc 1
2016-09-05T18:46:13.865711: step 15908, loss 0.00102246, acc 1
2016-09-05T18:46:14.120082: step 15909, loss 0.00095146, acc 1
2016-09-05T18:46:14.321610: step 15910, loss 0.000900751, acc 1
2016-09-05T18:46:14.576193: step 15911, loss 0.00090345, acc 1
2016-09-05T18:46:14.832139: step 15912, loss 0.000878152, acc 1
2016-09-05T18:46:15.058867: step 15913, loss 0.00089993, acc 1
2016-09-05T18:46:15.294603: step 15914, loss 0.000871715, acc 1
2016-09-05T18:46:15.538376: step 15915, loss 0.000855902, acc 1
2016-09-05T18:46:15.742876: step 15916, loss 0.00094571, acc 1
2016-09-05T18:46:15.965248: step 15917, loss 0.000952532, acc 1
2016-09-05T18:46:16.196653: step 15918, loss 0.000853232, acc 1
2016-09-05T18:46:16.400952: step 15919, loss 0.000843788, acc 1
2016-09-05T18:46:16.647087: step 15920, loss 0.000897404, acc 1
2016-09-05T18:46:16.850589: step 15921, loss 0.00103064, acc 1
2016-09-05T18:46:17.063827: step 15922, loss 0.000830609, acc 1
2016-09-05T18:46:17.265984: step 15923, loss 0.000904712, acc 1
2016-09-05T18:46:17.501906: step 15924, loss 0.000822928, acc 1
2016-09-05T18:46:17.737224: step 15925, loss 0.000926204, acc 1
2016-09-05T18:46:17.950500: step 15926, loss 0.000904646, acc 1
2016-09-05T18:46:18.172415: step 15927, loss 0.00080413, acc 1
2016-09-05T18:46:18.363514: step 15928, loss 0.000811788, acc 1
2016-09-05T18:46:18.563017: step 15929, loss 0.000797104, acc 1
2016-09-05T18:46:18.769764: step 15930, loss 0.000803119, acc 1
2016-09-05T18:46:18.998085: step 15931, loss 0.000974904, acc 1
2016-09-05T18:46:19.214770: step 15932, loss 0.000806213, acc 1
2016-09-05T18:46:19.449681: step 15933, loss 0.000764562, acc 1
2016-09-05T18:46:19.657132: step 15934, loss 0.000787995, acc 1
2016-09-05T18:46:19.873302: step 15935, loss 0.000973706, acc 1
2016-09-05T18:46:20.081917: step 15936, loss 0.000881796, acc 1
2016-09-05T18:46:20.318768: step 15937, loss 0.000793067, acc 1
2016-09-05T18:46:20.547444: step 15938, loss 0.000763885, acc 1
2016-09-05T18:46:20.747102: step 15939, loss 0.000763901, acc 1
2016-09-05T18:46:20.974903: step 15940, loss 0.0015271, acc 1
2016-09-05T18:46:21.181509: step 15941, loss 0.000997364, acc 1
2016-09-05T18:46:21.397143: step 15942, loss 0.000709281, acc 1
2016-09-05T18:46:21.617735: step 15943, loss 0.000798994, acc 1
2016-09-05T18:46:21.826270: step 15944, loss 0.000774768, acc 1
2016-09-05T18:46:22.050073: step 15945, loss 0.000793781, acc 1
2016-09-05T18:46:22.296847: step 15946, loss 0.000810543, acc 1
2016-09-05T18:46:22.493864: step 15947, loss 0.000787108, acc 1
2016-09-05T18:46:22.710219: step 15948, loss 0.00112949, acc 1
2016-09-05T18:46:22.912628: step 15949, loss 0.000730563, acc 1
2016-09-05T18:46:23.135486: step 15950, loss 0.000743229, acc 1
2016-09-05T18:46:23.363198: step 15951, loss 0.000713066, acc 1
2016-09-05T18:46:23.562880: step 15952, loss 0.00117668, acc 1
2016-09-05T18:46:23.807623: step 15953, loss 0.000953188, acc 1
2016-09-05T18:46:24.013725: step 15954, loss 0.000740522, acc 1
2016-09-05T18:46:24.226700: step 15955, loss 0.000877993, acc 1
2016-09-05T18:46:24.449076: step 15956, loss 0.000783947, acc 1
2016-09-05T18:46:24.675077: step 15957, loss 0.000731798, acc 1
2016-09-05T18:46:24.884963: step 15958, loss 0.000698375, acc 1
2016-09-05T18:46:25.113811: step 15959, loss 0.000833326, acc 1
2016-09-05T18:46:25.328991: step 15960, loss 0.00068794, acc 1
2016-09-05T18:46:25.537476: step 15961, loss 0.000735131, acc 1
2016-09-05T18:46:25.740160: step 15962, loss 0.000895458, acc 1
2016-09-05T18:46:25.958250: step 15963, loss 0.000814754, acc 1
2016-09-05T18:46:26.154135: step 15964, loss 0.00123157, acc 1
2016-09-05T18:46:26.386242: step 15965, loss 0.000871702, acc 1
2016-09-05T18:46:26.602334: step 15966, loss 0.000678393, acc 1
2016-09-05T18:46:26.829544: step 15967, loss 0.00069604, acc 1
2016-09-05T18:46:27.045886: step 15968, loss 0.000725944, acc 1
2016-09-05T18:46:27.251524: step 15969, loss 0.000679238, acc 1
2016-09-05T18:46:27.455821: step 15970, loss 0.000699325, acc 1
2016-09-05T18:46:27.653093: step 15971, loss 0.000863083, acc 1
2016-09-05T18:46:27.860141: step 15972, loss 0.000683229, acc 1
2016-09-05T18:46:28.094784: step 15973, loss 0.000741728, acc 1
2016-09-05T18:46:28.362813: step 15974, loss 0.000693829, acc 1
2016-09-05T18:46:28.587426: step 15975, loss 0.000805809, acc 1
2016-09-05T18:46:28.837683: step 15976, loss 0.000905427, acc 1
2016-09-05T18:46:29.056344: step 15977, loss 0.000833676, acc 1
2016-09-05T18:46:29.259733: step 15978, loss 0.00199264, acc 1
2016-09-05T18:46:29.465372: step 15979, loss 0.000643501, acc 1
2016-09-05T18:46:29.678114: step 15980, loss 0.000845142, acc 1
2016-09-05T18:46:29.908134: step 15981, loss 0.000702751, acc 1
2016-09-05T18:46:30.145536: step 15982, loss 0.000656984, acc 1
2016-09-05T18:46:30.366075: step 15983, loss 0.000780362, acc 1
2016-09-05T18:46:30.575500: step 15984, loss 0.000673658, acc 1
2016-09-05T18:46:30.790082: step 15985, loss 0.00383527, acc 1
2016-09-05T18:46:31.001673: step 15986, loss 0.000778334, acc 1
2016-09-05T18:46:31.233668: step 15987, loss 0.00066535, acc 1
2016-09-05T18:46:31.476755: step 15988, loss 0.000737198, acc 1
2016-09-05T18:46:31.693435: step 15989, loss 0.000702239, acc 1
2016-09-05T18:46:31.917707: step 15990, loss 0.000767779, acc 1
2016-09-05T18:46:32.133563: step 15991, loss 0.000958678, acc 1
2016-09-05T18:46:32.371269: step 15992, loss 0.00160119, acc 1
2016-09-05T18:46:32.592141: step 15993, loss 0.000851592, acc 1
2016-09-05T18:46:32.810326: step 15994, loss 0.0010694, acc 1
2016-09-05T18:46:33.019366: step 15995, loss 0.000823917, acc 1
2016-09-05T18:46:33.232917: step 15996, loss 0.000793948, acc 1
2016-09-05T18:46:33.451652: step 15997, loss 0.00106797, acc 1
2016-09-05T18:46:33.679699: step 15998, loss 0.00101533, acc 1
2016-09-05T18:46:33.899576: step 15999, loss 0.00102005, acc 1
2016-09-05T18:46:34.105437: step 16000, loss 0.00112767, acc 1

Evaluation:
2016-09-05T18:46:34.701011: step 16000, loss 1.83157, acc 0.719

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-16000

2016-09-05T18:46:35.437458: step 16001, loss 0.00106086, acc 1
2016-09-05T18:46:35.667565: step 16002, loss 0.000882238, acc 1
2016-09-05T18:46:35.883025: step 16003, loss 0.000906095, acc 1
2016-09-05T18:46:36.109658: step 16004, loss 0.000906512, acc 1
2016-09-05T18:46:36.319296: step 16005, loss 0.000949042, acc 1
2016-09-05T18:46:36.532490: step 16006, loss 0.000840766, acc 1
2016-09-05T18:46:36.754154: step 16007, loss 0.00102989, acc 1
2016-09-05T18:46:36.977688: step 16008, loss 0.000838302, acc 1
2016-09-05T18:46:37.200471: step 16009, loss 0.000845663, acc 1
2016-09-05T18:46:37.440525: step 16010, loss 0.00110844, acc 1
2016-09-05T18:46:37.703851: step 16011, loss 0.000892451, acc 1
2016-09-05T18:46:37.954372: step 16012, loss 0.000920747, acc 1
2016-09-05T18:46:38.179614: step 16013, loss 0.000810957, acc 1
2016-09-05T18:46:38.434310: step 16014, loss 0.000917307, acc 1
2016-09-05T18:46:38.633607: step 16015, loss 0.000825624, acc 1
2016-09-05T18:46:38.825461: step 16016, loss 0.000838185, acc 1
2016-09-05T18:46:39.039579: step 16017, loss 0.000841515, acc 1
2016-09-05T18:46:39.248962: step 16018, loss 0.000867858, acc 1
2016-09-05T18:46:39.440529: step 16019, loss 0.00109497, acc 1
2016-09-05T18:46:39.655194: step 16020, loss 0.000769028, acc 1
2016-09-05T18:46:39.858924: step 16021, loss 0.000821388, acc 1
2016-09-05T18:46:40.064417: step 16022, loss 0.000835072, acc 1
2016-09-05T18:46:40.314054: step 16023, loss 0.000957448, acc 1
2016-09-05T18:46:40.556723: step 16024, loss 0.000764828, acc 1
2016-09-05T18:46:40.766239: step 16025, loss 0.00100375, acc 1
2016-09-05T18:46:40.998029: step 16026, loss 0.000886814, acc 1
2016-09-05T18:46:41.218967: step 16027, loss 0.00095806, acc 1
2016-09-05T18:46:41.465189: step 16028, loss 0.0010855, acc 1
2016-09-05T18:46:41.685479: step 16029, loss 0.00126962, acc 1
2016-09-05T18:46:41.890243: step 16030, loss 0.000737569, acc 1
2016-09-05T18:46:42.106847: step 16031, loss 0.000721056, acc 1
2016-09-05T18:46:42.310153: step 16032, loss 0.000731127, acc 1
2016-09-05T18:46:42.548518: step 16033, loss 0.00100145, acc 1
2016-09-05T18:46:42.771220: step 16034, loss 0.000745784, acc 1
2016-09-05T18:46:42.990265: step 16035, loss 0.000832027, acc 1
2016-09-05T18:46:43.210692: step 16036, loss 0.000733711, acc 1
2016-09-05T18:46:43.430150: step 16037, loss 0.000730957, acc 1
2016-09-05T18:46:43.659385: step 16038, loss 0.000826547, acc 1
2016-09-05T18:46:43.884722: step 16039, loss 0.000692292, acc 1
2016-09-05T18:46:44.112530: step 16040, loss 0.0008547, acc 1
2016-09-05T18:46:44.319654: step 16041, loss 0.000713452, acc 1
2016-09-05T18:46:44.536062: step 16042, loss 0.000743866, acc 1
2016-09-05T18:46:44.742475: step 16043, loss 0.000689074, acc 1
2016-09-05T18:46:44.948076: step 16044, loss 0.000853865, acc 1
2016-09-05T18:46:45.170844: step 16045, loss 0.000670086, acc 1
2016-09-05T18:46:45.397749: step 16046, loss 0.000895133, acc 1
2016-09-05T18:46:45.595189: step 16047, loss 0.000904607, acc 1
2016-09-05T18:46:45.801966: step 16048, loss 0.000716719, acc 1
2016-09-05T18:46:46.012854: step 16049, loss 0.000712296, acc 1
2016-09-05T18:46:46.223309: step 16050, loss 0.000687268, acc 1
2016-09-05T18:46:46.430597: step 16051, loss 0.000628609, acc 1
2016-09-05T18:46:46.657356: step 16052, loss 0.000708504, acc 1
2016-09-05T18:46:46.884624: step 16053, loss 0.000642742, acc 1
2016-09-05T18:46:47.091872: step 16054, loss 0.000786858, acc 1
2016-09-05T18:46:47.309497: step 16055, loss 0.000964188, acc 1
2016-09-05T18:46:47.541480: step 16056, loss 0.000715474, acc 1
2016-09-05T18:46:47.777498: step 16057, loss 0.000652933, acc 1
2016-09-05T18:46:47.983234: step 16058, loss 0.000957752, acc 1
2016-09-05T18:46:48.205613: step 16059, loss 0.000795954, acc 1
2016-09-05T18:46:48.423101: step 16060, loss 0.000773696, acc 1
2016-09-05T18:46:48.639762: step 16061, loss 0.000684839, acc 1
2016-09-05T18:46:48.854694: step 16062, loss 0.000840475, acc 1
2016-09-05T18:46:49.088413: step 16063, loss 0.000633179, acc 1
2016-09-05T18:46:49.340606: step 16064, loss 0.000737656, acc 1
2016-09-05T18:46:49.567763: step 16065, loss 0.000855067, acc 1
2016-09-05T18:46:49.764657: step 16066, loss 0.000939232, acc 1
2016-09-05T18:46:49.974414: step 16067, loss 0.000771288, acc 1
2016-09-05T18:46:50.204149: step 16068, loss 0.000653022, acc 1
2016-09-05T18:46:50.414807: step 16069, loss 0.000612248, acc 1
2016-09-05T18:46:50.653888: step 16070, loss 0.000691072, acc 1
2016-09-05T18:46:50.856825: step 16071, loss 0.000609382, acc 1
2016-09-05T18:46:51.065898: step 16072, loss 0.000616506, acc 1
2016-09-05T18:46:51.270186: step 16073, loss 0.000668556, acc 1
2016-09-05T18:46:51.475414: step 16074, loss 0.000634191, acc 1
2016-09-05T18:46:51.687845: step 16075, loss 0.000809327, acc 1
2016-09-05T18:46:51.905859: step 16076, loss 0.000672415, acc 1
2016-09-05T18:46:52.124171: step 16077, loss 0.000643458, acc 1
2016-09-05T18:46:52.353437: step 16078, loss 0.000696036, acc 1
2016-09-05T18:46:52.575199: step 16079, loss 0.00119464, acc 1
2016-09-05T18:46:52.779467: step 16080, loss 0.000665313, acc 1
2016-09-05T18:46:52.991651: step 16081, loss 0.000710043, acc 1
2016-09-05T18:46:53.202666: step 16082, loss 0.000600495, acc 1
2016-09-05T18:46:53.421252: step 16083, loss 0.000803671, acc 1
2016-09-05T18:46:53.649595: step 16084, loss 0.00100269, acc 1
2016-09-05T18:46:53.874793: step 16085, loss 0.000761436, acc 1
2016-09-05T18:46:54.094497: step 16086, loss 0.000674934, acc 1
2016-09-05T18:46:54.343692: step 16087, loss 0.000677936, acc 1
2016-09-05T18:46:54.590493: step 16088, loss 0.0007593, acc 1
2016-09-05T18:46:54.813830: step 16089, loss 0.00093927, acc 1
2016-09-05T18:46:55.045813: step 16090, loss 0.00155412, acc 1
2016-09-05T18:46:55.273747: step 16091, loss 0.000693198, acc 1
2016-09-05T18:46:55.506950: step 16092, loss 0.000778575, acc 1
2016-09-05T18:46:55.724596: step 16093, loss 0.000640596, acc 1
2016-09-05T18:46:55.950893: step 16094, loss 0.000796437, acc 1
2016-09-05T18:46:56.215018: step 16095, loss 0.000684763, acc 1
2016-09-05T18:46:56.417931: step 16096, loss 0.000960984, acc 1
2016-09-05T18:46:56.642528: step 16097, loss 0.00068634, acc 1
2016-09-05T18:46:56.858420: step 16098, loss 0.000864381, acc 1
2016-09-05T18:46:57.074916: step 16099, loss 0.00110575, acc 1
2016-09-05T18:46:57.314893: step 16100, loss 0.00078294, acc 1

Evaluation:
2016-09-05T18:46:57.926037: step 16100, loss 1.73336, acc 0.708

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-16100

2016-09-05T18:46:58.748371: step 16101, loss 0.000911179, acc 1
2016-09-05T18:46:58.877953: step 16102, loss 0.000697662, acc 1
2016-09-05T18:46:59.131349: step 16103, loss 0.000674044, acc 1
2016-09-05T18:46:59.331646: step 16104, loss 0.000629157, acc 1
2016-09-05T18:46:59.544871: step 16105, loss 0.000628038, acc 1
2016-09-05T18:46:59.746466: step 16106, loss 0.000875712, acc 1
2016-09-05T18:46:59.974368: step 16107, loss 0.000655177, acc 1
2016-09-05T18:47:00.183184: step 16108, loss 0.000642717, acc 1
2016-09-05T18:47:00.437637: step 16109, loss 0.000631582, acc 1
2016-09-05T18:47:00.638862: step 16110, loss 0.000673384, acc 1
2016-09-05T18:47:00.855704: step 16111, loss 0.000698128, acc 1
2016-09-05T18:47:01.061440: step 16112, loss 0.000668476, acc 1
2016-09-05T18:47:01.315109: step 16113, loss 0.000625575, acc 1
2016-09-05T18:47:01.558508: step 16114, loss 0.000694426, acc 1
2016-09-05T18:47:01.753480: step 16115, loss 0.000742057, acc 1
2016-09-05T18:47:01.964207: step 16116, loss 0.000648679, acc 1
2016-09-05T18:47:02.156905: step 16117, loss 0.000638679, acc 1
2016-09-05T18:47:02.360258: step 16118, loss 0.000617114, acc 1
2016-09-05T18:47:02.553253: step 16119, loss 0.000801795, acc 1
2016-09-05T18:47:02.767569: step 16120, loss 0.0006029, acc 1
2016-09-05T18:47:02.976506: step 16121, loss 0.000671197, acc 1
2016-09-05T18:47:03.201087: step 16122, loss 0.000621683, acc 1
2016-09-05T18:47:03.432992: step 16123, loss 0.000586756, acc 1
2016-09-05T18:47:03.663677: step 16124, loss 0.000616788, acc 1
2016-09-05T18:47:03.868530: step 16125, loss 0.000604716, acc 1
2016-09-05T18:47:04.090210: step 16126, loss 0.00111947, acc 1
2016-09-05T18:47:04.294842: step 16127, loss 0.000690966, acc 1
2016-09-05T18:47:04.501639: step 16128, loss 0.000714212, acc 1
2016-09-05T18:47:04.727234: step 16129, loss 0.000750672, acc 1
2016-09-05T18:47:04.944125: step 16130, loss 0.00057545, acc 1
2016-09-05T18:47:05.164410: step 16131, loss 0.000587788, acc 1
2016-09-05T18:47:05.380625: step 16132, loss 0.000563603, acc 1
2016-09-05T18:47:05.588078: step 16133, loss 0.000636692, acc 1
2016-09-05T18:47:05.796526: step 16134, loss 0.00110097, acc 1
2016-09-05T18:47:06.008860: step 16135, loss 0.000575346, acc 1
2016-09-05T18:47:06.261389: step 16136, loss 0.000809417, acc 1
2016-09-05T18:47:06.511184: step 16137, loss 0.000550994, acc 1
2016-09-05T18:47:06.717132: step 16138, loss 0.000769429, acc 1
2016-09-05T18:47:06.928060: step 16139, loss 0.000624451, acc 1
2016-09-05T18:47:07.134741: step 16140, loss 0.000542186, acc 1
2016-09-05T18:47:07.357461: step 16141, loss 0.000600957, acc 1
2016-09-05T18:47:07.582586: step 16142, loss 0.000860085, acc 1
2016-09-05T18:47:07.813584: step 16143, loss 0.000591643, acc 1
2016-09-05T18:47:08.027911: step 16144, loss 0.000684593, acc 1
2016-09-05T18:47:08.229183: step 16145, loss 0.000630451, acc 1
2016-09-05T18:47:08.439354: step 16146, loss 0.000845307, acc 1
2016-09-05T18:47:08.670824: step 16147, loss 0.000662356, acc 1
2016-09-05T18:47:08.893865: step 16148, loss 0.000579034, acc 1
2016-09-05T18:47:09.113382: step 16149, loss 0.000662921, acc 1
2016-09-05T18:47:09.317275: step 16150, loss 0.000564533, acc 1
2016-09-05T18:47:09.535732: step 16151, loss 0.000618934, acc 1
2016-09-05T18:47:09.753515: step 16152, loss 0.000687271, acc 1
2016-09-05T18:47:09.962776: step 16153, loss 0.000602843, acc 1
2016-09-05T18:47:10.173668: step 16154, loss 0.000596841, acc 1
2016-09-05T18:47:10.382514: step 16155, loss 0.000660997, acc 1
2016-09-05T18:47:10.596679: step 16156, loss 0.000753945, acc 1
2016-09-05T18:47:10.813405: step 16157, loss 0.000621019, acc 1
2016-09-05T18:47:11.056244: step 16158, loss 0.000544337, acc 1
2016-09-05T18:47:11.251539: step 16159, loss 0.000661004, acc 1
2016-09-05T18:47:11.469022: step 16160, loss 0.000707229, acc 1
2016-09-05T18:47:11.680518: step 16161, loss 0.00101193, acc 1
2016-09-05T18:47:11.893280: step 16162, loss 0.000584866, acc 1
2016-09-05T18:47:12.121379: step 16163, loss 0.000563563, acc 1
2016-09-05T18:47:12.339216: step 16164, loss 0.000582148, acc 1
2016-09-05T18:47:12.565461: step 16165, loss 0.000621521, acc 1
2016-09-05T18:47:12.772238: step 16166, loss 0.000542137, acc 1
2016-09-05T18:47:12.989998: step 16167, loss 0.000554295, acc 1
2016-09-05T18:47:13.213209: step 16168, loss 0.000729269, acc 1
2016-09-05T18:47:13.459926: step 16169, loss 0.000738525, acc 1
2016-09-05T18:47:13.678935: step 16170, loss 0.000678998, acc 1
2016-09-05T18:47:13.892859: step 16171, loss 0.000630682, acc 1
2016-09-05T18:47:14.106427: step 16172, loss 0.000544183, acc 1
2016-09-05T18:47:14.323879: step 16173, loss 0.000725902, acc 1
2016-09-05T18:47:14.532924: step 16174, loss 0.000605604, acc 1
2016-09-05T18:47:14.746396: step 16175, loss 0.000586404, acc 1
2016-09-05T18:47:14.948878: step 16176, loss 0.000661677, acc 1
2016-09-05T18:47:15.186171: step 16177, loss 0.000556947, acc 1
2016-09-05T18:47:15.389601: step 16178, loss 0.00139197, acc 1
2016-09-05T18:47:15.595074: step 16179, loss 0.000618298, acc 1
2016-09-05T18:47:15.813906: step 16180, loss 0.000631636, acc 1
2016-09-05T18:47:16.045847: step 16181, loss 0.000582689, acc 1
2016-09-05T18:47:16.288514: step 16182, loss 0.000553188, acc 1
2016-09-05T18:47:16.491154: step 16183, loss 0.00168711, acc 1
2016-09-05T18:47:16.702574: step 16184, loss 0.000662699, acc 1
2016-09-05T18:47:16.911662: step 16185, loss 0.00068455, acc 1
2016-09-05T18:47:17.134647: step 16186, loss 0.00054046, acc 1
2016-09-05T18:47:17.348726: step 16187, loss 0.000640826, acc 1
2016-09-05T18:47:17.583002: step 16188, loss 0.000865836, acc 1
2016-09-05T18:47:17.772117: step 16189, loss 0.000942293, acc 1
2016-09-05T18:47:17.996177: step 16190, loss 0.000663241, acc 1
2016-09-05T18:47:18.205054: step 16191, loss 0.000588876, acc 1
2016-09-05T18:47:18.431684: step 16192, loss 0.000590596, acc 1
2016-09-05T18:47:18.655728: step 16193, loss 0.000597843, acc 1
2016-09-05T18:47:18.886905: step 16194, loss 0.000786121, acc 1
2016-09-05T18:47:19.126642: step 16195, loss 0.000850208, acc 1
2016-09-05T18:47:19.337596: step 16196, loss 0.000799021, acc 1
2016-09-05T18:47:19.571447: step 16197, loss 0.000593343, acc 1
2016-09-05T18:47:19.777240: step 16198, loss 0.000590392, acc 1
2016-09-05T18:47:20.015825: step 16199, loss 0.00057984, acc 1
2016-09-05T18:47:20.230104: step 16200, loss 0.000576348, acc 1

Evaluation:
2016-09-05T18:47:20.829906: step 16200, loss 1.64442, acc 0.72

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-16200

2016-09-05T18:47:21.499271: step 16201, loss 0.000661672, acc 1
2016-09-05T18:47:21.716428: step 16202, loss 0.00064035, acc 1
2016-09-05T18:47:21.961900: step 16203, loss 0.000687429, acc 1
2016-09-05T18:47:22.179624: step 16204, loss 0.000625875, acc 1
2016-09-05T18:47:22.380996: step 16205, loss 0.000606532, acc 1
2016-09-05T18:47:22.592147: step 16206, loss 0.000582446, acc 1
2016-09-05T18:47:22.793970: step 16207, loss 0.000653199, acc 1
2016-09-05T18:47:23.005094: step 16208, loss 0.000646931, acc 1
2016-09-05T18:47:23.210920: step 16209, loss 0.000570717, acc 1
2016-09-05T18:47:23.438562: step 16210, loss 0.000571195, acc 1
2016-09-05T18:47:23.671384: step 16211, loss 0.000557799, acc 1
2016-09-05T18:47:23.889871: step 16212, loss 0.000633611, acc 1
2016-09-05T18:47:24.106186: step 16213, loss 0.000980511, acc 1
2016-09-05T18:47:24.324192: step 16214, loss 0.000716505, acc 1
2016-09-05T18:47:24.555004: step 16215, loss 0.000647143, acc 1
2016-09-05T18:47:24.756022: step 16216, loss 0.000583099, acc 1
2016-09-05T18:47:24.978631: step 16217, loss 0.000676927, acc 1
2016-09-05T18:47:25.180068: step 16218, loss 0.000656566, acc 1
2016-09-05T18:47:25.399180: step 16219, loss 0.00053565, acc 1
2016-09-05T18:47:25.626777: step 16220, loss 0.000705755, acc 1
2016-09-05T18:47:25.844859: step 16221, loss 0.000684776, acc 1
2016-09-05T18:47:26.066260: step 16222, loss 0.000536318, acc 1
2016-09-05T18:47:26.314291: step 16223, loss 0.000541607, acc 1
2016-09-05T18:47:26.532331: step 16224, loss 0.000669069, acc 1
2016-09-05T18:47:26.748278: step 16225, loss 0.000671606, acc 1
2016-09-05T18:47:26.960921: step 16226, loss 0.000728667, acc 1
2016-09-05T18:47:27.193990: step 16227, loss 0.000787619, acc 1
2016-09-05T18:47:27.384045: step 16228, loss 0.000586696, acc 1
2016-09-05T18:47:27.631172: step 16229, loss 0.00102242, acc 1
2016-09-05T18:47:27.858441: step 16230, loss 0.000569303, acc 1
2016-09-05T18:47:28.111337: step 16231, loss 0.000689437, acc 1
2016-09-05T18:47:28.316382: step 16232, loss 0.00058682, acc 1
2016-09-05T18:47:28.528673: step 16233, loss 0.000547866, acc 1
2016-09-05T18:47:28.762095: step 16234, loss 0.000715483, acc 1
2016-09-05T18:47:28.976587: step 16235, loss 0.00055233, acc 1
2016-09-05T18:47:29.192109: step 16236, loss 0.00053389, acc 1
2016-09-05T18:47:29.399537: step 16237, loss 0.000551922, acc 1
2016-09-05T18:47:29.603082: step 16238, loss 0.000796128, acc 1
2016-09-05T18:47:29.846368: step 16239, loss 0.000635536, acc 1
2016-09-05T18:47:30.056565: step 16240, loss 0.000557607, acc 1
2016-09-05T18:47:30.283396: step 16241, loss 0.000578347, acc 1
2016-09-05T18:47:30.514754: step 16242, loss 0.000686526, acc 1
2016-09-05T18:47:30.776655: step 16243, loss 0.000554916, acc 1
2016-09-05T18:47:30.978588: step 16244, loss 0.00062648, acc 1
2016-09-05T18:47:31.198203: step 16245, loss 0.000720347, acc 1
2016-09-05T18:47:31.413686: step 16246, loss 0.0016673, acc 1
2016-09-05T18:47:31.637113: step 16247, loss 0.000636605, acc 1
2016-09-05T18:47:31.880204: step 16248, loss 0.000662907, acc 1
2016-09-05T18:47:32.083287: step 16249, loss 0.000769368, acc 1
2016-09-05T18:47:32.304544: step 16250, loss 0.000534906, acc 1
2016-09-05T18:47:32.506152: step 16251, loss 0.000823311, acc 1
2016-09-05T18:47:32.732380: step 16252, loss 0.00067535, acc 1
2016-09-05T18:47:32.942146: step 16253, loss 0.000701903, acc 1
2016-09-05T18:47:33.172366: step 16254, loss 0.000712911, acc 1
2016-09-05T18:47:33.382027: step 16255, loss 0.00059019, acc 1
2016-09-05T18:47:33.609282: step 16256, loss 0.000617988, acc 1
2016-09-05T18:47:33.828677: step 16257, loss 0.000627817, acc 1
2016-09-05T18:47:34.049905: step 16258, loss 0.000692271, acc 1
2016-09-05T18:47:34.281443: step 16259, loss 0.000763333, acc 1
2016-09-05T18:47:34.488332: step 16260, loss 0.00093005, acc 1
2016-09-05T18:47:34.712836: step 16261, loss 0.000568377, acc 1
2016-09-05T18:47:34.924482: step 16262, loss 0.00285431, acc 1
2016-09-05T18:47:35.153487: step 16263, loss 0.000612164, acc 1
2016-09-05T18:47:35.374265: step 16264, loss 0.000604644, acc 1
2016-09-05T18:47:35.619477: step 16265, loss 0.00068283, acc 1
2016-09-05T18:47:35.825634: step 16266, loss 0.000601515, acc 1
2016-09-05T18:47:36.044116: step 16267, loss 0.00102333, acc 1
2016-09-05T18:47:36.247461: step 16268, loss 0.00078301, acc 1
2016-09-05T18:47:36.478843: step 16269, loss 0.000677917, acc 1
2016-09-05T18:47:36.706421: step 16270, loss 0.000714823, acc 1
2016-09-05T18:47:36.933716: step 16271, loss 0.00071997, acc 1
2016-09-05T18:47:37.189725: step 16272, loss 0.000632077, acc 1
2016-09-05T18:47:37.407814: step 16273, loss 0.00107097, acc 1
2016-09-05T18:47:37.625310: step 16274, loss 0.000619126, acc 1
2016-09-05T18:47:37.832050: step 16275, loss 0.000712602, acc 1
2016-09-05T18:47:38.044824: step 16276, loss 0.000740789, acc 1
2016-09-05T18:47:38.258578: step 16277, loss 0.000644955, acc 1
2016-09-05T18:47:38.482012: step 16278, loss 0.00111572, acc 1
2016-09-05T18:47:38.702019: step 16279, loss 0.000712969, acc 1
2016-09-05T18:47:38.929215: step 16280, loss 0.00070805, acc 1
2016-09-05T18:47:39.142178: step 16281, loss 0.000736755, acc 1
2016-09-05T18:47:39.335955: step 16282, loss 0.000658474, acc 1
2016-09-05T18:47:39.554706: step 16283, loss 0.000742609, acc 1
2016-09-05T18:47:39.777307: step 16284, loss 0.000697237, acc 1
2016-09-05T18:47:39.979361: step 16285, loss 0.00102025, acc 1
2016-09-05T18:47:40.186219: step 16286, loss 0.000652055, acc 1
2016-09-05T18:47:40.407415: step 16287, loss 0.000684703, acc 1
2016-09-05T18:47:40.620486: step 16288, loss 0.000919208, acc 1
2016-09-05T18:47:40.855467: step 16289, loss 0.00066946, acc 1
2016-09-05T18:47:41.066758: step 16290, loss 0.000879713, acc 1
2016-09-05T18:47:41.337565: step 16291, loss 0.000662643, acc 1
2016-09-05T18:47:41.573692: step 16292, loss 0.000801748, acc 1
2016-09-05T18:47:41.782804: step 16293, loss 0.000679989, acc 1
2016-09-05T18:47:42.001791: step 16294, loss 0.000684285, acc 1
2016-09-05T18:47:42.206162: step 16295, loss 0.000628922, acc 1
2016-09-05T18:47:42.353408: step 16296, loss 0.000692567, acc 1
2016-09-05T18:47:42.589075: step 16297, loss 0.000810219, acc 1
2016-09-05T18:47:42.811149: step 16298, loss 0.000682175, acc 1
2016-09-05T18:47:43.017535: step 16299, loss 0.000623376, acc 1
2016-09-05T18:47:43.238265: step 16300, loss 0.000816997, acc 1

Evaluation:
2016-09-05T18:47:43.836490: step 16300, loss 1.66432, acc 0.719

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-16300

2016-09-05T18:47:44.591685: step 16301, loss 0.000639369, acc 1
2016-09-05T18:47:44.831536: step 16302, loss 0.000749213, acc 1
2016-09-05T18:47:45.032641: step 16303, loss 0.000684491, acc 1
2016-09-05T18:47:45.255780: step 16304, loss 0.000605562, acc 1
2016-09-05T18:47:45.483594: step 16305, loss 0.000598125, acc 1
2016-09-05T18:47:45.711074: step 16306, loss 0.000734931, acc 1
2016-09-05T18:47:45.927971: step 16307, loss 0.000654972, acc 1
2016-09-05T18:47:46.144880: step 16308, loss 0.000618159, acc 1
2016-09-05T18:47:46.371993: step 16309, loss 0.000573787, acc 1
2016-09-05T18:47:46.590253: step 16310, loss 0.000624183, acc 1
2016-09-05T18:47:46.803571: step 16311, loss 0.000612558, acc 1
2016-09-05T18:47:47.004364: step 16312, loss 0.000575182, acc 1
2016-09-05T18:47:47.216802: step 16313, loss 0.000626528, acc 1
2016-09-05T18:47:47.436632: step 16314, loss 0.000600912, acc 1
2016-09-05T18:47:47.671942: step 16315, loss 0.000554352, acc 1
2016-09-05T18:47:47.926736: step 16316, loss 0.00058287, acc 1
2016-09-05T18:47:48.159146: step 16317, loss 0.000627558, acc 1
2016-09-05T18:47:48.379991: step 16318, loss 0.00052541, acc 1
2016-09-05T18:47:48.596206: step 16319, loss 0.000617325, acc 1
2016-09-05T18:47:48.841849: step 16320, loss 0.000709559, acc 1
2016-09-05T18:47:49.052948: step 16321, loss 0.000581139, acc 1
2016-09-05T18:47:49.324742: step 16322, loss 0.000508425, acc 1
2016-09-05T18:47:49.539880: step 16323, loss 0.000580616, acc 1
2016-09-05T18:47:49.763123: step 16324, loss 0.000612057, acc 1
2016-09-05T18:47:49.965157: step 16325, loss 0.000827644, acc 1
2016-09-05T18:47:50.195799: step 16326, loss 0.000670075, acc 1
2016-09-05T18:47:50.424581: step 16327, loss 0.000552236, acc 1
2016-09-05T18:47:50.657898: step 16328, loss 0.000627052, acc 1
2016-09-05T18:47:50.874878: step 16329, loss 0.000545563, acc 1
2016-09-05T18:47:51.100198: step 16330, loss 0.000562015, acc 1
2016-09-05T18:47:51.349530: step 16331, loss 0.000521736, acc 1
2016-09-05T18:47:51.561680: step 16332, loss 0.000605273, acc 1
2016-09-05T18:47:51.767474: step 16333, loss 0.000675079, acc 1
2016-09-05T18:47:51.990926: step 16334, loss 0.000510053, acc 1
2016-09-05T18:47:52.195952: step 16335, loss 0.000639161, acc 1
2016-09-05T18:47:52.420878: step 16336, loss 0.000638342, acc 1
2016-09-05T18:47:52.663034: step 16337, loss 0.000891924, acc 1
2016-09-05T18:47:52.890409: step 16338, loss 0.00067665, acc 1
2016-09-05T18:47:53.099338: step 16339, loss 0.00125959, acc 1
2016-09-05T18:47:53.309240: step 16340, loss 0.00208052, acc 1
2016-09-05T18:47:53.527001: step 16341, loss 0.000710954, acc 1
2016-09-05T18:47:53.746474: step 16342, loss 0.000771374, acc 1
2016-09-05T18:47:53.969455: step 16343, loss 0.000813577, acc 1
2016-09-05T18:47:54.189484: step 16344, loss 0.000882644, acc 1
2016-09-05T18:47:54.401027: step 16345, loss 0.0009571, acc 1
2016-09-05T18:47:54.602357: step 16346, loss 0.0012711, acc 1
2016-09-05T18:47:54.802231: step 16347, loss 0.00542548, acc 1
2016-09-05T18:47:55.032346: step 16348, loss 0.000843847, acc 1
2016-09-05T18:47:55.249210: step 16349, loss 0.000834719, acc 1
2016-09-05T18:47:55.461953: step 16350, loss 0.000935146, acc 1
2016-09-05T18:47:55.706296: step 16351, loss 0.00104285, acc 1
2016-09-05T18:47:55.932951: step 16352, loss 0.00145714, acc 1
2016-09-05T18:47:56.156846: step 16353, loss 0.0106662, acc 1
2016-09-05T18:47:56.386138: step 16354, loss 0.00138952, acc 1
2016-09-05T18:47:56.612633: step 16355, loss 0.00146663, acc 1
2016-09-05T18:47:56.813312: step 16356, loss 0.00166727, acc 1
2016-09-05T18:47:57.019130: step 16357, loss 0.0018879, acc 1
2016-09-05T18:47:57.267844: step 16358, loss 0.00216542, acc 1
2016-09-05T18:47:57.514100: step 16359, loss 0.00234244, acc 1
2016-09-05T18:47:57.716178: step 16360, loss 0.00313133, acc 1
2016-09-05T18:47:57.920628: step 16361, loss 0.00309596, acc 1
2016-09-05T18:47:58.136262: step 16362, loss 0.00513421, acc 1
2016-09-05T18:47:58.346944: step 16363, loss 0.0031963, acc 1
2016-09-05T18:47:58.577006: step 16364, loss 0.0045262, acc 1
2016-09-05T18:47:58.789599: step 16365, loss 0.00352269, acc 1
2016-09-05T18:47:59.011523: step 16366, loss 0.00367324, acc 1
2016-09-05T18:47:59.213387: step 16367, loss 0.00386658, acc 1
2016-09-05T18:47:59.412636: step 16368, loss 0.00395476, acc 1
2016-09-05T18:47:59.614486: step 16369, loss 0.00407077, acc 1
2016-09-05T18:47:59.828018: step 16370, loss 0.00417692, acc 1
2016-09-05T18:48:00.031702: step 16371, loss 0.00425621, acc 1
2016-09-05T18:48:00.247671: step 16372, loss 0.00432513, acc 1
2016-09-05T18:48:00.440527: step 16373, loss 0.00437825, acc 1
2016-09-05T18:48:00.650296: step 16374, loss 0.00441773, acc 1
2016-09-05T18:48:00.852234: step 16375, loss 0.00444249, acc 1
2016-09-05T18:48:01.063047: step 16376, loss 0.00445499, acc 1
2016-09-05T18:48:01.272578: step 16377, loss 0.00445625, acc 1
2016-09-05T18:48:01.521436: step 16378, loss 0.00444645, acc 1
2016-09-05T18:48:01.732561: step 16379, loss 0.00443045, acc 1
2016-09-05T18:48:01.939776: step 16380, loss 0.00439961, acc 1
2016-09-05T18:48:02.164868: step 16381, loss 0.00436391, acc 1
2016-09-05T18:48:02.376077: step 16382, loss 0.00432267, acc 1
2016-09-05T18:48:02.591173: step 16383, loss 0.00427454, acc 1
2016-09-05T18:48:02.807429: step 16384, loss 0.00423172, acc 1
2016-09-05T18:48:03.039573: step 16385, loss 0.00416127, acc 1
2016-09-05T18:48:03.255226: step 16386, loss 0.00659651, acc 1
2016-09-05T18:48:03.452606: step 16387, loss 0.00403366, acc 1
2016-09-05T18:48:03.651128: step 16388, loss 0.00397571, acc 1
2016-09-05T18:48:03.864932: step 16389, loss 0.00392296, acc 1
2016-09-05T18:48:04.066719: step 16390, loss 0.00387649, acc 1
2016-09-05T18:48:04.281179: step 16391, loss 0.00382554, acc 1
2016-09-05T18:48:04.503729: step 16392, loss 0.00377842, acc 1
2016-09-05T18:48:04.756136: step 16393, loss 0.0037313, acc 1
2016-09-05T18:48:04.970518: step 16394, loss 0.00368476, acc 1
2016-09-05T18:48:05.167193: step 16395, loss 0.00363495, acc 1
2016-09-05T18:48:05.386663: step 16396, loss 0.00363415, acc 1
2016-09-05T18:48:05.606171: step 16397, loss 0.00354492, acc 1
2016-09-05T18:48:05.837336: step 16398, loss 0.0094655, acc 1
2016-09-05T18:48:06.077275: step 16399, loss 0.00346734, acc 1
2016-09-05T18:48:06.298759: step 16400, loss 0.0034741, acc 1

Evaluation:
2016-09-05T18:48:06.926625: step 16400, loss 3.16687, acc 0.722

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-16400

2016-09-05T18:48:07.625110: step 16401, loss 0.00350604, acc 1
2016-09-05T18:48:07.841331: step 16402, loss 0.0035516, acc 1
2016-09-05T18:48:08.056455: step 16403, loss 0.0036007, acc 1
2016-09-05T18:48:08.281565: step 16404, loss 0.00368207, acc 1
2016-09-05T18:48:08.484436: step 16405, loss 0.00508142, acc 1
2016-09-05T18:48:08.715630: step 16406, loss 0.00773258, acc 1
2016-09-05T18:48:08.937274: step 16407, loss 0.00379793, acc 1
2016-09-05T18:48:09.157941: step 16408, loss 0.00385573, acc 1
2016-09-05T18:48:09.377965: step 16409, loss 0.00484382, acc 1
2016-09-05T18:48:09.623208: step 16410, loss 0.00397405, acc 1
2016-09-05T18:48:09.836006: step 16411, loss 0.00403462, acc 1
2016-09-05T18:48:10.074756: step 16412, loss 0.00408969, acc 1
2016-09-05T18:48:10.301420: step 16413, loss 0.00414088, acc 1
2016-09-05T18:48:10.518365: step 16414, loss 0.00417948, acc 1
2016-09-05T18:48:10.727668: step 16415, loss 0.00421243, acc 1
2016-09-05T18:48:10.932551: step 16416, loss 0.0042365, acc 1
2016-09-05T18:48:11.140984: step 16417, loss 0.00425115, acc 1
2016-09-05T18:48:11.343148: step 16418, loss 0.00434807, acc 1
2016-09-05T18:48:11.570948: step 16419, loss 0.00425692, acc 1
2016-09-05T18:48:11.820429: step 16420, loss 0.00424654, acc 1
2016-09-05T18:48:12.038839: step 16421, loss 0.00423059, acc 1
2016-09-05T18:48:12.244503: step 16422, loss 0.00420967, acc 1
2016-09-05T18:48:12.463299: step 16423, loss 0.00420977, acc 1
2016-09-05T18:48:12.691764: step 16424, loss 0.00414402, acc 1
2016-09-05T18:48:12.909039: step 16425, loss 0.00410951, acc 1
2016-09-05T18:48:13.150795: step 16426, loss 0.0041021, acc 1
2016-09-05T18:48:13.355538: step 16427, loss 0.00402649, acc 1
2016-09-05T18:48:13.564510: step 16428, loss 0.00423051, acc 1
2016-09-05T18:48:13.767674: step 16429, loss 0.00391165, acc 1
2016-09-05T18:48:13.992007: step 16430, loss 0.0040546, acc 1
2016-09-05T18:48:14.190483: step 16431, loss 0.14071, acc 0.98
2016-09-05T18:48:14.411917: step 16432, loss 0.00368126, acc 1
2016-09-05T18:48:14.625690: step 16433, loss 0.00394912, acc 1
2016-09-05T18:48:14.868152: step 16434, loss 0.00624762, acc 1
2016-09-05T18:48:15.070221: step 16435, loss 0.376185, acc 0.96
2016-09-05T18:48:15.284188: step 16436, loss 0.00514086, acc 1
2016-09-05T18:48:15.491583: step 16437, loss 0.00574986, acc 1
2016-09-05T18:48:15.729958: step 16438, loss 0.00661275, acc 1
2016-09-05T18:48:15.966253: step 16439, loss 0.00765452, acc 1
2016-09-05T18:48:16.166440: step 16440, loss 0.151163, acc 0.96
2016-09-05T18:48:16.378604: step 16441, loss 0.00963757, acc 1
2016-09-05T18:48:16.582663: step 16442, loss 0.0103968, acc 1
2016-09-05T18:48:16.799170: step 16443, loss 0.0113669, acc 1
2016-09-05T18:48:17.004329: step 16444, loss 0.012344, acc 1
2016-09-05T18:48:17.227198: step 16445, loss 0.0133042, acc 1
2016-09-05T18:48:17.429025: step 16446, loss 0.0142309, acc 1
2016-09-05T18:48:17.649275: step 16447, loss 0.0151103, acc 1
2016-09-05T18:48:17.883820: step 16448, loss 0.0159361, acc 1
2016-09-05T18:48:18.088836: step 16449, loss 0.0167028, acc 1
2016-09-05T18:48:18.289461: step 16450, loss 0.0174081, acc 1
2016-09-05T18:48:18.508033: step 16451, loss 0.018051, acc 1
2016-09-05T18:48:18.708396: step 16452, loss 0.0186327, acc 1
2016-09-05T18:48:18.935300: step 16453, loss 0.019156, acc 1
2016-09-05T18:48:19.147285: step 16454, loss 0.0196181, acc 1
2016-09-05T18:48:19.366544: step 16455, loss 0.0200274, acc 1
2016-09-05T18:48:19.604906: step 16456, loss 0.020385, acc 1
2016-09-05T18:48:19.807756: step 16457, loss 0.0206938, acc 1
2016-09-05T18:48:20.019431: step 16458, loss 0.0209579, acc 1
2016-09-05T18:48:20.228344: step 16459, loss 0.0211802, acc 1
2016-09-05T18:48:20.459642: step 16460, loss 0.0214222, acc 1
2016-09-05T18:48:20.675575: step 16461, loss 0.0216043, acc 1
2016-09-05T18:48:20.914681: step 16462, loss 0.0216279, acc 1
2016-09-05T18:48:21.116311: step 16463, loss 0.0217281, acc 1
2016-09-05T18:48:21.329371: step 16464, loss 0.137136, acc 0.98
2016-09-05T18:48:21.542100: step 16465, loss 0.0217946, acc 1
2016-09-05T18:48:21.770899: step 16466, loss 0.0218836, acc 1
2016-09-05T18:48:21.999476: step 16467, loss 0.0220163, acc 1
2016-09-05T18:48:22.224502: step 16468, loss 0.0221887, acc 1
2016-09-05T18:48:22.441434: step 16469, loss 0.0223455, acc 1
2016-09-05T18:48:22.646231: step 16470, loss 0.0225181, acc 1
2016-09-05T18:48:22.863856: step 16471, loss 0.022685, acc 1
2016-09-05T18:48:23.069145: step 16472, loss 0.0228409, acc 1
2016-09-05T18:48:23.284662: step 16473, loss 0.0229817, acc 1
2016-09-05T18:48:23.478054: step 16474, loss 0.0231052, acc 1
2016-09-05T18:48:23.692339: step 16475, loss 0.0232099, acc 1
2016-09-05T18:48:23.916394: step 16476, loss 0.0232949, acc 1
2016-09-05T18:48:24.134342: step 16477, loss 0.0233603, acc 1
2016-09-05T18:48:24.336890: step 16478, loss 0.0234062, acc 1
2016-09-05T18:48:24.556828: step 16479, loss 0.0234439, acc 1
2016-09-05T18:48:24.766595: step 16480, loss 0.0234424, acc 1
2016-09-05T18:48:24.967338: step 16481, loss 0.0234344, acc 1
2016-09-05T18:48:25.219674: step 16482, loss 0.0234105, acc 1
2016-09-05T18:48:25.465220: step 16483, loss 0.0233717, acc 1
2016-09-05T18:48:25.668122: step 16484, loss 0.0233191, acc 1
2016-09-05T18:48:25.868283: step 16485, loss 0.0232539, acc 1
2016-09-05T18:48:26.074420: step 16486, loss 0.0231771, acc 1
2016-09-05T18:48:26.281963: step 16487, loss 0.0230927, acc 1
2016-09-05T18:48:26.514822: step 16488, loss 0.022993, acc 1
2016-09-05T18:48:26.730781: step 16489, loss 0.0228876, acc 1
2016-09-05T18:48:26.873928: step 16490, loss 0.0227745, acc 1
2016-09-05T18:48:27.080805: step 16491, loss 0.0226549, acc 1
2016-09-05T18:48:27.291710: step 16492, loss 0.0225282, acc 1
2016-09-05T18:48:27.503366: step 16493, loss 0.0223984, acc 1
2016-09-05T18:48:27.730931: step 16494, loss 0.0222602, acc 1
2016-09-05T18:48:27.954645: step 16495, loss 0.0221197, acc 1
2016-09-05T18:48:28.207369: step 16496, loss 0.0219754, acc 1
2016-09-05T18:48:28.412916: step 16497, loss 0.021828, acc 1
2016-09-05T18:48:28.619294: step 16498, loss 0.0216779, acc 1
2016-09-05T18:48:28.819093: step 16499, loss 0.0215256, acc 1
2016-09-05T18:48:29.044038: step 16500, loss 0.0213713, acc 1

Evaluation:
2016-09-05T18:48:29.650949: step 16500, loss 8.03034, acc 0.711

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-16500

2016-09-05T18:48:30.368343: step 16501, loss 0.0212154, acc 1
2016-09-05T18:48:30.595396: step 16502, loss 0.02106, acc 1
2016-09-05T18:48:30.809469: step 16503, loss 0.0209002, acc 1
2016-09-05T18:48:31.030880: step 16504, loss 0.0207815, acc 1
2016-09-05T18:48:31.246293: step 16505, loss 0.0205818, acc 1
2016-09-05T18:48:31.467631: step 16506, loss 0.0204222, acc 1
2016-09-05T18:48:31.690463: step 16507, loss 0.0202622, acc 1
2016-09-05T18:48:31.926810: step 16508, loss 0.0201023, acc 1
2016-09-05T18:48:32.123031: step 16509, loss 0.0199611, acc 1
2016-09-05T18:48:32.351071: step 16510, loss 0.0197832, acc 1
2016-09-05T18:48:32.565706: step 16511, loss 0.0196243, acc 1
2016-09-05T18:48:32.786964: step 16512, loss 0.0194658, acc 1
2016-09-05T18:48:33.017111: step 16513, loss 0.019308, acc 1
2016-09-05T18:48:33.247775: step 16514, loss 0.0191508, acc 1
2016-09-05T18:48:33.485826: step 16515, loss 0.0189945, acc 1
2016-09-05T18:48:33.688870: step 16516, loss 0.018839, acc 1
2016-09-05T18:48:33.920972: step 16517, loss 0.0186843, acc 1
2016-09-05T18:48:34.139955: step 16518, loss 0.0185307, acc 1
2016-09-05T18:48:34.368365: step 16519, loss 0.0189542, acc 1
2016-09-05T18:48:34.566606: step 16520, loss 0.189974, acc 0.98
2016-09-05T18:48:34.756503: step 16521, loss 0.0180321, acc 1
2016-09-05T18:48:34.970025: step 16522, loss 0.0179818, acc 1
2016-09-05T18:48:35.186552: step 16523, loss 0.0180357, acc 1
2016-09-05T18:48:35.386997: step 16524, loss 0.0181621, acc 1
2016-09-05T18:48:35.618151: step 16525, loss 0.0183365, acc 1
2016-09-05T18:48:35.829249: step 16526, loss 0.01854, acc 1
2016-09-05T18:48:36.059552: step 16527, loss 0.0191713, acc 1
2016-09-05T18:48:36.291287: step 16528, loss 0.0189804, acc 1
2016-09-05T18:48:36.494182: step 16529, loss 0.0191974, acc 1
2016-09-05T18:48:36.697020: step 16530, loss 0.0194036, acc 1
2016-09-05T18:48:36.895319: step 16531, loss 0.0196117, acc 1
2016-09-05T18:48:37.097979: step 16532, loss 0.0197703, acc 1
2016-09-05T18:48:37.300642: step 16533, loss 0.0199383, acc 1
2016-09-05T18:48:37.526610: step 16534, loss 0.020062, acc 1
2016-09-05T18:48:37.752168: step 16535, loss 0.0201788, acc 1
2016-09-05T18:48:37.986219: step 16536, loss 0.0203714, acc 1
2016-09-05T18:48:38.195764: step 16537, loss 0.0203537, acc 1
2016-09-05T18:48:38.410592: step 16538, loss 0.142358, acc 0.98
2016-09-05T18:48:38.626218: step 16539, loss 0.26803, acc 0.96
2016-09-05T18:48:38.846084: step 16540, loss 0.0203479, acc 1
2016-09-05T18:48:39.066848: step 16541, loss 0.0204941, acc 1
2016-09-05T18:48:39.285394: step 16542, loss 0.0207699, acc 1
2016-09-05T18:48:39.507121: step 16543, loss 0.0211317, acc 1
2016-09-05T18:48:39.721483: step 16544, loss 0.0215471, acc 1
2016-09-05T18:48:39.932133: step 16545, loss 0.0219906, acc 1
2016-09-05T18:48:40.137215: step 16546, loss 0.0224431, acc 1
2016-09-05T18:48:40.341636: step 16547, loss 0.0228902, acc 1
2016-09-05T18:48:40.541181: step 16548, loss 0.0233219, acc 1
2016-09-05T18:48:40.750758: step 16549, loss 0.0237306, acc 1
2016-09-05T18:48:40.956561: step 16550, loss 0.0241116, acc 1
2016-09-05T18:48:41.155868: step 16551, loss 0.0244619, acc 1
2016-09-05T18:48:41.353050: step 16552, loss 0.0247793, acc 1
2016-09-05T18:48:41.580491: step 16553, loss 0.0250651, acc 1
2016-09-05T18:48:41.784237: step 16554, loss 0.0326347, acc 1
2016-09-05T18:48:42.014114: step 16555, loss 0.0257555, acc 1
2016-09-05T18:48:42.238023: step 16556, loss 0.135566, acc 0.98
2016-09-05T18:48:42.452410: step 16557, loss 0.0258575, acc 1
2016-09-05T18:48:42.657331: step 16558, loss 0.02591, acc 1
2016-09-05T18:48:42.898020: step 16559, loss 0.0301535, acc 1
2016-09-05T18:48:43.135011: step 16560, loss 0.0261586, acc 1
2016-09-05T18:48:43.352268: step 16561, loss 0.0262907, acc 1
2016-09-05T18:48:43.566488: step 16562, loss 0.0264182, acc 1
2016-09-05T18:48:43.764434: step 16563, loss 0.0265383, acc 1
2016-09-05T18:48:43.979099: step 16564, loss 0.0266472, acc 1
2016-09-05T18:48:44.195914: step 16565, loss 0.0267427, acc 1
2016-09-05T18:48:44.405113: step 16566, loss 0.0268235, acc 1
2016-09-05T18:48:44.641422: step 16567, loss 0.026889, acc 1
2016-09-05T18:48:44.867109: step 16568, loss 0.0269389, acc 1
2016-09-05T18:48:45.066121: step 16569, loss 0.0272862, acc 1
2016-09-05T18:48:45.288504: step 16570, loss 0.026993, acc 1
2016-09-05T18:48:45.500771: step 16571, loss 0.0269983, acc 1
2016-09-05T18:48:45.730656: step 16572, loss 0.0269901, acc 1
2016-09-05T18:48:45.963331: step 16573, loss 0.0269691, acc 1
2016-09-05T18:48:46.177563: step 16574, loss 0.0269361, acc 1
2016-09-05T18:48:46.383828: step 16575, loss 0.0268919, acc 1
2016-09-05T18:48:46.590714: step 16576, loss 0.0268373, acc 1
2016-09-05T18:48:46.804876: step 16577, loss 0.0267735, acc 1
2016-09-05T18:48:47.045058: step 16578, loss 0.0267004, acc 1
2016-09-05T18:48:47.278362: step 16579, loss 0.0266196, acc 1
2016-09-05T18:48:47.490559: step 16580, loss 0.0265319, acc 1
2016-09-05T18:48:47.711655: step 16581, loss 0.0264369, acc 1
2016-09-05T18:48:47.914939: step 16582, loss 0.026337, acc 1
2016-09-05T18:48:48.128469: step 16583, loss 0.0262305, acc 1
2016-09-05T18:48:48.350071: step 16584, loss 0.0261198, acc 1
2016-09-05T18:48:48.596508: step 16585, loss 0.0260048, acc 1
2016-09-05T18:48:48.806842: step 16586, loss 0.0258861, acc 1
2016-09-05T18:48:49.013590: step 16587, loss 0.025764, acc 1
2016-09-05T18:48:49.232824: step 16588, loss 0.025639, acc 1
2016-09-05T18:48:49.457089: step 16589, loss 0.0255113, acc 1
2016-09-05T18:48:49.679787: step 16590, loss 0.0253814, acc 1
2016-09-05T18:48:49.866864: step 16591, loss 0.0252496, acc 1
2016-09-05T18:48:50.098664: step 16592, loss 0.0252972, acc 1
2016-09-05T18:48:50.305297: step 16593, loss 0.0272589, acc 1
2016-09-05T18:48:50.517476: step 16594, loss 0.0248468, acc 1
2016-09-05T18:48:50.747763: step 16595, loss 0.024711, acc 1
2016-09-05T18:48:50.985439: step 16596, loss 0.0245746, acc 1
2016-09-05T18:48:51.223227: step 16597, loss 0.0244373, acc 1
2016-09-05T18:48:51.420879: step 16598, loss 0.0242989, acc 1
2016-09-05T18:48:51.635656: step 16599, loss 0.0241603, acc 1
2016-09-05T18:48:51.837861: step 16600, loss 0.0240215, acc 1

Evaluation:
2016-09-05T18:48:52.442837: step 16600, loss 8.46881, acc 0.721

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-16600

2016-09-05T18:48:53.151711: step 16601, loss 0.0238824, acc 1
2016-09-05T18:48:53.372558: step 16602, loss 0.023814, acc 1
2016-09-05T18:48:53.596012: step 16603, loss 0.0236041, acc 1
2016-09-05T18:48:53.826568: step 16604, loss 0.0234651, acc 1
2016-09-05T18:48:54.025934: step 16605, loss 0.0234249, acc 1
2016-09-05T18:48:54.255472: step 16606, loss 0.0231877, acc 1
2016-09-05T18:48:54.474840: step 16607, loss 0.0230495, acc 1
2016-09-05T18:48:54.743486: step 16608, loss 0.0229118, acc 1
2016-09-05T18:48:54.949278: step 16609, loss 0.022774, acc 1
2016-09-05T18:48:55.168264: step 16610, loss 0.0226369, acc 1
2016-09-05T18:48:55.384924: step 16611, loss 0.0225002, acc 1
2016-09-05T18:48:55.605851: step 16612, loss 0.022364, acc 1
2016-09-05T18:48:55.848946: step 16613, loss 0.0222283, acc 1
2016-09-05T18:48:56.063403: step 16614, loss 0.0220932, acc 1
2016-09-05T18:48:56.282565: step 16615, loss 0.0220679, acc 1
2016-09-05T18:48:56.498659: step 16616, loss 0.0218249, acc 1
2016-09-05T18:48:56.725878: step 16617, loss 0.0216917, acc 1
2016-09-05T18:48:56.937387: step 16618, loss 0.0215596, acc 1
2016-09-05T18:48:57.163485: step 16619, loss 0.0214273, acc 1
2016-09-05T18:48:57.367592: step 16620, loss 0.0212961, acc 1
2016-09-05T18:48:57.593581: step 16621, loss 0.0211655, acc 1
2016-09-05T18:48:57.805963: step 16622, loss 0.0210368, acc 1
2016-09-05T18:48:58.039754: step 16623, loss 0.0209064, acc 1
2016-09-05T18:48:58.291998: step 16624, loss 0.0207779, acc 1
2016-09-05T18:48:58.516366: step 16625, loss 0.0206501, acc 1
2016-09-05T18:48:58.721567: step 16626, loss 0.020523, acc 1
2016-09-05T18:48:58.914607: step 16627, loss 0.0203966, acc 1
2016-09-05T18:48:59.133555: step 16628, loss 0.0203469, acc 1
2016-09-05T18:48:59.348258: step 16629, loss 0.0201461, acc 1
2016-09-05T18:48:59.578019: step 16630, loss 0.020022, acc 1
2016-09-05T18:48:59.777470: step 16631, loss 0.0198986, acc 1
2016-09-05T18:49:00.015617: step 16632, loss 0.0197759, acc 1
2016-09-05T18:49:00.233379: step 16633, loss 0.019654, acc 1
2016-09-05T18:49:00.432002: step 16634, loss 0.0195327, acc 1
2016-09-05T18:49:00.630959: step 16635, loss 0.0194121, acc 1
2016-09-05T18:49:00.859842: step 16636, loss 0.0192927, acc 1
2016-09-05T18:49:01.085232: step 16637, loss 0.0191732, acc 1
2016-09-05T18:49:01.328482: step 16638, loss 0.0190548, acc 1
2016-09-05T18:49:01.539458: step 16639, loss 0.0189371, acc 1
2016-09-05T18:49:01.750627: step 16640, loss 0.0188201, acc 1
2016-09-05T18:49:01.962656: step 16641, loss 0.0187038, acc 1
2016-09-05T18:49:02.192110: step 16642, loss 0.0185882, acc 1
2016-09-05T18:49:02.431341: step 16643, loss 0.0184733, acc 1
2016-09-05T18:49:02.656169: step 16644, loss 0.0183591, acc 1
2016-09-05T18:49:02.880618: step 16645, loss 0.0182456, acc 1
2016-09-05T18:49:03.097908: step 16646, loss 0.018145, acc 1
2016-09-05T18:49:03.306515: step 16647, loss 0.0180207, acc 1
2016-09-05T18:49:03.546020: step 16648, loss 0.0179093, acc 1
2016-09-05T18:49:03.757318: step 16649, loss 0.0177986, acc 1
2016-09-05T18:49:03.970636: step 16650, loss 0.0176886, acc 1
2016-09-05T18:49:04.186883: step 16651, loss 0.0176338, acc 1
2016-09-05T18:49:04.410584: step 16652, loss 0.0174706, acc 1
2016-09-05T18:49:04.623384: step 16653, loss 0.0173627, acc 1
2016-09-05T18:49:04.857893: step 16654, loss 0.0172554, acc 1
2016-09-05T18:49:05.054507: step 16655, loss 0.0171491, acc 1
2016-09-05T18:49:05.274675: step 16656, loss 0.0221776, acc 1
2016-09-05T18:49:05.478110: step 16657, loss 0.0169394, acc 1
2016-09-05T18:49:05.738762: step 16658, loss 0.0168364, acc 1
2016-09-05T18:49:05.982461: step 16659, loss 0.016734, acc 1
2016-09-05T18:49:06.186336: step 16660, loss 0.016632, acc 1
2016-09-05T18:49:06.396236: step 16661, loss 0.0165304, acc 1
2016-09-05T18:49:06.605877: step 16662, loss 0.0164294, acc 1
2016-09-05T18:49:06.842794: step 16663, loss 0.0174458, acc 1
2016-09-05T18:49:07.074215: step 16664, loss 0.0162299, acc 1
2016-09-05T18:49:07.293554: step 16665, loss 0.0161312, acc 1
2016-09-05T18:49:07.490650: step 16666, loss 0.016033, acc 1
2016-09-05T18:49:07.710543: step 16667, loss 0.0159412, acc 1
2016-09-05T18:49:07.924517: step 16668, loss 0.015838, acc 1
2016-09-05T18:49:08.160044: step 16669, loss 0.0157413, acc 1
2016-09-05T18:49:08.371127: step 16670, loss 0.015645, acc 1
2016-09-05T18:49:08.573065: step 16671, loss 0.01555, acc 1
2016-09-05T18:49:08.788319: step 16672, loss 0.0154538, acc 1
2016-09-05T18:49:08.992896: step 16673, loss 0.015359, acc 1
2016-09-05T18:49:09.201279: step 16674, loss 0.0152647, acc 1
2016-09-05T18:49:09.416197: step 16675, loss 0.0151709, acc 1
2016-09-05T18:49:09.658224: step 16676, loss 0.0150776, acc 1
2016-09-05T18:49:09.916983: step 16677, loss 0.0149849, acc 1
2016-09-05T18:49:10.123986: step 16678, loss 0.0148927, acc 1
2016-09-05T18:49:10.336233: step 16679, loss 0.014801, acc 1
2016-09-05T18:49:10.549859: step 16680, loss 0.014711, acc 1
2016-09-05T18:49:10.764465: step 16681, loss 0.0146191, acc 1
2016-09-05T18:49:11.000286: step 16682, loss 0.014529, acc 1
2016-09-05T18:49:11.234607: step 16683, loss 0.0144394, acc 1
2016-09-05T18:49:11.389755: step 16684, loss 0.0143504, acc 1
2016-09-05T18:49:11.615565: step 16685, loss 0.0142618, acc 1
2016-09-05T18:49:11.811478: step 16686, loss 0.0141738, acc 1
2016-09-05T18:49:12.016044: step 16687, loss 0.0140935, acc 1
2016-09-05T18:49:12.213750: step 16688, loss 0.0139994, acc 1
2016-09-05T18:49:12.418676: step 16689, loss 0.013913, acc 1
2016-09-05T18:49:12.631968: step 16690, loss 0.0138427, acc 1
2016-09-05T18:49:12.840493: step 16691, loss 0.0137421, acc 1
2016-09-05T18:49:13.050200: step 16692, loss 0.0136569, acc 1
2016-09-05T18:49:13.275452: step 16693, loss 0.0135725, acc 1
2016-09-05T18:49:13.494470: step 16694, loss 0.0134887, acc 1
2016-09-05T18:49:13.707902: step 16695, loss 0.0134066, acc 1
2016-09-05T18:49:13.940751: step 16696, loss 0.0133226, acc 1
2016-09-05T18:49:14.151990: step 16697, loss 0.0132403, acc 1
2016-09-05T18:49:14.355281: step 16698, loss 0.0131585, acc 1
2016-09-05T18:49:14.601546: step 16699, loss 0.0131185, acc 1
2016-09-05T18:49:14.841555: step 16700, loss 0.0130966, acc 1

Evaluation:
2016-09-05T18:49:15.424659: step 16700, loss 6.24322, acc 0.722

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-16700

2016-09-05T18:49:16.151562: step 16701, loss 0.0129165, acc 1
2016-09-05T18:49:16.356234: step 16702, loss 0.0128369, acc 1
2016-09-05T18:49:16.573705: step 16703, loss 0.0127584, acc 1
2016-09-05T18:49:16.777764: step 16704, loss 0.0126792, acc 1
2016-09-05T18:49:16.979988: step 16705, loss 0.012601, acc 1
2016-09-05T18:49:17.178956: step 16706, loss 0.0125233, acc 1
2016-09-05T18:49:17.382709: step 16707, loss 0.0134427, acc 1
2016-09-05T18:49:17.608365: step 16708, loss 0.0123702, acc 1
2016-09-05T18:49:17.826953: step 16709, loss 0.0122947, acc 1
2016-09-05T18:49:18.053644: step 16710, loss 0.0122196, acc 1
2016-09-05T18:49:18.271908: step 16711, loss 0.0121449, acc 1
2016-09-05T18:49:18.478021: step 16712, loss 0.0120705, acc 1
2016-09-05T18:49:18.677846: step 16713, loss 0.0119965, acc 1
2016-09-05T18:49:18.879828: step 16714, loss 0.0129621, acc 1
2016-09-05T18:49:19.087433: step 16715, loss 0.0118508, acc 1
2016-09-05T18:49:19.309909: step 16716, loss 0.0117788, acc 1
2016-09-05T18:49:19.538691: step 16717, loss 0.0117071, acc 1
2016-09-05T18:49:19.765754: step 16718, loss 0.0116358, acc 1
2016-09-05T18:49:19.985369: step 16719, loss 0.0115648, acc 1
2016-09-05T18:49:20.210569: step 16720, loss 0.0114942, acc 1
2016-09-05T18:49:20.414145: step 16721, loss 0.0114239, acc 1
2016-09-05T18:49:20.621574: step 16722, loss 0.011354, acc 1
2016-09-05T18:49:20.832199: step 16723, loss 0.0112844, acc 1
2016-09-05T18:49:21.041295: step 16724, loss 0.0112152, acc 1
2016-09-05T18:49:21.258009: step 16725, loss 0.0111464, acc 1
2016-09-05T18:49:21.455715: step 16726, loss 0.011078, acc 1
2016-09-05T18:49:21.669207: step 16727, loss 0.0110098, acc 1
2016-09-05T18:49:21.863917: step 16728, loss 0.0109421, acc 1
2016-09-05T18:49:22.064474: step 16729, loss 0.0108748, acc 1
2016-09-05T18:49:22.283722: step 16730, loss 0.0108078, acc 1
2016-09-05T18:49:22.525539: step 16731, loss 0.0107414, acc 1
2016-09-05T18:49:22.724395: step 16732, loss 0.0106751, acc 1
2016-09-05T18:49:22.937347: step 16733, loss 0.0106093, acc 1
2016-09-05T18:49:23.153071: step 16734, loss 0.0114395, acc 1
2016-09-05T18:49:23.356610: step 16735, loss 0.0104796, acc 1
2016-09-05T18:49:23.559105: step 16736, loss 0.0104157, acc 1
2016-09-05T18:49:23.793555: step 16737, loss 0.0103602, acc 1
2016-09-05T18:49:23.998199: step 16738, loss 0.0102911, acc 1
2016-09-05T18:49:24.251221: step 16739, loss 0.0102258, acc 1
2016-09-05T18:49:24.455875: step 16740, loss 0.0101648, acc 1
2016-09-05T18:49:24.670029: step 16741, loss 0.0101009, acc 1
2016-09-05T18:49:24.873916: step 16742, loss 0.0100458, acc 1
2016-09-05T18:49:25.109482: step 16743, loss 0.00997728, acc 1
2016-09-05T18:49:25.339298: step 16744, loss 0.00991599, acc 1
2016-09-05T18:49:25.538736: step 16745, loss 0.00985564, acc 1
2016-09-05T18:49:25.748299: step 16746, loss 0.00980875, acc 1
2016-09-05T18:49:25.966768: step 16747, loss 0.00973418, acc 1
2016-09-05T18:49:26.184087: step 16748, loss 0.00968196, acc 1
2016-09-05T18:49:26.388900: step 16749, loss 0.00997566, acc 1
2016-09-05T18:49:26.604763: step 16750, loss 0.00955608, acc 1
2016-09-05T18:49:26.825751: step 16751, loss 0.00949757, acc 1
2016-09-05T18:49:27.037386: step 16752, loss 0.00943944, acc 1
2016-09-05T18:49:27.253370: step 16753, loss 0.00938158, acc 1
2016-09-05T18:49:27.481318: step 16754, loss 0.00932403, acc 1
2016-09-05T18:49:27.689510: step 16755, loss 0.0092668, acc 1
2016-09-05T18:49:27.925017: step 16756, loss 0.00920994, acc 1
2016-09-05T18:49:28.160243: step 16757, loss 0.00915325, acc 1
2016-09-05T18:49:28.388617: step 16758, loss 0.00909695, acc 1
2016-09-05T18:49:28.599319: step 16759, loss 0.00904095, acc 1
2016-09-05T18:49:28.810191: step 16760, loss 0.00899528, acc 1
2016-09-05T18:49:29.043973: step 16761, loss 0.0089816, acc 1
2016-09-05T18:49:29.254114: step 16762, loss 0.00887524, acc 1
2016-09-05T18:49:29.481445: step 16763, loss 0.00884784, acc 1
2016-09-05T18:49:29.699060: step 16764, loss 0.00877015, acc 1
2016-09-05T18:49:29.920501: step 16765, loss 0.00871227, acc 1
2016-09-05T18:49:30.131349: step 16766, loss 0.00894476, acc 1
2016-09-05T18:49:30.381400: step 16767, loss 0.00860572, acc 1
2016-09-05T18:49:30.589376: step 16768, loss 0.00855305, acc 1
2016-09-05T18:49:30.801014: step 16769, loss 0.00850064, acc 1
2016-09-05T18:49:31.021310: step 16770, loss 0.0084487, acc 1
2016-09-05T18:49:31.236477: step 16771, loss 0.00839666, acc 1
2016-09-05T18:49:31.457825: step 16772, loss 0.00834508, acc 1
2016-09-05T18:49:31.688464: step 16773, loss 0.00829378, acc 1
2016-09-05T18:49:31.897410: step 16774, loss 0.00824276, acc 1
2016-09-05T18:49:32.104029: step 16775, loss 0.00819203, acc 1
2016-09-05T18:49:32.308428: step 16776, loss 0.00821424, acc 1
2016-09-05T18:49:32.512350: step 16777, loss 0.00809261, acc 1
2016-09-05T18:49:32.729493: step 16778, loss 0.0080418, acc 1
2016-09-05T18:49:32.944784: step 16779, loss 0.00799229, acc 1
2016-09-05T18:49:33.156275: step 16780, loss 0.0079431, acc 1
2016-09-05T18:49:33.361794: step 16781, loss 0.00789512, acc 1
2016-09-05T18:49:33.586241: step 16782, loss 0.00784549, acc 1
2016-09-05T18:49:33.815606: step 16783, loss 0.00779719, acc 1
2016-09-05T18:49:34.017428: step 16784, loss 0.00774903, acc 1
2016-09-05T18:49:34.227879: step 16785, loss 0.00770121, acc 1
2016-09-05T18:49:34.438686: step 16786, loss 0.00765392, acc 1
2016-09-05T18:49:34.649559: step 16787, loss 0.00760641, acc 1
2016-09-05T18:49:34.849496: step 16788, loss 0.00755946, acc 1
2016-09-05T18:49:35.055832: step 16789, loss 0.00751273, acc 1
2016-09-05T18:49:35.250754: step 16790, loss 0.00746654, acc 1
2016-09-05T18:49:35.461356: step 16791, loss 0.00742074, acc 1
2016-09-05T18:49:35.689040: step 16792, loss 0.0073743, acc 1
2016-09-05T18:49:35.937282: step 16793, loss 0.00732871, acc 1
2016-09-05T18:49:36.150734: step 16794, loss 0.00728357, acc 1
2016-09-05T18:49:36.368939: step 16795, loss 0.00723834, acc 1
2016-09-05T18:49:36.572247: step 16796, loss 0.00719356, acc 1
2016-09-05T18:49:36.773070: step 16797, loss 0.00714906, acc 1
2016-09-05T18:49:36.965139: step 16798, loss 0.00710484, acc 1
2016-09-05T18:49:37.176869: step 16799, loss 0.0070609, acc 1
2016-09-05T18:49:37.403816: step 16800, loss 0.00701718, acc 1

Evaluation:
2016-09-05T18:49:38.009164: step 16800, loss 4.5852, acc 0.722

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-16800

2016-09-05T18:49:38.788618: step 16801, loss 0.00697384, acc 1
2016-09-05T18:49:38.982769: step 16802, loss 0.0069307, acc 1
2016-09-05T18:49:39.186698: step 16803, loss 0.00702618, acc 1
2016-09-05T18:49:39.396076: step 16804, loss 0.00684534, acc 1
2016-09-05T18:49:39.619451: step 16805, loss 0.00680308, acc 1
2016-09-05T18:49:39.830081: step 16806, loss 0.00676114, acc 1
2016-09-05T18:49:40.064944: step 16807, loss 0.00671941, acc 1
2016-09-05T18:49:40.275257: step 16808, loss 0.00671459, acc 1
2016-09-05T18:49:40.493388: step 16809, loss 0.00663901, acc 1
2016-09-05T18:49:40.708207: step 16810, loss 0.00659588, acc 1
2016-09-05T18:49:40.908633: step 16811, loss 0.00655585, acc 1
2016-09-05T18:49:41.125294: step 16812, loss 0.00651477, acc 1
2016-09-05T18:49:41.339764: step 16813, loss 0.00647455, acc 1
2016-09-05T18:49:41.539839: step 16814, loss 0.00643473, acc 1
2016-09-05T18:49:41.747211: step 16815, loss 0.00639488, acc 1
2016-09-05T18:49:41.962078: step 16816, loss 0.00640059, acc 1
2016-09-05T18:49:42.182817: step 16817, loss 0.0063536, acc 1
2016-09-05T18:49:42.393116: step 16818, loss 0.0062772, acc 1
2016-09-05T18:49:42.609419: step 16819, loss 0.00623855, acc 1
2016-09-05T18:49:42.810741: step 16820, loss 0.00620014, acc 1
2016-09-05T18:49:43.016204: step 16821, loss 0.00616206, acc 1
2016-09-05T18:49:43.236193: step 16822, loss 0.00612388, acc 1
2016-09-05T18:49:43.432028: step 16823, loss 0.00608738, acc 1
2016-09-05T18:49:43.636903: step 16824, loss 0.00604852, acc 1
2016-09-05T18:49:43.835584: step 16825, loss 0.00601114, acc 1
2016-09-05T18:49:44.028329: step 16826, loss 0.00597391, acc 1
2016-09-05T18:49:44.226310: step 16827, loss 0.00593698, acc 1
2016-09-05T18:49:44.439105: step 16828, loss 0.00624022, acc 1
2016-09-05T18:49:44.646606: step 16829, loss 0.00605388, acc 1
2016-09-05T18:49:44.870223: step 16830, loss 0.00583125, acc 1
2016-09-05T18:49:45.081178: step 16831, loss 0.00650275, acc 1
2016-09-05T18:49:45.311682: step 16832, loss 0.00576005, acc 1
2016-09-05T18:49:45.560501: step 16833, loss 0.00574132, acc 1
2016-09-05T18:49:45.752505: step 16834, loss 0.00569229, acc 1
2016-09-05T18:49:45.962377: step 16835, loss 0.00565691, acc 1
2016-09-05T18:49:46.188804: step 16836, loss 0.00564476, acc 1
2016-09-05T18:49:46.393973: step 16837, loss 0.00558909, acc 1
2016-09-05T18:49:46.603597: step 16838, loss 0.00555555, acc 1
2016-09-05T18:49:46.839593: step 16839, loss 0.00552176, acc 1
2016-09-05T18:49:47.041539: step 16840, loss 0.0054885, acc 1
2016-09-05T18:49:47.265475: step 16841, loss 0.00545535, acc 1
2016-09-05T18:49:47.469951: step 16842, loss 0.0054217, acc 1
2016-09-05T18:49:47.676139: step 16843, loss 0.00542182, acc 1
2016-09-05T18:49:47.883074: step 16844, loss 0.00535576, acc 1
2016-09-05T18:49:48.116444: step 16845, loss 0.00545353, acc 1
2016-09-05T18:49:48.331914: step 16846, loss 0.0052977, acc 1
2016-09-05T18:49:48.562311: step 16847, loss 0.00525887, acc 1
2016-09-05T18:49:48.774685: step 16848, loss 0.0101818, acc 1
2016-09-05T18:49:48.974352: step 16849, loss 0.00519665, acc 1
2016-09-05T18:49:49.186096: step 16850, loss 0.00516707, acc 1
2016-09-05T18:49:49.377236: step 16851, loss 0.00514778, acc 1
2016-09-05T18:49:49.573396: step 16852, loss 0.00578505, acc 1
2016-09-05T18:49:49.774616: step 16853, loss 0.00518804, acc 1
2016-09-05T18:49:49.990567: step 16854, loss 0.00505675, acc 1
2016-09-05T18:49:50.194500: step 16855, loss 0.00505199, acc 1
2016-09-05T18:49:50.401226: step 16856, loss 0.0049949, acc 1
2016-09-05T18:49:50.614140: step 16857, loss 0.00496558, acc 1
2016-09-05T18:49:50.836473: step 16858, loss 0.00493724, acc 1
2016-09-05T18:49:51.050830: step 16859, loss 0.00491084, acc 1
2016-09-05T18:49:51.246592: step 16860, loss 0.00488168, acc 1
2016-09-05T18:49:51.455418: step 16861, loss 0.00485192, acc 1
2016-09-05T18:49:51.686934: step 16862, loss 0.00482343, acc 1
2016-09-05T18:49:51.900175: step 16863, loss 0.00479598, acc 1
2016-09-05T18:49:52.131308: step 16864, loss 0.00476653, acc 1
2016-09-05T18:49:52.343706: step 16865, loss 0.0047457, acc 1
2016-09-05T18:49:52.557741: step 16866, loss 0.00505813, acc 1
2016-09-05T18:49:52.782893: step 16867, loss 0.00468195, acc 1
2016-09-05T18:49:53.002343: step 16868, loss 0.00465827, acc 1
2016-09-05T18:49:53.227281: step 16869, loss 0.0046264, acc 1
2016-09-05T18:49:53.450232: step 16870, loss 0.00459846, acc 1
2016-09-05T18:49:53.673657: step 16871, loss 0.00457075, acc 1
2016-09-05T18:49:53.912489: step 16872, loss 0.00454323, acc 1
2016-09-05T18:49:54.138322: step 16873, loss 0.00451555, acc 1
2016-09-05T18:49:54.344654: step 16874, loss 0.00448961, acc 1
2016-09-05T18:49:54.545546: step 16875, loss 0.00446082, acc 1
2016-09-05T18:49:54.761962: step 16876, loss 0.00443467, acc 1
2016-09-05T18:49:54.981613: step 16877, loss 0.00445658, acc 1
2016-09-05T18:49:55.160718: step 16878, loss 0.0043792, acc 1
2016-09-05T18:49:55.378737: step 16879, loss 0.00435243, acc 1
2016-09-05T18:49:55.603824: step 16880, loss 0.00432594, acc 1
2016-09-05T18:49:55.805340: step 16881, loss 0.00429928, acc 1
2016-09-05T18:49:56.048192: step 16882, loss 0.00427881, acc 1
2016-09-05T18:49:56.262884: step 16883, loss 0.00424637, acc 1
2016-09-05T18:49:56.475236: step 16884, loss 0.00421986, acc 1
2016-09-05T18:49:56.682663: step 16885, loss 0.00419417, acc 1
2016-09-05T18:49:56.909526: step 16886, loss 0.00416779, acc 1
2016-09-05T18:49:57.127744: step 16887, loss 0.00414202, acc 1
2016-09-05T18:49:57.370729: step 16888, loss 0.00411756, acc 1
2016-09-05T18:49:57.577084: step 16889, loss 0.00409074, acc 1
2016-09-05T18:49:57.814858: step 16890, loss 0.00407044, acc 1
2016-09-05T18:49:58.071374: step 16891, loss 0.0040431, acc 1
2016-09-05T18:49:58.278116: step 16892, loss 0.00401807, acc 1
2016-09-05T18:49:58.492968: step 16893, loss 0.00416072, acc 1
2016-09-05T18:49:58.702429: step 16894, loss 0.00396539, acc 1
2016-09-05T18:49:58.924285: step 16895, loss 0.00394266, acc 1
2016-09-05T18:49:59.159726: step 16896, loss 0.00392138, acc 1
2016-09-05T18:49:59.373552: step 16897, loss 0.00389288, acc 1
2016-09-05T18:49:59.563294: step 16898, loss 0.00387972, acc 1
2016-09-05T18:49:59.770607: step 16899, loss 0.00413095, acc 1
2016-09-05T18:49:59.987547: step 16900, loss 0.00392148, acc 1

Evaluation:
2016-09-05T18:50:00.588887: step 16900, loss 3.38704, acc 0.72

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-16900

2016-09-05T18:50:01.316563: step 16901, loss 0.00383225, acc 1
2016-09-05T18:50:01.532931: step 16902, loss 0.0038185, acc 1
2016-09-05T18:50:01.752279: step 16903, loss 0.00375353, acc 1
2016-09-05T18:50:01.967585: step 16904, loss 0.00375639, acc 1
2016-09-05T18:50:02.203923: step 16905, loss 0.00371013, acc 1
2016-09-05T18:50:02.433091: step 16906, loss 0.00368567, acc 1
2016-09-05T18:50:02.652625: step 16907, loss 0.0036623, acc 1
2016-09-05T18:50:02.852997: step 16908, loss 0.00364247, acc 1
2016-09-05T18:50:03.078938: step 16909, loss 0.0036186, acc 1
2016-09-05T18:50:03.333349: step 16910, loss 0.00359549, acc 1
2016-09-05T18:50:03.528342: step 16911, loss 0.00357423, acc 1
2016-09-05T18:50:03.733117: step 16912, loss 0.00355144, acc 1
2016-09-05T18:50:03.996947: step 16913, loss 0.00353142, acc 1
2016-09-05T18:50:04.236178: step 16914, loss 0.00355614, acc 1
2016-09-05T18:50:04.438613: step 16915, loss 0.00349425, acc 1
2016-09-05T18:50:04.650063: step 16916, loss 0.00385452, acc 1
2016-09-05T18:50:04.867457: step 16917, loss 0.00344437, acc 1
2016-09-05T18:50:05.086289: step 16918, loss 0.00342567, acc 1
2016-09-05T18:50:05.293330: step 16919, loss 0.00340221, acc 1
2016-09-05T18:50:05.505136: step 16920, loss 0.00338258, acc 1
2016-09-05T18:50:05.700805: step 16921, loss 0.00336223, acc 1
2016-09-05T18:50:05.912715: step 16922, loss 0.00335242, acc 1
2016-09-05T18:50:06.144053: step 16923, loss 0.00332038, acc 1
2016-09-05T18:50:06.366281: step 16924, loss 0.00330057, acc 1
2016-09-05T18:50:06.570153: step 16925, loss 0.00328021, acc 1
2016-09-05T18:50:06.788693: step 16926, loss 0.00326866, acc 1
2016-09-05T18:50:06.997046: step 16927, loss 0.0032407, acc 1
2016-09-05T18:50:07.206567: step 16928, loss 0.00450566, acc 1
2016-09-05T18:50:07.431573: step 16929, loss 0.00323254, acc 1
2016-09-05T18:50:07.624361: step 16930, loss 0.00351803, acc 1
2016-09-05T18:50:07.835117: step 16931, loss 0.00316463, acc 1
2016-09-05T18:50:08.043102: step 16932, loss 0.00315531, acc 1
2016-09-05T18:50:08.251095: step 16933, loss 0.00348699, acc 1
2016-09-05T18:50:08.463754: step 16934, loss 0.00312696, acc 1
2016-09-05T18:50:08.672018: step 16935, loss 0.00321321, acc 1
2016-09-05T18:50:08.868550: step 16936, loss 0.00309905, acc 1
2016-09-05T18:50:09.072904: step 16937, loss 0.00308678, acc 1
2016-09-05T18:50:09.290113: step 16938, loss 0.00304208, acc 1
2016-09-05T18:50:09.502675: step 16939, loss 0.00302367, acc 1
2016-09-05T18:50:09.709726: step 16940, loss 0.00300632, acc 1
2016-09-05T18:50:09.951543: step 16941, loss 0.00301505, acc 1
2016-09-05T18:50:10.169382: step 16942, loss 0.00298881, acc 1
2016-09-05T18:50:10.380898: step 16943, loss 0.00296763, acc 1
2016-09-05T18:50:10.579318: step 16944, loss 0.00295105, acc 1
2016-09-05T18:50:10.783808: step 16945, loss 0.00291915, acc 1
2016-09-05T18:50:10.985417: step 16946, loss 0.00291812, acc 1
2016-09-05T18:50:11.188628: step 16947, loss 0.002925, acc 1
2016-09-05T18:50:11.390842: step 16948, loss 0.00286599, acc 1
2016-09-05T18:50:11.580865: step 16949, loss 0.00330305, acc 1
2016-09-05T18:50:11.786771: step 16950, loss 0.00283586, acc 1
2016-09-05T18:50:11.986233: step 16951, loss 0.00420479, acc 1
2016-09-05T18:50:12.208325: step 16952, loss 0.00280027, acc 1
2016-09-05T18:50:12.408164: step 16953, loss 0.00281096, acc 1
2016-09-05T18:50:12.612419: step 16954, loss 0.00281422, acc 1
2016-09-05T18:50:12.829387: step 16955, loss 0.00315076, acc 1
2016-09-05T18:50:13.041379: step 16956, loss 0.0027406, acc 1
2016-09-05T18:50:13.267547: step 16957, loss 0.00282512, acc 1
2016-09-05T18:50:13.502665: step 16958, loss 0.0027293, acc 1
2016-09-05T18:50:13.708816: step 16959, loss 0.00353768, acc 1
2016-09-05T18:50:13.907850: step 16960, loss 0.00269876, acc 1
2016-09-05T18:50:14.110901: step 16961, loss 0.00266601, acc 1
2016-09-05T18:50:14.320618: step 16962, loss 0.00284233, acc 1
2016-09-05T18:50:14.561460: step 16963, loss 0.00267312, acc 1
2016-09-05T18:50:14.792328: step 16964, loss 0.0026299, acc 1
2016-09-05T18:50:14.998512: step 16965, loss 0.00262438, acc 1
2016-09-05T18:50:15.231519: step 16966, loss 0.00259449, acc 1
2016-09-05T18:50:15.441999: step 16967, loss 0.00257991, acc 1
2016-09-05T18:50:15.648821: step 16968, loss 0.00263707, acc 1
2016-09-05T18:50:15.889561: step 16969, loss 0.00255208, acc 1
2016-09-05T18:50:16.152445: step 16970, loss 0.00253554, acc 1
2016-09-05T18:50:16.365904: step 16971, loss 0.00256688, acc 1
2016-09-05T18:50:16.569009: step 16972, loss 0.00260892, acc 1
2016-09-05T18:50:16.771813: step 16973, loss 0.00250587, acc 1
2016-09-05T18:50:16.998939: step 16974, loss 0.0026514, acc 1
2016-09-05T18:50:17.233382: step 16975, loss 0.00247975, acc 1
2016-09-05T18:50:17.439524: step 16976, loss 0.00319327, acc 1
2016-09-05T18:50:17.665363: step 16977, loss 0.00245336, acc 1
2016-09-05T18:50:17.872764: step 16978, loss 0.00242638, acc 1
2016-09-05T18:50:18.076707: step 16979, loss 0.00241189, acc 1
2016-09-05T18:50:18.296138: step 16980, loss 0.00240105, acc 1
2016-09-05T18:50:18.513208: step 16981, loss 0.00343752, acc 1
2016-09-05T18:50:18.736111: step 16982, loss 0.00236975, acc 1
2016-09-05T18:50:18.934549: step 16983, loss 0.00398349, acc 1
2016-09-05T18:50:19.144485: step 16984, loss 0.00234381, acc 1
2016-09-05T18:50:19.341439: step 16985, loss 0.00233803, acc 1
2016-09-05T18:50:19.559764: step 16986, loss 0.00232237, acc 1
2016-09-05T18:50:19.774567: step 16987, loss 0.00231058, acc 1
2016-09-05T18:50:20.000154: step 16988, loss 0.0022983, acc 1
2016-09-05T18:50:20.219627: step 16989, loss 0.00229575, acc 1
2016-09-05T18:50:20.441683: step 16990, loss 0.00227396, acc 1
2016-09-05T18:50:20.679687: step 16991, loss 0.00358774, acc 1
2016-09-05T18:50:20.902666: step 16992, loss 0.00225257, acc 1
2016-09-05T18:50:21.115377: step 16993, loss 0.00229059, acc 1
2016-09-05T18:50:21.356912: step 16994, loss 0.00222277, acc 1
2016-09-05T18:50:21.584163: step 16995, loss 0.00224392, acc 1
2016-09-05T18:50:21.801264: step 16996, loss 0.00222142, acc 1
2016-09-05T18:50:22.009301: step 16997, loss 0.00223086, acc 1
2016-09-05T18:50:22.206076: step 16998, loss 0.00218965, acc 1
2016-09-05T18:50:22.420605: step 16999, loss 0.00255715, acc 1
2016-09-05T18:50:22.629885: step 17000, loss 0.0021659, acc 1

Evaluation:
2016-09-05T18:50:23.240027: step 17000, loss 2.58414, acc 0.718

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-17000

2016-09-05T18:50:23.964060: step 17001, loss 0.00218237, acc 1
2016-09-05T18:50:24.178087: step 17002, loss 0.00216955, acc 1
2016-09-05T18:50:24.428581: step 17003, loss 0.00213066, acc 1
2016-09-05T18:50:24.635346: step 17004, loss 0.00215864, acc 1
2016-09-05T18:50:24.839562: step 17005, loss 0.00213343, acc 1
2016-09-05T18:50:25.043837: step 17006, loss 0.00261399, acc 1
2016-09-05T18:50:25.275497: step 17007, loss 0.00211323, acc 1
2016-09-05T18:50:25.490673: step 17008, loss 0.00208232, acc 1
2016-09-05T18:50:25.762021: step 17009, loss 0.00207124, acc 1
2016-09-05T18:50:25.964595: step 17010, loss 0.00206091, acc 1
2016-09-05T18:50:26.182944: step 17011, loss 0.00204518, acc 1
2016-09-05T18:50:26.397424: step 17012, loss 0.00202217, acc 1
2016-09-05T18:50:26.612392: step 17013, loss 0.0020335, acc 1
2016-09-05T18:50:26.823279: step 17014, loss 0.0111142, acc 1
2016-09-05T18:50:27.023335: step 17015, loss 0.00199591, acc 1
2016-09-05T18:50:27.246458: step 17016, loss 0.0023782, acc 1
2016-09-05T18:50:27.453890: step 17017, loss 0.00200393, acc 1
2016-09-05T18:50:27.661553: step 17018, loss 0.00205132, acc 1
2016-09-05T18:50:27.863463: step 17019, loss 0.00203544, acc 1
2016-09-05T18:50:28.081626: step 17020, loss 0.0019506, acc 1
2016-09-05T18:50:28.296346: step 17021, loss 0.0020678, acc 1
2016-09-05T18:50:28.518196: step 17022, loss 0.00195216, acc 1
2016-09-05T18:50:28.752623: step 17023, loss 0.00210119, acc 1
2016-09-05T18:50:28.971162: step 17024, loss 0.00198524, acc 1
2016-09-05T18:50:29.202885: step 17025, loss 0.00197009, acc 1
2016-09-05T18:50:29.446069: step 17026, loss 0.00195847, acc 1
2016-09-05T18:50:29.658193: step 17027, loss 0.0042256, acc 1
2016-09-05T18:50:29.869692: step 17028, loss 0.00203445, acc 1
2016-09-05T18:50:30.080889: step 17029, loss 0.00193045, acc 1
2016-09-05T18:50:30.297746: step 17030, loss 0.00303384, acc 1
2016-09-05T18:50:30.511317: step 17031, loss 0.00196755, acc 1
2016-09-05T18:50:30.712810: step 17032, loss 0.00199108, acc 1
2016-09-05T18:50:30.934131: step 17033, loss 0.00191125, acc 1
2016-09-05T18:50:31.146257: step 17034, loss 0.00203476, acc 1
2016-09-05T18:50:31.356565: step 17035, loss 0.00190704, acc 1
2016-09-05T18:50:31.615743: step 17036, loss 0.00189157, acc 1
2016-09-05T18:50:31.836839: step 17037, loss 0.00188553, acc 1
2016-09-05T18:50:32.067292: step 17038, loss 0.0018849, acc 1
2016-09-05T18:50:32.291793: step 17039, loss 0.00188416, acc 1
2016-09-05T18:50:32.494774: step 17040, loss 0.00186892, acc 1
2016-09-05T18:50:32.695902: step 17041, loss 0.00187754, acc 1
2016-09-05T18:50:32.921107: step 17042, loss 0.00185545, acc 1
2016-09-05T18:50:33.126804: step 17043, loss 0.00201472, acc 1
2016-09-05T18:50:33.346339: step 17044, loss 0.0018742, acc 1
2016-09-05T18:50:33.563934: step 17045, loss 0.00183494, acc 1
2016-09-05T18:50:33.809401: step 17046, loss 0.004576, acc 1
2016-09-05T18:50:34.016119: step 17047, loss 0.00183597, acc 1
2016-09-05T18:50:34.245804: step 17048, loss 0.00181225, acc 1
2016-09-05T18:50:34.457872: step 17049, loss 0.00180515, acc 1
2016-09-05T18:50:34.689873: step 17050, loss 0.00179622, acc 1
2016-09-05T18:50:34.909437: step 17051, loss 0.00183189, acc 1
2016-09-05T18:50:35.132423: step 17052, loss 0.00178894, acc 1
2016-09-05T18:50:35.344492: step 17053, loss 0.00188661, acc 1
2016-09-05T18:50:35.556865: step 17054, loss 0.00176433, acc 1
2016-09-05T18:50:35.773181: step 17055, loss 0.00176674, acc 1
2016-09-05T18:50:35.985026: step 17056, loss 0.00180943, acc 1
2016-09-05T18:50:36.213355: step 17057, loss 0.00173726, acc 1
2016-09-05T18:50:36.434458: step 17058, loss 0.00172625, acc 1
2016-09-05T18:50:36.661155: step 17059, loss 0.00188322, acc 1
2016-09-05T18:50:36.866622: step 17060, loss 0.00208343, acc 1
2016-09-05T18:50:37.093825: step 17061, loss 0.00170095, acc 1
2016-09-05T18:50:37.313516: step 17062, loss 0.0016951, acc 1
2016-09-05T18:50:37.544631: step 17063, loss 0.0069292, acc 1
2016-09-05T18:50:37.761363: step 17064, loss 0.00167487, acc 1
2016-09-05T18:50:37.961872: step 17065, loss 0.00221008, acc 1
2016-09-05T18:50:38.171415: step 17066, loss 0.00172051, acc 1
2016-09-05T18:50:38.385678: step 17067, loss 0.00168158, acc 1
2016-09-05T18:50:38.601583: step 17068, loss 0.00168641, acc 1
2016-09-05T18:50:38.825004: step 17069, loss 0.00168544, acc 1
2016-09-05T18:50:39.056372: step 17070, loss 0.00168219, acc 1
2016-09-05T18:50:39.265182: step 17071, loss 0.00323097, acc 1
2016-09-05T18:50:39.410105: step 17072, loss 0.00169323, acc 1
2016-09-05T18:50:39.624260: step 17073, loss 0.00161589, acc 1
2016-09-05T18:50:39.856062: step 17074, loss 0.00162823, acc 1
2016-09-05T18:50:40.083391: step 17075, loss 0.0016015, acc 1
2016-09-05T18:50:40.300630: step 17076, loss 0.00184733, acc 1
2016-09-05T18:50:40.503618: step 17077, loss 0.00159074, acc 1
2016-09-05T18:50:40.717141: step 17078, loss 0.00158208, acc 1
2016-09-05T18:50:40.931143: step 17079, loss 0.00159023, acc 1
2016-09-05T18:50:41.151490: step 17080, loss 0.00172615, acc 1
2016-09-05T18:50:41.418786: step 17081, loss 0.00156038, acc 1
2016-09-05T18:50:41.628518: step 17082, loss 0.00155357, acc 1
2016-09-05T18:50:41.838317: step 17083, loss 0.00288461, acc 1
2016-09-05T18:50:42.046810: step 17084, loss 0.00158557, acc 1
2016-09-05T18:50:42.269880: step 17085, loss 0.00153431, acc 1
2016-09-05T18:50:42.474624: step 17086, loss 0.00153457, acc 1
2016-09-05T18:50:42.708935: step 17087, loss 0.00153192, acc 1
2016-09-05T18:50:42.908576: step 17088, loss 0.00153048, acc 1
2016-09-05T18:50:43.125262: step 17089, loss 0.00165073, acc 1
2016-09-05T18:50:43.359084: step 17090, loss 0.0017909, acc 1
2016-09-05T18:50:43.573983: step 17091, loss 0.00149719, acc 1
2016-09-05T18:50:43.802905: step 17092, loss 0.00148953, acc 1
2016-09-05T18:50:44.023266: step 17093, loss 0.00175195, acc 1
2016-09-05T18:50:44.247325: step 17094, loss 0.00150824, acc 1
2016-09-05T18:50:44.453944: step 17095, loss 0.00146583, acc 1
2016-09-05T18:50:44.669708: step 17096, loss 0.0014979, acc 1
2016-09-05T18:50:44.892299: step 17097, loss 0.00147816, acc 1
2016-09-05T18:50:45.134482: step 17098, loss 0.00145564, acc 1
2016-09-05T18:50:45.326223: step 17099, loss 0.00144894, acc 1
2016-09-05T18:50:45.537138: step 17100, loss 0.00237726, acc 1

Evaluation:
2016-09-05T18:50:46.150095: step 17100, loss 2.19148, acc 0.716

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-17100

2016-09-05T18:50:46.919224: step 17101, loss 0.00142894, acc 1
2016-09-05T18:50:47.158043: step 17102, loss 0.00143089, acc 1
2016-09-05T18:50:47.364432: step 17103, loss 0.00143821, acc 1
2016-09-05T18:50:47.579818: step 17104, loss 0.00141009, acc 1
2016-09-05T18:50:47.789834: step 17105, loss 0.0014192, acc 1
2016-09-05T18:50:48.027673: step 17106, loss 0.00174603, acc 1
2016-09-05T18:50:48.259299: step 17107, loss 0.00140407, acc 1
2016-09-05T18:50:48.471873: step 17108, loss 0.0014195, acc 1
2016-09-05T18:50:48.693233: step 17109, loss 0.00139808, acc 1
2016-09-05T18:50:48.894334: step 17110, loss 0.00136309, acc 1
2016-09-05T18:50:49.120831: step 17111, loss 0.00134115, acc 1
2016-09-05T18:50:49.355278: step 17112, loss 0.00142468, acc 1
2016-09-05T18:50:49.572605: step 17113, loss 0.00134142, acc 1
2016-09-05T18:50:49.775351: step 17114, loss 0.00176909, acc 1
2016-09-05T18:50:49.990498: step 17115, loss 0.00143556, acc 1
2016-09-05T18:50:50.191403: step 17116, loss 0.00139778, acc 1
2016-09-05T18:50:50.412612: step 17117, loss 0.00132233, acc 1
2016-09-05T18:50:50.629843: step 17118, loss 0.00133674, acc 1
2016-09-05T18:50:50.846677: step 17119, loss 0.00130165, acc 1
2016-09-05T18:50:51.076629: step 17120, loss 0.00132258, acc 1
2016-09-05T18:50:51.281410: step 17121, loss 0.00129392, acc 1
2016-09-05T18:50:51.495922: step 17122, loss 0.00128564, acc 1
2016-09-05T18:50:51.715974: step 17123, loss 0.00131411, acc 1
2016-09-05T18:50:51.974726: step 17124, loss 0.00132627, acc 1
2016-09-05T18:50:52.205134: step 17125, loss 0.00128718, acc 1
2016-09-05T18:50:52.414025: step 17126, loss 0.00136969, acc 1
2016-09-05T18:50:52.621484: step 17127, loss 0.00124703, acc 1
2016-09-05T18:50:52.856218: step 17128, loss 0.00142328, acc 1
2016-09-05T18:50:53.065873: step 17129, loss 0.00129084, acc 1
2016-09-05T18:50:53.271856: step 17130, loss 0.00132793, acc 1
2016-09-05T18:50:53.518329: step 17131, loss 0.00120901, acc 1
2016-09-05T18:50:53.713815: step 17132, loss 0.00121333, acc 1
2016-09-05T18:50:53.925113: step 17133, loss 0.00131263, acc 1
2016-09-05T18:50:54.123442: step 17134, loss 0.00191934, acc 1
2016-09-05T18:50:54.328133: step 17135, loss 0.00121599, acc 1
2016-09-05T18:50:54.549932: step 17136, loss 0.00125268, acc 1
2016-09-05T18:50:54.770169: step 17137, loss 0.00118398, acc 1
2016-09-05T18:50:55.013453: step 17138, loss 0.00118127, acc 1
2016-09-05T18:50:55.235308: step 17139, loss 0.00121768, acc 1
2016-09-05T18:50:55.431821: step 17140, loss 0.00116873, acc 1
2016-09-05T18:50:55.639736: step 17141, loss 0.0012003, acc 1
2016-09-05T18:50:55.897710: step 17142, loss 0.00117236, acc 1
2016-09-05T18:50:56.099043: step 17143, loss 0.0011533, acc 1
2016-09-05T18:50:56.317354: step 17144, loss 0.00115168, acc 1
2016-09-05T18:50:56.510577: step 17145, loss 0.00118355, acc 1
2016-09-05T18:50:56.724187: step 17146, loss 0.0011173, acc 1
2016-09-05T18:50:56.932476: step 17147, loss 0.00205178, acc 1
2016-09-05T18:50:57.147166: step 17148, loss 0.00122626, acc 1
2016-09-05T18:50:57.354359: step 17149, loss 0.0013387, acc 1
2016-09-05T18:50:57.572688: step 17150, loss 0.00110937, acc 1
2016-09-05T18:50:57.799785: step 17151, loss 0.00118044, acc 1
2016-09-05T18:50:58.013619: step 17152, loss 0.00153013, acc 1
2016-09-05T18:50:58.249018: step 17153, loss 0.00357675, acc 1
2016-09-05T18:50:58.476149: step 17154, loss 0.00109239, acc 1
2016-09-05T18:50:58.705480: step 17155, loss 0.00136646, acc 1
2016-09-05T18:50:58.924427: step 17156, loss 0.00123909, acc 1
2016-09-05T18:50:59.168779: step 17157, loss 0.00109009, acc 1
2016-09-05T18:50:59.376147: step 17158, loss 0.00109231, acc 1
2016-09-05T18:50:59.586587: step 17159, loss 0.00265595, acc 1
2016-09-05T18:50:59.808262: step 17160, loss 0.00147164, acc 1
2016-09-05T18:51:00.032926: step 17161, loss 0.00164655, acc 1
2016-09-05T18:51:00.282831: step 17162, loss 0.00176507, acc 1
2016-09-05T18:51:00.481386: step 17163, loss 0.00155624, acc 1
2016-09-05T18:51:00.693963: step 17164, loss 0.00108558, acc 1
2016-09-05T18:51:00.930488: step 17165, loss 0.0014122, acc 1
2016-09-05T18:51:01.168203: step 17166, loss 0.00185715, acc 1
2016-09-05T18:51:01.411972: step 17167, loss 0.00125994, acc 1
2016-09-05T18:51:01.627380: step 17168, loss 0.001071, acc 1
2016-09-05T18:51:01.885015: step 17169, loss 0.00110491, acc 1
2016-09-05T18:51:02.108143: step 17170, loss 0.00127721, acc 1
2016-09-05T18:51:02.320756: step 17171, loss 0.00107022, acc 1
2016-09-05T18:51:02.554436: step 17172, loss 0.00109741, acc 1
2016-09-05T18:51:02.781461: step 17173, loss 0.00114025, acc 1
2016-09-05T18:51:02.997059: step 17174, loss 0.00143072, acc 1
2016-09-05T18:51:03.216429: step 17175, loss 0.00106334, acc 1
2016-09-05T18:51:03.434916: step 17176, loss 0.00119982, acc 1
2016-09-05T18:51:03.634573: step 17177, loss 0.00112436, acc 1
2016-09-05T18:51:03.824700: step 17178, loss 0.00111384, acc 1
2016-09-05T18:51:04.039741: step 17179, loss 0.00110035, acc 1
2016-09-05T18:51:04.247749: step 17180, loss 0.00306513, acc 1
2016-09-05T18:51:04.481084: step 17181, loss 0.00110475, acc 1
2016-09-05T18:51:04.713443: step 17182, loss 0.00103396, acc 1
2016-09-05T18:51:04.949408: step 17183, loss 0.00121255, acc 1
2016-09-05T18:51:05.155230: step 17184, loss 0.00119453, acc 1
2016-09-05T18:51:05.364253: step 17185, loss 0.00105341, acc 1
2016-09-05T18:51:05.583788: step 17186, loss 0.00116899, acc 1
2016-09-05T18:51:05.822574: step 17187, loss 0.00111568, acc 1
2016-09-05T18:51:06.041469: step 17188, loss 0.00100971, acc 1
2016-09-05T18:51:06.249758: step 17189, loss 0.00113655, acc 1
2016-09-05T18:51:06.471133: step 17190, loss 0.00123375, acc 1
2016-09-05T18:51:06.689735: step 17191, loss 0.00108261, acc 1
2016-09-05T18:51:06.938014: step 17192, loss 0.00142854, acc 1
2016-09-05T18:51:07.133931: step 17193, loss 0.00100778, acc 1
2016-09-05T18:51:07.331700: step 17194, loss 0.00109348, acc 1
2016-09-05T18:51:07.529280: step 17195, loss 0.0012333, acc 1
2016-09-05T18:51:07.757488: step 17196, loss 0.000982257, acc 1
2016-09-05T18:51:08.021387: step 17197, loss 0.00118678, acc 1
2016-09-05T18:51:08.242145: step 17198, loss 0.00108091, acc 1
2016-09-05T18:51:08.457635: step 17199, loss 0.00100548, acc 1
2016-09-05T18:51:08.662149: step 17200, loss 0.00103656, acc 1

Evaluation:
2016-09-05T18:51:09.274791: step 17200, loss 1.93507, acc 0.713

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-17200

2016-09-05T18:51:09.957297: step 17201, loss 0.00104141, acc 1
2016-09-05T18:51:10.186483: step 17202, loss 0.000966198, acc 1
2016-09-05T18:51:10.412123: step 17203, loss 0.00119127, acc 1
2016-09-05T18:51:10.641432: step 17204, loss 0.00110192, acc 1
2016-09-05T18:51:10.863704: step 17205, loss 0.000968862, acc 1
2016-09-05T18:51:11.084722: step 17206, loss 0.0014971, acc 1
2016-09-05T18:51:11.303305: step 17207, loss 0.000971107, acc 1
2016-09-05T18:51:11.528432: step 17208, loss 0.000960422, acc 1
2016-09-05T18:51:11.756243: step 17209, loss 0.00153053, acc 1
2016-09-05T18:51:11.957428: step 17210, loss 0.00160214, acc 1
2016-09-05T18:51:12.169476: step 17211, loss 0.000962102, acc 1
2016-09-05T18:51:12.378622: step 17212, loss 0.000962401, acc 1
2016-09-05T18:51:12.592991: step 17213, loss 0.0009807, acc 1
2016-09-05T18:51:12.793913: step 17214, loss 0.00114419, acc 1
2016-09-05T18:51:13.025572: step 17215, loss 0.000969184, acc 1
2016-09-05T18:51:13.237365: step 17216, loss 0.00091743, acc 1
2016-09-05T18:51:13.461390: step 17217, loss 0.00111132, acc 1
2016-09-05T18:51:13.645028: step 17218, loss 0.00120057, acc 1
2016-09-05T18:51:13.862710: step 17219, loss 0.000933411, acc 1
2016-09-05T18:51:14.074899: step 17220, loss 0.00103403, acc 1
2016-09-05T18:51:14.283650: step 17221, loss 0.00097075, acc 1
2016-09-05T18:51:14.487810: step 17222, loss 0.00090189, acc 1
2016-09-05T18:51:14.697851: step 17223, loss 0.00120369, acc 1
2016-09-05T18:51:14.907690: step 17224, loss 0.000996791, acc 1
2016-09-05T18:51:15.117216: step 17225, loss 0.000985146, acc 1
2016-09-05T18:51:15.321664: step 17226, loss 0.00122291, acc 1
2016-09-05T18:51:15.562810: step 17227, loss 0.000921952, acc 1
2016-09-05T18:51:15.791384: step 17228, loss 0.00100947, acc 1
2016-09-05T18:51:16.004499: step 17229, loss 0.00102672, acc 1
2016-09-05T18:51:16.219189: step 17230, loss 0.000882879, acc 1
2016-09-05T18:51:16.427856: step 17231, loss 0.00111899, acc 1
2016-09-05T18:51:16.647337: step 17232, loss 0.00105508, acc 1
2016-09-05T18:51:16.862490: step 17233, loss 0.000883208, acc 1
2016-09-05T18:51:17.107839: step 17234, loss 0.000979325, acc 1
2016-09-05T18:51:17.324674: step 17235, loss 0.00218878, acc 1
2016-09-05T18:51:17.546644: step 17236, loss 0.000902931, acc 1
2016-09-05T18:51:17.755175: step 17237, loss 0.000953883, acc 1
2016-09-05T18:51:17.986375: step 17238, loss 0.000964684, acc 1
2016-09-05T18:51:18.214854: step 17239, loss 0.00137284, acc 1
2016-09-05T18:51:18.419535: step 17240, loss 0.00118439, acc 1
2016-09-05T18:51:18.634770: step 17241, loss 0.00290077, acc 1
2016-09-05T18:51:18.841790: step 17242, loss 0.00103808, acc 1
2016-09-05T18:51:19.052222: step 17243, loss 0.000949844, acc 1
2016-09-05T18:51:19.260827: step 17244, loss 0.000876518, acc 1
2016-09-05T18:51:19.502233: step 17245, loss 0.00148624, acc 1
2016-09-05T18:51:19.744320: step 17246, loss 0.000876767, acc 1
2016-09-05T18:51:19.950599: step 17247, loss 0.00213701, acc 1
2016-09-05T18:51:20.152180: step 17248, loss 0.000970834, acc 1
2016-09-05T18:51:20.391221: step 17249, loss 0.000858776, acc 1
2016-09-05T18:51:20.600096: step 17250, loss 0.00101341, acc 1
2016-09-05T18:51:20.809514: step 17251, loss 0.00112238, acc 1
2016-09-05T18:51:21.031506: step 17252, loss 0.00111641, acc 1
2016-09-05T18:51:21.250954: step 17253, loss 0.000993343, acc 1
2016-09-05T18:51:21.462321: step 17254, loss 0.00103699, acc 1
2016-09-05T18:51:21.660865: step 17255, loss 0.000956973, acc 1
2016-09-05T18:51:21.866435: step 17256, loss 0.00101026, acc 1
2016-09-05T18:51:22.063575: step 17257, loss 0.00111686, acc 1
2016-09-05T18:51:22.267854: step 17258, loss 0.000962783, acc 1
2016-09-05T18:51:22.472671: step 17259, loss 0.000904649, acc 1
2016-09-05T18:51:22.704415: step 17260, loss 0.000894052, acc 1
2016-09-05T18:51:22.930157: step 17261, loss 0.000932082, acc 1
2016-09-05T18:51:23.169087: step 17262, loss 0.00127204, acc 1
2016-09-05T18:51:23.367249: step 17263, loss 0.000905053, acc 1
2016-09-05T18:51:23.581771: step 17264, loss 0.00160363, acc 1
2016-09-05T18:51:23.798579: step 17265, loss 0.00181165, acc 1
2016-09-05T18:51:23.957513: step 17266, loss 0.00117024, acc 1
2016-09-05T18:51:24.185496: step 17267, loss 0.000883537, acc 1
2016-09-05T18:51:24.410205: step 17268, loss 0.000884749, acc 1
2016-09-05T18:51:24.626706: step 17269, loss 0.000916869, acc 1
2016-09-05T18:51:24.875452: step 17270, loss 0.000868589, acc 1
2016-09-05T18:51:25.087440: step 17271, loss 0.00089255, acc 1
2016-09-05T18:51:25.286391: step 17272, loss 0.000911205, acc 1
2016-09-05T18:51:25.502069: step 17273, loss 0.000977997, acc 1
2016-09-05T18:51:25.707279: step 17274, loss 0.000842049, acc 1
2016-09-05T18:51:25.914841: step 17275, loss 0.000910249, acc 1
2016-09-05T18:51:26.121426: step 17276, loss 0.000843319, acc 1
2016-09-05T18:51:26.361048: step 17277, loss 0.000988029, acc 1
2016-09-05T18:51:26.598948: step 17278, loss 0.000840311, acc 1
2016-09-05T18:51:26.829253: step 17279, loss 0.000872305, acc 1
2016-09-05T18:51:27.052604: step 17280, loss 0.000969965, acc 1
2016-09-05T18:51:27.257345: step 17281, loss 0.000893135, acc 1
2016-09-05T18:51:27.478591: step 17282, loss 0.000912177, acc 1
2016-09-05T18:51:27.699565: step 17283, loss 0.000897171, acc 1
2016-09-05T18:51:27.895813: step 17284, loss 0.000907161, acc 1
2016-09-05T18:51:28.119146: step 17285, loss 0.000854665, acc 1
2016-09-05T18:51:28.358192: step 17286, loss 0.000815231, acc 1
2016-09-05T18:51:28.580914: step 17287, loss 0.000895591, acc 1
2016-09-05T18:51:28.800799: step 17288, loss 0.000808204, acc 1
2016-09-05T18:51:29.009405: step 17289, loss 0.000949525, acc 1
2016-09-05T18:51:29.238970: step 17290, loss 0.000988491, acc 1
2016-09-05T18:51:29.450384: step 17291, loss 0.000926611, acc 1
2016-09-05T18:51:29.656334: step 17292, loss 0.000925642, acc 1
2016-09-05T18:51:29.878869: step 17293, loss 0.000819695, acc 1
2016-09-05T18:51:30.097647: step 17294, loss 0.000931591, acc 1
2016-09-05T18:51:30.329288: step 17295, loss 0.00106551, acc 1
2016-09-05T18:51:30.542185: step 17296, loss 0.00112804, acc 1
2016-09-05T18:51:30.747767: step 17297, loss 0.00112729, acc 1
2016-09-05T18:51:30.951918: step 17298, loss 0.00100153, acc 1
2016-09-05T18:51:31.159721: step 17299, loss 0.000912212, acc 1
2016-09-05T18:51:31.365644: step 17300, loss 0.000843954, acc 1

Evaluation:
2016-09-05T18:51:31.972929: step 17300, loss 1.81797, acc 0.714

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-17300

2016-09-05T18:51:32.728461: step 17301, loss 0.000981436, acc 1
2016-09-05T18:51:32.980330: step 17302, loss 0.000924582, acc 1
2016-09-05T18:51:33.184590: step 17303, loss 0.000781217, acc 1
2016-09-05T18:51:33.385370: step 17304, loss 0.00127288, acc 1
2016-09-05T18:51:33.589704: step 17305, loss 0.00075709, acc 1
2016-09-05T18:51:33.797387: step 17306, loss 0.000753046, acc 1
2016-09-05T18:51:34.009635: step 17307, loss 0.000925928, acc 1
2016-09-05T18:51:34.257707: step 17308, loss 0.00123281, acc 1
2016-09-05T18:51:34.477409: step 17309, loss 0.000804149, acc 1
2016-09-05T18:51:34.714751: step 17310, loss 0.000888946, acc 1
2016-09-05T18:51:34.940257: step 17311, loss 0.000781116, acc 1
2016-09-05T18:51:35.165432: step 17312, loss 0.00151901, acc 1
2016-09-05T18:51:35.384128: step 17313, loss 0.0011289, acc 1
2016-09-05T18:51:35.597102: step 17314, loss 0.000859418, acc 1
2016-09-05T18:51:35.800903: step 17315, loss 0.00080674, acc 1
2016-09-05T18:51:36.037490: step 17316, loss 0.000747754, acc 1
2016-09-05T18:51:36.257036: step 17317, loss 0.000787562, acc 1
2016-09-05T18:51:36.476117: step 17318, loss 0.00082746, acc 1
2016-09-05T18:51:36.679351: step 17319, loss 0.000785298, acc 1
2016-09-05T18:51:36.899461: step 17320, loss 0.00107369, acc 1
2016-09-05T18:51:37.102208: step 17321, loss 0.00125475, acc 1
2016-09-05T18:51:37.316319: step 17322, loss 0.000751246, acc 1
2016-09-05T18:51:37.533136: step 17323, loss 0.000776635, acc 1
2016-09-05T18:51:37.755683: step 17324, loss 0.000983588, acc 1
2016-09-05T18:51:37.989791: step 17325, loss 0.000802973, acc 1
2016-09-05T18:51:38.203097: step 17326, loss 0.000889843, acc 1
2016-09-05T18:51:38.407660: step 17327, loss 0.000892701, acc 1
2016-09-05T18:51:38.617271: step 17328, loss 0.000974959, acc 1
2016-09-05T18:51:38.813587: step 17329, loss 0.00079582, acc 1
2016-09-05T18:51:39.029142: step 17330, loss 0.000759563, acc 1
2016-09-05T18:51:39.255139: step 17331, loss 0.000738896, acc 1
2016-09-05T18:51:39.476222: step 17332, loss 0.000927604, acc 1
2016-09-05T18:51:39.712264: step 17333, loss 0.000755549, acc 1
2016-09-05T18:51:39.902640: step 17334, loss 0.00429272, acc 1
2016-09-05T18:51:40.131244: step 17335, loss 0.000780826, acc 1
2016-09-05T18:51:40.346004: step 17336, loss 0.00125404, acc 1
2016-09-05T18:51:40.559018: step 17337, loss 0.00101115, acc 1
2016-09-05T18:51:40.783118: step 17338, loss 0.000859995, acc 1
2016-09-05T18:51:41.018103: step 17339, loss 0.000822706, acc 1
2016-09-05T18:51:41.220485: step 17340, loss 0.00101477, acc 1
2016-09-05T18:51:41.444334: step 17341, loss 0.00115395, acc 1
2016-09-05T18:51:41.638421: step 17342, loss 0.00110793, acc 1
2016-09-05T18:51:41.842321: step 17343, loss 0.00234478, acc 1
2016-09-05T18:51:42.055747: step 17344, loss 0.00130319, acc 1
2016-09-05T18:51:42.292584: step 17345, loss 0.002017, acc 1
2016-09-05T18:51:42.511259: step 17346, loss 0.00114336, acc 1
2016-09-05T18:51:42.751429: step 17347, loss 0.0009327, acc 1
2016-09-05T18:51:42.962871: step 17348, loss 0.000977665, acc 1
2016-09-05T18:51:43.181608: step 17349, loss 0.000883437, acc 1
2016-09-05T18:51:43.413646: step 17350, loss 0.00104877, acc 1
2016-09-05T18:51:43.649104: step 17351, loss 0.000907825, acc 1
2016-09-05T18:51:43.868963: step 17352, loss 0.000922251, acc 1
2016-09-05T18:51:44.067367: step 17353, loss 0.000971462, acc 1
2016-09-05T18:51:44.314284: step 17354, loss 0.000895718, acc 1
2016-09-05T18:51:44.557556: step 17355, loss 0.000907313, acc 1
2016-09-05T18:51:44.749392: step 17356, loss 0.000923094, acc 1
2016-09-05T18:51:44.970437: step 17357, loss 0.00098152, acc 1
2016-09-05T18:51:45.171369: step 17358, loss 0.000924023, acc 1
2016-09-05T18:51:45.373877: step 17359, loss 0.00097628, acc 1
2016-09-05T18:51:45.588723: step 17360, loss 0.000927775, acc 1
2016-09-05T18:51:45.824472: step 17361, loss 0.000926747, acc 1
2016-09-05T18:51:46.046218: step 17362, loss 0.00100891, acc 1
2016-09-05T18:51:46.284932: step 17363, loss 0.000943536, acc 1
2016-09-05T18:51:46.487368: step 17364, loss 0.000924882, acc 1
2016-09-05T18:51:46.692895: step 17365, loss 0.000897515, acc 1
2016-09-05T18:51:46.894353: step 17366, loss 0.000996732, acc 1
2016-09-05T18:51:47.121563: step 17367, loss 0.000993016, acc 1
2016-09-05T18:51:47.361231: step 17368, loss 0.000876169, acc 1
2016-09-05T18:51:47.601970: step 17369, loss 0.000925733, acc 1
2016-09-05T18:51:47.822949: step 17370, loss 0.000994153, acc 1
2016-09-05T18:51:48.041165: step 17371, loss 0.000929815, acc 1
2016-09-05T18:51:48.258417: step 17372, loss 0.000860553, acc 1
2016-09-05T18:51:48.482922: step 17373, loss 0.00176965, acc 1
2016-09-05T18:51:48.712336: step 17374, loss 0.000979757, acc 1
2016-09-05T18:51:48.940677: step 17375, loss 0.000942148, acc 1
2016-09-05T18:51:49.150978: step 17376, loss 0.0009611, acc 1
2016-09-05T18:51:49.367012: step 17377, loss 0.000976895, acc 1
2016-09-05T18:51:49.576940: step 17378, loss 0.000889726, acc 1
2016-09-05T18:51:49.812454: step 17379, loss 0.000842553, acc 1
2016-09-05T18:51:50.013897: step 17380, loss 0.000867577, acc 1
2016-09-05T18:51:50.220204: step 17381, loss 0.000896818, acc 1
2016-09-05T18:51:50.428679: step 17382, loss 0.000928731, acc 1
2016-09-05T18:51:50.660014: step 17383, loss 0.00167448, acc 1
2016-09-05T18:51:50.874152: step 17384, loss 0.00147708, acc 1
2016-09-05T18:51:51.114264: step 17385, loss 0.000879427, acc 1
2016-09-05T18:51:51.317439: step 17386, loss 0.000897458, acc 1
2016-09-05T18:51:51.514867: step 17387, loss 0.00083933, acc 1
2016-09-05T18:51:51.729243: step 17388, loss 0.00122699, acc 1
2016-09-05T18:51:51.945572: step 17389, loss 0.000839165, acc 1
2016-09-05T18:51:52.165872: step 17390, loss 0.000977295, acc 1
2016-09-05T18:51:52.396876: step 17391, loss 0.00199825, acc 1
2016-09-05T18:51:52.638676: step 17392, loss 0.000862738, acc 1
2016-09-05T18:51:52.853752: step 17393, loss 0.000833274, acc 1
2016-09-05T18:51:53.071966: step 17394, loss 0.000873812, acc 1
2016-09-05T18:51:53.267986: step 17395, loss 0.000962464, acc 1
2016-09-05T18:51:53.506134: step 17396, loss 0.00078933, acc 1
2016-09-05T18:51:53.734244: step 17397, loss 0.00080863, acc 1
2016-09-05T18:51:53.962392: step 17398, loss 0.000827343, acc 1
2016-09-05T18:51:54.172745: step 17399, loss 0.000807329, acc 1
2016-09-05T18:51:54.393185: step 17400, loss 0.000951383, acc 1

Evaluation:
2016-09-05T18:51:54.996494: step 17400, loss 1.84385, acc 0.711

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-17400

2016-09-05T18:51:55.720257: step 17401, loss 0.000817805, acc 1
2016-09-05T18:51:55.968782: step 17402, loss 0.000784162, acc 1
2016-09-05T18:51:56.186271: step 17403, loss 0.000859198, acc 1
2016-09-05T18:51:56.394158: step 17404, loss 0.000803511, acc 1
2016-09-05T18:51:56.603573: step 17405, loss 0.00100784, acc 1
2016-09-05T18:51:56.860094: step 17406, loss 0.000883518, acc 1
2016-09-05T18:51:57.083690: step 17407, loss 0.00111002, acc 1
2016-09-05T18:51:57.295535: step 17408, loss 0.000837759, acc 1
2016-09-05T18:51:57.501890: step 17409, loss 0.000870865, acc 1
2016-09-05T18:51:57.709743: step 17410, loss 0.00106939, acc 1
2016-09-05T18:51:57.920723: step 17411, loss 0.000852921, acc 1
2016-09-05T18:51:58.160096: step 17412, loss 0.000869572, acc 1
2016-09-05T18:51:58.411172: step 17413, loss 0.000867425, acc 1
2016-09-05T18:51:58.617618: step 17414, loss 0.00105897, acc 1
2016-09-05T18:51:58.837760: step 17415, loss 0.000849765, acc 1
2016-09-05T18:51:59.064631: step 17416, loss 0.000768194, acc 1
2016-09-05T18:51:59.308404: step 17417, loss 0.00182731, acc 1
2016-09-05T18:51:59.514226: step 17418, loss 0.000743446, acc 1
2016-09-05T18:51:59.726450: step 17419, loss 0.000965727, acc 1
2016-09-05T18:51:59.932844: step 17420, loss 0.000771363, acc 1
2016-09-05T18:52:00.156909: step 17421, loss 0.000739991, acc 1
2016-09-05T18:52:00.415567: step 17422, loss 0.00172189, acc 1
2016-09-05T18:52:00.608736: step 17423, loss 0.000761695, acc 1
2016-09-05T18:52:00.829200: step 17424, loss 0.000765447, acc 1
2016-09-05T18:52:01.044976: step 17425, loss 0.00078683, acc 1
2016-09-05T18:52:01.275515: step 17426, loss 0.000782096, acc 1
2016-09-05T18:52:01.504895: step 17427, loss 0.00114692, acc 1
2016-09-05T18:52:01.721459: step 17428, loss 0.000857316, acc 1
2016-09-05T18:52:01.924346: step 17429, loss 0.000828562, acc 1
2016-09-05T18:52:02.131094: step 17430, loss 0.0008395, acc 1
2016-09-05T18:52:02.330214: step 17431, loss 0.00182514, acc 1
2016-09-05T18:52:02.549843: step 17432, loss 0.000882533, acc 1
2016-09-05T18:52:02.767309: step 17433, loss 0.000878127, acc 1
2016-09-05T18:52:03.017410: step 17434, loss 0.00110024, acc 1
2016-09-05T18:52:03.247190: step 17435, loss 0.00073015, acc 1
2016-09-05T18:52:03.463020: step 17436, loss 0.00111263, acc 1
2016-09-05T18:52:03.676249: step 17437, loss 0.000794094, acc 1
2016-09-05T18:52:03.900947: step 17438, loss 0.00103604, acc 1
2016-09-05T18:52:04.153899: step 17439, loss 0.000823712, acc 1
2016-09-05T18:52:04.369340: step 17440, loss 0.000804849, acc 1
2016-09-05T18:52:04.590159: step 17441, loss 0.000721724, acc 1
2016-09-05T18:52:04.833475: step 17442, loss 0.000977087, acc 1
2016-09-05T18:52:05.057685: step 17443, loss 0.000759906, acc 1
2016-09-05T18:52:05.276647: step 17444, loss 0.000919883, acc 1
2016-09-05T18:52:05.473958: step 17445, loss 0.00106231, acc 1
2016-09-05T18:52:05.685589: step 17446, loss 0.000769077, acc 1
2016-09-05T18:52:05.903970: step 17447, loss 0.000836006, acc 1
2016-09-05T18:52:06.145454: step 17448, loss 0.000780347, acc 1
2016-09-05T18:52:06.367353: step 17449, loss 0.000878722, acc 1
2016-09-05T18:52:06.585858: step 17450, loss 0.00078038, acc 1
2016-09-05T18:52:06.810647: step 17451, loss 0.00128146, acc 1
2016-09-05T18:52:07.019026: step 17452, loss 0.000746621, acc 1
2016-09-05T18:52:07.240246: step 17453, loss 0.000765296, acc 1
2016-09-05T18:52:07.477156: step 17454, loss 0.000716114, acc 1
2016-09-05T18:52:07.691684: step 17455, loss 0.00100799, acc 1
2016-09-05T18:52:07.896150: step 17456, loss 0.000794837, acc 1
2016-09-05T18:52:08.108249: step 17457, loss 0.0007905, acc 1
2016-09-05T18:52:08.324002: step 17458, loss 0.000755054, acc 1
2016-09-05T18:52:08.547996: step 17459, loss 0.000717295, acc 1
2016-09-05T18:52:08.696820: step 17460, loss 0.00077508, acc 1
2016-09-05T18:52:08.914368: step 17461, loss 0.000703734, acc 1
2016-09-05T18:52:09.125750: step 17462, loss 0.000822531, acc 1
2016-09-05T18:52:09.356923: step 17463, loss 0.000952191, acc 1
2016-09-05T18:52:09.577577: step 17464, loss 0.000883126, acc 1
2016-09-05T18:52:09.790945: step 17465, loss 0.000806772, acc 1
2016-09-05T18:52:10.009432: step 17466, loss 0.00105834, acc 1
2016-09-05T18:52:10.277431: step 17467, loss 0.000706521, acc 1
2016-09-05T18:52:10.498641: step 17468, loss 0.000712713, acc 1
2016-09-05T18:52:10.701319: step 17469, loss 0.000696043, acc 1
2016-09-05T18:52:10.902526: step 17470, loss 0.000685344, acc 1
2016-09-05T18:52:11.117921: step 17471, loss 0.000740966, acc 1
2016-09-05T18:52:11.340206: step 17472, loss 0.00103289, acc 1
2016-09-05T18:52:11.553197: step 17473, loss 0.00128883, acc 1
2016-09-05T18:52:11.786815: step 17474, loss 0.000665838, acc 1
2016-09-05T18:52:11.983498: step 17475, loss 0.000685456, acc 1
2016-09-05T18:52:12.213620: step 17476, loss 0.000801044, acc 1
2016-09-05T18:52:12.424490: step 17477, loss 0.000711367, acc 1
2016-09-05T18:52:12.644862: step 17478, loss 0.000723261, acc 1
2016-09-05T18:52:12.861134: step 17479, loss 0.000952911, acc 1
2016-09-05T18:52:13.096743: step 17480, loss 0.000998408, acc 1
2016-09-05T18:52:13.313421: step 17481, loss 0.000694919, acc 1
2016-09-05T18:52:13.524645: step 17482, loss 0.000680765, acc 1
2016-09-05T18:52:13.733071: step 17483, loss 0.000656117, acc 1
2016-09-05T18:52:13.946983: step 17484, loss 0.00103769, acc 1
2016-09-05T18:52:14.175768: step 17485, loss 0.000655644, acc 1
2016-09-05T18:52:14.377512: step 17486, loss 0.000651414, acc 1
2016-09-05T18:52:14.592406: step 17487, loss 0.000662823, acc 1
2016-09-05T18:52:14.823851: step 17488, loss 0.000729863, acc 1
2016-09-05T18:52:15.043076: step 17489, loss 0.000660145, acc 1
2016-09-05T18:52:15.246185: step 17490, loss 0.000676917, acc 1
2016-09-05T18:52:15.454613: step 17491, loss 0.00064908, acc 1
2016-09-05T18:52:15.653640: step 17492, loss 0.000703482, acc 1
2016-09-05T18:52:15.860843: step 17493, loss 0.000640522, acc 1
2016-09-05T18:52:16.057429: step 17494, loss 0.000702882, acc 1
2016-09-05T18:52:16.269304: step 17495, loss 0.000648949, acc 1
2016-09-05T18:52:16.473130: step 17496, loss 0.0006374, acc 1
2016-09-05T18:52:16.699577: step 17497, loss 0.000657816, acc 1
2016-09-05T18:52:16.917609: step 17498, loss 0.000658044, acc 1
2016-09-05T18:52:17.131130: step 17499, loss 0.000760926, acc 1
2016-09-05T18:52:17.354215: step 17500, loss 0.000611469, acc 1

Evaluation:
2016-09-05T18:52:17.960174: step 17500, loss 1.68907, acc 0.711

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-17500

2016-09-05T18:52:18.800489: step 17501, loss 0.000642525, acc 1
2016-09-05T18:52:19.013546: step 17502, loss 0.000751512, acc 1
2016-09-05T18:52:19.273302: step 17503, loss 0.000793635, acc 1
2016-09-05T18:52:19.486644: step 17504, loss 0.000634164, acc 1
2016-09-05T18:52:19.696596: step 17505, loss 0.00093919, acc 1
2016-09-05T18:52:19.921273: step 17506, loss 0.00141464, acc 1
2016-09-05T18:52:20.134376: step 17507, loss 0.000655374, acc 1
2016-09-05T18:52:20.372128: step 17508, loss 0.00111123, acc 1
2016-09-05T18:52:20.589164: step 17509, loss 0.00060611, acc 1
2016-09-05T18:52:20.807811: step 17510, loss 0.00153602, acc 1
2016-09-05T18:52:21.061373: step 17511, loss 0.000753371, acc 1
2016-09-05T18:52:21.326365: step 17512, loss 0.000646129, acc 1
2016-09-05T18:52:21.539258: step 17513, loss 0.000714865, acc 1
2016-09-05T18:52:21.749054: step 17514, loss 0.000620796, acc 1
2016-09-05T18:52:21.979659: step 17515, loss 0.000662702, acc 1
2016-09-05T18:52:22.234744: step 17516, loss 0.000625346, acc 1
2016-09-05T18:52:22.511438: step 17517, loss 0.000722887, acc 1
2016-09-05T18:52:22.744772: step 17518, loss 0.000749015, acc 1
2016-09-05T18:52:22.961310: step 17519, loss 0.000753473, acc 1
2016-09-05T18:52:23.166953: step 17520, loss 0.000867008, acc 1
2016-09-05T18:52:23.409530: step 17521, loss 0.000707503, acc 1
2016-09-05T18:52:23.623357: step 17522, loss 0.000842768, acc 1
2016-09-05T18:52:23.826380: step 17523, loss 0.000723873, acc 1
2016-09-05T18:52:24.056124: step 17524, loss 0.000956964, acc 1
2016-09-05T18:52:24.271928: step 17525, loss 0.000649024, acc 1
2016-09-05T18:52:24.473404: step 17526, loss 0.000732459, acc 1
2016-09-05T18:52:24.694144: step 17527, loss 0.000665188, acc 1
2016-09-05T18:52:24.921478: step 17528, loss 0.000867163, acc 1
2016-09-05T18:52:25.157057: step 17529, loss 0.000668846, acc 1
2016-09-05T18:52:25.364258: step 17530, loss 0.000646959, acc 1
2016-09-05T18:52:25.579722: step 17531, loss 0.000679231, acc 1
2016-09-05T18:52:25.804887: step 17532, loss 0.00135963, acc 1
2016-09-05T18:52:26.052145: step 17533, loss 0.000643404, acc 1
2016-09-05T18:52:26.240180: step 17534, loss 0.000627648, acc 1
2016-09-05T18:52:26.461078: step 17535, loss 0.000600233, acc 1
2016-09-05T18:52:26.650864: step 17536, loss 0.000711381, acc 1
2016-09-05T18:52:26.847916: step 17537, loss 0.000690689, acc 1
2016-09-05T18:52:27.067403: step 17538, loss 0.000683399, acc 1
2016-09-05T18:52:27.306849: step 17539, loss 0.000861533, acc 1
2016-09-05T18:52:27.546957: step 17540, loss 0.00085234, acc 1
2016-09-05T18:52:27.768256: step 17541, loss 0.000743697, acc 1
2016-09-05T18:52:27.983117: step 17542, loss 0.000615637, acc 1
2016-09-05T18:52:28.196413: step 17543, loss 0.000658683, acc 1
2016-09-05T18:52:28.423741: step 17544, loss 0.000704705, acc 1
2016-09-05T18:52:28.623123: step 17545, loss 0.000640329, acc 1
2016-09-05T18:52:28.863186: step 17546, loss 0.000734535, acc 1
2016-09-05T18:52:29.058859: step 17547, loss 0.000843848, acc 1
2016-09-05T18:52:29.288220: step 17548, loss 0.000613704, acc 1
2016-09-05T18:52:29.489351: step 17549, loss 0.000717809, acc 1
2016-09-05T18:52:29.690827: step 17550, loss 0.000604633, acc 1
2016-09-05T18:52:29.897667: step 17551, loss 0.000620138, acc 1
2016-09-05T18:52:30.106755: step 17552, loss 0.000686858, acc 1
2016-09-05T18:52:30.312950: step 17553, loss 0.000654354, acc 1
2016-09-05T18:52:30.538598: step 17554, loss 0.000610939, acc 1
2016-09-05T18:52:30.768446: step 17555, loss 0.00103047, acc 1
2016-09-05T18:52:30.989467: step 17556, loss 0.000735061, acc 1
2016-09-05T18:52:31.206313: step 17557, loss 0.000684669, acc 1
2016-09-05T18:52:31.395709: step 17558, loss 0.000645737, acc 1
2016-09-05T18:52:31.605381: step 17559, loss 0.00101526, acc 1
2016-09-05T18:52:31.826394: step 17560, loss 0.000719396, acc 1
2016-09-05T18:52:32.045431: step 17561, loss 0.000641067, acc 1
2016-09-05T18:52:32.261828: step 17562, loss 0.000891271, acc 1
2016-09-05T18:52:32.508956: step 17563, loss 0.00127788, acc 1
2016-09-05T18:52:32.729983: step 17564, loss 0.000771091, acc 1
2016-09-05T18:52:32.944188: step 17565, loss 0.00070901, acc 1
2016-09-05T18:52:33.152955: step 17566, loss 0.000690347, acc 1
2016-09-05T18:52:33.370760: step 17567, loss 0.000688928, acc 1
2016-09-05T18:52:33.603434: step 17568, loss 0.000689298, acc 1
2016-09-05T18:52:33.796835: step 17569, loss 0.000638475, acc 1
2016-09-05T18:52:34.028890: step 17570, loss 0.00068785, acc 1
2016-09-05T18:52:34.242940: step 17571, loss 0.00086564, acc 1
2016-09-05T18:52:34.482938: step 17572, loss 0.000735389, acc 1
2016-09-05T18:52:34.690850: step 17573, loss 0.000963633, acc 1
2016-09-05T18:52:34.919655: step 17574, loss 0.000772012, acc 1
2016-09-05T18:52:35.135993: step 17575, loss 0.00089871, acc 1
2016-09-05T18:52:35.339802: step 17576, loss 0.000725451, acc 1
2016-09-05T18:52:35.588072: step 17577, loss 0.000745544, acc 1
2016-09-05T18:52:35.817426: step 17578, loss 0.000651033, acc 1
2016-09-05T18:52:36.037092: step 17579, loss 0.000730939, acc 1
2016-09-05T18:52:36.239286: step 17580, loss 0.000618534, acc 1
2016-09-05T18:52:36.451645: step 17581, loss 0.000626486, acc 1
2016-09-05T18:52:36.665695: step 17582, loss 0.000789956, acc 1
2016-09-05T18:52:36.900244: step 17583, loss 0.00191435, acc 1
2016-09-05T18:52:37.131893: step 17584, loss 0.000676014, acc 1
2016-09-05T18:52:37.348027: step 17585, loss 0.000737144, acc 1
2016-09-05T18:52:37.545372: step 17586, loss 0.00137483, acc 1
2016-09-05T18:52:37.753235: step 17587, loss 0.000734607, acc 1
2016-09-05T18:52:37.959690: step 17588, loss 0.000602822, acc 1
2016-09-05T18:52:38.184528: step 17589, loss 0.000742189, acc 1
2016-09-05T18:52:38.397257: step 17590, loss 0.000753573, acc 1
2016-09-05T18:52:38.614132: step 17591, loss 0.00100312, acc 1
2016-09-05T18:52:38.854536: step 17592, loss 0.000757811, acc 1
2016-09-05T18:52:39.058545: step 17593, loss 0.000636917, acc 1
2016-09-05T18:52:39.282557: step 17594, loss 0.000695428, acc 1
2016-09-05T18:52:39.482205: step 17595, loss 0.000661663, acc 1
2016-09-05T18:52:39.728418: step 17596, loss 0.000638385, acc 1
2016-09-05T18:52:39.963792: step 17597, loss 0.000728819, acc 1
2016-09-05T18:52:40.191215: step 17598, loss 0.000674131, acc 1
2016-09-05T18:52:40.406520: step 17599, loss 0.000610639, acc 1
2016-09-05T18:52:40.630666: step 17600, loss 0.000743789, acc 1

Evaluation:
2016-09-05T18:52:41.235701: step 17600, loss 1.73094, acc 0.708

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-17600

2016-09-05T18:52:41.953717: step 17601, loss 0.000601391, acc 1
2016-09-05T18:52:42.195198: step 17602, loss 0.00109941, acc 1
2016-09-05T18:52:42.403686: step 17603, loss 0.000600356, acc 1
2016-09-05T18:52:42.616138: step 17604, loss 0.000746555, acc 1
2016-09-05T18:52:42.815220: step 17605, loss 0.000772796, acc 1
2016-09-05T18:52:43.029013: step 17606, loss 0.000707491, acc 1
2016-09-05T18:52:43.244714: step 17607, loss 0.000927424, acc 1
2016-09-05T18:52:43.481773: step 17608, loss 0.000970855, acc 1
2016-09-05T18:52:43.719769: step 17609, loss 0.00145561, acc 1
2016-09-05T18:52:43.929470: step 17610, loss 0.000648769, acc 1
2016-09-05T18:52:44.145381: step 17611, loss 0.000630238, acc 1
2016-09-05T18:52:44.354428: step 17612, loss 0.000642854, acc 1
2016-09-05T18:52:44.572379: step 17613, loss 0.00085775, acc 1
2016-09-05T18:52:44.791863: step 17614, loss 0.000776487, acc 1
2016-09-05T18:52:45.005883: step 17615, loss 0.000792224, acc 1
2016-09-05T18:52:45.225401: step 17616, loss 0.000657938, acc 1
2016-09-05T18:52:45.441069: step 17617, loss 0.000643311, acc 1
2016-09-05T18:52:45.634875: step 17618, loss 0.00060742, acc 1
2016-09-05T18:52:45.858290: step 17619, loss 0.000861958, acc 1
2016-09-05T18:52:46.074146: step 17620, loss 0.000672846, acc 1
2016-09-05T18:52:46.286754: step 17621, loss 0.000657803, acc 1
2016-09-05T18:52:46.507708: step 17622, loss 0.000623092, acc 1
2016-09-05T18:52:46.727779: step 17623, loss 0.000739145, acc 1
2016-09-05T18:52:46.964630: step 17624, loss 0.000955638, acc 1
2016-09-05T18:52:47.164445: step 17625, loss 0.000653145, acc 1
2016-09-05T18:52:47.372698: step 17626, loss 0.000790794, acc 1
2016-09-05T18:52:47.592925: step 17627, loss 0.000807244, acc 1
2016-09-05T18:52:47.859573: step 17628, loss 0.000695734, acc 1
2016-09-05T18:52:48.060837: step 17629, loss 0.000624534, acc 1
2016-09-05T18:52:48.268296: step 17630, loss 0.000723445, acc 1
2016-09-05T18:52:48.467029: step 17631, loss 0.000585976, acc 1
2016-09-05T18:52:48.683527: step 17632, loss 0.000699367, acc 1
2016-09-05T18:52:48.931516: step 17633, loss 0.000745413, acc 1
2016-09-05T18:52:49.161402: step 17634, loss 0.000682311, acc 1
2016-09-05T18:52:49.377611: step 17635, loss 0.000646502, acc 1
2016-09-05T18:52:49.574233: step 17636, loss 0.000809549, acc 1
2016-09-05T18:52:49.790161: step 17637, loss 0.00106016, acc 1
2016-09-05T18:52:49.996577: step 17638, loss 0.000673501, acc 1
2016-09-05T18:52:50.221180: step 17639, loss 0.00060501, acc 1
2016-09-05T18:52:50.430728: step 17640, loss 0.000595066, acc 1
2016-09-05T18:52:50.648847: step 17641, loss 0.000617566, acc 1
2016-09-05T18:52:50.861415: step 17642, loss 0.000820871, acc 1
2016-09-05T18:52:51.084991: step 17643, loss 0.000664132, acc 1
2016-09-05T18:52:51.297311: step 17644, loss 0.000949202, acc 1
2016-09-05T18:52:51.509252: step 17645, loss 0.000578279, acc 1
2016-09-05T18:52:51.717387: step 17646, loss 0.000680093, acc 1
2016-09-05T18:52:51.939370: step 17647, loss 0.000705938, acc 1
2016-09-05T18:52:52.167291: step 17648, loss 0.000868991, acc 1
2016-09-05T18:52:52.403026: step 17649, loss 0.000770424, acc 1
2016-09-05T18:52:52.615405: step 17650, loss 0.000678072, acc 1
2016-09-05T18:52:52.818002: step 17651, loss 0.000638824, acc 1
2016-09-05T18:52:53.034284: step 17652, loss 0.00069838, acc 1
2016-09-05T18:52:53.252540: step 17653, loss 0.000671268, acc 1
2016-09-05T18:52:53.405079: step 17654, loss 0.00112636, acc 1
2016-09-05T18:52:53.609061: step 17655, loss 0.00065039, acc 1
2016-09-05T18:52:53.821345: step 17656, loss 0.000608803, acc 1
2016-09-05T18:52:54.018580: step 17657, loss 0.000685556, acc 1
2016-09-05T18:52:54.227509: step 17658, loss 0.000717, acc 1
2016-09-05T18:52:54.441784: step 17659, loss 0.000598464, acc 1
2016-09-05T18:52:54.670075: step 17660, loss 0.000583958, acc 1
2016-09-05T18:52:54.893387: step 17661, loss 0.000581374, acc 1
2016-09-05T18:52:55.132152: step 17662, loss 0.000686845, acc 1
2016-09-05T18:52:55.330796: step 17663, loss 0.000590237, acc 1
2016-09-05T18:52:55.540610: step 17664, loss 0.00064186, acc 1
2016-09-05T18:52:55.746965: step 17665, loss 0.000837631, acc 1
2016-09-05T18:52:55.955517: step 17666, loss 0.000764646, acc 1
2016-09-05T18:52:56.171601: step 17667, loss 0.000701392, acc 1
2016-09-05T18:52:56.397951: step 17668, loss 0.000595829, acc 1
2016-09-05T18:52:56.638225: step 17669, loss 0.000565978, acc 1
2016-09-05T18:52:56.839090: step 17670, loss 0.000579334, acc 1
2016-09-05T18:52:57.039853: step 17671, loss 0.000674172, acc 1
2016-09-05T18:52:57.251947: step 17672, loss 0.000588702, acc 1
2016-09-05T18:52:57.508465: step 17673, loss 0.000638697, acc 1
2016-09-05T18:52:57.718047: step 17674, loss 0.000634353, acc 1
2016-09-05T18:52:57.941203: step 17675, loss 0.000569114, acc 1
2016-09-05T18:52:58.146792: step 17676, loss 0.000622231, acc 1
2016-09-05T18:52:58.350388: step 17677, loss 0.00081297, acc 1
2016-09-05T18:52:58.556944: step 17678, loss 0.00109468, acc 1
2016-09-05T18:52:58.774576: step 17679, loss 0.000621669, acc 1
2016-09-05T18:52:58.987470: step 17680, loss 0.000873088, acc 1
2016-09-05T18:52:59.223411: step 17681, loss 0.00057534, acc 1
2016-09-05T18:52:59.445733: step 17682, loss 0.000858593, acc 1
2016-09-05T18:52:59.659551: step 17683, loss 0.000618845, acc 1
2016-09-05T18:52:59.876982: step 17684, loss 0.000621099, acc 1
2016-09-05T18:53:00.092032: step 17685, loss 0.000616915, acc 1
2016-09-05T18:53:00.326929: step 17686, loss 0.000786248, acc 1
2016-09-05T18:53:00.566296: step 17687, loss 0.000628849, acc 1
2016-09-05T18:53:00.785549: step 17688, loss 0.000986581, acc 1
2016-09-05T18:53:00.991479: step 17689, loss 0.000610056, acc 1
2016-09-05T18:53:01.203272: step 17690, loss 0.000663402, acc 1
2016-09-05T18:53:01.398886: step 17691, loss 0.000573011, acc 1
2016-09-05T18:53:01.635296: step 17692, loss 0.000647855, acc 1
2016-09-05T18:53:01.842812: step 17693, loss 0.000745697, acc 1
2016-09-05T18:53:02.061550: step 17694, loss 0.000557652, acc 1
2016-09-05T18:53:02.280158: step 17695, loss 0.000564294, acc 1
2016-09-05T18:53:02.482750: step 17696, loss 0.000554966, acc 1
2016-09-05T18:53:02.696406: step 17697, loss 0.000568883, acc 1
2016-09-05T18:53:02.905922: step 17698, loss 0.000846406, acc 1
2016-09-05T18:53:03.131960: step 17699, loss 0.000793367, acc 1
2016-09-05T18:53:03.354558: step 17700, loss 0.000872447, acc 1

Evaluation:
2016-09-05T18:53:03.983509: step 17700, loss 1.65125, acc 0.709

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-17700

2016-09-05T18:53:04.633324: step 17701, loss 0.000834437, acc 1
2016-09-05T18:53:04.849716: step 17702, loss 0.000740421, acc 1
2016-09-05T18:53:05.050906: step 17703, loss 0.000696161, acc 1
2016-09-05T18:53:05.296213: step 17704, loss 0.000607765, acc 1
2016-09-05T18:53:05.510162: step 17705, loss 0.000747879, acc 1
2016-09-05T18:53:05.723276: step 17706, loss 0.000985979, acc 1
2016-09-05T18:53:05.940441: step 17707, loss 0.000918717, acc 1
2016-09-05T18:53:06.168256: step 17708, loss 0.000660448, acc 1
2016-09-05T18:53:06.379916: step 17709, loss 0.000779957, acc 1
2016-09-05T18:53:06.593758: step 17710, loss 0.000553572, acc 1
2016-09-05T18:53:06.800331: step 17711, loss 0.000558811, acc 1
2016-09-05T18:53:06.999643: step 17712, loss 0.000803086, acc 1
2016-09-05T18:53:07.216497: step 17713, loss 0.000774834, acc 1
2016-09-05T18:53:07.419990: step 17714, loss 0.000597325, acc 1
2016-09-05T18:53:07.645830: step 17715, loss 0.000800673, acc 1
2016-09-05T18:53:07.869328: step 17716, loss 0.000799963, acc 1
2016-09-05T18:53:08.090348: step 17717, loss 0.000580561, acc 1
2016-09-05T18:53:08.329355: step 17718, loss 0.000643054, acc 1
2016-09-05T18:53:08.550071: step 17719, loss 0.000622263, acc 1
2016-09-05T18:53:08.777796: step 17720, loss 0.000577157, acc 1
2016-09-05T18:53:09.001709: step 17721, loss 0.000658264, acc 1
2016-09-05T18:53:09.213302: step 17722, loss 0.000848912, acc 1
2016-09-05T18:53:09.456218: step 17723, loss 0.000621197, acc 1
2016-09-05T18:53:09.691603: step 17724, loss 0.000598723, acc 1
2016-09-05T18:53:09.936379: step 17725, loss 0.000687391, acc 1
2016-09-05T18:53:10.161903: step 17726, loss 0.000895902, acc 1
2016-09-05T18:53:10.367857: step 17727, loss 0.000745175, acc 1
2016-09-05T18:53:10.577114: step 17728, loss 0.00194594, acc 1
2016-09-05T18:53:10.793645: step 17729, loss 0.000586015, acc 1
2016-09-05T18:53:10.989535: step 17730, loss 0.000653315, acc 1
2016-09-05T18:53:11.209867: step 17731, loss 0.000601477, acc 1
2016-09-05T18:53:11.419524: step 17732, loss 0.000794193, acc 1
2016-09-05T18:53:11.649393: step 17733, loss 0.000591101, acc 1
2016-09-05T18:53:11.861325: step 17734, loss 0.000649795, acc 1
2016-09-05T18:53:12.080628: step 17735, loss 0.000702848, acc 1
2016-09-05T18:53:12.307406: step 17736, loss 0.000679125, acc 1
2016-09-05T18:53:12.532675: step 17737, loss 0.000822596, acc 1
2016-09-05T18:53:12.765150: step 17738, loss 0.000618938, acc 1
2016-09-05T18:53:12.986538: step 17739, loss 0.000626541, acc 1
2016-09-05T18:53:13.246066: step 17740, loss 0.000942735, acc 1
2016-09-05T18:53:13.461122: step 17741, loss 0.000595478, acc 1
2016-09-05T18:53:13.667113: step 17742, loss 0.000575808, acc 1
2016-09-05T18:53:13.880382: step 17743, loss 0.000583521, acc 1
2016-09-05T18:53:14.081419: step 17744, loss 0.000712692, acc 1
2016-09-05T18:53:14.285559: step 17745, loss 0.000580301, acc 1
2016-09-05T18:53:14.491673: step 17746, loss 0.000661714, acc 1
2016-09-05T18:53:14.698898: step 17747, loss 0.000648301, acc 1
2016-09-05T18:53:14.958187: step 17748, loss 0.000602317, acc 1
2016-09-05T18:53:15.209079: step 17749, loss 0.000573356, acc 1
2016-09-05T18:53:15.426187: step 17750, loss 0.000946591, acc 1
2016-09-05T18:53:15.700971: step 17751, loss 0.00074676, acc 1
2016-09-05T18:53:15.908595: step 17752, loss 0.000575493, acc 1
2016-09-05T18:53:16.119259: step 17753, loss 0.00132405, acc 1
2016-09-05T18:53:16.333899: step 17754, loss 0.00084033, acc 1
2016-09-05T18:53:16.559433: step 17755, loss 0.000590813, acc 1
2016-09-05T18:53:16.785400: step 17756, loss 0.00062981, acc 1
2016-09-05T18:53:17.007197: step 17757, loss 0.00057621, acc 1
2016-09-05T18:53:17.206696: step 17758, loss 0.000561738, acc 1
2016-09-05T18:53:17.424407: step 17759, loss 0.000639541, acc 1
2016-09-05T18:53:17.631528: step 17760, loss 0.000583692, acc 1
2016-09-05T18:53:17.843251: step 17761, loss 0.000725548, acc 1
2016-09-05T18:53:18.069700: step 17762, loss 0.000611868, acc 1
2016-09-05T18:53:18.308802: step 17763, loss 0.000663474, acc 1
2016-09-05T18:53:18.521179: step 17764, loss 0.000597515, acc 1
2016-09-05T18:53:18.714583: step 17765, loss 0.000735616, acc 1
2016-09-05T18:53:18.923307: step 17766, loss 0.000653707, acc 1
2016-09-05T18:53:19.137579: step 17767, loss 0.00058141, acc 1
2016-09-05T18:53:19.370059: step 17768, loss 0.000633181, acc 1
2016-09-05T18:53:19.590490: step 17769, loss 0.000564326, acc 1
2016-09-05T18:53:19.823682: step 17770, loss 0.00135815, acc 1
2016-09-05T18:53:20.032691: step 17771, loss 0.000844114, acc 1
2016-09-05T18:53:20.254878: step 17772, loss 0.000569038, acc 1
2016-09-05T18:53:20.464667: step 17773, loss 0.000561934, acc 1
2016-09-05T18:53:20.688408: step 17774, loss 0.000635126, acc 1
2016-09-05T18:53:20.893352: step 17775, loss 0.000558189, acc 1
2016-09-05T18:53:21.096712: step 17776, loss 0.000774993, acc 1
2016-09-05T18:53:21.307427: step 17777, loss 0.000708783, acc 1
2016-09-05T18:53:21.529419: step 17778, loss 0.000634601, acc 1
2016-09-05T18:53:21.762190: step 17779, loss 0.000616192, acc 1
2016-09-05T18:53:21.968839: step 17780, loss 0.000600958, acc 1
2016-09-05T18:53:22.199224: step 17781, loss 0.000585551, acc 1
2016-09-05T18:53:22.413905: step 17782, loss 0.000703748, acc 1
2016-09-05T18:53:22.653940: step 17783, loss 0.000574257, acc 1
2016-09-05T18:53:22.867939: step 17784, loss 0.000587191, acc 1
2016-09-05T18:53:23.089120: step 17785, loss 0.000563874, acc 1
2016-09-05T18:53:23.315528: step 17786, loss 0.00054294, acc 1
2016-09-05T18:53:23.526519: step 17787, loss 0.000593548, acc 1
2016-09-05T18:53:23.750466: step 17788, loss 0.000617666, acc 1
2016-09-05T18:53:23.969792: step 17789, loss 0.000968617, acc 1
2016-09-05T18:53:24.181128: step 17790, loss 0.000585005, acc 1
2016-09-05T18:53:24.397600: step 17791, loss 0.000886504, acc 1
2016-09-05T18:53:24.621410: step 17792, loss 0.000578109, acc 1
2016-09-05T18:53:24.833010: step 17793, loss 0.000723284, acc 1
2016-09-05T18:53:25.057418: step 17794, loss 0.00090493, acc 1
2016-09-05T18:53:25.276316: step 17795, loss 0.000574384, acc 1
2016-09-05T18:53:25.497354: step 17796, loss 0.000847824, acc 1
2016-09-05T18:53:25.699839: step 17797, loss 0.000545619, acc 1
2016-09-05T18:53:25.920213: step 17798, loss 0.000578146, acc 1
2016-09-05T18:53:26.138073: step 17799, loss 0.000747495, acc 1
2016-09-05T18:53:26.383028: step 17800, loss 0.00059032, acc 1

Evaluation:
2016-09-05T18:53:26.990222: step 17800, loss 1.64897, acc 0.712

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-17800

2016-09-05T18:53:27.736159: step 17801, loss 0.00069728, acc 1
2016-09-05T18:53:27.955672: step 17802, loss 0.000639654, acc 1
2016-09-05T18:53:28.179858: step 17803, loss 0.000612599, acc 1
2016-09-05T18:53:28.407390: step 17804, loss 0.000607329, acc 1
2016-09-05T18:53:28.617847: step 17805, loss 0.000698638, acc 1
2016-09-05T18:53:28.818805: step 17806, loss 0.000550283, acc 1
2016-09-05T18:53:29.045800: step 17807, loss 0.000692927, acc 1
2016-09-05T18:53:29.247499: step 17808, loss 0.000558017, acc 1
2016-09-05T18:53:29.460001: step 17809, loss 0.000600119, acc 1
2016-09-05T18:53:29.670951: step 17810, loss 0.00060674, acc 1
2016-09-05T18:53:29.920862: step 17811, loss 0.000560457, acc 1
2016-09-05T18:53:30.136042: step 17812, loss 0.000579899, acc 1
2016-09-05T18:53:30.392066: step 17813, loss 0.000563416, acc 1
2016-09-05T18:53:30.629525: step 17814, loss 0.000686716, acc 1
2016-09-05T18:53:30.834241: step 17815, loss 0.000585004, acc 1
2016-09-05T18:53:31.056044: step 17816, loss 0.00128453, acc 1
2016-09-05T18:53:31.266323: step 17817, loss 0.000704756, acc 1
2016-09-05T18:53:31.475890: step 17818, loss 0.000682769, acc 1
2016-09-05T18:53:31.689910: step 17819, loss 0.000658503, acc 1
2016-09-05T18:53:31.904100: step 17820, loss 0.000592972, acc 1
2016-09-05T18:53:32.097472: step 17821, loss 0.000935768, acc 1
2016-09-05T18:53:32.318195: step 17822, loss 0.000648295, acc 1
2016-09-05T18:53:32.562956: step 17823, loss 0.000585556, acc 1
2016-09-05T18:53:32.801464: step 17824, loss 0.000642077, acc 1
2016-09-05T18:53:33.046462: step 17825, loss 0.000900102, acc 1
2016-09-05T18:53:33.247552: step 17826, loss 0.000543796, acc 1
2016-09-05T18:53:33.461123: step 17827, loss 0.000590398, acc 1
2016-09-05T18:53:33.683072: step 17828, loss 0.00083137, acc 1
2016-09-05T18:53:33.933072: step 17829, loss 0.000543723, acc 1
2016-09-05T18:53:34.135980: step 17830, loss 0.000995887, acc 1
2016-09-05T18:53:34.364613: step 17831, loss 0.000644869, acc 1
2016-09-05T18:53:34.564078: step 17832, loss 0.000601609, acc 1
2016-09-05T18:53:34.764326: step 17833, loss 0.000679119, acc 1
2016-09-05T18:53:34.980208: step 17834, loss 0.00647213, acc 1
2016-09-05T18:53:35.183720: step 17835, loss 0.0010408, acc 1
2016-09-05T18:53:35.384274: step 17836, loss 0.000639143, acc 1
2016-09-05T18:53:35.588914: step 17837, loss 0.00098046, acc 1
2016-09-05T18:53:35.837450: step 17838, loss 0.000687296, acc 1
2016-09-05T18:53:36.069395: step 17839, loss 0.000677794, acc 1
2016-09-05T18:53:36.278823: step 17840, loss 0.00262383, acc 1
2016-09-05T18:53:36.523030: step 17841, loss 0.00093269, acc 1
2016-09-05T18:53:36.752315: step 17842, loss 0.000674146, acc 1
2016-09-05T18:53:36.990973: step 17843, loss 0.000679707, acc 1
2016-09-05T18:53:37.200694: step 17844, loss 0.000665118, acc 1
2016-09-05T18:53:37.403070: step 17845, loss 0.000683844, acc 1
2016-09-05T18:53:37.621791: step 17846, loss 0.000718371, acc 1
2016-09-05T18:53:37.838580: step 17847, loss 0.000736967, acc 1
2016-09-05T18:53:38.011427: step 17848, loss 0.0007112, acc 1
2016-09-05T18:53:38.219810: step 17849, loss 0.000785852, acc 1
2016-09-05T18:53:38.430022: step 17850, loss 0.00121618, acc 1
2016-09-05T18:53:38.648384: step 17851, loss 0.000794266, acc 1
2016-09-05T18:53:38.893725: step 17852, loss 0.000762911, acc 1
2016-09-05T18:53:39.107875: step 17853, loss 0.000959017, acc 1
2016-09-05T18:53:39.308727: step 17854, loss 0.000802232, acc 1
2016-09-05T18:53:39.504753: step 17855, loss 0.00077533, acc 1
2016-09-05T18:53:39.710166: step 17856, loss 0.000775179, acc 1
2016-09-05T18:53:39.932418: step 17857, loss 0.000873318, acc 1
2016-09-05T18:53:40.148050: step 17858, loss 0.000868087, acc 1
2016-09-05T18:53:40.380643: step 17859, loss 0.000827495, acc 1
2016-09-05T18:53:40.606685: step 17860, loss 0.000823946, acc 1
2016-09-05T18:53:40.807656: step 17861, loss 0.000824514, acc 1
2016-09-05T18:53:41.018755: step 17862, loss 0.000826463, acc 1
2016-09-05T18:53:41.251000: step 17863, loss 0.000775935, acc 1
2016-09-05T18:53:41.464709: step 17864, loss 0.000887883, acc 1
2016-09-05T18:53:41.714732: step 17865, loss 0.000786793, acc 1
2016-09-05T18:53:41.931215: step 17866, loss 0.00199856, acc 1
2016-09-05T18:53:42.141786: step 17867, loss 0.00081579, acc 1
2016-09-05T18:53:42.359664: step 17868, loss 0.000778261, acc 1
2016-09-05T18:53:42.589947: step 17869, loss 0.00101461, acc 1
2016-09-05T18:53:42.817925: step 17870, loss 0.000782167, acc 1
2016-09-05T18:53:43.032471: step 17871, loss 0.00084886, acc 1
2016-09-05T18:53:43.255192: step 17872, loss 0.000800338, acc 1
2016-09-05T18:53:43.473449: step 17873, loss 0.00181491, acc 1
2016-09-05T18:53:43.702686: step 17874, loss 0.000775867, acc 1
2016-09-05T18:53:43.913582: step 17875, loss 0.00081996, acc 1
2016-09-05T18:53:44.105425: step 17876, loss 0.00101134, acc 1
2016-09-05T18:53:44.318640: step 17877, loss 0.000979992, acc 1
2016-09-05T18:53:44.540072: step 17878, loss 0.000888543, acc 1
2016-09-05T18:53:44.765037: step 17879, loss 0.00102286, acc 1
2016-09-05T18:53:44.966013: step 17880, loss 0.000815541, acc 1
2016-09-05T18:53:45.177089: step 17881, loss 0.00126251, acc 1
2016-09-05T18:53:45.387638: step 17882, loss 0.000861455, acc 1
2016-09-05T18:53:45.602015: step 17883, loss 0.000856462, acc 1
2016-09-05T18:53:45.816903: step 17884, loss 0.000922186, acc 1
2016-09-05T18:53:46.031012: step 17885, loss 0.000971644, acc 1
2016-09-05T18:53:46.257433: step 17886, loss 0.00114288, acc 1
2016-09-05T18:53:46.486316: step 17887, loss 0.00105357, acc 1
2016-09-05T18:53:46.690788: step 17888, loss 0.00224947, acc 1
2016-09-05T18:53:46.921522: step 17889, loss 0.000859719, acc 1
2016-09-05T18:53:47.137505: step 17890, loss 0.000821263, acc 1
2016-09-05T18:53:47.377008: step 17891, loss 0.000939734, acc 1
2016-09-05T18:53:47.590513: step 17892, loss 0.000833847, acc 1
2016-09-05T18:53:47.784398: step 17893, loss 0.000805961, acc 1
2016-09-05T18:53:47.987004: step 17894, loss 0.000828757, acc 1
2016-09-05T18:53:48.198874: step 17895, loss 0.000865395, acc 1
2016-09-05T18:53:48.446056: step 17896, loss 0.000893405, acc 1
2016-09-05T18:53:48.677442: step 17897, loss 0.000842667, acc 1
2016-09-05T18:53:48.906546: step 17898, loss 0.00213376, acc 1
2016-09-05T18:53:49.128897: step 17899, loss 0.000893306, acc 1
2016-09-05T18:53:49.350898: step 17900, loss 0.000826835, acc 1

Evaluation:
2016-09-05T18:53:49.947087: step 17900, loss 1.91502, acc 0.711

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-17900

2016-09-05T18:53:50.622649: step 17901, loss 0.00123313, acc 1
2016-09-05T18:53:50.882786: step 17902, loss 0.000820015, acc 1
2016-09-05T18:53:51.106436: step 17903, loss 0.000833807, acc 1
2016-09-05T18:53:51.319097: step 17904, loss 0.000832098, acc 1
2016-09-05T18:53:51.528081: step 17905, loss 0.000865903, acc 1
2016-09-05T18:53:51.739629: step 17906, loss 0.000830769, acc 1
2016-09-05T18:53:51.939949: step 17907, loss 0.000856328, acc 1
2016-09-05T18:53:52.163861: step 17908, loss 0.000843246, acc 1
2016-09-05T18:53:52.376458: step 17909, loss 0.000826739, acc 1
2016-09-05T18:53:52.608643: step 17910, loss 0.000830536, acc 1
2016-09-05T18:53:52.806805: step 17911, loss 0.00082053, acc 1
2016-09-05T18:53:53.034798: step 17912, loss 0.000826145, acc 1
2016-09-05T18:53:53.246516: step 17913, loss 0.00121064, acc 1
2016-09-05T18:53:53.471456: step 17914, loss 0.000815928, acc 1
2016-09-05T18:53:53.690300: step 17915, loss 0.000802161, acc 1
2016-09-05T18:53:53.905337: step 17916, loss 0.000832728, acc 1
2016-09-05T18:53:54.138745: step 17917, loss 0.000801849, acc 1
2016-09-05T18:53:54.349037: step 17918, loss 0.0008766, acc 1
2016-09-05T18:53:54.568863: step 17919, loss 0.00095503, acc 1
2016-09-05T18:53:54.772943: step 17920, loss 0.000795384, acc 1
2016-09-05T18:53:54.987512: step 17921, loss 0.000803627, acc 1
2016-09-05T18:53:55.193772: step 17922, loss 0.000789558, acc 1
2016-09-05T18:53:55.431129: step 17923, loss 0.00114749, acc 1
2016-09-05T18:53:55.640370: step 17924, loss 0.000808204, acc 1
2016-09-05T18:53:55.848028: step 17925, loss 0.000784527, acc 1
2016-09-05T18:53:56.046622: step 17926, loss 0.000755087, acc 1
2016-09-05T18:53:56.253476: step 17927, loss 0.000741798, acc 1
2016-09-05T18:53:56.451946: step 17928, loss 0.000770094, acc 1
2016-09-05T18:53:56.657060: step 17929, loss 0.000799217, acc 1
2016-09-05T18:53:56.865236: step 17930, loss 0.00076729, acc 1
2016-09-05T18:53:57.098224: step 17931, loss 0.000729436, acc 1
2016-09-05T18:53:57.334102: step 17932, loss 0.000797303, acc 1
2016-09-05T18:53:57.551280: step 17933, loss 0.000872074, acc 1
2016-09-05T18:53:57.755312: step 17934, loss 0.000737517, acc 1
2016-09-05T18:53:57.956040: step 17935, loss 0.000741728, acc 1
2016-09-05T18:53:58.171379: step 17936, loss 0.000730906, acc 1
2016-09-05T18:53:58.375882: step 17937, loss 0.0007024, acc 1
2016-09-05T18:53:58.610550: step 17938, loss 0.000697213, acc 1
2016-09-05T18:53:58.825546: step 17939, loss 0.00100347, acc 1
2016-09-05T18:53:59.040459: step 17940, loss 0.000789399, acc 1
2016-09-05T18:53:59.269642: step 17941, loss 0.000968464, acc 1
2016-09-05T18:53:59.490270: step 17942, loss 0.000701743, acc 1
2016-09-05T18:53:59.722736: step 17943, loss 0.000711664, acc 1
2016-09-05T18:53:59.939853: step 17944, loss 0.000800074, acc 1
2016-09-05T18:54:00.154180: step 17945, loss 0.000788042, acc 1
2016-09-05T18:54:00.387914: step 17946, loss 0.00069284, acc 1
2016-09-05T18:54:00.592751: step 17947, loss 0.000739278, acc 1
2016-09-05T18:54:00.791496: step 17948, loss 0.000679528, acc 1
2016-09-05T18:54:01.005719: step 17949, loss 0.000771565, acc 1
2016-09-05T18:54:01.220787: step 17950, loss 0.000775777, acc 1
2016-09-05T18:54:01.434951: step 17951, loss 0.000645383, acc 1
2016-09-05T18:54:01.660077: step 17952, loss 0.000635204, acc 1
2016-09-05T18:54:01.898887: step 17953, loss 0.000700145, acc 1
2016-09-05T18:54:02.103464: step 17954, loss 0.000830138, acc 1
2016-09-05T18:54:02.313715: step 17955, loss 0.000786915, acc 1
2016-09-05T18:54:02.521677: step 17956, loss 0.0007102, acc 1
2016-09-05T18:54:02.754039: step 17957, loss 0.000715781, acc 1
2016-09-05T18:54:02.976313: step 17958, loss 0.00063807, acc 1
2016-09-05T18:54:03.203806: step 17959, loss 0.000666174, acc 1
2016-09-05T18:54:03.437288: step 17960, loss 0.000644935, acc 1
2016-09-05T18:54:03.648533: step 17961, loss 0.000710008, acc 1
2016-09-05T18:54:03.866153: step 17962, loss 0.000613319, acc 1
2016-09-05T18:54:04.068831: step 17963, loss 0.000609712, acc 1
2016-09-05T18:54:04.312188: step 17964, loss 0.000608147, acc 1
2016-09-05T18:54:04.519689: step 17965, loss 0.00060817, acc 1
2016-09-05T18:54:04.729131: step 17966, loss 0.000643649, acc 1
2016-09-05T18:54:04.936107: step 17967, loss 0.00100678, acc 1
2016-09-05T18:54:05.168155: step 17968, loss 0.000733347, acc 1
2016-09-05T18:54:05.469899: step 17969, loss 0.000624622, acc 1
2016-09-05T18:54:05.706957: step 17970, loss 0.000605189, acc 1
2016-09-05T18:54:05.954961: step 17971, loss 0.000635136, acc 1
2016-09-05T18:54:06.151664: step 17972, loss 0.00062596, acc 1
2016-09-05T18:54:06.362592: step 17973, loss 0.00059899, acc 1
2016-09-05T18:54:06.576951: step 17974, loss 0.000610418, acc 1
2016-09-05T18:54:06.802140: step 17975, loss 0.000635063, acc 1
2016-09-05T18:54:07.029902: step 17976, loss 0.000635016, acc 1
2016-09-05T18:54:07.229525: step 17977, loss 0.000739433, acc 1
2016-09-05T18:54:07.442049: step 17978, loss 0.000581328, acc 1
2016-09-05T18:54:07.653399: step 17979, loss 0.000595437, acc 1
2016-09-05T18:54:07.874738: step 17980, loss 0.000586631, acc 1
2016-09-05T18:54:08.086114: step 17981, loss 0.000617719, acc 1
2016-09-05T18:54:08.313056: step 17982, loss 0.000754019, acc 1
2016-09-05T18:54:08.544145: step 17983, loss 0.000767407, acc 1
2016-09-05T18:54:08.770139: step 17984, loss 0.000542583, acc 1
2016-09-05T18:54:08.967521: step 17985, loss 0.000640658, acc 1
2016-09-05T18:54:09.177135: step 17986, loss 0.000888165, acc 1
2016-09-05T18:54:09.399206: step 17987, loss 0.000596869, acc 1
2016-09-05T18:54:09.622925: step 17988, loss 0.000640348, acc 1
2016-09-05T18:54:09.835117: step 17989, loss 0.0015919, acc 1
2016-09-05T18:54:10.067374: step 17990, loss 0.00075686, acc 1
2016-09-05T18:54:10.282366: step 17991, loss 0.000556476, acc 1
2016-09-05T18:54:10.499648: step 17992, loss 0.000620611, acc 1
2016-09-05T18:54:10.704878: step 17993, loss 0.00066317, acc 1
2016-09-05T18:54:10.914154: step 17994, loss 0.00091181, acc 1
2016-09-05T18:54:11.147259: step 17995, loss 0.000657994, acc 1
2016-09-05T18:54:11.377039: step 17996, loss 0.00086063, acc 1
2016-09-05T18:54:11.593954: step 17997, loss 0.00056794, acc 1
2016-09-05T18:54:11.802635: step 17998, loss 0.000575452, acc 1
2016-09-05T18:54:12.051578: step 17999, loss 0.000603432, acc 1
2016-09-05T18:54:12.280206: step 18000, loss 0.000843952, acc 1

Evaluation:
2016-09-05T18:54:12.871772: step 18000, loss 1.6486, acc 0.714

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-18000

2016-09-05T18:54:13.585739: step 18001, loss 0.000671271, acc 1
2016-09-05T18:54:13.847109: step 18002, loss 0.000572276, acc 1
2016-09-05T18:54:14.081147: step 18003, loss 0.000848273, acc 1
2016-09-05T18:54:14.286567: step 18004, loss 0.000629328, acc 1
2016-09-05T18:54:14.509212: step 18005, loss 0.000608513, acc 1
2016-09-05T18:54:14.708859: step 18006, loss 0.00066674, acc 1
2016-09-05T18:54:14.914885: step 18007, loss 0.000579382, acc 1
2016-09-05T18:54:15.130586: step 18008, loss 0.000783849, acc 1
2016-09-05T18:54:15.350297: step 18009, loss 0.000592636, acc 1
2016-09-05T18:54:15.559918: step 18010, loss 0.000597037, acc 1
2016-09-05T18:54:15.785995: step 18011, loss 0.00058272, acc 1
2016-09-05T18:54:15.993813: step 18012, loss 0.000540596, acc 1
2016-09-05T18:54:16.222513: step 18013, loss 0.000557273, acc 1
2016-09-05T18:54:16.450351: step 18014, loss 0.000565438, acc 1
2016-09-05T18:54:16.658027: step 18015, loss 0.00060801, acc 1
2016-09-05T18:54:16.862423: step 18016, loss 0.000551461, acc 1
2016-09-05T18:54:17.078534: step 18017, loss 0.000829102, acc 1
2016-09-05T18:54:17.291266: step 18018, loss 0.00055394, acc 1
2016-09-05T18:54:17.509349: step 18019, loss 0.00110961, acc 1
2016-09-05T18:54:17.744376: step 18020, loss 0.000776756, acc 1
2016-09-05T18:54:17.953453: step 18021, loss 0.000591921, acc 1
2016-09-05T18:54:18.175461: step 18022, loss 0.00078246, acc 1
2016-09-05T18:54:18.381902: step 18023, loss 0.000599257, acc 1
2016-09-05T18:54:18.590452: step 18024, loss 0.00054149, acc 1
2016-09-05T18:54:18.801039: step 18025, loss 0.00056564, acc 1
2016-09-05T18:54:19.034568: step 18026, loss 0.000730426, acc 1
2016-09-05T18:54:19.261337: step 18027, loss 0.000797104, acc 1
2016-09-05T18:54:19.479366: step 18028, loss 0.000662692, acc 1
2016-09-05T18:54:19.686124: step 18029, loss 0.000634745, acc 1
2016-09-05T18:54:19.895068: step 18030, loss 0.000642224, acc 1
2016-09-05T18:54:20.128083: step 18031, loss 0.000701394, acc 1
2016-09-05T18:54:20.355510: step 18032, loss 0.000606616, acc 1
2016-09-05T18:54:20.597538: step 18033, loss 0.000662756, acc 1
2016-09-05T18:54:20.801943: step 18034, loss 0.000553288, acc 1
2016-09-05T18:54:21.020019: step 18035, loss 0.000655244, acc 1
2016-09-05T18:54:21.240766: step 18036, loss 0.000625198, acc 1
2016-09-05T18:54:21.474480: step 18037, loss 0.000558909, acc 1
2016-09-05T18:54:21.719015: step 18038, loss 0.00077619, acc 1
2016-09-05T18:54:21.938519: step 18039, loss 0.000564935, acc 1
2016-09-05T18:54:22.150064: step 18040, loss 0.000633459, acc 1
2016-09-05T18:54:22.393066: step 18041, loss 0.000667684, acc 1
2016-09-05T18:54:22.530761: step 18042, loss 0.00085743, acc 1
2016-09-05T18:54:22.742621: step 18043, loss 0.000742582, acc 1
2016-09-05T18:54:22.956810: step 18044, loss 0.000565615, acc 1
2016-09-05T18:54:23.189097: step 18045, loss 0.000529157, acc 1
2016-09-05T18:54:23.410773: step 18046, loss 0.000687749, acc 1
2016-09-05T18:54:23.619352: step 18047, loss 0.000607127, acc 1
2016-09-05T18:54:23.837761: step 18048, loss 0.000768709, acc 1
2016-09-05T18:54:24.063767: step 18049, loss 0.00058236, acc 1
2016-09-05T18:54:24.269864: step 18050, loss 0.000565961, acc 1
2016-09-05T18:54:24.470150: step 18051, loss 0.000520514, acc 1
2016-09-05T18:54:24.693030: step 18052, loss 0.000551608, acc 1
2016-09-05T18:54:24.903661: step 18053, loss 0.000583005, acc 1
2016-09-05T18:54:25.125486: step 18054, loss 0.000697201, acc 1
2016-09-05T18:54:25.361872: step 18055, loss 0.000619333, acc 1
2016-09-05T18:54:25.566664: step 18056, loss 0.000583646, acc 1
2016-09-05T18:54:25.815413: step 18057, loss 0.000627657, acc 1
2016-09-05T18:54:26.058114: step 18058, loss 0.000762794, acc 1
2016-09-05T18:54:26.272846: step 18059, loss 0.00055029, acc 1
2016-09-05T18:54:26.497261: step 18060, loss 0.000732189, acc 1
2016-09-05T18:54:26.704970: step 18061, loss 0.0005463, acc 1
2016-09-05T18:54:26.923648: step 18062, loss 0.000552641, acc 1
2016-09-05T18:54:27.156698: step 18063, loss 0.000550728, acc 1
2016-09-05T18:54:27.379726: step 18064, loss 0.000516961, acc 1
2016-09-05T18:54:27.593838: step 18065, loss 0.000599387, acc 1
2016-09-05T18:54:27.814421: step 18066, loss 0.000502807, acc 1
2016-09-05T18:54:28.033476: step 18067, loss 0.000526567, acc 1
2016-09-05T18:54:28.265121: step 18068, loss 0.00059684, acc 1
2016-09-05T18:54:28.475677: step 18069, loss 0.000550295, acc 1
2016-09-05T18:54:28.682872: step 18070, loss 0.000601059, acc 1
2016-09-05T18:54:28.879463: step 18071, loss 0.000797309, acc 1
2016-09-05T18:54:29.093489: step 18072, loss 0.000576373, acc 1
2016-09-05T18:54:29.308203: step 18073, loss 0.000700252, acc 1
2016-09-05T18:54:29.534028: step 18074, loss 0.000579777, acc 1
2016-09-05T18:54:29.783493: step 18075, loss 0.000546552, acc 1
2016-09-05T18:54:29.991426: step 18076, loss 0.000772107, acc 1
2016-09-05T18:54:30.200561: step 18077, loss 0.000529903, acc 1
2016-09-05T18:54:30.410560: step 18078, loss 0.000529532, acc 1
2016-09-05T18:54:30.618508: step 18079, loss 0.000834327, acc 1
2016-09-05T18:54:30.831917: step 18080, loss 0.00054769, acc 1
2016-09-05T18:54:31.077446: step 18081, loss 0.000523715, acc 1
2016-09-05T18:54:31.322133: step 18082, loss 0.000592989, acc 1
2016-09-05T18:54:31.564266: step 18083, loss 0.000661245, acc 1
2016-09-05T18:54:31.789387: step 18084, loss 0.000532231, acc 1
2016-09-05T18:54:31.992836: step 18085, loss 0.00098625, acc 1
2016-09-05T18:54:32.213901: step 18086, loss 0.000609947, acc 1
2016-09-05T18:54:32.423429: step 18087, loss 0.00071098, acc 1
2016-09-05T18:54:32.689432: step 18088, loss 0.000508343, acc 1
2016-09-05T18:54:32.910290: step 18089, loss 0.000521971, acc 1
2016-09-05T18:54:33.123596: step 18090, loss 0.000659522, acc 1
2016-09-05T18:54:33.330080: step 18091, loss 0.000795217, acc 1
2016-09-05T18:54:33.596961: step 18092, loss 0.000657116, acc 1
2016-09-05T18:54:33.825370: step 18093, loss 0.000513308, acc 1
2016-09-05T18:54:34.044241: step 18094, loss 0.000616546, acc 1
2016-09-05T18:54:34.261714: step 18095, loss 0.000531897, acc 1
2016-09-05T18:54:34.489643: step 18096, loss 0.000727081, acc 1
2016-09-05T18:54:34.725725: step 18097, loss 0.000563073, acc 1
2016-09-05T18:54:34.924449: step 18098, loss 0.00110983, acc 1
2016-09-05T18:54:35.137189: step 18099, loss 0.000708223, acc 1
2016-09-05T18:54:35.341120: step 18100, loss 0.000542605, acc 1

Evaluation:
2016-09-05T18:54:35.920340: step 18100, loss 1.63628, acc 0.715

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-18100

2016-09-05T18:54:36.665056: step 18101, loss 0.000520641, acc 1
2016-09-05T18:54:36.882049: step 18102, loss 0.00061981, acc 1
2016-09-05T18:54:37.100779: step 18103, loss 0.000741258, acc 1
2016-09-05T18:54:37.326922: step 18104, loss 0.000721077, acc 1
2016-09-05T18:54:37.530862: step 18105, loss 0.000547426, acc 1
2016-09-05T18:54:37.771770: step 18106, loss 0.000545546, acc 1
2016-09-05T18:54:37.979829: step 18107, loss 0.00049946, acc 1
2016-09-05T18:54:38.193211: step 18108, loss 0.000551112, acc 1
2016-09-05T18:54:38.430849: step 18109, loss 0.000675365, acc 1
2016-09-05T18:54:38.639454: step 18110, loss 0.000891624, acc 1
2016-09-05T18:54:38.872688: step 18111, loss 0.00053834, acc 1
2016-09-05T18:54:39.093702: step 18112, loss 0.000665566, acc 1
2016-09-05T18:54:39.295531: step 18113, loss 0.000743965, acc 1
2016-09-05T18:54:39.513711: step 18114, loss 0.000612202, acc 1
2016-09-05T18:54:39.743716: step 18115, loss 0.000656796, acc 1
2016-09-05T18:54:39.959868: step 18116, loss 0.000555572, acc 1
2016-09-05T18:54:40.178669: step 18117, loss 0.000563889, acc 1
2016-09-05T18:54:40.377458: step 18118, loss 0.000537429, acc 1
2016-09-05T18:54:40.581399: step 18119, loss 0.000540654, acc 1
2016-09-05T18:54:40.806351: step 18120, loss 0.000501608, acc 1
2016-09-05T18:54:41.034234: step 18121, loss 0.00108104, acc 1
2016-09-05T18:54:41.259914: step 18122, loss 0.000588549, acc 1
2016-09-05T18:54:41.456426: step 18123, loss 0.000520179, acc 1
2016-09-05T18:54:41.669238: step 18124, loss 0.000525745, acc 1
2016-09-05T18:54:41.889275: step 18125, loss 0.000519747, acc 1
2016-09-05T18:54:42.112934: step 18126, loss 0.000508932, acc 1
2016-09-05T18:54:42.327284: step 18127, loss 0.000570554, acc 1
2016-09-05T18:54:42.573659: step 18128, loss 0.000561396, acc 1
2016-09-05T18:54:42.781713: step 18129, loss 0.000644917, acc 1
2016-09-05T18:54:43.016446: step 18130, loss 0.00064209, acc 1
2016-09-05T18:54:43.224789: step 18131, loss 0.000517585, acc 1
2016-09-05T18:54:43.462239: step 18132, loss 0.00050049, acc 1
2016-09-05T18:54:43.718847: step 18133, loss 0.000534837, acc 1
2016-09-05T18:54:43.929069: step 18134, loss 0.000509621, acc 1
2016-09-05T18:54:44.138827: step 18135, loss 0.000747189, acc 1
2016-09-05T18:54:44.354093: step 18136, loss 0.000606223, acc 1
2016-09-05T18:54:44.568694: step 18137, loss 0.000526049, acc 1
2016-09-05T18:54:44.790633: step 18138, loss 0.000554159, acc 1
2016-09-05T18:54:45.037825: step 18139, loss 0.000502572, acc 1
2016-09-05T18:54:45.241150: step 18140, loss 0.000598983, acc 1
2016-09-05T18:54:45.453537: step 18141, loss 0.00055548, acc 1
2016-09-05T18:54:45.746403: step 18142, loss 0.000795682, acc 1
2016-09-05T18:54:45.957062: step 18143, loss 0.000512192, acc 1
2016-09-05T18:54:46.182354: step 18144, loss 0.000621163, acc 1
2016-09-05T18:54:46.397399: step 18145, loss 0.000492095, acc 1
2016-09-05T18:54:46.616975: step 18146, loss 0.000706696, acc 1
2016-09-05T18:54:46.846958: step 18147, loss 0.000683226, acc 1
2016-09-05T18:54:47.066022: step 18148, loss 0.000508507, acc 1
2016-09-05T18:54:47.283732: step 18149, loss 0.000599076, acc 1
2016-09-05T18:54:47.512570: step 18150, loss 0.00116294, acc 1
2016-09-05T18:54:47.760855: step 18151, loss 0.000818138, acc 1
2016-09-05T18:54:47.973732: step 18152, loss 0.000546701, acc 1
2016-09-05T18:54:48.195692: step 18153, loss 0.000548408, acc 1
2016-09-05T18:54:48.398489: step 18154, loss 0.000520231, acc 1
2016-09-05T18:54:48.632207: step 18155, loss 0.000551775, acc 1
2016-09-05T18:54:48.849999: step 18156, loss 0.000516789, acc 1
2016-09-05T18:54:49.057423: step 18157, loss 0.000498319, acc 1
2016-09-05T18:54:49.268776: step 18158, loss 0.000676248, acc 1
2016-09-05T18:54:49.481299: step 18159, loss 0.000661104, acc 1
2016-09-05T18:54:49.688186: step 18160, loss 0.000621151, acc 1
2016-09-05T18:54:49.896645: step 18161, loss 0.000505409, acc 1
2016-09-05T18:54:50.096684: step 18162, loss 0.000490947, acc 1
2016-09-05T18:54:50.303764: step 18163, loss 0.000498262, acc 1
2016-09-05T18:54:50.523619: step 18164, loss 0.00050163, acc 1
2016-09-05T18:54:50.732731: step 18165, loss 0.000550099, acc 1
2016-09-05T18:54:50.955316: step 18166, loss 0.000746838, acc 1
2016-09-05T18:54:51.220731: step 18167, loss 0.00075431, acc 1
2016-09-05T18:54:51.454445: step 18168, loss 0.000470846, acc 1
2016-09-05T18:54:51.672322: step 18169, loss 0.000782803, acc 1
2016-09-05T18:54:51.906631: step 18170, loss 0.000527644, acc 1
2016-09-05T18:54:52.112061: step 18171, loss 0.000893709, acc 1
2016-09-05T18:54:52.328674: step 18172, loss 0.00051672, acc 1
2016-09-05T18:54:52.535366: step 18173, loss 0.000597835, acc 1
2016-09-05T18:54:52.751896: step 18174, loss 0.00059767, acc 1
2016-09-05T18:54:52.976735: step 18175, loss 0.000565146, acc 1
2016-09-05T18:54:53.201056: step 18176, loss 0.000581277, acc 1
2016-09-05T18:54:53.424502: step 18177, loss 0.000833569, acc 1
2016-09-05T18:54:53.624696: step 18178, loss 0.000989214, acc 1
2016-09-05T18:54:53.839972: step 18179, loss 0.000660911, acc 1
2016-09-05T18:54:54.073337: step 18180, loss 0.000607608, acc 1
2016-09-05T18:54:54.305459: step 18181, loss 0.000505456, acc 1
2016-09-05T18:54:54.528773: step 18182, loss 0.00053605, acc 1
2016-09-05T18:54:54.758693: step 18183, loss 0.000765002, acc 1
2016-09-05T18:54:54.968655: step 18184, loss 0.000731984, acc 1
2016-09-05T18:54:55.184472: step 18185, loss 0.000528526, acc 1
2016-09-05T18:54:55.402934: step 18186, loss 0.000539538, acc 1
2016-09-05T18:54:55.635366: step 18187, loss 0.00111483, acc 1
2016-09-05T18:54:55.846649: step 18188, loss 0.000570182, acc 1
2016-09-05T18:54:56.044575: step 18189, loss 0.000569155, acc 1
2016-09-05T18:54:56.246978: step 18190, loss 0.00063854, acc 1
2016-09-05T18:54:56.449480: step 18191, loss 0.000525706, acc 1
2016-09-05T18:54:56.675813: step 18192, loss 0.00127402, acc 1
2016-09-05T18:54:56.878631: step 18193, loss 0.000610638, acc 1
2016-09-05T18:54:57.103994: step 18194, loss 0.000511289, acc 1
2016-09-05T18:54:57.327506: step 18195, loss 0.000631537, acc 1
2016-09-05T18:54:57.554950: step 18196, loss 0.00162899, acc 1
2016-09-05T18:54:57.758693: step 18197, loss 0.000594303, acc 1
2016-09-05T18:54:57.988404: step 18198, loss 0.00067102, acc 1
2016-09-05T18:54:58.207286: step 18199, loss 0.000632611, acc 1
2016-09-05T18:54:58.432145: step 18200, loss 0.000622588, acc 1

Evaluation:
2016-09-05T18:54:59.034112: step 18200, loss 1.71799, acc 0.713

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-18200

2016-09-05T18:54:59.729743: step 18201, loss 0.000605718, acc 1
2016-09-05T18:54:59.945711: step 18202, loss 0.000695435, acc 1
2016-09-05T18:55:00.160167: step 18203, loss 0.00129408, acc 1
2016-09-05T18:55:00.396371: step 18204, loss 0.000558588, acc 1
2016-09-05T18:55:00.599398: step 18205, loss 0.000753122, acc 1
2016-09-05T18:55:00.805408: step 18206, loss 0.00054857, acc 1
2016-09-05T18:55:01.017508: step 18207, loss 0.000642496, acc 1
2016-09-05T18:55:01.232693: step 18208, loss 0.00070523, acc 1
2016-09-05T18:55:01.451368: step 18209, loss 0.000627981, acc 1
2016-09-05T18:55:01.699117: step 18210, loss 0.000622651, acc 1
2016-09-05T18:55:01.901386: step 18211, loss 0.000562176, acc 1
2016-09-05T18:55:02.111235: step 18212, loss 0.000853304, acc 1
2016-09-05T18:55:02.323230: step 18213, loss 0.000552948, acc 1
2016-09-05T18:55:02.544651: step 18214, loss 0.000732803, acc 1
2016-09-05T18:55:02.793378: step 18215, loss 0.000684921, acc 1
2016-09-05T18:55:03.011100: step 18216, loss 0.000576218, acc 1
2016-09-05T18:55:03.229285: step 18217, loss 0.000599209, acc 1
2016-09-05T18:55:03.453014: step 18218, loss 0.000601126, acc 1
2016-09-05T18:55:03.657030: step 18219, loss 0.000594896, acc 1
2016-09-05T18:55:03.871870: step 18220, loss 0.000627432, acc 1
2016-09-05T18:55:04.116041: step 18221, loss 0.000581905, acc 1
2016-09-05T18:55:04.329159: step 18222, loss 0.000689604, acc 1
2016-09-05T18:55:04.550372: step 18223, loss 0.000578816, acc 1
2016-09-05T18:55:04.758180: step 18224, loss 0.000623033, acc 1
2016-09-05T18:55:04.969885: step 18225, loss 0.000562604, acc 1
2016-09-05T18:55:05.218548: step 18226, loss 0.000615155, acc 1
2016-09-05T18:55:05.404748: step 18227, loss 0.000619957, acc 1
2016-09-05T18:55:05.634461: step 18228, loss 0.000544747, acc 1
2016-09-05T18:55:05.841213: step 18229, loss 0.00105437, acc 1
2016-09-05T18:55:06.038929: step 18230, loss 0.000529452, acc 1
2016-09-05T18:55:06.256312: step 18231, loss 0.000607506, acc 1
2016-09-05T18:55:06.479780: step 18232, loss 0.000525373, acc 1
2016-09-05T18:55:06.688366: step 18233, loss 0.000648783, acc 1
2016-09-05T18:55:06.904697: step 18234, loss 0.000832973, acc 1
2016-09-05T18:55:07.119944: step 18235, loss 0.000776163, acc 1
2016-09-05T18:55:07.259668: step 18236, loss 0.000824339, acc 1
2016-09-05T18:55:07.486916: step 18237, loss 0.000570165, acc 1
2016-09-05T18:55:07.725461: step 18238, loss 0.000841783, acc 1
2016-09-05T18:55:07.974402: step 18239, loss 0.000537747, acc 1
2016-09-05T18:55:08.219155: step 18240, loss 0.000558912, acc 1
2016-09-05T18:55:08.441893: step 18241, loss 0.000649777, acc 1
2016-09-05T18:55:08.656339: step 18242, loss 0.000532215, acc 1
2016-09-05T18:55:08.867498: step 18243, loss 0.000598691, acc 1
2016-09-05T18:55:09.116604: step 18244, loss 0.000713561, acc 1
2016-09-05T18:55:09.371171: step 18245, loss 0.000684083, acc 1
2016-09-05T18:55:09.580849: step 18246, loss 0.000626515, acc 1
2016-09-05T18:55:09.797439: step 18247, loss 0.000519195, acc 1
2016-09-05T18:55:10.029531: step 18248, loss 0.000613444, acc 1
2016-09-05T18:55:10.267570: step 18249, loss 0.000599873, acc 1
2016-09-05T18:55:10.473437: step 18250, loss 0.000631642, acc 1
2016-09-05T18:55:10.683073: step 18251, loss 0.000547717, acc 1
2016-09-05T18:55:10.882837: step 18252, loss 0.000611737, acc 1
2016-09-05T18:55:11.083802: step 18253, loss 0.000627807, acc 1
2016-09-05T18:55:11.295305: step 18254, loss 0.00057776, acc 1
2016-09-05T18:55:11.511085: step 18255, loss 0.000510147, acc 1
2016-09-05T18:55:11.724302: step 18256, loss 0.000575402, acc 1
2016-09-05T18:55:11.952752: step 18257, loss 0.00058099, acc 1
2016-09-05T18:55:12.189998: step 18258, loss 0.000565037, acc 1
2016-09-05T18:55:12.392571: step 18259, loss 0.00050728, acc 1
2016-09-05T18:55:12.605629: step 18260, loss 0.000546682, acc 1
2016-09-05T18:55:12.804202: step 18261, loss 0.000627744, acc 1
2016-09-05T18:55:13.022437: step 18262, loss 0.000523735, acc 1
2016-09-05T18:55:13.233623: step 18263, loss 0.000525158, acc 1
2016-09-05T18:55:13.431075: step 18264, loss 0.00055057, acc 1
2016-09-05T18:55:13.642352: step 18265, loss 0.000561179, acc 1
2016-09-05T18:55:13.890529: step 18266, loss 0.000565665, acc 1
2016-09-05T18:55:14.103375: step 18267, loss 0.00050138, acc 1
2016-09-05T18:55:14.317954: step 18268, loss 0.000567814, acc 1
2016-09-05T18:55:14.522006: step 18269, loss 0.000510375, acc 1
2016-09-05T18:55:14.725114: step 18270, loss 0.000517374, acc 1
2016-09-05T18:55:14.934346: step 18271, loss 0.000592277, acc 1
2016-09-05T18:55:15.171861: step 18272, loss 0.000487657, acc 1
2016-09-05T18:55:15.414502: step 18273, loss 0.000525515, acc 1
2016-09-05T18:55:15.620916: step 18274, loss 0.000489836, acc 1
2016-09-05T18:55:15.826884: step 18275, loss 0.000489263, acc 1
2016-09-05T18:55:16.036020: step 18276, loss 0.000521043, acc 1
2016-09-05T18:55:16.244089: step 18277, loss 0.000528581, acc 1
2016-09-05T18:55:16.453881: step 18278, loss 0.000511197, acc 1
2016-09-05T18:55:16.700800: step 18279, loss 0.000516064, acc 1
2016-09-05T18:55:16.933291: step 18280, loss 0.000915929, acc 1
2016-09-05T18:55:17.153274: step 18281, loss 0.000571477, acc 1
2016-09-05T18:55:17.353457: step 18282, loss 0.000700956, acc 1
2016-09-05T18:55:17.575169: step 18283, loss 0.000527449, acc 1
2016-09-05T18:55:17.777741: step 18284, loss 0.000496043, acc 1
2016-09-05T18:55:18.010761: step 18285, loss 0.000562424, acc 1
2016-09-05T18:55:18.238963: step 18286, loss 0.000463454, acc 1
2016-09-05T18:55:18.440747: step 18287, loss 0.000549366, acc 1
2016-09-05T18:55:18.640004: step 18288, loss 0.000613894, acc 1
2016-09-05T18:55:18.874858: step 18289, loss 0.000570467, acc 1
2016-09-05T18:55:19.098456: step 18290, loss 0.000561713, acc 1
2016-09-05T18:55:19.316094: step 18291, loss 0.000464202, acc 1
2016-09-05T18:55:19.551365: step 18292, loss 0.000485485, acc 1
2016-09-05T18:55:19.759017: step 18293, loss 0.000519365, acc 1
2016-09-05T18:55:19.971128: step 18294, loss 0.000588978, acc 1
2016-09-05T18:55:20.174286: step 18295, loss 0.000534028, acc 1
2016-09-05T18:55:20.422807: step 18296, loss 0.000571098, acc 1
2016-09-05T18:55:20.637409: step 18297, loss 0.000583383, acc 1
2016-09-05T18:55:20.858011: step 18298, loss 0.000495311, acc 1
2016-09-05T18:55:21.090134: step 18299, loss 0.000538211, acc 1
2016-09-05T18:55:21.308284: step 18300, loss 0.000507175, acc 1

Evaluation:
2016-09-05T18:55:21.920426: step 18300, loss 1.55509, acc 0.718

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-18300

2016-09-05T18:55:22.614951: step 18301, loss 0.00049279, acc 1
2016-09-05T18:55:22.826410: step 18302, loss 0.000480572, acc 1
2016-09-05T18:55:23.026551: step 18303, loss 0.000584807, acc 1
2016-09-05T18:55:23.237220: step 18304, loss 0.000733651, acc 1
2016-09-05T18:55:23.473306: step 18305, loss 0.000577667, acc 1
2016-09-05T18:55:23.685649: step 18306, loss 0.000522503, acc 1
2016-09-05T18:55:23.881275: step 18307, loss 0.000490945, acc 1
2016-09-05T18:55:24.093715: step 18308, loss 0.000526983, acc 1
2016-09-05T18:55:24.287659: step 18309, loss 0.000473839, acc 1
2016-09-05T18:55:24.498482: step 18310, loss 0.000451839, acc 1
2016-09-05T18:55:24.707282: step 18311, loss 0.000663781, acc 1
2016-09-05T18:55:24.935396: step 18312, loss 0.000612341, acc 1
2016-09-05T18:55:25.154717: step 18313, loss 0.000531364, acc 1
2016-09-05T18:55:25.408297: step 18314, loss 0.000620241, acc 1
2016-09-05T18:55:25.601913: step 18315, loss 0.000479362, acc 1
2016-09-05T18:55:25.795179: step 18316, loss 0.000527279, acc 1
2016-09-05T18:55:25.998280: step 18317, loss 0.000639353, acc 1
2016-09-05T18:55:26.207183: step 18318, loss 0.000493835, acc 1
2016-09-05T18:55:26.404042: step 18319, loss 0.000474829, acc 1
2016-09-05T18:55:26.622969: step 18320, loss 0.00080266, acc 1
2016-09-05T18:55:26.845598: step 18321, loss 0.00058605, acc 1
2016-09-05T18:55:27.055731: step 18322, loss 0.000597344, acc 1
2016-09-05T18:55:27.270100: step 18323, loss 0.000667235, acc 1
2016-09-05T18:55:27.488444: step 18324, loss 0.000576334, acc 1
2016-09-05T18:55:27.714060: step 18325, loss 0.000907554, acc 1
2016-09-05T18:55:27.923580: step 18326, loss 0.000478845, acc 1
2016-09-05T18:55:28.128407: step 18327, loss 0.000759335, acc 1
2016-09-05T18:55:28.339742: step 18328, loss 0.000665148, acc 1
2016-09-05T18:55:28.561127: step 18329, loss 0.000532533, acc 1
2016-09-05T18:55:28.766053: step 18330, loss 0.000508147, acc 1
2016-09-05T18:55:29.005663: step 18331, loss 0.00047894, acc 1
2016-09-05T18:55:29.224809: step 18332, loss 0.000555348, acc 1
2016-09-05T18:55:29.436559: step 18333, loss 0.000483442, acc 1
2016-09-05T18:55:29.644100: step 18334, loss 0.000578013, acc 1
2016-09-05T18:55:29.899539: step 18335, loss 0.000554987, acc 1
2016-09-05T18:55:30.135713: step 18336, loss 0.000848243, acc 1
2016-09-05T18:55:30.341540: step 18337, loss 0.000503207, acc 1
2016-09-05T18:55:30.548082: step 18338, loss 0.000552542, acc 1
2016-09-05T18:55:30.743638: step 18339, loss 0.000501129, acc 1
2016-09-05T18:55:30.970596: step 18340, loss 0.000535663, acc 1
2016-09-05T18:55:31.187343: step 18341, loss 0.000662529, acc 1
2016-09-05T18:55:31.401674: step 18342, loss 0.000582378, acc 1
2016-09-05T18:55:31.613312: step 18343, loss 0.000670637, acc 1
2016-09-05T18:55:31.853441: step 18344, loss 0.000539956, acc 1
2016-09-05T18:55:32.081652: step 18345, loss 0.000493014, acc 1
2016-09-05T18:55:32.305631: step 18346, loss 0.000559849, acc 1
2016-09-05T18:55:32.524979: step 18347, loss 0.000479347, acc 1
2016-09-05T18:55:32.727756: step 18348, loss 0.000485524, acc 1
2016-09-05T18:55:32.965483: step 18349, loss 0.000578632, acc 1
2016-09-05T18:55:33.172600: step 18350, loss 0.000648203, acc 1
2016-09-05T18:55:33.383431: step 18351, loss 0.000585215, acc 1
2016-09-05T18:55:33.580169: step 18352, loss 0.000491802, acc 1
2016-09-05T18:55:33.785164: step 18353, loss 0.000721718, acc 1
2016-09-05T18:55:33.992543: step 18354, loss 0.000476776, acc 1
2016-09-05T18:55:34.216106: step 18355, loss 0.00056427, acc 1
2016-09-05T18:55:34.429912: step 18356, loss 0.000483737, acc 1
2016-09-05T18:55:34.663155: step 18357, loss 0.000675502, acc 1
2016-09-05T18:55:34.861378: step 18358, loss 0.000845675, acc 1
2016-09-05T18:55:35.088576: step 18359, loss 0.000708817, acc 1
2016-09-05T18:55:35.288335: step 18360, loss 0.000465399, acc 1
2016-09-05T18:55:35.481469: step 18361, loss 0.000555052, acc 1
2016-09-05T18:55:35.685014: step 18362, loss 0.000600888, acc 1
2016-09-05T18:55:35.910430: step 18363, loss 0.000504823, acc 1
2016-09-05T18:55:36.125379: step 18364, loss 0.000690866, acc 1
2016-09-05T18:55:36.351171: step 18365, loss 0.000603936, acc 1
2016-09-05T18:55:36.594356: step 18366, loss 0.000541969, acc 1
2016-09-05T18:55:36.812590: step 18367, loss 0.000541091, acc 1
2016-09-05T18:55:37.053000: step 18368, loss 0.000468297, acc 1
2016-09-05T18:55:37.303266: step 18369, loss 0.00071768, acc 1
2016-09-05T18:55:37.534066: step 18370, loss 0.000487551, acc 1
2016-09-05T18:55:37.746346: step 18371, loss 0.000846756, acc 1
2016-09-05T18:55:37.968217: step 18372, loss 0.00049995, acc 1
2016-09-05T18:55:38.208131: step 18373, loss 0.000544557, acc 1
2016-09-05T18:55:38.418854: step 18374, loss 0.000599603, acc 1
2016-09-05T18:55:38.630815: step 18375, loss 0.00053547, acc 1
2016-09-05T18:55:38.835486: step 18376, loss 0.000618987, acc 1
2016-09-05T18:55:39.085532: step 18377, loss 0.000912625, acc 1
2016-09-05T18:55:39.317422: step 18378, loss 0.000822013, acc 1
2016-09-05T18:55:39.524062: step 18379, loss 0.000758045, acc 1
2016-09-05T18:55:39.728249: step 18380, loss 0.000609663, acc 1
2016-09-05T18:55:39.928312: step 18381, loss 0.00108716, acc 1
2016-09-05T18:55:40.122821: step 18382, loss 0.000751269, acc 1
2016-09-05T18:55:40.335978: step 18383, loss 0.000688263, acc 1
2016-09-05T18:55:40.534644: step 18384, loss 0.000501773, acc 1
2016-09-05T18:55:40.755555: step 18385, loss 0.000652122, acc 1
2016-09-05T18:55:40.976955: step 18386, loss 0.000523315, acc 1
2016-09-05T18:55:41.190079: step 18387, loss 0.000514423, acc 1
2016-09-05T18:55:41.413420: step 18388, loss 0.000578011, acc 1
2016-09-05T18:55:41.640476: step 18389, loss 0.000829318, acc 1
2016-09-05T18:55:41.860827: step 18390, loss 0.000615731, acc 1
2016-09-05T18:55:42.085682: step 18391, loss 0.000558233, acc 1
2016-09-05T18:55:42.298583: step 18392, loss 0.000523554, acc 1
2016-09-05T18:55:42.523959: step 18393, loss 0.000533693, acc 1
2016-09-05T18:55:42.726598: step 18394, loss 0.000677736, acc 1
2016-09-05T18:55:42.944418: step 18395, loss 0.000519768, acc 1
2016-09-05T18:55:43.167573: step 18396, loss 0.000562826, acc 1
2016-09-05T18:55:43.377484: step 18397, loss 0.000578932, acc 1
2016-09-05T18:55:43.605044: step 18398, loss 0.000520145, acc 1
2016-09-05T18:55:43.812041: step 18399, loss 0.000518422, acc 1
2016-09-05T18:55:44.027300: step 18400, loss 0.000527331, acc 1

Evaluation:
2016-09-05T18:55:44.629325: step 18400, loss 1.67557, acc 0.711

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-18400

2016-09-05T18:55:45.374899: step 18401, loss 0.000563506, acc 1
2016-09-05T18:55:45.600357: step 18402, loss 0.000790756, acc 1
2016-09-05T18:55:45.814149: step 18403, loss 0.000505308, acc 1
2016-09-05T18:55:46.035972: step 18404, loss 0.000547484, acc 1
2016-09-05T18:55:46.252076: step 18405, loss 0.000608304, acc 1
2016-09-05T18:55:46.485887: step 18406, loss 0.000550844, acc 1
2016-09-05T18:55:46.703616: step 18407, loss 0.000585541, acc 1
2016-09-05T18:55:46.903389: step 18408, loss 0.000514046, acc 1
2016-09-05T18:55:47.114110: step 18409, loss 0.000542238, acc 1
2016-09-05T18:55:47.345248: step 18410, loss 0.000571437, acc 1
2016-09-05T18:55:47.553964: step 18411, loss 0.00059598, acc 1
2016-09-05T18:55:47.774834: step 18412, loss 0.000741374, acc 1
2016-09-05T18:55:47.998823: step 18413, loss 0.000655991, acc 1
2016-09-05T18:55:48.201678: step 18414, loss 0.000573091, acc 1
2016-09-05T18:55:48.412595: step 18415, loss 0.000538199, acc 1
2016-09-05T18:55:48.609835: step 18416, loss 0.000834753, acc 1
2016-09-05T18:55:48.820051: step 18417, loss 0.000535547, acc 1
2016-09-05T18:55:49.028330: step 18418, loss 0.000533447, acc 1
2016-09-05T18:55:49.288597: step 18419, loss 0.000533328, acc 1
2016-09-05T18:55:49.495650: step 18420, loss 0.000569003, acc 1
2016-09-05T18:55:49.722408: step 18421, loss 0.000518961, acc 1
2016-09-05T18:55:49.925667: step 18422, loss 0.000510658, acc 1
2016-09-05T18:55:50.141122: step 18423, loss 0.000526238, acc 1
2016-09-05T18:55:50.348250: step 18424, loss 0.000519597, acc 1
2016-09-05T18:55:50.576010: step 18425, loss 0.00055371, acc 1
2016-09-05T18:55:50.814073: step 18426, loss 0.000917947, acc 1
2016-09-05T18:55:51.024946: step 18427, loss 0.0016395, acc 1
2016-09-05T18:55:51.222197: step 18428, loss 0.00068114, acc 1
2016-09-05T18:55:51.433795: step 18429, loss 0.000884851, acc 1
2016-09-05T18:55:51.565161: step 18430, loss 0.000520691, acc 1
2016-09-05T18:55:51.785658: step 18431, loss 0.000587149, acc 1
2016-09-05T18:55:52.009476: step 18432, loss 0.000638467, acc 1
2016-09-05T18:55:52.197638: step 18433, loss 0.0005813, acc 1
2016-09-05T18:55:52.407704: step 18434, loss 0.000617992, acc 1
2016-09-05T18:55:52.635056: step 18435, loss 0.000543238, acc 1
2016-09-05T18:55:52.850823: step 18436, loss 0.000707, acc 1
2016-09-05T18:55:53.068651: step 18437, loss 0.00130072, acc 1
2016-09-05T18:55:53.284329: step 18438, loss 0.000548165, acc 1
2016-09-05T18:55:53.497416: step 18439, loss 0.000569159, acc 1
2016-09-05T18:55:53.710862: step 18440, loss 0.000650662, acc 1
2016-09-05T18:55:53.953332: step 18441, loss 0.000620314, acc 1
2016-09-05T18:55:54.178042: step 18442, loss 0.000555579, acc 1
2016-09-05T18:55:54.380621: step 18443, loss 0.000583537, acc 1
2016-09-05T18:55:54.604943: step 18444, loss 0.000626968, acc 1
2016-09-05T18:55:54.829888: step 18445, loss 0.000621811, acc 1
2016-09-05T18:55:55.066439: step 18446, loss 0.000567825, acc 1
2016-09-05T18:55:55.289253: step 18447, loss 0.000604379, acc 1
2016-09-05T18:55:55.510954: step 18448, loss 0.000558557, acc 1
2016-09-05T18:55:55.755417: step 18449, loss 0.000672245, acc 1
2016-09-05T18:55:55.972686: step 18450, loss 0.000544448, acc 1
2016-09-05T18:55:56.194237: step 18451, loss 0.000706092, acc 1
2016-09-05T18:55:56.419331: step 18452, loss 0.000605411, acc 1
2016-09-05T18:55:56.664260: step 18453, loss 0.000584836, acc 1
2016-09-05T18:55:56.879514: step 18454, loss 0.00053805, acc 1
2016-09-05T18:55:57.080328: step 18455, loss 0.000603767, acc 1
2016-09-05T18:55:57.299312: step 18456, loss 0.000672057, acc 1
2016-09-05T18:55:57.504845: step 18457, loss 0.000650857, acc 1
2016-09-05T18:55:57.737932: step 18458, loss 0.000519777, acc 1
2016-09-05T18:55:57.976216: step 18459, loss 0.000552472, acc 1
2016-09-05T18:55:58.210484: step 18460, loss 0.000583412, acc 1
2016-09-05T18:55:58.430028: step 18461, loss 0.000544329, acc 1
2016-09-05T18:55:58.636052: step 18462, loss 0.000593312, acc 1
2016-09-05T18:55:58.877424: step 18463, loss 0.000602707, acc 1
2016-09-05T18:55:59.090329: step 18464, loss 0.000643278, acc 1
2016-09-05T18:55:59.307646: step 18465, loss 0.000523001, acc 1
2016-09-05T18:55:59.521092: step 18466, loss 0.00142747, acc 1
2016-09-05T18:55:59.738681: step 18467, loss 0.000632562, acc 1
2016-09-05T18:55:59.963491: step 18468, loss 0.000521869, acc 1
2016-09-05T18:56:00.195912: step 18469, loss 0.000562195, acc 1
2016-09-05T18:56:00.411853: step 18470, loss 0.000573763, acc 1
2016-09-05T18:56:00.633256: step 18471, loss 0.00056738, acc 1
2016-09-05T18:56:00.832836: step 18472, loss 0.000754836, acc 1
2016-09-05T18:56:01.042886: step 18473, loss 0.00050801, acc 1
2016-09-05T18:56:01.250474: step 18474, loss 0.000580279, acc 1
2016-09-05T18:56:01.476130: step 18475, loss 0.000524812, acc 1
2016-09-05T18:56:01.700373: step 18476, loss 0.000524794, acc 1
2016-09-05T18:56:01.911953: step 18477, loss 0.000534192, acc 1
2016-09-05T18:56:02.125952: step 18478, loss 0.000530976, acc 1
2016-09-05T18:56:02.335393: step 18479, loss 0.000571633, acc 1
2016-09-05T18:56:02.574819: step 18480, loss 0.000521155, acc 1
2016-09-05T18:56:02.791294: step 18481, loss 0.000572383, acc 1
2016-09-05T18:56:03.046519: step 18482, loss 0.000736153, acc 1
2016-09-05T18:56:03.254838: step 18483, loss 0.000493921, acc 1
2016-09-05T18:56:03.475085: step 18484, loss 0.000839074, acc 1
2016-09-05T18:56:03.703746: step 18485, loss 0.00054706, acc 1
2016-09-05T18:56:03.940665: step 18486, loss 0.000527109, acc 1
2016-09-05T18:56:04.159347: step 18487, loss 0.000572303, acc 1
2016-09-05T18:56:04.364832: step 18488, loss 0.000602489, acc 1
2016-09-05T18:56:04.577273: step 18489, loss 0.000544474, acc 1
2016-09-05T18:56:04.785793: step 18490, loss 0.000508293, acc 1
2016-09-05T18:56:04.991998: step 18491, loss 0.000536165, acc 1
2016-09-05T18:56:05.196429: step 18492, loss 0.000558996, acc 1
2016-09-05T18:56:05.424746: step 18493, loss 0.000545538, acc 1
2016-09-05T18:56:05.666135: step 18494, loss 0.000857148, acc 1
2016-09-05T18:56:05.884901: step 18495, loss 0.000620409, acc 1
2016-09-05T18:56:06.097313: step 18496, loss 0.000715919, acc 1
2016-09-05T18:56:06.327001: step 18497, loss 0.000503884, acc 1
2016-09-05T18:56:06.563051: step 18498, loss 0.000523503, acc 1
2016-09-05T18:56:06.761918: step 18499, loss 0.000563616, acc 1
2016-09-05T18:56:06.969360: step 18500, loss 0.000588319, acc 1

Evaluation:
2016-09-05T18:56:07.590813: step 18500, loss 1.60436, acc 0.718

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-18500

2016-09-05T18:56:08.352210: step 18501, loss 0.000567994, acc 1
2016-09-05T18:56:08.595501: step 18502, loss 0.000605106, acc 1
2016-09-05T18:56:08.826139: step 18503, loss 0.000482413, acc 1
2016-09-05T18:56:09.048756: step 18504, loss 0.000518565, acc 1
2016-09-05T18:56:09.274811: step 18505, loss 0.000615504, acc 1
2016-09-05T18:56:09.512298: step 18506, loss 0.000569752, acc 1
2016-09-05T18:56:09.737880: step 18507, loss 0.000566881, acc 1
2016-09-05T18:56:09.958464: step 18508, loss 0.00064023, acc 1
2016-09-05T18:56:10.190263: step 18509, loss 0.000663334, acc 1
2016-09-05T18:56:10.404207: step 18510, loss 0.000531529, acc 1
2016-09-05T18:56:10.603748: step 18511, loss 0.000605844, acc 1
2016-09-05T18:56:10.820492: step 18512, loss 0.000577268, acc 1
2016-09-05T18:56:11.025606: step 18513, loss 0.000647371, acc 1
2016-09-05T18:56:11.269275: step 18514, loss 0.000607943, acc 1
2016-09-05T18:56:11.512664: step 18515, loss 0.000586377, acc 1
2016-09-05T18:56:11.711383: step 18516, loss 0.000676292, acc 1
2016-09-05T18:56:11.926826: step 18517, loss 0.000712282, acc 1
2016-09-05T18:56:12.140980: step 18518, loss 0.000627978, acc 1
2016-09-05T18:56:12.388918: step 18519, loss 0.000529437, acc 1
2016-09-05T18:56:12.617423: step 18520, loss 0.000549211, acc 1
2016-09-05T18:56:12.853314: step 18521, loss 0.000479534, acc 1
2016-09-05T18:56:13.064922: step 18522, loss 0.000592812, acc 1
2016-09-05T18:56:13.277848: step 18523, loss 0.000603497, acc 1
2016-09-05T18:56:13.517570: step 18524, loss 0.000513285, acc 1
2016-09-05T18:56:13.717147: step 18525, loss 0.000538832, acc 1
2016-09-05T18:56:13.936740: step 18526, loss 0.000523663, acc 1
2016-09-05T18:56:14.155203: step 18527, loss 0.000646107, acc 1
2016-09-05T18:56:14.366928: step 18528, loss 0.000494753, acc 1
2016-09-05T18:56:14.583850: step 18529, loss 0.000808555, acc 1
2016-09-05T18:56:14.808320: step 18530, loss 0.00054986, acc 1
2016-09-05T18:56:15.029465: step 18531, loss 0.000560061, acc 1
2016-09-05T18:56:15.261182: step 18532, loss 0.000541425, acc 1
2016-09-05T18:56:15.461268: step 18533, loss 0.000536476, acc 1
2016-09-05T18:56:15.665291: step 18534, loss 0.000547671, acc 1
2016-09-05T18:56:15.884050: step 18535, loss 0.000479092, acc 1
2016-09-05T18:56:16.119315: step 18536, loss 0.000477883, acc 1
2016-09-05T18:56:16.354344: step 18537, loss 0.000926159, acc 1
2016-09-05T18:56:16.556082: step 18538, loss 0.000566736, acc 1
2016-09-05T18:56:16.757511: step 18539, loss 0.000552939, acc 1
2016-09-05T18:56:16.973368: step 18540, loss 0.000568352, acc 1
2016-09-05T18:56:17.191263: step 18541, loss 0.000471844, acc 1
2016-09-05T18:56:17.405340: step 18542, loss 0.000472052, acc 1
2016-09-05T18:56:17.627520: step 18543, loss 0.000469661, acc 1
2016-09-05T18:56:17.856206: step 18544, loss 0.000641927, acc 1
2016-09-05T18:56:18.077758: step 18545, loss 0.000506906, acc 1
2016-09-05T18:56:18.286093: step 18546, loss 0.000468185, acc 1
2016-09-05T18:56:18.511358: step 18547, loss 0.000596069, acc 1
2016-09-05T18:56:18.731109: step 18548, loss 0.000613202, acc 1
2016-09-05T18:56:18.943256: step 18549, loss 0.000873051, acc 1
2016-09-05T18:56:19.164884: step 18550, loss 0.000749348, acc 1
2016-09-05T18:56:19.365951: step 18551, loss 0.00072386, acc 1
2016-09-05T18:56:19.597953: step 18552, loss 0.000623398, acc 1
2016-09-05T18:56:19.816205: step 18553, loss 0.000480984, acc 1
2016-09-05T18:56:20.054357: step 18554, loss 0.000525712, acc 1
2016-09-05T18:56:20.293561: step 18555, loss 0.000988872, acc 1
2016-09-05T18:56:20.503114: step 18556, loss 0.00052351, acc 1
2016-09-05T18:56:20.715705: step 18557, loss 0.000547313, acc 1
2016-09-05T18:56:20.936552: step 18558, loss 0.000624074, acc 1
2016-09-05T18:56:21.168097: step 18559, loss 0.000492795, acc 1
2016-09-05T18:56:21.392663: step 18560, loss 0.000523397, acc 1
2016-09-05T18:56:21.607938: step 18561, loss 0.000522841, acc 1
2016-09-05T18:56:21.811029: step 18562, loss 0.000567958, acc 1
2016-09-05T18:56:22.024042: step 18563, loss 0.000613327, acc 1
2016-09-05T18:56:22.254803: step 18564, loss 0.000616383, acc 1
2016-09-05T18:56:22.493735: step 18565, loss 0.00053884, acc 1
2016-09-05T18:56:22.706135: step 18566, loss 0.000495026, acc 1
2016-09-05T18:56:22.917149: step 18567, loss 0.000646524, acc 1
2016-09-05T18:56:23.129384: step 18568, loss 0.000626409, acc 1
2016-09-05T18:56:23.345446: step 18569, loss 0.000590651, acc 1
2016-09-05T18:56:23.564592: step 18570, loss 0.000488398, acc 1
2016-09-05T18:56:23.772049: step 18571, loss 0.000590802, acc 1
2016-09-05T18:56:23.996660: step 18572, loss 0.000486071, acc 1
2016-09-05T18:56:24.238340: step 18573, loss 0.000598348, acc 1
2016-09-05T18:56:24.445499: step 18574, loss 0.000490734, acc 1
2016-09-05T18:56:24.644527: step 18575, loss 0.000505568, acc 1
2016-09-05T18:56:24.847879: step 18576, loss 0.00051112, acc 1
2016-09-05T18:56:25.046564: step 18577, loss 0.000558973, acc 1
2016-09-05T18:56:25.251591: step 18578, loss 0.000535406, acc 1
2016-09-05T18:56:25.457394: step 18579, loss 0.000607428, acc 1
2016-09-05T18:56:25.668785: step 18580, loss 0.000515693, acc 1
2016-09-05T18:56:25.881943: step 18581, loss 0.000488375, acc 1
2016-09-05T18:56:26.093755: step 18582, loss 0.000666112, acc 1
2016-09-05T18:56:26.306594: step 18583, loss 0.000488545, acc 1
2016-09-05T18:56:26.531302: step 18584, loss 0.00054583, acc 1
2016-09-05T18:56:26.752227: step 18585, loss 0.00068407, acc 1
2016-09-05T18:56:26.991397: step 18586, loss 0.000479957, acc 1
2016-09-05T18:56:27.203045: step 18587, loss 0.000473085, acc 1
2016-09-05T18:56:27.445407: step 18588, loss 0.000503672, acc 1
2016-09-05T18:56:27.642384: step 18589, loss 0.000506963, acc 1
2016-09-05T18:56:27.869455: step 18590, loss 0.000558353, acc 1
2016-09-05T18:56:28.095648: step 18591, loss 0.00050526, acc 1
2016-09-05T18:56:28.302186: step 18592, loss 0.000494601, acc 1
2016-09-05T18:56:28.521065: step 18593, loss 0.000639337, acc 1
2016-09-05T18:56:28.737967: step 18594, loss 0.000490848, acc 1
2016-09-05T18:56:28.965418: step 18595, loss 0.000524565, acc 1
2016-09-05T18:56:29.202012: step 18596, loss 0.000479669, acc 1
2016-09-05T18:56:29.447414: step 18597, loss 0.000449197, acc 1
2016-09-05T18:56:29.693430: step 18598, loss 0.00050556, acc 1
2016-09-05T18:56:29.912328: step 18599, loss 0.000464072, acc 1
2016-09-05T18:56:30.131134: step 18600, loss 0.000505923, acc 1

Evaluation:
2016-09-05T18:56:30.751292: step 18600, loss 1.583, acc 0.708

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-18600

2016-09-05T18:56:31.538190: step 18601, loss 0.000608359, acc 1
2016-09-05T18:56:31.753899: step 18602, loss 0.000450076, acc 1
2016-09-05T18:56:31.955465: step 18603, loss 0.000504479, acc 1
2016-09-05T18:56:32.186411: step 18604, loss 0.000689827, acc 1
2016-09-05T18:56:32.402910: step 18605, loss 0.000446621, acc 1
2016-09-05T18:56:32.625391: step 18606, loss 0.000465231, acc 1
2016-09-05T18:56:32.835834: step 18607, loss 0.00059363, acc 1
2016-09-05T18:56:33.049997: step 18608, loss 0.000581239, acc 1
2016-09-05T18:56:33.261741: step 18609, loss 0.000639173, acc 1
2016-09-05T18:56:33.486832: step 18610, loss 0.000490434, acc 1
2016-09-05T18:56:33.716129: step 18611, loss 0.000569956, acc 1
2016-09-05T18:56:33.942341: step 18612, loss 0.000527663, acc 1
2016-09-05T18:56:34.162585: step 18613, loss 0.00061575, acc 1
2016-09-05T18:56:34.372481: step 18614, loss 0.000445751, acc 1
2016-09-05T18:56:34.581533: step 18615, loss 0.000457663, acc 1
2016-09-05T18:56:34.790650: step 18616, loss 0.000531902, acc 1
2016-09-05T18:56:35.000420: step 18617, loss 0.00065094, acc 1
2016-09-05T18:56:35.203652: step 18618, loss 0.000641851, acc 1
2016-09-05T18:56:35.425657: step 18619, loss 0.000539067, acc 1
2016-09-05T18:56:35.654882: step 18620, loss 0.000573457, acc 1
2016-09-05T18:56:35.879211: step 18621, loss 0.000530113, acc 1
2016-09-05T18:56:36.078509: step 18622, loss 0.000563314, acc 1
2016-09-05T18:56:36.311128: step 18623, loss 0.000533192, acc 1
2016-09-05T18:56:36.505294: step 18624, loss 0.000446542, acc 1
2016-09-05T18:56:36.725274: step 18625, loss 0.000465911, acc 1
2016-09-05T18:56:36.961521: step 18626, loss 0.000469711, acc 1
2016-09-05T18:56:37.190360: step 18627, loss 0.0006028, acc 1
2016-09-05T18:56:37.401863: step 18628, loss 0.000469749, acc 1
2016-09-05T18:56:37.619659: step 18629, loss 0.000525172, acc 1
2016-09-05T18:56:37.848171: step 18630, loss 0.000525916, acc 1
2016-09-05T18:56:38.084153: step 18631, loss 0.00045312, acc 1
2016-09-05T18:56:38.314269: step 18632, loss 0.000494311, acc 1
2016-09-05T18:56:38.526811: step 18633, loss 0.000511146, acc 1
2016-09-05T18:56:38.728014: step 18634, loss 0.000474659, acc 1
2016-09-05T18:56:38.939415: step 18635, loss 0.000454175, acc 1
2016-09-05T18:56:39.162394: step 18636, loss 0.00075927, acc 1
2016-09-05T18:56:39.419192: step 18637, loss 0.000432569, acc 1
2016-09-05T18:56:39.618707: step 18638, loss 0.00046201, acc 1
2016-09-05T18:56:39.820597: step 18639, loss 0.000457035, acc 1
2016-09-05T18:56:40.029086: step 18640, loss 0.000713267, acc 1
2016-09-05T18:56:40.226049: step 18641, loss 0.000558416, acc 1
2016-09-05T18:56:40.426989: step 18642, loss 0.000530159, acc 1
2016-09-05T18:56:40.632704: step 18643, loss 0.000670495, acc 1
2016-09-05T18:56:40.837012: step 18644, loss 0.000510237, acc 1
2016-09-05T18:56:41.030533: step 18645, loss 0.000440808, acc 1
2016-09-05T18:56:41.236779: step 18646, loss 0.000458738, acc 1
2016-09-05T18:56:41.451471: step 18647, loss 0.000523936, acc 1
2016-09-05T18:56:41.658635: step 18648, loss 0.000620051, acc 1
2016-09-05T18:56:41.886493: step 18649, loss 0.000453979, acc 1
2016-09-05T18:56:42.114972: step 18650, loss 0.000526218, acc 1
2016-09-05T18:56:42.332969: step 18651, loss 0.000462275, acc 1
2016-09-05T18:56:42.590766: step 18652, loss 0.000635276, acc 1
2016-09-05T18:56:42.817389: step 18653, loss 0.000467523, acc 1
2016-09-05T18:56:43.024184: step 18654, loss 0.000489295, acc 1
2016-09-05T18:56:43.224231: step 18655, loss 0.000618969, acc 1
2016-09-05T18:56:43.433468: step 18656, loss 0.000476133, acc 1
2016-09-05T18:56:43.637992: step 18657, loss 0.000506678, acc 1
2016-09-05T18:56:43.851041: step 18658, loss 0.000537453, acc 1
2016-09-05T18:56:44.060122: step 18659, loss 0.000540051, acc 1
2016-09-05T18:56:44.289196: step 18660, loss 0.000470994, acc 1
2016-09-05T18:56:44.496179: step 18661, loss 0.000449798, acc 1
2016-09-05T18:56:44.746684: step 18662, loss 0.000621604, acc 1
2016-09-05T18:56:44.953361: step 18663, loss 0.000745444, acc 1
2016-09-05T18:56:45.178790: step 18664, loss 0.000458107, acc 1
2016-09-05T18:56:45.382777: step 18665, loss 0.000509761, acc 1
2016-09-05T18:56:45.608488: step 18666, loss 0.000582224, acc 1
2016-09-05T18:56:45.835147: step 18667, loss 0.000463886, acc 1
2016-09-05T18:56:46.057390: step 18668, loss 0.000769628, acc 1
2016-09-05T18:56:46.275350: step 18669, loss 0.00048319, acc 1
2016-09-05T18:56:46.488212: step 18670, loss 0.000449533, acc 1
2016-09-05T18:56:46.691927: step 18671, loss 0.000499168, acc 1
2016-09-05T18:56:46.890315: step 18672, loss 0.000455758, acc 1
2016-09-05T18:56:47.107001: step 18673, loss 0.000583987, acc 1
2016-09-05T18:56:47.321985: step 18674, loss 0.000749913, acc 1
2016-09-05T18:56:47.554765: step 18675, loss 0.000553019, acc 1
2016-09-05T18:56:47.769966: step 18676, loss 0.000502357, acc 1
2016-09-05T18:56:47.994932: step 18677, loss 0.000730277, acc 1
2016-09-05T18:56:48.202454: step 18678, loss 0.000443346, acc 1
2016-09-05T18:56:48.412668: step 18679, loss 0.000474613, acc 1
2016-09-05T18:56:48.611834: step 18680, loss 0.000490906, acc 1
2016-09-05T18:56:48.830045: step 18681, loss 0.000466848, acc 1
2016-09-05T18:56:49.032167: step 18682, loss 0.000685394, acc 1
2016-09-05T18:56:49.227345: step 18683, loss 0.000438443, acc 1
2016-09-05T18:56:49.444487: step 18684, loss 0.00045025, acc 1
2016-09-05T18:56:49.651186: step 18685, loss 0.000497936, acc 1
2016-09-05T18:56:49.864664: step 18686, loss 0.000786254, acc 1
2016-09-05T18:56:50.075373: step 18687, loss 0.000459247, acc 1
2016-09-05T18:56:50.297435: step 18688, loss 0.000468845, acc 1
2016-09-05T18:56:50.511011: step 18689, loss 0.000471967, acc 1
2016-09-05T18:56:50.708809: step 18690, loss 0.000672493, acc 1
2016-09-05T18:56:50.936748: step 18691, loss 0.000516905, acc 1
2016-09-05T18:56:51.163262: step 18692, loss 0.000482141, acc 1
2016-09-05T18:56:51.361848: step 18693, loss 0.000611139, acc 1
2016-09-05T18:56:51.588189: step 18694, loss 0.000665544, acc 1
2016-09-05T18:56:51.800526: step 18695, loss 0.00072458, acc 1
2016-09-05T18:56:52.028157: step 18696, loss 0.000628792, acc 1
2016-09-05T18:56:52.240754: step 18697, loss 0.000606555, acc 1
2016-09-05T18:56:52.480401: step 18698, loss 0.000619856, acc 1
2016-09-05T18:56:52.727743: step 18699, loss 0.000512062, acc 1
2016-09-05T18:56:52.942974: step 18700, loss 0.000485737, acc 1

Evaluation:
2016-09-05T18:56:53.564601: step 18700, loss 1.60991, acc 0.71

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-18700

2016-09-05T18:56:54.291342: step 18701, loss 0.000509702, acc 1
2016-09-05T18:56:54.503860: step 18702, loss 0.000463198, acc 1
2016-09-05T18:56:54.753428: step 18703, loss 0.000498149, acc 1
2016-09-05T18:56:54.965823: step 18704, loss 0.000505674, acc 1
2016-09-05T18:56:55.168226: step 18705, loss 0.000481021, acc 1
2016-09-05T18:56:55.371707: step 18706, loss 0.000555664, acc 1
2016-09-05T18:56:55.588885: step 18707, loss 0.000469121, acc 1
2016-09-05T18:56:55.816489: step 18708, loss 0.000465774, acc 1
2016-09-05T18:56:56.035503: step 18709, loss 0.000741026, acc 1
2016-09-05T18:56:56.249912: step 18710, loss 0.000492649, acc 1
2016-09-05T18:56:56.475834: step 18711, loss 0.000474439, acc 1
2016-09-05T18:56:56.674140: step 18712, loss 0.000514519, acc 1
2016-09-05T18:56:56.885581: step 18713, loss 0.000466735, acc 1
2016-09-05T18:56:57.115783: step 18714, loss 0.000572109, acc 1
2016-09-05T18:56:57.355714: step 18715, loss 0.000488606, acc 1
2016-09-05T18:56:57.579303: step 18716, loss 0.000431594, acc 1
2016-09-05T18:56:57.792170: step 18717, loss 0.000510296, acc 1
2016-09-05T18:56:57.996167: step 18718, loss 0.000704218, acc 1
2016-09-05T18:56:58.201798: step 18719, loss 0.000635285, acc 1
2016-09-05T18:56:58.409181: step 18720, loss 0.000567953, acc 1
2016-09-05T18:56:58.615639: step 18721, loss 0.000442848, acc 1
2016-09-05T18:56:58.830626: step 18722, loss 0.000596237, acc 1
2016-09-05T18:56:59.041703: step 18723, loss 0.00050243, acc 1
2016-09-05T18:56:59.285381: step 18724, loss 0.000520683, acc 1
2016-09-05T18:56:59.504973: step 18725, loss 0.000585384, acc 1
2016-09-05T18:56:59.712769: step 18726, loss 0.000667736, acc 1
2016-09-05T18:56:59.910482: step 18727, loss 0.000526143, acc 1
2016-09-05T18:57:00.132071: step 18728, loss 0.000523335, acc 1
2016-09-05T18:57:00.360300: step 18729, loss 0.000485646, acc 1
2016-09-05T18:57:00.573236: step 18730, loss 0.000668926, acc 1
2016-09-05T18:57:00.809109: step 18731, loss 0.000455374, acc 1
2016-09-05T18:57:01.020778: step 18732, loss 0.000475131, acc 1
2016-09-05T18:57:01.224505: step 18733, loss 0.000527057, acc 1
2016-09-05T18:57:01.438540: step 18734, loss 0.000499906, acc 1
2016-09-05T18:57:01.640283: step 18735, loss 0.000504137, acc 1
2016-09-05T18:57:01.861097: step 18736, loss 0.000482516, acc 1
2016-09-05T18:57:02.080378: step 18737, loss 0.000537684, acc 1
2016-09-05T18:57:02.299645: step 18738, loss 0.000471199, acc 1
2016-09-05T18:57:02.513137: step 18739, loss 0.000466006, acc 1
2016-09-05T18:57:02.733115: step 18740, loss 0.000540932, acc 1
2016-09-05T18:57:02.944500: step 18741, loss 0.000552901, acc 1
2016-09-05T18:57:03.175689: step 18742, loss 0.000558611, acc 1
2016-09-05T18:57:03.425807: step 18743, loss 0.000591299, acc 1
2016-09-05T18:57:03.641544: step 18744, loss 0.00073098, acc 1
2016-09-05T18:57:03.876576: step 18745, loss 0.000485192, acc 1
2016-09-05T18:57:04.086170: step 18746, loss 0.000498788, acc 1
2016-09-05T18:57:04.303067: step 18747, loss 0.000527034, acc 1
2016-09-05T18:57:04.542109: step 18748, loss 0.000460584, acc 1
2016-09-05T18:57:04.740885: step 18749, loss 0.000462325, acc 1
2016-09-05T18:57:04.969081: step 18750, loss 0.000495139, acc 1
2016-09-05T18:57:05.189632: step 18751, loss 0.000527382, acc 1
2016-09-05T18:57:05.406879: step 18752, loss 0.000683061, acc 1
2016-09-05T18:57:05.613331: step 18753, loss 0.000510124, acc 1
2016-09-05T18:57:05.853400: step 18754, loss 0.000543956, acc 1
2016-09-05T18:57:06.061139: step 18755, loss 0.000514228, acc 1
2016-09-05T18:57:06.287956: step 18756, loss 0.000623253, acc 1
2016-09-05T18:57:06.491951: step 18757, loss 0.000484823, acc 1
2016-09-05T18:57:06.709995: step 18758, loss 0.000482097, acc 1
2016-09-05T18:57:06.969883: step 18759, loss 0.000515613, acc 1
2016-09-05T18:57:07.176050: step 18760, loss 0.000436059, acc 1
2016-09-05T18:57:07.401027: step 18761, loss 0.000432886, acc 1
2016-09-05T18:57:07.623470: step 18762, loss 0.000466897, acc 1
2016-09-05T18:57:07.868757: step 18763, loss 0.000492158, acc 1
2016-09-05T18:57:08.081786: step 18764, loss 0.000468252, acc 1
2016-09-05T18:57:08.300495: step 18765, loss 0.000741859, acc 1
2016-09-05T18:57:08.513265: step 18766, loss 0.000560621, acc 1
2016-09-05T18:57:08.736427: step 18767, loss 0.00044453, acc 1
2016-09-05T18:57:08.986051: step 18768, loss 0.000494531, acc 1
2016-09-05T18:57:09.188374: step 18769, loss 0.000560916, acc 1
2016-09-05T18:57:09.400532: step 18770, loss 0.000495163, acc 1
2016-09-05T18:57:09.612215: step 18771, loss 0.000766644, acc 1
2016-09-05T18:57:09.831512: step 18772, loss 0.000475051, acc 1
2016-09-05T18:57:10.043642: step 18773, loss 0.000483573, acc 1
2016-09-05T18:57:10.259360: step 18774, loss 0.000591485, acc 1
2016-09-05T18:57:10.489442: step 18775, loss 0.000437614, acc 1
2016-09-05T18:57:10.720426: step 18776, loss 0.000682834, acc 1
2016-09-05T18:57:10.937318: step 18777, loss 0.000665757, acc 1
2016-09-05T18:57:11.164408: step 18778, loss 0.00068246, acc 1
2016-09-05T18:57:11.397430: step 18779, loss 0.000514616, acc 1
2016-09-05T18:57:11.609010: step 18780, loss 0.000465814, acc 1
2016-09-05T18:57:11.827604: step 18781, loss 0.000460117, acc 1
2016-09-05T18:57:12.035558: step 18782, loss 0.000593833, acc 1
2016-09-05T18:57:12.258298: step 18783, loss 0.000498197, acc 1
2016-09-05T18:57:12.481455: step 18784, loss 0.000482067, acc 1
2016-09-05T18:57:12.712223: step 18785, loss 0.000490116, acc 1
2016-09-05T18:57:12.938004: step 18786, loss 0.000538092, acc 1
2016-09-05T18:57:13.172850: step 18787, loss 0.000455134, acc 1
2016-09-05T18:57:13.396651: step 18788, loss 0.00047166, acc 1
2016-09-05T18:57:13.630171: step 18789, loss 0.000797264, acc 1
2016-09-05T18:57:13.839747: step 18790, loss 0.000546239, acc 1
2016-09-05T18:57:14.056567: step 18791, loss 0.0005657, acc 1
2016-09-05T18:57:14.280257: step 18792, loss 0.00105183, acc 1
2016-09-05T18:57:14.487453: step 18793, loss 0.000491445, acc 1
2016-09-05T18:57:14.725896: step 18794, loss 0.000505271, acc 1
2016-09-05T18:57:14.937460: step 18795, loss 0.00071063, acc 1
2016-09-05T18:57:15.156608: step 18796, loss 0.000682603, acc 1
2016-09-05T18:57:15.397367: step 18797, loss 0.000771416, acc 1
2016-09-05T18:57:15.602791: step 18798, loss 0.000519455, acc 1
2016-09-05T18:57:15.868262: step 18799, loss 0.000667313, acc 1
2016-09-05T18:57:16.121692: step 18800, loss 0.000485913, acc 1

Evaluation:
2016-09-05T18:57:16.728106: step 18800, loss 1.66222, acc 0.708

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-18800

2016-09-05T18:57:17.472814: step 18801, loss 0.000530892, acc 1
2016-09-05T18:57:17.683180: step 18802, loss 0.000497674, acc 1
2016-09-05T18:57:17.893447: step 18803, loss 0.000551207, acc 1
2016-09-05T18:57:18.093957: step 18804, loss 0.000556109, acc 1
2016-09-05T18:57:18.343722: step 18805, loss 0.000492438, acc 1
2016-09-05T18:57:18.591042: step 18806, loss 0.000469253, acc 1
2016-09-05T18:57:18.822185: step 18807, loss 0.000545062, acc 1
2016-09-05T18:57:19.078199: step 18808, loss 0.000638121, acc 1
2016-09-05T18:57:19.303986: step 18809, loss 0.000580384, acc 1
2016-09-05T18:57:19.517155: step 18810, loss 0.000461534, acc 1
2016-09-05T18:57:19.719648: step 18811, loss 0.000472563, acc 1
2016-09-05T18:57:19.934654: step 18812, loss 0.0004741, acc 1
2016-09-05T18:57:20.150650: step 18813, loss 0.000558093, acc 1
2016-09-05T18:57:20.399545: step 18814, loss 0.000477263, acc 1
2016-09-05T18:57:20.625310: step 18815, loss 0.000520901, acc 1
2016-09-05T18:57:20.895534: step 18816, loss 0.000486863, acc 1
2016-09-05T18:57:21.107915: step 18817, loss 0.000500997, acc 1
2016-09-05T18:57:21.230866: step 18818, loss 0.000471952, acc 1
2016-09-05T18:57:21.467674: step 18819, loss 0.000491063, acc 1
2016-09-05T18:57:21.697479: step 18820, loss 0.000629431, acc 1
2016-09-05T18:57:21.915536: step 18821, loss 0.000575821, acc 1
2016-09-05T18:57:22.117209: step 18822, loss 0.000452529, acc 1
2016-09-05T18:57:22.321881: step 18823, loss 0.000479286, acc 1
2016-09-05T18:57:22.531221: step 18824, loss 0.000473929, acc 1
2016-09-05T18:57:22.756312: step 18825, loss 0.000511513, acc 1
2016-09-05T18:57:22.959996: step 18826, loss 0.000688728, acc 1
2016-09-05T18:57:23.193555: step 18827, loss 0.000722072, acc 1
2016-09-05T18:57:23.413391: step 18828, loss 0.000446486, acc 1
2016-09-05T18:57:23.627027: step 18829, loss 0.000480303, acc 1
2016-09-05T18:57:23.839617: step 18830, loss 0.00043882, acc 1
2016-09-05T18:57:24.068795: step 18831, loss 0.000596822, acc 1
2016-09-05T18:57:24.314169: step 18832, loss 0.000640319, acc 1
2016-09-05T18:57:24.545280: step 18833, loss 0.000445687, acc 1
2016-09-05T18:57:24.750621: step 18834, loss 0.000510894, acc 1
2016-09-05T18:57:24.952124: step 18835, loss 0.00050458, acc 1
2016-09-05T18:57:25.161953: step 18836, loss 0.000430207, acc 1
2016-09-05T18:57:25.361366: step 18837, loss 0.000488893, acc 1
2016-09-05T18:57:25.580146: step 18838, loss 0.000472534, acc 1
2016-09-05T18:57:25.809224: step 18839, loss 0.00119445, acc 1
2016-09-05T18:57:26.040017: step 18840, loss 0.000457846, acc 1
2016-09-05T18:57:26.252865: step 18841, loss 0.000443351, acc 1
2016-09-05T18:57:26.461341: step 18842, loss 0.000627795, acc 1
2016-09-05T18:57:26.660757: step 18843, loss 0.000485259, acc 1
2016-09-05T18:57:26.876079: step 18844, loss 0.000493897, acc 1
2016-09-05T18:57:27.081057: step 18845, loss 0.000483397, acc 1
2016-09-05T18:57:27.286380: step 18846, loss 0.000549845, acc 1
2016-09-05T18:57:27.505809: step 18847, loss 0.000488409, acc 1
2016-09-05T18:57:27.731905: step 18848, loss 0.000666691, acc 1
2016-09-05T18:57:27.952289: step 18849, loss 0.00099404, acc 1
2016-09-05T18:57:28.158587: step 18850, loss 0.000490587, acc 1
2016-09-05T18:57:28.381399: step 18851, loss 0.000538319, acc 1
2016-09-05T18:57:28.598304: step 18852, loss 0.000486561, acc 1
2016-09-05T18:57:28.829048: step 18853, loss 0.000509401, acc 1
2016-09-05T18:57:29.059679: step 18854, loss 0.000516758, acc 1
2016-09-05T18:57:29.274976: step 18855, loss 0.000482842, acc 1
2016-09-05T18:57:29.487114: step 18856, loss 0.000592641, acc 1
2016-09-05T18:57:29.718016: step 18857, loss 0.000575117, acc 1
2016-09-05T18:57:29.965378: step 18858, loss 0.000458835, acc 1
2016-09-05T18:57:30.173953: step 18859, loss 0.000505842, acc 1
2016-09-05T18:57:30.383911: step 18860, loss 0.000563708, acc 1
2016-09-05T18:57:30.586718: step 18861, loss 0.000477514, acc 1
2016-09-05T18:57:30.783820: step 18862, loss 0.000469004, acc 1
2016-09-05T18:57:30.974592: step 18863, loss 0.000490368, acc 1
2016-09-05T18:57:31.194538: step 18864, loss 0.000472563, acc 1
2016-09-05T18:57:31.395728: step 18865, loss 0.000898042, acc 1
2016-09-05T18:57:31.653707: step 18866, loss 0.000488921, acc 1
2016-09-05T18:57:31.869464: step 18867, loss 0.000656798, acc 1
2016-09-05T18:57:32.103296: step 18868, loss 0.000526658, acc 1
2016-09-05T18:57:32.315633: step 18869, loss 0.000884835, acc 1
2016-09-05T18:57:32.549398: step 18870, loss 0.000500087, acc 1
2016-09-05T18:57:32.759654: step 18871, loss 0.000524816, acc 1
2016-09-05T18:57:32.950744: step 18872, loss 0.000513391, acc 1
2016-09-05T18:57:33.169423: step 18873, loss 0.000469224, acc 1
2016-09-05T18:57:33.378862: step 18874, loss 0.000576495, acc 1
2016-09-05T18:57:33.605357: step 18875, loss 0.000546661, acc 1
2016-09-05T18:57:33.804063: step 18876, loss 0.000471668, acc 1
2016-09-05T18:57:34.014990: step 18877, loss 0.000508637, acc 1
2016-09-05T18:57:34.210965: step 18878, loss 0.000492292, acc 1
2016-09-05T18:57:34.416343: step 18879, loss 0.000614883, acc 1
2016-09-05T18:57:34.629385: step 18880, loss 0.000498428, acc 1
2016-09-05T18:57:34.870554: step 18881, loss 0.000503294, acc 1
2016-09-05T18:57:35.087046: step 18882, loss 0.000501995, acc 1
2016-09-05T18:57:35.339607: step 18883, loss 0.000481353, acc 1
2016-09-05T18:57:35.544204: step 18884, loss 0.000493488, acc 1
2016-09-05T18:57:35.792857: step 18885, loss 0.000463237, acc 1
2016-09-05T18:57:36.001474: step 18886, loss 0.000480078, acc 1
2016-09-05T18:57:36.211111: step 18887, loss 0.000482939, acc 1
2016-09-05T18:57:36.443489: step 18888, loss 0.00051414, acc 1
2016-09-05T18:57:36.662201: step 18889, loss 0.000556177, acc 1
2016-09-05T18:57:36.895249: step 18890, loss 0.00055199, acc 1
2016-09-05T18:57:37.098891: step 18891, loss 0.00043774, acc 1
2016-09-05T18:57:37.344129: step 18892, loss 0.00275215, acc 1
2016-09-05T18:57:37.540110: step 18893, loss 0.00100234, acc 1
2016-09-05T18:57:37.744395: step 18894, loss 0.000936211, acc 1
2016-09-05T18:57:37.950191: step 18895, loss 0.000481645, acc 1
2016-09-05T18:57:38.160686: step 18896, loss 0.00067763, acc 1
2016-09-05T18:57:38.373323: step 18897, loss 0.000740026, acc 1
2016-09-05T18:57:38.596097: step 18898, loss 0.000682782, acc 1
2016-09-05T18:57:38.804541: step 18899, loss 0.000715607, acc 1
2016-09-05T18:57:39.039312: step 18900, loss 0.000806933, acc 1

Evaluation:
2016-09-05T18:57:39.641281: step 18900, loss 1.92923, acc 0.71

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-18900

2016-09-05T18:57:40.311117: step 18901, loss 0.000646739, acc 1
2016-09-05T18:57:40.544515: step 18902, loss 0.000980829, acc 1
2016-09-05T18:57:40.777230: step 18903, loss 0.000699418, acc 1
2016-09-05T18:57:40.987725: step 18904, loss 0.000692683, acc 1
2016-09-05T18:57:41.195475: step 18905, loss 0.000720372, acc 1
2016-09-05T18:57:41.413868: step 18906, loss 0.000704168, acc 1
2016-09-05T18:57:41.614980: step 18907, loss 0.000756758, acc 1
2016-09-05T18:57:41.827842: step 18908, loss 0.00071911, acc 1
2016-09-05T18:57:42.035899: step 18909, loss 0.000798715, acc 1
2016-09-05T18:57:42.263481: step 18910, loss 0.000716383, acc 1
2016-09-05T18:57:42.489734: step 18911, loss 0.000688726, acc 1
2016-09-05T18:57:42.699773: step 18912, loss 0.000670434, acc 1
2016-09-05T18:57:42.914263: step 18913, loss 0.000680678, acc 1
2016-09-05T18:57:43.147967: step 18914, loss 0.000718724, acc 1
2016-09-05T18:57:43.392545: step 18915, loss 0.00070803, acc 1
2016-09-05T18:57:43.599648: step 18916, loss 0.00070239, acc 1
2016-09-05T18:57:43.827435: step 18917, loss 0.000668878, acc 1
2016-09-05T18:57:44.045309: step 18918, loss 0.00100326, acc 1
2016-09-05T18:57:44.263337: step 18919, loss 0.000763246, acc 1
2016-09-05T18:57:44.506078: step 18920, loss 0.000676447, acc 1
2016-09-05T18:57:44.709385: step 18921, loss 0.000666232, acc 1
2016-09-05T18:57:44.935459: step 18922, loss 0.000744706, acc 1
2016-09-05T18:57:45.156865: step 18923, loss 0.000659114, acc 1
2016-09-05T18:57:45.378959: step 18924, loss 0.000661938, acc 1
2016-09-05T18:57:45.619928: step 18925, loss 0.000675884, acc 1
2016-09-05T18:57:45.832811: step 18926, loss 0.000677544, acc 1
2016-09-05T18:57:46.039756: step 18927, loss 0.000638323, acc 1
2016-09-05T18:57:46.264958: step 18928, loss 0.000892757, acc 1
2016-09-05T18:57:46.482283: step 18929, loss 0.000628607, acc 1
2016-09-05T18:57:46.690855: step 18930, loss 0.000607984, acc 1
2016-09-05T18:57:46.902817: step 18931, loss 0.000598962, acc 1
2016-09-05T18:57:47.106379: step 18932, loss 0.00063672, acc 1
2016-09-05T18:57:47.332304: step 18933, loss 0.000601914, acc 1
2016-09-05T18:57:47.539436: step 18934, loss 0.000734755, acc 1
2016-09-05T18:57:47.742643: step 18935, loss 0.000731546, acc 1
2016-09-05T18:57:47.969825: step 18936, loss 0.000725979, acc 1
2016-09-05T18:57:48.192697: step 18937, loss 0.000609779, acc 1
2016-09-05T18:57:48.415653: step 18938, loss 0.000629817, acc 1
2016-09-05T18:57:48.648899: step 18939, loss 0.000617988, acc 1
2016-09-05T18:57:48.860462: step 18940, loss 0.000564944, acc 1
2016-09-05T18:57:49.068620: step 18941, loss 0.000573607, acc 1
2016-09-05T18:57:49.275606: step 18942, loss 0.000744514, acc 1
2016-09-05T18:57:49.507816: step 18943, loss 0.00070815, acc 1
2016-09-05T18:57:49.732580: step 18944, loss 0.000629996, acc 1
2016-09-05T18:57:49.945426: step 18945, loss 0.000560354, acc 1
2016-09-05T18:57:50.163537: step 18946, loss 0.000660675, acc 1
2016-09-05T18:57:50.374971: step 18947, loss 0.000643483, acc 1
2016-09-05T18:57:50.591329: step 18948, loss 0.000564761, acc 1
2016-09-05T18:57:50.801243: step 18949, loss 0.000514769, acc 1
2016-09-05T18:57:51.038509: step 18950, loss 0.000555548, acc 1
2016-09-05T18:57:51.264711: step 18951, loss 0.000634186, acc 1
2016-09-05T18:57:51.471020: step 18952, loss 0.000572415, acc 1
2016-09-05T18:57:51.687523: step 18953, loss 0.000527648, acc 1
2016-09-05T18:57:51.917463: step 18954, loss 0.000604456, acc 1
2016-09-05T18:57:52.148018: step 18955, loss 0.000534867, acc 1
2016-09-05T18:57:52.352151: step 18956, loss 0.000534932, acc 1
2016-09-05T18:57:52.585286: step 18957, loss 0.000626727, acc 1
2016-09-05T18:57:52.798230: step 18958, loss 0.00095647, acc 1
2016-09-05T18:57:53.045745: step 18959, loss 0.000521939, acc 1
2016-09-05T18:57:53.297834: step 18960, loss 0.000629336, acc 1
2016-09-05T18:57:53.586166: step 18961, loss 0.000514904, acc 1
2016-09-05T18:57:53.836121: step 18962, loss 0.000558501, acc 1
2016-09-05T18:57:54.048325: step 18963, loss 0.000536066, acc 1
2016-09-05T18:57:54.290308: step 18964, loss 0.000477408, acc 1
2016-09-05T18:57:54.498046: step 18965, loss 0.000519098, acc 1
2016-09-05T18:57:54.723303: step 18966, loss 0.000492818, acc 1
2016-09-05T18:57:54.927358: step 18967, loss 0.000522353, acc 1
2016-09-05T18:57:55.163254: step 18968, loss 0.000523686, acc 1
2016-09-05T18:57:55.422390: step 18969, loss 0.000486897, acc 1
2016-09-05T18:57:55.678382: step 18970, loss 0.000778995, acc 1
2016-09-05T18:57:55.912699: step 18971, loss 0.000501656, acc 1
2016-09-05T18:57:56.117781: step 18972, loss 0.000470496, acc 1
2016-09-05T18:57:56.337943: step 18973, loss 0.000710007, acc 1
2016-09-05T18:57:56.561154: step 18974, loss 0.000572484, acc 1
2016-09-05T18:57:56.803027: step 18975, loss 0.000586885, acc 1
2016-09-05T18:57:57.011516: step 18976, loss 0.000567714, acc 1
2016-09-05T18:57:57.237247: step 18977, loss 0.000574377, acc 1
2016-09-05T18:57:57.443825: step 18978, loss 0.000534313, acc 1
2016-09-05T18:57:57.666679: step 18979, loss 0.000943163, acc 1
2016-09-05T18:57:57.880760: step 18980, loss 0.000598823, acc 1
2016-09-05T18:57:58.091557: step 18981, loss 0.000521958, acc 1
2016-09-05T18:57:58.312217: step 18982, loss 0.000563664, acc 1
2016-09-05T18:57:58.525951: step 18983, loss 0.000563997, acc 1
2016-09-05T18:57:58.732382: step 18984, loss 0.00058191, acc 1
2016-09-05T18:57:58.943890: step 18985, loss 0.000488886, acc 1
2016-09-05T18:57:59.202542: step 18986, loss 0.000484915, acc 1
2016-09-05T18:57:59.413435: step 18987, loss 0.000478995, acc 1
2016-09-05T18:57:59.640958: step 18988, loss 0.000503058, acc 1
2016-09-05T18:57:59.855318: step 18989, loss 0.000599845, acc 1
2016-09-05T18:58:00.060166: step 18990, loss 0.000488017, acc 1
2016-09-05T18:58:00.320405: step 18991, loss 0.000639476, acc 1
2016-09-05T18:58:00.518389: step 18992, loss 0.000538411, acc 1
2016-09-05T18:58:00.744174: step 18993, loss 0.00055336, acc 1
2016-09-05T18:58:00.941397: step 18994, loss 0.000489976, acc 1
2016-09-05T18:58:01.164824: step 18995, loss 0.000866241, acc 1
2016-09-05T18:58:01.364218: step 18996, loss 0.000495033, acc 1
2016-09-05T18:58:01.583627: step 18997, loss 0.000521925, acc 1
2016-09-05T18:58:01.794357: step 18998, loss 0.000799214, acc 1
2016-09-05T18:58:02.022974: step 18999, loss 0.000988453, acc 1
2016-09-05T18:58:02.238876: step 19000, loss 0.000615177, acc 1

Evaluation:
2016-09-05T18:58:02.837922: step 19000, loss 1.62811, acc 0.705

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-19000

2016-09-05T18:58:03.604165: step 19001, loss 0.000522151, acc 1
2016-09-05T18:58:03.833219: step 19002, loss 0.000647417, acc 1
2016-09-05T18:58:04.050193: step 19003, loss 0.000846756, acc 1
2016-09-05T18:58:04.263279: step 19004, loss 0.000529365, acc 1
2016-09-05T18:58:04.492761: step 19005, loss 0.000477988, acc 1
2016-09-05T18:58:04.701153: step 19006, loss 0.000478482, acc 1
2016-09-05T18:58:04.913020: step 19007, loss 0.000525061, acc 1
2016-09-05T18:58:05.117701: step 19008, loss 0.000508482, acc 1
2016-09-05T18:58:05.336253: step 19009, loss 0.000515668, acc 1
2016-09-05T18:58:05.556245: step 19010, loss 0.000589294, acc 1
2016-09-05T18:58:05.781562: step 19011, loss 0.000536735, acc 1
2016-09-05T18:58:05.939208: step 19012, loss 0.00065292, acc 1
2016-09-05T18:58:06.148232: step 19013, loss 0.000614216, acc 1
2016-09-05T18:58:06.379460: step 19014, loss 0.000532044, acc 1
2016-09-05T18:58:06.612368: step 19015, loss 0.00073027, acc 1
2016-09-05T18:58:06.820741: step 19016, loss 0.000534406, acc 1
2016-09-05T18:58:07.020296: step 19017, loss 0.000579944, acc 1
2016-09-05T18:58:07.227826: step 19018, loss 0.000540268, acc 1
2016-09-05T18:58:07.439053: step 19019, loss 0.000523573, acc 1
2016-09-05T18:58:07.679237: step 19020, loss 0.00057132, acc 1
2016-09-05T18:58:07.892520: step 19021, loss 0.000549976, acc 1
2016-09-05T18:58:08.125760: step 19022, loss 0.000498857, acc 1
2016-09-05T18:58:08.344694: step 19023, loss 0.000466894, acc 1
2016-09-05T18:58:08.568202: step 19024, loss 0.000580391, acc 1
2016-09-05T18:58:08.791892: step 19025, loss 0.000582187, acc 1
2016-09-05T18:58:09.043238: step 19026, loss 0.000476549, acc 1
2016-09-05T18:58:09.246809: step 19027, loss 0.000467027, acc 1
2016-09-05T18:58:09.448725: step 19028, loss 0.00051878, acc 1
2016-09-05T18:58:09.693091: step 19029, loss 0.000493863, acc 1
2016-09-05T18:58:09.908722: step 19030, loss 0.000465046, acc 1
2016-09-05T18:58:10.150562: step 19031, loss 0.000500069, acc 1
2016-09-05T18:58:10.356869: step 19032, loss 0.00044844, acc 1
2016-09-05T18:58:10.579286: step 19033, loss 0.000466379, acc 1
2016-09-05T18:58:10.778339: step 19034, loss 0.000536766, acc 1
2016-09-05T18:58:10.984989: step 19035, loss 0.000454571, acc 1
2016-09-05T18:58:11.204902: step 19036, loss 0.000452713, acc 1
2016-09-05T18:58:11.429769: step 19037, loss 0.000478721, acc 1
2016-09-05T18:58:11.670025: step 19038, loss 0.000484611, acc 1
2016-09-05T18:58:11.876249: step 19039, loss 0.000595717, acc 1
2016-09-05T18:58:12.092298: step 19040, loss 0.00054596, acc 1
2016-09-05T18:58:12.301810: step 19041, loss 0.000501487, acc 1
2016-09-05T18:58:12.523083: step 19042, loss 0.000625369, acc 1
2016-09-05T18:58:12.738114: step 19043, loss 0.000430059, acc 1
2016-09-05T18:58:12.977801: step 19044, loss 0.00042183, acc 1
2016-09-05T18:58:13.182335: step 19045, loss 0.000862087, acc 1
2016-09-05T18:58:13.387333: step 19046, loss 0.000446129, acc 1
2016-09-05T18:58:13.596889: step 19047, loss 0.000472849, acc 1
2016-09-05T18:58:13.802649: step 19048, loss 0.000443337, acc 1
2016-09-05T18:58:14.011475: step 19049, loss 0.000518403, acc 1
2016-09-05T18:58:14.242504: step 19050, loss 0.000457615, acc 1
2016-09-05T18:58:14.479137: step 19051, loss 0.000571678, acc 1
2016-09-05T18:58:14.698986: step 19052, loss 0.000427186, acc 1
2016-09-05T18:58:14.915345: step 19053, loss 0.00069506, acc 1
2016-09-05T18:58:15.118494: step 19054, loss 0.000554889, acc 1
2016-09-05T18:58:15.349485: step 19055, loss 0.000676162, acc 1
2016-09-05T18:58:15.594679: step 19056, loss 0.000465191, acc 1
2016-09-05T18:58:15.820562: step 19057, loss 0.000436588, acc 1
2016-09-05T18:58:16.045495: step 19058, loss 0.00049115, acc 1
2016-09-05T18:58:16.302369: step 19059, loss 0.000574433, acc 1
2016-09-05T18:58:16.517854: step 19060, loss 0.000536266, acc 1
2016-09-05T18:58:16.725736: step 19061, loss 0.000576591, acc 1
2016-09-05T18:58:16.939902: step 19062, loss 0.00051984, acc 1
2016-09-05T18:58:17.147852: step 19063, loss 0.000421187, acc 1
2016-09-05T18:58:17.369350: step 19064, loss 0.000421238, acc 1
2016-09-05T18:58:17.605279: step 19065, loss 0.000548921, acc 1
2016-09-05T18:58:17.826176: step 19066, loss 0.000479412, acc 1
2016-09-05T18:58:18.038596: step 19067, loss 0.000477306, acc 1
2016-09-05T18:58:18.261744: step 19068, loss 0.000498882, acc 1
2016-09-05T18:58:18.503895: step 19069, loss 0.000450417, acc 1
2016-09-05T18:58:18.705244: step 19070, loss 0.000525783, acc 1
2016-09-05T18:58:18.940303: step 19071, loss 0.000567788, acc 1
2016-09-05T18:58:19.155314: step 19072, loss 0.000429088, acc 1
2016-09-05T18:58:19.370796: step 19073, loss 0.000502796, acc 1
2016-09-05T18:58:19.586716: step 19074, loss 0.000568214, acc 1
2016-09-05T18:58:19.836721: step 19075, loss 0.000456263, acc 1
2016-09-05T18:58:20.038401: step 19076, loss 0.000548758, acc 1
2016-09-05T18:58:20.254375: step 19077, loss 0.000459116, acc 1
2016-09-05T18:58:20.457628: step 19078, loss 0.000454741, acc 1
2016-09-05T18:58:20.685800: step 19079, loss 0.000455314, acc 1
2016-09-05T18:58:20.914431: step 19080, loss 0.000436412, acc 1
2016-09-05T18:58:21.150955: step 19081, loss 0.000524132, acc 1
2016-09-05T18:58:21.368723: step 19082, loss 0.00068323, acc 1
2016-09-05T18:58:21.572912: step 19083, loss 0.000482275, acc 1
2016-09-05T18:58:21.792866: step 19084, loss 0.000465315, acc 1
2016-09-05T18:58:22.009892: step 19085, loss 0.000455136, acc 1
2016-09-05T18:58:22.221128: step 19086, loss 0.000631264, acc 1
2016-09-05T18:58:22.452945: step 19087, loss 0.000423317, acc 1
2016-09-05T18:58:22.669582: step 19088, loss 0.000604281, acc 1
2016-09-05T18:58:22.873632: step 19089, loss 0.000584934, acc 1
2016-09-05T18:58:23.096211: step 19090, loss 0.000458065, acc 1
2016-09-05T18:58:23.318490: step 19091, loss 0.00041219, acc 1
2016-09-05T18:58:23.530929: step 19092, loss 0.000518199, acc 1
2016-09-05T18:58:23.760572: step 19093, loss 0.000527702, acc 1
2016-09-05T18:58:23.966739: step 19094, loss 0.000938231, acc 1
2016-09-05T18:58:24.175620: step 19095, loss 0.000571195, acc 1
2016-09-05T18:58:24.390478: step 19096, loss 0.000495113, acc 1
2016-09-05T18:58:24.612294: step 19097, loss 0.000429011, acc 1
2016-09-05T18:58:24.837894: step 19098, loss 0.000463216, acc 1
2016-09-05T18:58:25.070437: step 19099, loss 0.00042852, acc 1
2016-09-05T18:58:25.306190: step 19100, loss 0.000497966, acc 1

Evaluation:
2016-09-05T18:58:25.897872: step 19100, loss 1.6, acc 0.719

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-19100

2016-09-05T18:58:26.642590: step 19101, loss 0.000550035, acc 1
2016-09-05T18:58:26.852393: step 19102, loss 0.000445899, acc 1
2016-09-05T18:58:27.079181: step 19103, loss 0.000527026, acc 1
2016-09-05T18:58:27.297833: step 19104, loss 0.000428145, acc 1
2016-09-05T18:58:27.528247: step 19105, loss 0.000693961, acc 1
2016-09-05T18:58:27.735162: step 19106, loss 0.000530293, acc 1
2016-09-05T18:58:27.939351: step 19107, loss 0.000584871, acc 1
2016-09-05T18:58:28.165303: step 19108, loss 0.000472154, acc 1
2016-09-05T18:58:28.389585: step 19109, loss 0.000537498, acc 1
2016-09-05T18:58:28.623891: step 19110, loss 0.000423242, acc 1
2016-09-05T18:58:28.821742: step 19111, loss 0.00047678, acc 1
2016-09-05T18:58:29.019603: step 19112, loss 0.0004767, acc 1
2016-09-05T18:58:29.230622: step 19113, loss 0.000443855, acc 1
2016-09-05T18:58:29.450231: step 19114, loss 0.000453434, acc 1
2016-09-05T18:58:29.669301: step 19115, loss 0.00052788, acc 1
2016-09-05T18:58:29.899882: step 19116, loss 0.000433626, acc 1
2016-09-05T18:58:30.115411: step 19117, loss 0.000496649, acc 1
2016-09-05T18:58:30.343670: step 19118, loss 0.000431894, acc 1
2016-09-05T18:58:30.556710: step 19119, loss 0.000415854, acc 1
2016-09-05T18:58:30.813455: step 19120, loss 0.000448144, acc 1
2016-09-05T18:58:31.037393: step 19121, loss 0.000600702, acc 1
2016-09-05T18:58:31.252550: step 19122, loss 0.000565462, acc 1
2016-09-05T18:58:31.465308: step 19123, loss 0.000438719, acc 1
2016-09-05T18:58:31.671280: step 19124, loss 0.000480652, acc 1
2016-09-05T18:58:31.913106: step 19125, loss 0.000522481, acc 1
2016-09-05T18:58:32.126654: step 19126, loss 0.000544167, acc 1
2016-09-05T18:58:32.363359: step 19127, loss 0.000560084, acc 1
2016-09-05T18:58:32.571552: step 19128, loss 0.000479445, acc 1
2016-09-05T18:58:32.794162: step 19129, loss 0.000512905, acc 1
2016-09-05T18:58:33.008791: step 19130, loss 0.000482337, acc 1
2016-09-05T18:58:33.252320: step 19131, loss 0.000898015, acc 1
2016-09-05T18:58:33.471279: step 19132, loss 0.000425641, acc 1
2016-09-05T18:58:33.656448: step 19133, loss 0.000450951, acc 1
2016-09-05T18:58:33.865460: step 19134, loss 0.000496203, acc 1
2016-09-05T18:58:34.085576: step 19135, loss 0.000427007, acc 1
2016-09-05T18:58:34.298359: step 19136, loss 0.00042866, acc 1
2016-09-05T18:58:34.498982: step 19137, loss 0.000480381, acc 1
2016-09-05T18:58:34.709601: step 19138, loss 0.000440072, acc 1
2016-09-05T18:58:34.912365: step 19139, loss 0.000475803, acc 1
2016-09-05T18:58:35.125549: step 19140, loss 0.000428881, acc 1
2016-09-05T18:58:35.355993: step 19141, loss 0.000439314, acc 1
2016-09-05T18:58:35.573425: step 19142, loss 0.000480874, acc 1
2016-09-05T18:58:35.788942: step 19143, loss 0.000511292, acc 1
2016-09-05T18:58:36.001319: step 19144, loss 0.000404787, acc 1
2016-09-05T18:58:36.213634: step 19145, loss 0.000426341, acc 1
2016-09-05T18:58:36.425541: step 19146, loss 0.000443776, acc 1
2016-09-05T18:58:36.649613: step 19147, loss 0.000567337, acc 1
2016-09-05T18:58:36.900440: step 19148, loss 0.000502155, acc 1
2016-09-05T18:58:37.119148: step 19149, loss 0.000461592, acc 1
2016-09-05T18:58:37.329402: step 19150, loss 0.000507603, acc 1
2016-09-05T18:58:37.540883: step 19151, loss 0.000615838, acc 1
2016-09-05T18:58:37.751855: step 19152, loss 0.000445138, acc 1
2016-09-05T18:58:37.975626: step 19153, loss 0.000438066, acc 1
2016-09-05T18:58:38.182705: step 19154, loss 0.000510255, acc 1
2016-09-05T18:58:38.427103: step 19155, loss 0.000629353, acc 1
2016-09-05T18:58:38.631358: step 19156, loss 0.000453301, acc 1
2016-09-05T18:58:38.832782: step 19157, loss 0.000478252, acc 1
2016-09-05T18:58:39.057970: step 19158, loss 0.000432027, acc 1
2016-09-05T18:58:39.329423: step 19159, loss 0.000447603, acc 1
2016-09-05T18:58:39.563325: step 19160, loss 0.000519472, acc 1
2016-09-05T18:58:39.773128: step 19161, loss 0.000765454, acc 1
2016-09-05T18:58:39.983681: step 19162, loss 0.000498454, acc 1
2016-09-05T18:58:40.188991: step 19163, loss 0.000518285, acc 1
2016-09-05T18:58:40.407481: step 19164, loss 0.00062457, acc 1
2016-09-05T18:58:40.633483: step 19165, loss 0.000557491, acc 1
2016-09-05T18:58:40.867590: step 19166, loss 0.000495563, acc 1
2016-09-05T18:58:41.086053: step 19167, loss 0.00041167, acc 1
2016-09-05T18:58:41.288441: step 19168, loss 0.000405161, acc 1
2016-09-05T18:58:41.497693: step 19169, loss 0.000425334, acc 1
2016-09-05T18:58:41.723079: step 19170, loss 0.000531581, acc 1
2016-09-05T18:58:41.935651: step 19171, loss 0.000563194, acc 1
2016-09-05T18:58:42.127529: step 19172, loss 0.000408979, acc 1
2016-09-05T18:58:42.371921: step 19173, loss 0.000537587, acc 1
2016-09-05T18:58:42.589279: step 19174, loss 0.000467668, acc 1
2016-09-05T18:58:42.849393: step 19175, loss 0.000455353, acc 1
2016-09-05T18:58:43.073789: step 19176, loss 0.000536813, acc 1
2016-09-05T18:58:43.291529: step 19177, loss 0.000535747, acc 1
2016-09-05T18:58:43.502707: step 19178, loss 0.000582548, acc 1
2016-09-05T18:58:43.717669: step 19179, loss 0.000531769, acc 1
2016-09-05T18:58:43.936640: step 19180, loss 0.000634225, acc 1
2016-09-05T18:58:44.169403: step 19181, loss 0.000502624, acc 1
2016-09-05T18:58:44.400956: step 19182, loss 0.000433048, acc 1
2016-09-05T18:58:44.612173: step 19183, loss 0.000478643, acc 1
2016-09-05T18:58:44.826172: step 19184, loss 0.0005273, acc 1
2016-09-05T18:58:45.033464: step 19185, loss 0.000513708, acc 1
2016-09-05T18:58:45.273389: step 19186, loss 0.00050977, acc 1
2016-09-05T18:58:45.503150: step 19187, loss 0.000449905, acc 1
2016-09-05T18:58:45.737843: step 19188, loss 0.000548665, acc 1
2016-09-05T18:58:45.955839: step 19189, loss 0.000511757, acc 1
2016-09-05T18:58:46.199084: step 19190, loss 0.000775129, acc 1
2016-09-05T18:58:46.445383: step 19191, loss 0.000589705, acc 1
2016-09-05T18:58:46.643689: step 19192, loss 0.000457236, acc 1
2016-09-05T18:58:46.889451: step 19193, loss 0.000618814, acc 1
2016-09-05T18:58:47.112587: step 19194, loss 0.000641496, acc 1
2016-09-05T18:58:47.327314: step 19195, loss 0.000780022, acc 1
2016-09-05T18:58:47.567356: step 19196, loss 0.000458788, acc 1
2016-09-05T18:58:47.764456: step 19197, loss 0.000743574, acc 1
2016-09-05T18:58:47.999689: step 19198, loss 0.000460615, acc 1
2016-09-05T18:58:48.209421: step 19199, loss 0.00049065, acc 1
2016-09-05T18:58:48.424134: step 19200, loss 0.000561596, acc 1

Evaluation:
2016-09-05T18:58:49.040877: step 19200, loss 1.67762, acc 0.714

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-19200

2016-09-05T18:58:49.803685: step 19201, loss 0.000497753, acc 1
2016-09-05T18:58:50.051127: step 19202, loss 0.00052072, acc 1
2016-09-05T18:58:50.274733: step 19203, loss 0.00046266, acc 1
2016-09-05T18:58:50.490279: step 19204, loss 0.00051436, acc 1
2016-09-05T18:58:50.708597: step 19205, loss 0.000468861, acc 1
2016-09-05T18:58:50.865437: step 19206, loss 0.00051282, acc 1
2016-09-05T18:58:51.085399: step 19207, loss 0.000481692, acc 1
2016-09-05T18:58:51.298125: step 19208, loss 0.000529361, acc 1
2016-09-05T18:58:51.493463: step 19209, loss 0.000554541, acc 1
2016-09-05T18:58:51.713299: step 19210, loss 0.000493243, acc 1
2016-09-05T18:58:51.935868: step 19211, loss 0.000463397, acc 1
2016-09-05T18:58:52.158841: step 19212, loss 0.000503994, acc 1
2016-09-05T18:58:52.386907: step 19213, loss 0.00060027, acc 1
2016-09-05T18:58:52.612431: step 19214, loss 0.000447348, acc 1
2016-09-05T18:58:52.835690: step 19215, loss 0.000427279, acc 1
2016-09-05T18:58:53.069440: step 19216, loss 0.000487014, acc 1
2016-09-05T18:58:53.282203: step 19217, loss 0.000452578, acc 1
2016-09-05T18:58:53.494329: step 19218, loss 0.000527247, acc 1
2016-09-05T18:58:53.709592: step 19219, loss 0.000476881, acc 1
2016-09-05T18:58:53.912298: step 19220, loss 0.000453879, acc 1
2016-09-05T18:58:54.131795: step 19221, loss 0.000460406, acc 1
2016-09-05T18:58:54.339424: step 19222, loss 0.000456055, acc 1
2016-09-05T18:58:54.563513: step 19223, loss 0.000467915, acc 1
2016-09-05T18:58:54.794942: step 19224, loss 0.000599721, acc 1
2016-09-05T18:58:55.015791: step 19225, loss 0.000441771, acc 1
2016-09-05T18:58:55.230546: step 19226, loss 0.000424903, acc 1
2016-09-05T18:58:55.469629: step 19227, loss 0.000476889, acc 1
2016-09-05T18:58:55.694479: step 19228, loss 0.000452862, acc 1
2016-09-05T18:58:55.902542: step 19229, loss 0.000503964, acc 1
2016-09-05T18:58:56.113190: step 19230, loss 0.000456169, acc 1
2016-09-05T18:58:56.309290: step 19231, loss 0.000651777, acc 1
2016-09-05T18:58:56.521930: step 19232, loss 0.000732747, acc 1
2016-09-05T18:58:56.731714: step 19233, loss 0.000490809, acc 1
2016-09-05T18:58:56.938214: step 19234, loss 0.000415762, acc 1
2016-09-05T18:58:57.140453: step 19235, loss 0.000418732, acc 1
2016-09-05T18:58:57.357281: step 19236, loss 0.000695285, acc 1
2016-09-05T18:58:57.558360: step 19237, loss 0.000535278, acc 1
2016-09-05T18:58:57.783050: step 19238, loss 0.000417784, acc 1
2016-09-05T18:58:58.009258: step 19239, loss 0.000515599, acc 1
2016-09-05T18:58:58.230529: step 19240, loss 0.000501694, acc 1
2016-09-05T18:58:58.448622: step 19241, loss 0.000444414, acc 1
2016-09-05T18:58:58.670943: step 19242, loss 0.000495468, acc 1
2016-09-05T18:58:58.898697: step 19243, loss 0.000443159, acc 1
2016-09-05T18:58:59.100778: step 19244, loss 0.000746952, acc 1
2016-09-05T18:58:59.312446: step 19245, loss 0.000505078, acc 1
2016-09-05T18:58:59.513460: step 19246, loss 0.000451382, acc 1
2016-09-05T18:58:59.735610: step 19247, loss 0.00045376, acc 1
2016-09-05T18:58:59.931078: step 19248, loss 0.000450415, acc 1
2016-09-05T18:59:00.151116: step 19249, loss 0.000504871, acc 1
2016-09-05T18:59:00.370494: step 19250, loss 0.000437896, acc 1
2016-09-05T18:59:00.588323: step 19251, loss 0.000426208, acc 1
2016-09-05T18:59:00.804404: step 19252, loss 0.000423221, acc 1
2016-09-05T18:59:01.031861: step 19253, loss 0.000486019, acc 1
2016-09-05T18:59:01.225913: step 19254, loss 0.000513104, acc 1
2016-09-05T18:59:01.439431: step 19255, loss 0.000864565, acc 1
2016-09-05T18:59:01.647629: step 19256, loss 0.000497771, acc 1
2016-09-05T18:59:01.857806: step 19257, loss 0.000424161, acc 1
2016-09-05T18:59:02.062495: step 19258, loss 0.000484926, acc 1
2016-09-05T18:59:02.288649: step 19259, loss 0.000453862, acc 1
2016-09-05T18:59:02.518429: step 19260, loss 0.000443073, acc 1
2016-09-05T18:59:02.757445: step 19261, loss 0.000494005, acc 1
2016-09-05T18:59:02.976704: step 19262, loss 0.000419013, acc 1
2016-09-05T18:59:03.182659: step 19263, loss 0.000829085, acc 1
2016-09-05T18:59:03.410251: step 19264, loss 0.000512364, acc 1
2016-09-05T18:59:03.622623: step 19265, loss 0.000446308, acc 1
2016-09-05T18:59:03.862759: step 19266, loss 0.000506225, acc 1
2016-09-05T18:59:04.071131: step 19267, loss 0.00045258, acc 1
2016-09-05T18:59:04.275693: step 19268, loss 0.000452451, acc 1
2016-09-05T18:59:04.481509: step 19269, loss 0.000428591, acc 1
2016-09-05T18:59:04.703647: step 19270, loss 0.000529375, acc 1
2016-09-05T18:59:04.955022: step 19271, loss 0.000551227, acc 1
2016-09-05T18:59:05.160442: step 19272, loss 0.000417458, acc 1
2016-09-05T18:59:05.377149: step 19273, loss 0.00042837, acc 1
2016-09-05T18:59:05.582871: step 19274, loss 0.000435089, acc 1
2016-09-05T18:59:05.801227: step 19275, loss 0.000428627, acc 1
2016-09-05T18:59:06.005596: step 19276, loss 0.000429329, acc 1
2016-09-05T18:59:06.237485: step 19277, loss 0.00043314, acc 1
2016-09-05T18:59:06.428951: step 19278, loss 0.000458495, acc 1
2016-09-05T18:59:06.639215: step 19279, loss 0.000424937, acc 1
2016-09-05T18:59:06.855275: step 19280, loss 0.000438026, acc 1
2016-09-05T18:59:07.102833: step 19281, loss 0.000404388, acc 1
2016-09-05T18:59:07.312431: step 19282, loss 0.000486527, acc 1
2016-09-05T18:59:07.520480: step 19283, loss 0.000529321, acc 1
2016-09-05T18:59:07.727151: step 19284, loss 0.00046733, acc 1
2016-09-05T18:59:07.940953: step 19285, loss 0.000580778, acc 1
2016-09-05T18:59:08.161458: step 19286, loss 0.000535839, acc 1
2016-09-05T18:59:08.405431: step 19287, loss 0.000451359, acc 1
2016-09-05T18:59:08.646573: step 19288, loss 0.000600297, acc 1
2016-09-05T18:59:08.869095: step 19289, loss 0.000487627, acc 1
2016-09-05T18:59:09.086932: step 19290, loss 0.000553143, acc 1
2016-09-05T18:59:09.336911: step 19291, loss 0.000458498, acc 1
2016-09-05T18:59:09.554616: step 19292, loss 0.000425282, acc 1
2016-09-05T18:59:09.775287: step 19293, loss 0.000415741, acc 1
2016-09-05T18:59:09.989459: step 19294, loss 0.000793783, acc 1
2016-09-05T18:59:10.206211: step 19295, loss 0.000506142, acc 1
2016-09-05T18:59:10.416829: step 19296, loss 0.000502943, acc 1
2016-09-05T18:59:10.645301: step 19297, loss 0.000455057, acc 1
2016-09-05T18:59:10.850753: step 19298, loss 0.00049358, acc 1
2016-09-05T18:59:11.068198: step 19299, loss 0.000419528, acc 1
2016-09-05T18:59:11.284907: step 19300, loss 0.000447618, acc 1

Evaluation:
2016-09-05T18:59:11.883622: step 19300, loss 1.5892, acc 0.711

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-19300

2016-09-05T18:59:12.615911: step 19301, loss 0.000477849, acc 1
2016-09-05T18:59:12.830331: step 19302, loss 0.000478552, acc 1
2016-09-05T18:59:13.067359: step 19303, loss 0.000423766, acc 1
2016-09-05T18:59:13.261395: step 19304, loss 0.000595473, acc 1
2016-09-05T18:59:13.491234: step 19305, loss 0.000676456, acc 1
2016-09-05T18:59:13.692696: step 19306, loss 0.000428813, acc 1
2016-09-05T18:59:13.906920: step 19307, loss 0.000420155, acc 1
2016-09-05T18:59:14.126861: step 19308, loss 0.000599001, acc 1
2016-09-05T18:59:14.349049: step 19309, loss 0.000460751, acc 1
2016-09-05T18:59:14.577377: step 19310, loss 0.000421755, acc 1
2016-09-05T18:59:14.798992: step 19311, loss 0.000439227, acc 1
2016-09-05T18:59:15.013903: step 19312, loss 0.000513325, acc 1
2016-09-05T18:59:15.219314: step 19313, loss 0.000421962, acc 1
2016-09-05T18:59:15.437392: step 19314, loss 0.000420659, acc 1
2016-09-05T18:59:15.666016: step 19315, loss 0.000416678, acc 1
2016-09-05T18:59:15.906498: step 19316, loss 0.00049159, acc 1
2016-09-05T18:59:16.107097: step 19317, loss 0.000430521, acc 1
2016-09-05T18:59:16.310718: step 19318, loss 0.000481317, acc 1
2016-09-05T18:59:16.521255: step 19319, loss 0.000431923, acc 1
2016-09-05T18:59:16.742830: step 19320, loss 0.000553402, acc 1
2016-09-05T18:59:16.967416: step 19321, loss 0.000632391, acc 1
2016-09-05T18:59:17.193414: step 19322, loss 0.000412043, acc 1
2016-09-05T18:59:17.403687: step 19323, loss 0.000482486, acc 1
2016-09-05T18:59:17.610547: step 19324, loss 0.000458141, acc 1
2016-09-05T18:59:17.810334: step 19325, loss 0.000436369, acc 1
2016-09-05T18:59:18.017705: step 19326, loss 0.000513473, acc 1
2016-09-05T18:59:18.214586: step 19327, loss 0.000534182, acc 1
2016-09-05T18:59:18.421009: step 19328, loss 0.000393157, acc 1
2016-09-05T18:59:18.621230: step 19329, loss 0.000435174, acc 1
2016-09-05T18:59:18.833426: step 19330, loss 0.000432556, acc 1
2016-09-05T18:59:19.048595: step 19331, loss 0.000552324, acc 1
2016-09-05T18:59:19.272768: step 19332, loss 0.000464758, acc 1
2016-09-05T18:59:19.491282: step 19333, loss 0.000434303, acc 1
2016-09-05T18:59:19.715577: step 19334, loss 0.000443295, acc 1
2016-09-05T18:59:19.916320: step 19335, loss 0.000673571, acc 1
2016-09-05T18:59:20.131947: step 19336, loss 0.000810001, acc 1
2016-09-05T18:59:20.341680: step 19337, loss 0.000442993, acc 1
2016-09-05T18:59:20.565220: step 19338, loss 0.00044009, acc 1
2016-09-05T18:59:20.796384: step 19339, loss 0.000696755, acc 1
2016-09-05T18:59:21.025445: step 19340, loss 0.000441876, acc 1
2016-09-05T18:59:21.240469: step 19341, loss 0.000486706, acc 1
2016-09-05T18:59:21.439590: step 19342, loss 0.000586053, acc 1
2016-09-05T18:59:21.665834: step 19343, loss 0.000452101, acc 1
2016-09-05T18:59:21.894022: step 19344, loss 0.000456998, acc 1
2016-09-05T18:59:22.133469: step 19345, loss 0.000532162, acc 1
2016-09-05T18:59:22.350358: step 19346, loss 0.000465264, acc 1
2016-09-05T18:59:22.560762: step 19347, loss 0.000549912, acc 1
2016-09-05T18:59:22.764855: step 19348, loss 0.000561401, acc 1
2016-09-05T18:59:22.970631: step 19349, loss 0.000465383, acc 1
2016-09-05T18:59:23.180229: step 19350, loss 0.000512108, acc 1
2016-09-05T18:59:23.377228: step 19351, loss 0.000430138, acc 1
2016-09-05T18:59:23.582405: step 19352, loss 0.000427902, acc 1
2016-09-05T18:59:23.801543: step 19353, loss 0.000413677, acc 1
2016-09-05T18:59:24.030718: step 19354, loss 0.000521977, acc 1
2016-09-05T18:59:24.253443: step 19355, loss 0.000495099, acc 1
2016-09-05T18:59:24.486949: step 19356, loss 0.00043278, acc 1
2016-09-05T18:59:24.699413: step 19357, loss 0.000472553, acc 1
2016-09-05T18:59:24.911507: step 19358, loss 0.00041458, acc 1
2016-09-05T18:59:25.124139: step 19359, loss 0.000672185, acc 1
2016-09-05T18:59:25.342878: step 19360, loss 0.00063886, acc 1
2016-09-05T18:59:25.585599: step 19361, loss 0.000508974, acc 1
2016-09-05T18:59:25.792487: step 19362, loss 0.000506755, acc 1
2016-09-05T18:59:26.001563: step 19363, loss 0.000565999, acc 1
2016-09-05T18:59:26.218031: step 19364, loss 0.000436429, acc 1
2016-09-05T18:59:26.435510: step 19365, loss 0.000509732, acc 1
2016-09-05T18:59:26.633214: step 19366, loss 0.000430936, acc 1
2016-09-05T18:59:26.842300: step 19367, loss 0.000471452, acc 1
2016-09-05T18:59:27.043410: step 19368, loss 0.000438188, acc 1
2016-09-05T18:59:27.258109: step 19369, loss 0.000417625, acc 1
2016-09-05T18:59:27.500958: step 19370, loss 0.00051301, acc 1
2016-09-05T18:59:27.722120: step 19371, loss 0.000525635, acc 1
2016-09-05T18:59:27.918680: step 19372, loss 0.000415938, acc 1
2016-09-05T18:59:28.131295: step 19373, loss 0.000433681, acc 1
2016-09-05T18:59:28.330813: step 19374, loss 0.000535789, acc 1
2016-09-05T18:59:28.554714: step 19375, loss 0.000427857, acc 1
2016-09-05T18:59:28.797450: step 19376, loss 0.000856436, acc 1
2016-09-05T18:59:29.047757: step 19377, loss 0.0024283, acc 1
2016-09-05T18:59:29.326228: step 19378, loss 0.000650265, acc 1
2016-09-05T18:59:29.527615: step 19379, loss 0.000489478, acc 1
2016-09-05T18:59:29.730620: step 19380, loss 0.000524541, acc 1
2016-09-05T18:59:29.949093: step 19381, loss 0.000515246, acc 1
2016-09-05T18:59:30.197871: step 19382, loss 0.000551853, acc 1
2016-09-05T18:59:30.416576: step 19383, loss 0.000543001, acc 1
2016-09-05T18:59:30.638089: step 19384, loss 0.000579161, acc 1
2016-09-05T18:59:30.848644: step 19385, loss 0.000541583, acc 1
2016-09-05T18:59:31.064896: step 19386, loss 0.00054843, acc 1
2016-09-05T18:59:31.270280: step 19387, loss 0.00060805, acc 1
2016-09-05T18:59:31.481513: step 19388, loss 0.000654588, acc 1
2016-09-05T18:59:31.705292: step 19389, loss 0.000563788, acc 1
2016-09-05T18:59:31.929419: step 19390, loss 0.000594651, acc 1
2016-09-05T18:59:32.159331: step 19391, loss 0.000531749, acc 1
2016-09-05T18:59:32.361717: step 19392, loss 0.00054172, acc 1
2016-09-05T18:59:32.572501: step 19393, loss 0.000679105, acc 1
2016-09-05T18:59:32.787154: step 19394, loss 0.000628558, acc 1
2016-09-05T18:59:33.015672: step 19395, loss 0.000507174, acc 1
2016-09-05T18:59:33.245422: step 19396, loss 0.000754568, acc 1
2016-09-05T18:59:33.472786: step 19397, loss 0.000549088, acc 1
2016-09-05T18:59:33.692043: step 19398, loss 0.000502801, acc 1
2016-09-05T18:59:33.909708: step 19399, loss 0.00050953, acc 1
2016-09-05T18:59:34.074015: step 19400, loss 0.000517205, acc 1

Evaluation:
2016-09-05T18:59:34.706265: step 19400, loss 1.72983, acc 0.709

Saved model checkpoint to /home/cil/lstm-context-embeddings/runs/1473068725/checkpoints/model-19400

